{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Define the directory and file naming pattern\n",
    "directory = '/Users/zxgan/FYP_Kubernetes/Dataset/'\n",
    "file_prefix = 'node_node_'\n",
    "file_suffix = '_dataset.csv'\n",
    "num_files = 50\n",
    "\n",
    "# Initialize a list to store dataset shapes for each file\n",
    "dataset_shapes = []\n",
    "\n",
    "# Iterate over all files\n",
    "for i in range(num_files):\n",
    "    file_path = f\"{directory}{file_prefix}{i}{file_suffix}\"\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    data.drop(columns=['timestamp', 'pod_status_Pending', 'pod_status_Running', \n",
    "                       'pod_status_Succeeded', 'pod_status_Failed', 'pod_status_Unknown'], inplace=True)\n",
    "    \n",
    "    # Select numeric columns only\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = train_test_split(numeric_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Store the shapes of the datasets\n",
    "    dataset_shapes.append({\n",
    "        \"File\": f\"node_node_{i}\",\n",
    "        \"Training Set Features\": X_train.shape[0],\n",
    "        \"Testing Set Features\": X_test.shape[0],\n",
    "        \"Total Features\": numeric_data.shape[1]\n",
    "    })\n",
    "    \n",
    "    # Display the shapes for the current file\n",
    "    print(f\"Training Set Features for file {i}: {X_train.shape}\")\n",
    "    print(f\"Testing Set Features for file {i}: {X_test.shape}\")\n",
    "\n",
    "# Create a DataFrame for summary of dataset shapes\n",
    "shapes_df = pd.DataFrame(dataset_shapes)\n",
    "\n",
    "# Display the summary in an interactive table\n",
    "fig_table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(shapes_df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[shapes_df[col] for col in shapes_df.columns],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "fig_table.update_layout(title=\"Dataset Shapes Summary\", title_x=0.5)\n",
    "fig_table.show()\n",
    "\n",
    "# Save the summary as a CSV file for further analysis\n",
    "summary_csv_path = f\"/Users/zxgan/FYP_Kubernetes/Anomaly_Detection_summary.csv\"\n",
    "shapes_df.to_csv(summary_csv_path, index=False)\n",
    "print(f\"Summary saved to: {summary_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define a custom scoring function\n",
    "def custom_scorer(estimator, X):\n",
    "    y_pred = estimator.fit_predict(X)\n",
    "    return f1_score(np.ones(len(y_pred)), np.where(y_pred == -1, 0, 1))\n",
    "\n",
    "# Define parameter grid for fine-tuning Isolation Forest\n",
    "param_grid_if = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': ['auto', 0.8, 0.5],\n",
    "    'contamination': [0.05, 0.1, 0.2],\n",
    "    'max_features': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "# Directory and file naming\n",
    "directory = '/Users/zxgan/FYP_Kubernetes/Dataset/'\n",
    "file_prefix = 'node_node_'\n",
    "file_suffix = '_dataset.csv'\n",
    "num_files = 50\n",
    "\n",
    "# Initialize a summary list\n",
    "accuracy_summary = []\n",
    "\n",
    "# Process each file\n",
    "for i in range(num_files):\n",
    "    file_path = f\"{directory}{file_prefix}{i}{file_suffix}\"\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    data.drop(columns=['timestamp', 'pod_status_Pending', 'pod_status_Running', \n",
    "                       'pod_status_Succeeded', 'pod_status_Failed', 'pod_status_Unknown'], inplace=True)\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Split the data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test = train_test_split(numeric_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize Isolation Forest\n",
    "    base_model_if = IsolationForest(random_state=42)\n",
    "    grid_search_if = GridSearchCV(\n",
    "        estimator=base_model_if,\n",
    "        param_grid=param_grid_if,\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        scoring=make_scorer(custom_scorer)\n",
    "    )\n",
    "    grid_search_if.fit(X_train)\n",
    "    \n",
    "    # Get the best parameters and model\n",
    "    best_params_if = grid_search_if.best_params_\n",
    "    best_if = grid_search_if.best_estimator_\n",
    "    y_test_pred_if = np.where(best_if.predict(X_test) == -1, 0, 1)\n",
    "    accuracy_if = accuracy_score(np.ones(len(y_test_pred_if)), y_test_pred_if)\n",
    "    \n",
    "    # Save the Isolation Forest model\n",
    "    model_filename = f\"Isolation_Forest_Model_Node_{i}.pkl\"\n",
    "    with open(model_filename, \"wb\") as f:\n",
    "        pickle.dump(best_if, f)\n",
    "    print(f\"Model saved: {model_filename}\")\n",
    "    \n",
    "    # Collect accuracy\n",
    "    accuracy_summary.append({\n",
    "        \"Node\": f\"Node_{i}\",\n",
    "        \"Best Parameters\": best_params_if,\n",
    "        \"Accuracy\": accuracy_if\n",
    "    })\n",
    "\n",
    "# Final summary of accuracy across all datasets\n",
    "accuracy_df = pd.DataFrame(accuracy_summary)\n",
    "\n",
    "# Display the accuracy summary\n",
    "fig_summary = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(accuracy_df.columns), fill_color='paleturquoise', align='left'),\n",
    "    cells=dict(values=[accuracy_df[col] for col in accuracy_df.columns], fill_color='lavender', align='left'))\n",
    "])\n",
    "fig_summary.update_layout(title=\"Isolation Forest Accuracy Summary Across Nodes\", title_x=0.5)\n",
    "fig_summary.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, make_scorer\n",
    "import pickle\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Parameter grid for fine-tuning One-Class SVM\n",
    "param_grid_svm = {\n",
    "    'nu': [0.01, 0.05],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Custom scoring function\n",
    "def custom_scorer(estimator, X):\n",
    "    y_pred = estimator.fit_predict(X)\n",
    "    return f1_score(np.ones(len(y_pred)), np.where(y_pred == -1, 0, 1))\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=OneClassSVM(),\n",
    "    param_grid=param_grid_svm,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    scoring=make_scorer(custom_scorer)\n",
    ")\n",
    "grid_search_svm.fit(X_train)\n",
    "\n",
    "# Retrieve the best model and its parameters\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "print(\"One-Class SVM - Best Parameters:\", best_params_svm)\n",
    "\n",
    "# Refit the best model on the full training set\n",
    "best_svm.fit(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary format (0 for anomaly, 1 for normal)\n",
    "y_test_binary = np.where(y_test_pred == -1, 0, 1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(np.ones(len(y_test_binary)), y_test_binary)\n",
    "print(\"One-Class SVM - Accuracy:\", accuracy_svm)\n",
    "\n",
    "# Save the best model\n",
    "with open(\"best_one_class_svm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_svm, f)\n",
    "\n",
    "# Classification report\n",
    "classification_rep = classification_report(\n",
    "    np.ones(len(y_test_binary)),\n",
    "    y_test_binary,\n",
    "    labels=[0, 1],\n",
    "    target_names=[\"Anomaly\", \"Normal\"],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Extract precision, recall, and F1-score\n",
    "classification_results = pd.DataFrame(classification_rep).T\n",
    "\n",
    "# Accuracy summary\n",
    "accuracy_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"],\n",
    "    \"Value\": [\n",
    "        accuracy_svm,\n",
    "        classification_results.loc[\"Normal\"][\"precision\"],\n",
    "        classification_results.loc[\"Normal\"][\"recall\"],\n",
    "        classification_results.loc[\"Normal\"][\"f1-score\"]\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display results in an interactive table using Plotly\n",
    "fig_accuracy = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(accuracy_summary.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[accuracy_summary[\"Metric\"], accuracy_summary[\"Value\"]],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig_accuracy.update_layout(title=\"One-Class SVM Accuracy Summary\", title_x=0.5)\n",
    "fig_accuracy.show()\n",
    "\n",
    "# Model selection summary\n",
    "model_selection = pd.DataFrame({\n",
    "    \"Model\": [\"One-Class SVM\"],\n",
    "    \"Best Parameters\": [str(best_params_svm)],\n",
    "    \"Accuracy\": [accuracy_svm]\n",
    "})\n",
    "\n",
    "fig_model = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(model_selection.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[model_selection[\"Model\"], model_selection[\"Best Parameters\"], model_selection[\"Accuracy\"]],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig_model.update_layout(title=\"Model Selection Results\", title_x=0.5)\n",
    "fig_model.show()\n",
    "\n",
    "# Count anomalies detected\n",
    "num_anomalies = (y_test_binary == 0).sum()\n",
    "print(f\"Number of anomalies detected: {num_anomalies}\")\n",
    "\n",
    "# Scatter plot for anomalies visualization\n",
    "for feature in numeric_data.columns:\n",
    "    fig_scatter = go.Figure()\n",
    "\n",
    "    normal_data = X_test[y_test_pred == 1]\n",
    "    anomaly_data = X_test[y_test_pred == -1]\n",
    "\n",
    "    fig_scatter.add_trace(go.Scatter(\n",
    "        x=list(range(len(normal_data[feature]))),\n",
    "        y=normal_data[feature],\n",
    "        mode='markers',\n",
    "        marker=dict(color='blue'),\n",
    "        name='Normal Data'\n",
    "    ))\n",
    "\n",
    "    fig_scatter.add_trace(go.Scatter(\n",
    "        x=list(range(len(anomaly_data[feature]))),\n",
    "        y=anomaly_data[feature],\n",
    "        mode='markers',\n",
    "        marker=dict(color='red'),\n",
    "        name='Anomalies'\n",
    "    ))\n",
    "\n",
    "    fig_scatter.update_layout(\n",
    "        title=f\"Anomaly Detection Scatter Plot for {feature}\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=feature,\n",
    "        legend_title=\"Legend\"\n",
    "    )\n",
    "    fig_scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure input data is numeric\n",
    "example_input = X_test.iloc[0:5].select_dtypes(include=[np.number])\n",
    "print(\"Example Input (Numeric Only):\")\n",
    "print(example_input)\n",
    "\n",
    "# Get predictions for each model\n",
    "isolation_forest_output = best_if.predict(example_input)\n",
    "one_class_svm_output = best_svm.predict(example_input)\n",
    "ae_predictions = best_autoencoder.predict(example_input)\n",
    "\n",
    "# Calculate per-feature anomaly scores for the autoencoder\n",
    "ae_feature_anomaly_scores = np.power(ae_predictions - example_input.values, 2)\n",
    "\n",
    "# Average anomaly score across features\n",
    "ae_loss = np.mean(ae_feature_anomaly_scores, axis=1)\n",
    "\n",
    "# Prepare results in a DataFrame\n",
    "example_results = pd.DataFrame({\n",
    "    \"Index\": example_input.index,\n",
    "    \"Isolation Forest\": isolation_forest_output,\n",
    "    \"One-Class SVM\": one_class_svm_output,\n",
    "    \"Autoencoder Loss\": ae_loss\n",
    "})\n",
    "\n",
    "# Convert model outputs for better readability\n",
    "example_results[\"Isolation Forest\"] = example_results[\"Isolation Forest\"].replace({1: \"Normal\", -1: \"Anomaly\"})\n",
    "example_results[\"One-Class SVM\"] = example_results[\"One-Class SVM\"].replace({1: \"Normal\", -1: \"Anomaly\"})\n",
    "\n",
    "# Identify anomalous features for the autoencoder\n",
    "anomalous_features = []\n",
    "for row_idx, scores in enumerate(ae_feature_anomaly_scores):\n",
    "    feature_indices = np.where(scores > np.percentile(scores, 95))[0]  # Features with top 5% anomaly scores\n",
    "    feature_names = example_input.columns[feature_indices]\n",
    "    anomalous_features.append(\", \".join(feature_names))\n",
    "\n",
    "example_results[\"Anomalous Features (AE)\"] = anomalous_features\n",
    "\n",
    "# Display example inputs and outputs in an interactive table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"Feature \" + str(i) for i in range(1, example_input.shape[1] + 1)],\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[example_input[col].tolist() for col in example_input.columns],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "fig.update_layout(title=\"Example Input Features\", title_x=0.5)\n",
    "fig.show()\n",
    "\n",
    "fig_results = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(example_results.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[example_results[col] for col in example_results.columns],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "fig_results.update_layout(title=\"Model Outputs and Anomalous Features\", title_x=0.5)\n",
    "fig_results.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
