{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_0_dataset.csv\n",
      "Node 0 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Epoch 1/100\n",
      "17/17 - 2s - loss: 1.6350 - accuracy: 0.1955 - val_loss: 1.6349 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 2s/epoch - 140ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.1729 - val_loss: 1.6346 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6346 - accuracy: 0.1955 - val_loss: 1.6343 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6351 - accuracy: 0.2030 - val_loss: 1.6340 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6330 - accuracy: 0.2143 - val_loss: 1.6338 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6333 - accuracy: 0.2030 - val_loss: 1.6335 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6327 - accuracy: 0.2293 - val_loss: 1.6333 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6320 - accuracy: 0.2180 - val_loss: 1.6331 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6315 - accuracy: 0.2105 - val_loss: 1.6328 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6303 - accuracy: 0.2331 - val_loss: 1.6327 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6322 - accuracy: 0.2105 - val_loss: 1.6324 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6309 - accuracy: 0.1955 - val_loss: 1.6321 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6320 - accuracy: 0.2143 - val_loss: 1.6319 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2406 - val_loss: 1.6316 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6303 - accuracy: 0.2180 - val_loss: 1.6315 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6296 - accuracy: 0.1917 - val_loss: 1.6312 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6300 - accuracy: 0.2481 - val_loss: 1.6310 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6287 - accuracy: 0.2068 - val_loss: 1.6308 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6288 - accuracy: 0.2218 - val_loss: 1.6308 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6300 - accuracy: 0.2368 - val_loss: 1.6305 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6268 - accuracy: 0.2481 - val_loss: 1.6304 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6292 - accuracy: 0.1880 - val_loss: 1.6302 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6280 - accuracy: 0.2256 - val_loss: 1.6300 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6282 - accuracy: 0.2406 - val_loss: 1.6299 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6263 - accuracy: 0.2143 - val_loss: 1.6296 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6278 - accuracy: 0.2368 - val_loss: 1.6295 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6257 - accuracy: 0.2406 - val_loss: 1.6293 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6250 - accuracy: 0.2406 - val_loss: 1.6293 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6254 - accuracy: 0.2143 - val_loss: 1.6291 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6272 - accuracy: 0.2444 - val_loss: 1.6290 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6257 - accuracy: 0.2594 - val_loss: 1.6288 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6244 - accuracy: 0.2406 - val_loss: 1.6286 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6245 - accuracy: 0.2218 - val_loss: 1.6285 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6245 - accuracy: 0.2180 - val_loss: 1.6283 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2256 - val_loss: 1.6282 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2256 - val_loss: 1.6280 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2293 - val_loss: 1.6278 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6218 - accuracy: 0.2481 - val_loss: 1.6278 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6228 - accuracy: 0.2368 - val_loss: 1.6277 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6240 - accuracy: 0.2481 - val_loss: 1.6275 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6208 - accuracy: 0.2632 - val_loss: 1.6274 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6242 - accuracy: 0.2180 - val_loss: 1.6272 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2256 - val_loss: 1.6273 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6234 - accuracy: 0.2444 - val_loss: 1.6273 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2519 - val_loss: 1.6272 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6215 - accuracy: 0.2519 - val_loss: 1.6272 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2143 - val_loss: 1.6272 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2519 - val_loss: 1.6271 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6202 - accuracy: 0.2519 - val_loss: 1.6272 - val_accuracy: 0.1940 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2331 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 2.5000e-05 - 53ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.6178 - accuracy: 0.2632 - val_loss: 1.6271 - val_accuracy: 0.1940 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6218 - accuracy: 0.2218 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2500e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6208 - accuracy: 0.2143 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2500e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6198 - accuracy: 0.2331 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "17/17 - 0s - loss: 1.6196 - accuracy: 0.2707 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6209 - accuracy: 0.2105 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.2500e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6189 - accuracy: 0.2632 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.2500e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "17/17 - 0s - loss: 1.6179 - accuracy: 0.2744 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.2500e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2406 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6212 - accuracy: 0.2444 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2368 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.1250e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6213 - accuracy: 0.2519 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.5625e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2068 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.5625e-06 - 67ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "17/17 - 0s - loss: 1.6213 - accuracy: 0.2368 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.5625e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6187 - accuracy: 0.2519 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 7.8125e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2669 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 7.8125e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "17/17 - 0s - loss: 1.6190 - accuracy: 0.2632 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 7.8125e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6227 - accuracy: 0.2293 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.9062e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6236 - accuracy: 0.2218 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.9062e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2444 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 3.9062e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6205 - accuracy: 0.2368 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.9531e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2256 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.9531e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "17/17 - 0s - loss: 1.6212 - accuracy: 0.2180 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.9531e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6203 - accuracy: 0.2707 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 9.7656e-08 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6187 - accuracy: 0.2556 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 9.7656e-08 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2481 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 9.7656e-08 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6191 - accuracy: 0.2406 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 4.8828e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6202 - accuracy: 0.2368 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 4.8828e-08 - 43ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "17/17 - 0s - loss: 1.6182 - accuracy: 0.1992 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 4.8828e-08 - 43ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6184 - accuracy: 0.2932 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 2.4414e-08 - 43ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6181 - accuracy: 0.2293 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 2.4414e-08 - 44ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "17/17 - 0s - loss: 1.6186 - accuracy: 0.2481 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 2.4414e-08 - 43ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2331 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2207e-08 - 44ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6207 - accuracy: 0.2030 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2207e-08 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "17/17 - 0s - loss: 1.6209 - accuracy: 0.1992 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 1.2207e-08 - 45ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6207 - accuracy: 0.2143 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.1035e-09 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6187 - accuracy: 0.2707 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.1035e-09 - 44ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "17/17 - 0s - loss: 1.6196 - accuracy: 0.2519 - val_loss: 1.6271 - val_accuracy: 0.1791 - lr: 6.1035e-09 - 47ms/epoch - 3ms/step\n",
      "Node 0 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 2s - loss: 1.6366 - accuracy: 0.2180 - val_loss: 1.6345 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 2s/epoch - 259ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6353 - accuracy: 0.2143 - val_loss: 1.6344 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6348 - accuracy: 0.2180 - val_loss: 1.6341 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6333 - accuracy: 0.2406 - val_loss: 1.6338 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6349 - accuracy: 0.2368 - val_loss: 1.6337 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6350 - accuracy: 0.2143 - val_loss: 1.6336 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6340 - accuracy: 0.2030 - val_loss: 1.6334 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6342 - accuracy: 0.2293 - val_loss: 1.6333 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6342 - accuracy: 0.2105 - val_loss: 1.6331 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.1842 - val_loss: 1.6329 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.2218 - val_loss: 1.6327 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6348 - accuracy: 0.2143 - val_loss: 1.6325 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2368 - val_loss: 1.6323 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6324 - accuracy: 0.2105 - val_loss: 1.6322 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6322 - accuracy: 0.2256 - val_loss: 1.6321 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.2143 - val_loss: 1.6320 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.2293 - val_loss: 1.6318 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2256 - val_loss: 1.6316 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6324 - accuracy: 0.2143 - val_loss: 1.6316 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6296 - accuracy: 0.2406 - val_loss: 1.6315 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2368 - val_loss: 1.6314 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2218 - val_loss: 1.6313 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.2143 - val_loss: 1.6312 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6308 - accuracy: 0.2068 - val_loss: 1.6311 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.1880 - val_loss: 1.6310 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6284 - accuracy: 0.2519 - val_loss: 1.6308 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2293 - val_loss: 1.6306 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2293 - val_loss: 1.6305 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.2105 - val_loss: 1.6304 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.1880 - val_loss: 1.6302 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6286 - accuracy: 0.2218 - val_loss: 1.6301 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6298 - accuracy: 0.2180 - val_loss: 1.6300 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6258 - accuracy: 0.2406 - val_loss: 1.6298 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2068 - val_loss: 1.6296 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2143 - val_loss: 1.6295 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.1992 - val_loss: 1.6293 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.1917 - val_loss: 1.6292 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2368 - val_loss: 1.6290 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2406 - val_loss: 1.6289 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6245 - accuracy: 0.2256 - val_loss: 1.6287 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.2068 - val_loss: 1.6285 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6261 - accuracy: 0.2331 - val_loss: 1.6285 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6234 - accuracy: 0.1992 - val_loss: 1.6284 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2256 - val_loss: 1.6284 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.1955 - val_loss: 1.6283 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6240 - accuracy: 0.2256 - val_loss: 1.6282 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2256 - val_loss: 1.6281 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6236 - accuracy: 0.2105 - val_loss: 1.6280 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6226 - accuracy: 0.2256 - val_loss: 1.6279 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2180 - val_loss: 1.6278 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2143 - val_loss: 1.6277 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2331 - val_loss: 1.6276 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6244 - accuracy: 0.2256 - val_loss: 1.6274 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2030 - val_loss: 1.6273 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2180 - val_loss: 1.6272 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6249 - accuracy: 0.2293 - val_loss: 1.6271 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6187 - accuracy: 0.2556 - val_loss: 1.6270 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2030 - val_loss: 1.6269 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.1955 - val_loss: 1.6268 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2256 - val_loss: 1.6267 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6217 - accuracy: 0.2293 - val_loss: 1.6267 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2218 - val_loss: 1.6266 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2519 - val_loss: 1.6265 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.2293 - val_loss: 1.6264 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.1955 - val_loss: 1.6264 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6234 - accuracy: 0.2481 - val_loss: 1.6263 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6178 - accuracy: 0.2744 - val_loss: 1.6262 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6201 - accuracy: 0.2256 - val_loss: 1.6261 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6210 - accuracy: 0.2406 - val_loss: 1.6260 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6202 - accuracy: 0.2256 - val_loss: 1.6260 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6163 - accuracy: 0.2519 - val_loss: 1.6258 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6171 - accuracy: 0.2406 - val_loss: 1.6257 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6243 - accuracy: 0.2143 - val_loss: 1.6255 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6202 - accuracy: 0.2105 - val_loss: 1.6255 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2256 - val_loss: 1.6254 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6204 - accuracy: 0.2406 - val_loss: 1.6254 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.2256 - val_loss: 1.6254 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6217 - accuracy: 0.2256 - val_loss: 1.6253 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6151 - accuracy: 0.2218 - val_loss: 1.6253 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6197 - accuracy: 0.2481 - val_loss: 1.6253 - val_accuracy: 0.2239 - lr: 5.0000e-05 - 29ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2218 - val_loss: 1.6252 - val_accuracy: 0.2239 - lr: 5.0000e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6178 - accuracy: 0.2368 - val_loss: 1.6252 - val_accuracy: 0.2239 - lr: 5.0000e-05 - 30ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "9/9 - 0s - loss: 1.6197 - accuracy: 0.2406 - val_loss: 1.6252 - val_accuracy: 0.2239 - lr: 5.0000e-05 - 30ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6191 - accuracy: 0.2143 - val_loss: 1.6252 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 30ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6229 - accuracy: 0.2331 - val_loss: 1.6252 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6158 - accuracy: 0.2030 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 30ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6206 - accuracy: 0.2068 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2293 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 29ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2368 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 2.5000e-05 - 29ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6194 - accuracy: 0.2256 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 1.2500e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6189 - accuracy: 0.1955 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 1.2500e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "9/9 - 0s - loss: 1.6143 - accuracy: 0.2519 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 1.2500e-05 - 29ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2331 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 6.2500e-06 - 29ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6197 - accuracy: 0.2218 - val_loss: 1.6251 - val_accuracy: 0.2239 - lr: 6.2500e-06 - 29ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2481 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 6.2500e-06 - 30ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2143 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 3.1250e-06 - 29ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6185 - accuracy: 0.2293 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 3.1250e-06 - 29ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "9/9 - 0s - loss: 1.6183 - accuracy: 0.2331 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 3.1250e-06 - 29ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6177 - accuracy: 0.1842 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 1.5625e-06 - 30ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2180 - val_loss: 1.6250 - val_accuracy: 0.2239 - lr: 1.5625e-06 - 28ms/epoch - 3ms/step\n",
      "Node 0 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 2s - loss: 1.6601 - accuracy: 0.1842 - val_loss: 1.6596 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 2s/epoch - 137ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6586 - accuracy: 0.2218 - val_loss: 1.6589 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6580 - accuracy: 0.2143 - val_loss: 1.6580 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6560 - accuracy: 0.1955 - val_loss: 1.6572 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6566 - accuracy: 0.1880 - val_loss: 1.6564 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6552 - accuracy: 0.2030 - val_loss: 1.6555 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 57ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6535 - accuracy: 0.2293 - val_loss: 1.6547 - val_accuracy: 0.2687 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6546 - accuracy: 0.1729 - val_loss: 1.6540 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6522 - accuracy: 0.2143 - val_loss: 1.6533 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6509 - accuracy: 0.2180 - val_loss: 1.6525 - val_accuracy: 0.2537 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6503 - accuracy: 0.2180 - val_loss: 1.6518 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6511 - accuracy: 0.2030 - val_loss: 1.6512 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6481 - accuracy: 0.2444 - val_loss: 1.6506 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6497 - accuracy: 0.1955 - val_loss: 1.6500 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6479 - accuracy: 0.2331 - val_loss: 1.6492 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6462 - accuracy: 0.2519 - val_loss: 1.6484 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6452 - accuracy: 0.2256 - val_loss: 1.6478 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6450 - accuracy: 0.2105 - val_loss: 1.6472 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6454 - accuracy: 0.2368 - val_loss: 1.6465 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6432 - accuracy: 0.2180 - val_loss: 1.6460 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6426 - accuracy: 0.2218 - val_loss: 1.6454 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6428 - accuracy: 0.2180 - val_loss: 1.6450 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6419 - accuracy: 0.2068 - val_loss: 1.6446 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6402 - accuracy: 0.2256 - val_loss: 1.6441 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6406 - accuracy: 0.2594 - val_loss: 1.6436 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6399 - accuracy: 0.2068 - val_loss: 1.6433 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6384 - accuracy: 0.2481 - val_loss: 1.6428 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6376 - accuracy: 0.2368 - val_loss: 1.6423 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6376 - accuracy: 0.2556 - val_loss: 1.6420 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6364 - accuracy: 0.2594 - val_loss: 1.6414 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6362 - accuracy: 0.2368 - val_loss: 1.6410 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6349 - accuracy: 0.2406 - val_loss: 1.6407 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6321 - accuracy: 0.3045 - val_loss: 1.6403 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.2481 - val_loss: 1.6399 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6355 - accuracy: 0.1880 - val_loss: 1.6395 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.2218 - val_loss: 1.6391 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6327 - accuracy: 0.2180 - val_loss: 1.6389 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6335 - accuracy: 0.2444 - val_loss: 1.6386 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6317 - accuracy: 0.2180 - val_loss: 1.6385 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2707 - val_loss: 1.6382 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6303 - accuracy: 0.2556 - val_loss: 1.6380 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2331 - val_loss: 1.6375 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 85ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6312 - accuracy: 0.2180 - val_loss: 1.6372 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6298 - accuracy: 0.2180 - val_loss: 1.6368 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6265 - accuracy: 0.2481 - val_loss: 1.6365 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6295 - accuracy: 0.2594 - val_loss: 1.6363 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6265 - accuracy: 0.2481 - val_loss: 1.6361 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6233 - accuracy: 0.3083 - val_loss: 1.6359 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2218 - val_loss: 1.6358 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6299 - accuracy: 0.2444 - val_loss: 1.6357 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2519 - val_loss: 1.6354 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6261 - accuracy: 0.2744 - val_loss: 1.6350 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6239 - accuracy: 0.2444 - val_loss: 1.6348 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6194 - accuracy: 0.2707 - val_loss: 1.6347 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6191 - accuracy: 0.2707 - val_loss: 1.6345 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2519 - val_loss: 1.6343 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6251 - accuracy: 0.2030 - val_loss: 1.6341 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6161 - accuracy: 0.2970 - val_loss: 1.6340 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6243 - accuracy: 0.2556 - val_loss: 1.6340 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6160 - accuracy: 0.2632 - val_loss: 1.6338 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2744 - val_loss: 1.6339 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6178 - accuracy: 0.2820 - val_loss: 1.6340 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6173 - accuracy: 0.2594 - val_loss: 1.6338 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6192 - accuracy: 0.2444 - val_loss: 1.6337 - val_accuracy: 0.1791 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6213 - accuracy: 0.2030 - val_loss: 1.6337 - val_accuracy: 0.1791 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6177 - accuracy: 0.2669 - val_loss: 1.6336 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2218 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6133 - accuracy: 0.2820 - val_loss: 1.6335 - val_accuracy: 0.1791 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6148 - accuracy: 0.2632 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6141 - accuracy: 0.2331 - val_loss: 1.6335 - val_accuracy: 0.1791 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6116 - accuracy: 0.2594 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6133 - accuracy: 0.2820 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.6143 - accuracy: 0.2669 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6151 - accuracy: 0.2594 - val_loss: 1.6335 - val_accuracy: 0.1940 - lr: 1.2500e-05 - 69ms/epoch - 4ms/step\n",
      "Node 0 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 2s - loss: 1.6593 - accuracy: 0.2030 - val_loss: 1.6593 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 2s/epoch - 272ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6582 - accuracy: 0.2368 - val_loss: 1.6589 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6603 - accuracy: 0.2293 - val_loss: 1.6585 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6569 - accuracy: 0.2481 - val_loss: 1.6581 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6564 - accuracy: 0.2444 - val_loss: 1.6577 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6566 - accuracy: 0.1880 - val_loss: 1.6573 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6552 - accuracy: 0.2594 - val_loss: 1.6569 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6564 - accuracy: 0.1992 - val_loss: 1.6565 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6548 - accuracy: 0.1992 - val_loss: 1.6562 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6536 - accuracy: 0.2444 - val_loss: 1.6558 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6514 - accuracy: 0.2669 - val_loss: 1.6554 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6533 - accuracy: 0.2632 - val_loss: 1.6548 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6522 - accuracy: 0.2331 - val_loss: 1.6545 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6514 - accuracy: 0.2256 - val_loss: 1.6541 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6515 - accuracy: 0.2256 - val_loss: 1.6537 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6511 - accuracy: 0.2068 - val_loss: 1.6534 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6485 - accuracy: 0.2481 - val_loss: 1.6530 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6503 - accuracy: 0.2331 - val_loss: 1.6525 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6508 - accuracy: 0.2368 - val_loss: 1.6523 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6482 - accuracy: 0.2444 - val_loss: 1.6521 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6477 - accuracy: 0.2594 - val_loss: 1.6517 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6489 - accuracy: 0.2368 - val_loss: 1.6514 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6484 - accuracy: 0.2218 - val_loss: 1.6511 - val_accuracy: 0.2388 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6468 - accuracy: 0.2105 - val_loss: 1.6509 - val_accuracy: 0.2239 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6483 - accuracy: 0.2030 - val_loss: 1.6506 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6472 - accuracy: 0.2218 - val_loss: 1.6502 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6456 - accuracy: 0.2256 - val_loss: 1.6500 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6442 - accuracy: 0.2444 - val_loss: 1.6497 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6442 - accuracy: 0.2105 - val_loss: 1.6494 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6434 - accuracy: 0.2406 - val_loss: 1.6492 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6419 - accuracy: 0.2820 - val_loss: 1.6490 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6400 - accuracy: 0.2782 - val_loss: 1.6486 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6416 - accuracy: 0.2481 - val_loss: 1.6482 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6399 - accuracy: 0.2895 - val_loss: 1.6481 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6421 - accuracy: 0.2556 - val_loss: 1.6479 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6420 - accuracy: 0.2180 - val_loss: 1.6476 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6388 - accuracy: 0.2707 - val_loss: 1.6473 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6400 - accuracy: 0.2782 - val_loss: 1.6471 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6372 - accuracy: 0.2368 - val_loss: 1.6468 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6382 - accuracy: 0.2519 - val_loss: 1.6467 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6378 - accuracy: 0.2406 - val_loss: 1.6464 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6395 - accuracy: 0.2105 - val_loss: 1.6463 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6373 - accuracy: 0.2406 - val_loss: 1.6462 - val_accuracy: 0.2090 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6370 - accuracy: 0.2481 - val_loss: 1.6461 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.2632 - val_loss: 1.6460 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6349 - accuracy: 0.2782 - val_loss: 1.6460 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2632 - val_loss: 1.6458 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6347 - accuracy: 0.3008 - val_loss: 1.6455 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6381 - accuracy: 0.2368 - val_loss: 1.6452 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2406 - val_loss: 1.6448 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.2669 - val_loss: 1.6445 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.2406 - val_loss: 1.6443 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6354 - accuracy: 0.2293 - val_loss: 1.6442 - val_accuracy: 0.1940 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6320 - accuracy: 0.2519 - val_loss: 1.6442 - val_accuracy: 0.1791 - lr: 1.0000e-04 - 45ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2519 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2519 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 1.0000e-04 - 64ms/epoch - 7ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6330 - accuracy: 0.2594 - val_loss: 1.6442 - val_accuracy: 0.1493 - lr: 5.0000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6240 - accuracy: 0.2857 - val_loss: 1.6442 - val_accuracy: 0.1493 - lr: 5.0000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.2293 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 5.0000e-05 - 45ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2556 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 2.5000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.2406 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2594 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 2.5000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6262 - accuracy: 0.2632 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2594 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2594 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 1.2500e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2444 - val_loss: 1.6442 - val_accuracy: 0.1642 - lr: 6.2500e-06 - 45ms/epoch - 5ms/step\n",
      "Node 0 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 0 - Best Validation Accuracy: 0.2687\n",
      "Best model saved for Node 0 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_0.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_1_dataset.csv\n",
      "Node 1 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6345 - accuracy: 0.1950 - val_loss: 1.6329 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 3s/epoch - 160ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6380 - accuracy: 0.1701 - val_loss: 1.6325 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6353 - accuracy: 0.2116 - val_loss: 1.6325 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6354 - accuracy: 0.1784 - val_loss: 1.6323 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.1826 - val_loss: 1.6321 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2324 - val_loss: 1.6321 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6354 - accuracy: 0.1909 - val_loss: 1.6322 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6369 - accuracy: 0.1743 - val_loss: 1.6320 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6347 - accuracy: 0.1867 - val_loss: 1.6317 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2282 - val_loss: 1.6316 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2241 - val_loss: 1.6312 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6346 - accuracy: 0.1909 - val_loss: 1.6311 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2116 - val_loss: 1.6311 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2116 - val_loss: 1.6306 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2448 - val_loss: 1.6304 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2324 - val_loss: 1.6303 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.1992 - val_loss: 1.6302 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2241 - val_loss: 1.6300 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2324 - val_loss: 1.6299 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6294 - accuracy: 0.2241 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.2407 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2407 - val_loss: 1.6290 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6343 - accuracy: 0.1992 - val_loss: 1.6289 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2448 - val_loss: 1.6290 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2324 - val_loss: 1.6287 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2573 - val_loss: 1.6285 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2282 - val_loss: 1.6284 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6258 - accuracy: 0.2448 - val_loss: 1.6284 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2116 - val_loss: 1.6281 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2075 - val_loss: 1.6280 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2241 - val_loss: 1.6277 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.2033 - val_loss: 1.6275 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2116 - val_loss: 1.6274 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.1826 - val_loss: 1.6273 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.1909 - val_loss: 1.6272 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2490 - val_loss: 1.6273 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2365 - val_loss: 1.6273 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2531 - val_loss: 1.6275 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.1743 - val_loss: 1.6274 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2241 - val_loss: 1.6273 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.1867 - val_loss: 1.6273 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2531 - val_loss: 1.6272 - val_accuracy: 0.1803 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Node 1 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6368 - accuracy: 0.2241 - val_loss: 1.6361 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 2s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2282 - val_loss: 1.6359 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2116 - val_loss: 1.6358 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6374 - accuracy: 0.1701 - val_loss: 1.6357 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.1452 - val_loss: 1.6355 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2282 - val_loss: 1.6354 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.1743 - val_loss: 1.6352 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2199 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2033 - val_loss: 1.6348 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2116 - val_loss: 1.6346 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.1660 - val_loss: 1.6344 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2158 - val_loss: 1.6341 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.1992 - val_loss: 1.6339 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1992 - val_loss: 1.6336 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2116 - val_loss: 1.6334 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.1992 - val_loss: 1.6333 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2116 - val_loss: 1.6332 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2075 - val_loss: 1.6332 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2324 - val_loss: 1.6331 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.1701 - val_loss: 1.6330 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1992 - val_loss: 1.6329 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2614 - val_loss: 1.6327 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2282 - val_loss: 1.6325 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1867 - val_loss: 1.6324 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2158 - val_loss: 1.6322 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2780 - val_loss: 1.6320 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.1992 - val_loss: 1.6319 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2199 - val_loss: 1.6318 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2490 - val_loss: 1.6317 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2158 - val_loss: 1.6315 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.1743 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.1867 - val_loss: 1.6313 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.1784 - val_loss: 1.6311 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2158 - val_loss: 1.6309 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2365 - val_loss: 1.6308 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2282 - val_loss: 1.6307 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.1992 - val_loss: 1.6307 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.1867 - val_loss: 1.6306 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2407 - val_loss: 1.6304 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2365 - val_loss: 1.6303 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2075 - val_loss: 1.6302 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2614 - val_loss: 1.6300 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.1950 - val_loss: 1.6298 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2656 - val_loss: 1.6297 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2241 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2199 - val_loss: 1.6294 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2407 - val_loss: 1.6293 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2282 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2116 - val_loss: 1.6291 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2241 - val_loss: 1.6290 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2365 - val_loss: 1.6289 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2573 - val_loss: 1.6288 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2448 - val_loss: 1.6286 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2365 - val_loss: 1.6285 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2324 - val_loss: 1.6284 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.1950 - val_loss: 1.6283 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2075 - val_loss: 1.6283 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2739 - val_loss: 1.6282 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2199 - val_loss: 1.6281 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2116 - val_loss: 1.6279 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2324 - val_loss: 1.6277 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2324 - val_loss: 1.6276 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2365 - val_loss: 1.6275 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2241 - val_loss: 1.6274 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.1577 - val_loss: 1.6272 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2407 - val_loss: 1.6271 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2656 - val_loss: 1.6271 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2614 - val_loss: 1.6270 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2946 - val_loss: 1.6269 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2282 - val_loss: 1.6268 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2282 - val_loss: 1.6267 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2490 - val_loss: 1.6266 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2158 - val_loss: 1.6264 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2614 - val_loss: 1.6263 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2116 - val_loss: 1.6263 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2407 - val_loss: 1.6262 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2158 - val_loss: 1.6262 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.1909 - val_loss: 1.6261 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2448 - val_loss: 1.6260 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2407 - val_loss: 1.6259 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2407 - val_loss: 1.6258 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.1992 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2573 - val_loss: 1.6258 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2116 - val_loss: 1.6257 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2739 - val_loss: 1.6257 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2407 - val_loss: 1.6255 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2033 - val_loss: 1.6254 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2573 - val_loss: 1.6252 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2116 - val_loss: 1.6252 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2490 - val_loss: 1.6252 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2490 - val_loss: 1.6253 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2448 - val_loss: 1.6253 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 26ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2199 - val_loss: 1.6252 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2324 - val_loss: 1.6252 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.1992 - val_loss: 1.6251 - val_accuracy: 0.2787 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2158 - val_loss: 1.6251 - val_accuracy: 0.2787 - lr: 2.5000e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2739 - val_loss: 1.6250 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2282 - val_loss: 1.6250 - val_accuracy: 0.2787 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2199 - val_loss: 1.6250 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2573 - val_loss: 1.6249 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 26ms/epoch - 3ms/step\n",
      "Node 1 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6622 - accuracy: 0.1660 - val_loss: 1.6596 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 3s/epoch - 166ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6597 - accuracy: 0.2199 - val_loss: 1.6590 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6583 - accuracy: 0.1909 - val_loss: 1.6585 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6594 - accuracy: 0.1826 - val_loss: 1.6578 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6575 - accuracy: 0.2282 - val_loss: 1.6573 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6561 - accuracy: 0.2116 - val_loss: 1.6571 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6558 - accuracy: 0.1950 - val_loss: 1.6567 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6563 - accuracy: 0.1950 - val_loss: 1.6565 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6570 - accuracy: 0.1909 - val_loss: 1.6559 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6543 - accuracy: 0.1701 - val_loss: 1.6550 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6536 - accuracy: 0.1909 - val_loss: 1.6539 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6530 - accuracy: 0.2158 - val_loss: 1.6533 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6526 - accuracy: 0.1992 - val_loss: 1.6526 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6529 - accuracy: 0.1743 - val_loss: 1.6520 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6507 - accuracy: 0.2116 - val_loss: 1.6512 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6495 - accuracy: 0.2324 - val_loss: 1.6506 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6492 - accuracy: 0.1950 - val_loss: 1.6499 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6485 - accuracy: 0.1992 - val_loss: 1.6494 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6483 - accuracy: 0.2448 - val_loss: 1.6487 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2531 - val_loss: 1.6483 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6451 - accuracy: 0.2822 - val_loss: 1.6475 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6455 - accuracy: 0.2407 - val_loss: 1.6471 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6448 - accuracy: 0.2697 - val_loss: 1.6466 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6450 - accuracy: 0.2241 - val_loss: 1.6461 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6444 - accuracy: 0.2116 - val_loss: 1.6458 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6445 - accuracy: 0.2282 - val_loss: 1.6456 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6419 - accuracy: 0.2490 - val_loss: 1.6452 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6446 - accuracy: 0.2448 - val_loss: 1.6446 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6421 - accuracy: 0.2490 - val_loss: 1.6443 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6427 - accuracy: 0.2282 - val_loss: 1.6437 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6411 - accuracy: 0.1992 - val_loss: 1.6432 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6421 - accuracy: 0.2614 - val_loss: 1.6430 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6430 - accuracy: 0.1992 - val_loss: 1.6426 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6412 - accuracy: 0.1909 - val_loss: 1.6423 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6392 - accuracy: 0.2241 - val_loss: 1.6416 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6390 - accuracy: 0.2780 - val_loss: 1.6412 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6398 - accuracy: 0.2199 - val_loss: 1.6409 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6399 - accuracy: 0.2033 - val_loss: 1.6405 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6402 - accuracy: 0.2075 - val_loss: 1.6397 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6353 - accuracy: 0.2282 - val_loss: 1.6397 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6381 - accuracy: 0.2780 - val_loss: 1.6393 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6376 - accuracy: 0.2448 - val_loss: 1.6385 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6389 - accuracy: 0.1992 - val_loss: 1.6376 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6360 - accuracy: 0.2282 - val_loss: 1.6373 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6357 - accuracy: 0.2158 - val_loss: 1.6371 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6364 - accuracy: 0.2490 - val_loss: 1.6368 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6365 - accuracy: 0.2158 - val_loss: 1.6363 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2241 - val_loss: 1.6362 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2365 - val_loss: 1.6361 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6356 - accuracy: 0.2158 - val_loss: 1.6358 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2324 - val_loss: 1.6353 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6341 - accuracy: 0.2490 - val_loss: 1.6351 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2324 - val_loss: 1.6348 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6351 - accuracy: 0.2324 - val_loss: 1.6346 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2282 - val_loss: 1.6345 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2365 - val_loss: 1.6344 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2407 - val_loss: 1.6340 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6304 - accuracy: 0.2365 - val_loss: 1.6339 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2324 - val_loss: 1.6338 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6326 - accuracy: 0.2033 - val_loss: 1.6332 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6313 - accuracy: 0.2116 - val_loss: 1.6327 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2324 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2407 - val_loss: 1.6322 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2116 - val_loss: 1.6319 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2282 - val_loss: 1.6316 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2241 - val_loss: 1.6316 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2158 - val_loss: 1.6314 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2241 - val_loss: 1.6312 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.2407 - val_loss: 1.6313 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2448 - val_loss: 1.6312 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2365 - val_loss: 1.6313 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2241 - val_loss: 1.6313 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6267 - accuracy: 0.2282 - val_loss: 1.6311 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2531 - val_loss: 1.6309 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2365 - val_loss: 1.6307 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2116 - val_loss: 1.6307 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2697 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2614 - val_loss: 1.6306 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2116 - val_loss: 1.6305 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2656 - val_loss: 1.6303 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2365 - val_loss: 1.6301 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2490 - val_loss: 1.6300 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2490 - val_loss: 1.6301 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2531 - val_loss: 1.6300 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2490 - val_loss: 1.6299 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2158 - val_loss: 1.6298 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2241 - val_loss: 1.6297 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2241 - val_loss: 1.6296 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2282 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2241 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2241 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2282 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2531 - val_loss: 1.6295 - val_accuracy: 0.1967 - lr: 1.2500e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2407 - val_loss: 1.6296 - val_accuracy: 0.2131 - lr: 1.2500e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2988 - val_loss: 1.6296 - val_accuracy: 0.1967 - lr: 1.2500e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2448 - val_loss: 1.6296 - val_accuracy: 0.1803 - lr: 6.2500e-06 - 60ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2365 - val_loss: 1.6296 - val_accuracy: 0.1803 - lr: 6.2500e-06 - 63ms/epoch - 4ms/step\n",
      "Node 1 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6604 - accuracy: 0.2075 - val_loss: 1.6601 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 2s/epoch - 292ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6610 - accuracy: 0.1452 - val_loss: 1.6593 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.1950 - val_loss: 1.6587 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6605 - accuracy: 0.2033 - val_loss: 1.6582 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.1950 - val_loss: 1.6577 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6578 - accuracy: 0.1909 - val_loss: 1.6573 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.2282 - val_loss: 1.6570 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.1992 - val_loss: 1.6565 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2656 - val_loss: 1.6560 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2116 - val_loss: 1.6555 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.1909 - val_loss: 1.6550 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6523 - accuracy: 0.2282 - val_loss: 1.6546 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2448 - val_loss: 1.6540 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2158 - val_loss: 1.6534 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6528 - accuracy: 0.2324 - val_loss: 1.6529 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6529 - accuracy: 0.2365 - val_loss: 1.6525 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.1950 - val_loss: 1.6521 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2075 - val_loss: 1.6518 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2199 - val_loss: 1.6514 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2116 - val_loss: 1.6510 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6516 - accuracy: 0.1992 - val_loss: 1.6506 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6509 - accuracy: 0.2448 - val_loss: 1.6501 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2324 - val_loss: 1.6498 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6499 - accuracy: 0.2075 - val_loss: 1.6495 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2324 - val_loss: 1.6492 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6496 - accuracy: 0.2282 - val_loss: 1.6487 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6496 - accuracy: 0.2282 - val_loss: 1.6484 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.1992 - val_loss: 1.6482 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2241 - val_loss: 1.6480 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.2324 - val_loss: 1.6476 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6460 - accuracy: 0.2448 - val_loss: 1.6473 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2241 - val_loss: 1.6470 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2448 - val_loss: 1.6467 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2282 - val_loss: 1.6463 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6435 - accuracy: 0.2448 - val_loss: 1.6460 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2448 - val_loss: 1.6457 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2365 - val_loss: 1.6454 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2282 - val_loss: 1.6451 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2324 - val_loss: 1.6447 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2199 - val_loss: 1.6445 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6423 - accuracy: 0.2199 - val_loss: 1.6441 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2365 - val_loss: 1.6439 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6419 - accuracy: 0.2407 - val_loss: 1.6437 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2407 - val_loss: 1.6434 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 8ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2448 - val_loss: 1.6431 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2448 - val_loss: 1.6428 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2448 - val_loss: 1.6427 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2282 - val_loss: 1.6423 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2490 - val_loss: 1.6420 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2241 - val_loss: 1.6417 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2241 - val_loss: 1.6415 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2365 - val_loss: 1.6412 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.2282 - val_loss: 1.6410 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2241 - val_loss: 1.6407 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2490 - val_loss: 1.6404 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2448 - val_loss: 1.6402 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2241 - val_loss: 1.6399 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6374 - accuracy: 0.2199 - val_loss: 1.6397 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2407 - val_loss: 1.6395 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2365 - val_loss: 1.6392 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2324 - val_loss: 1.6388 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2199 - val_loss: 1.6387 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2324 - val_loss: 1.6386 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2448 - val_loss: 1.6384 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2033 - val_loss: 1.6382 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2407 - val_loss: 1.6381 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2490 - val_loss: 1.6379 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2365 - val_loss: 1.6377 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2282 - val_loss: 1.6376 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2407 - val_loss: 1.6373 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2697 - val_loss: 1.6371 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2365 - val_loss: 1.6369 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2282 - val_loss: 1.6367 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2490 - val_loss: 1.6366 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2531 - val_loss: 1.6365 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2656 - val_loss: 1.6364 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2573 - val_loss: 1.6362 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2448 - val_loss: 1.6360 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2365 - val_loss: 1.6359 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2199 - val_loss: 1.6358 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2116 - val_loss: 1.6356 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2282 - val_loss: 1.6354 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2448 - val_loss: 1.6353 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2324 - val_loss: 1.6352 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2241 - val_loss: 1.6351 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2365 - val_loss: 1.6351 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2448 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2573 - val_loss: 1.6349 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2656 - val_loss: 1.6347 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2822 - val_loss: 1.6345 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2531 - val_loss: 1.6343 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2531 - val_loss: 1.6341 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2573 - val_loss: 1.6339 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2697 - val_loss: 1.6337 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2573 - val_loss: 1.6336 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2199 - val_loss: 1.6335 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2282 - val_loss: 1.6333 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2407 - val_loss: 1.6333 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2656 - val_loss: 1.6331 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2365 - val_loss: 1.6329 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Node 1 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 1 - Best Validation Accuracy: 0.3115\n",
      "Best model saved for Node 1 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_1.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_2_dataset.csv\n",
      "Node 2 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6347 - accuracy: 0.2254 - val_loss: 1.6349 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 3s/epoch - 177ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6341 - accuracy: 0.1721 - val_loss: 1.6346 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6351 - accuracy: 0.1844 - val_loss: 1.6343 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2049 - val_loss: 1.6340 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.2172 - val_loss: 1.6338 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.1885 - val_loss: 1.6336 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2500 - val_loss: 1.6333 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2131 - val_loss: 1.6331 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2049 - val_loss: 1.6329 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2213 - val_loss: 1.6327 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2131 - val_loss: 1.6324 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2377 - val_loss: 1.6322 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.2213 - val_loss: 1.6319 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.1967 - val_loss: 1.6317 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2090 - val_loss: 1.6314 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.2172 - val_loss: 1.6312 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.1803 - val_loss: 1.6310 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.1926 - val_loss: 1.6308 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.1926 - val_loss: 1.6307 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2172 - val_loss: 1.6305 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2172 - val_loss: 1.6301 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.1885 - val_loss: 1.6299 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.1680 - val_loss: 1.6298 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2254 - val_loss: 1.6296 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2418 - val_loss: 1.6293 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2131 - val_loss: 1.6291 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.1967 - val_loss: 1.6290 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2254 - val_loss: 1.6289 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2336 - val_loss: 1.6287 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2213 - val_loss: 1.6285 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2336 - val_loss: 1.6284 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6250 - accuracy: 0.2213 - val_loss: 1.6282 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2172 - val_loss: 1.6280 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6257 - accuracy: 0.2213 - val_loss: 1.6278 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2459 - val_loss: 1.6278 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2500 - val_loss: 1.6276 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2295 - val_loss: 1.6275 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.1967 - val_loss: 1.6273 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2172 - val_loss: 1.6270 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2295 - val_loss: 1.6269 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2377 - val_loss: 1.6267 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2213 - val_loss: 1.6266 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2049 - val_loss: 1.6265 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2172 - val_loss: 1.6262 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6202 - accuracy: 0.2377 - val_loss: 1.6261 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.1844 - val_loss: 1.6260 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2459 - val_loss: 1.6259 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2418 - val_loss: 1.6257 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2131 - val_loss: 1.6256 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2500 - val_loss: 1.6255 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2172 - val_loss: 1.6253 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2131 - val_loss: 1.6252 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2131 - val_loss: 1.6251 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2869 - val_loss: 1.6250 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6249 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2336 - val_loss: 1.6247 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6195 - accuracy: 0.2295 - val_loss: 1.6246 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2541 - val_loss: 1.6244 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2418 - val_loss: 1.6243 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2336 - val_loss: 1.6242 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2172 - val_loss: 1.6240 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2418 - val_loss: 1.6240 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2336 - val_loss: 1.6239 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2377 - val_loss: 1.6237 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2377 - val_loss: 1.6236 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2131 - val_loss: 1.6235 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2459 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2295 - val_loss: 1.6232 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6181 - accuracy: 0.2664 - val_loss: 1.6231 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2582 - val_loss: 1.6230 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2172 - val_loss: 1.6228 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2377 - val_loss: 1.6226 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2377 - val_loss: 1.6225 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2213 - val_loss: 1.6223 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2459 - val_loss: 1.6222 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6122 - accuracy: 0.2582 - val_loss: 1.6220 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2664 - val_loss: 1.6220 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2746 - val_loss: 1.6219 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2295 - val_loss: 1.6218 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2459 - val_loss: 1.6217 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2090 - val_loss: 1.6216 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2213 - val_loss: 1.6214 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2500 - val_loss: 1.6213 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2213 - val_loss: 1.6212 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.1885 - val_loss: 1.6211 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2377 - val_loss: 1.6210 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2377 - val_loss: 1.6210 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2705 - val_loss: 1.6208 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6137 - accuracy: 0.2623 - val_loss: 1.6207 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2295 - val_loss: 1.6206 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6104 - accuracy: 0.2746 - val_loss: 1.6206 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6120 - accuracy: 0.2377 - val_loss: 1.6205 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2541 - val_loss: 1.6204 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6094 - accuracy: 0.2910 - val_loss: 1.6204 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2336 - val_loss: 1.6203 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2090 - val_loss: 1.6202 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2049 - val_loss: 1.6200 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2254 - val_loss: 1.6199 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6148 - accuracy: 0.2336 - val_loss: 1.6198 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Node 2 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6358 - accuracy: 0.1844 - val_loss: 1.6359 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 2s/epoch - 303ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.1885 - val_loss: 1.6357 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.1885 - val_loss: 1.6356 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 308ms/epoch - 39ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2336 - val_loss: 1.6354 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2254 - val_loss: 1.6353 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.1926 - val_loss: 1.6351 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.1844 - val_loss: 1.6349 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2131 - val_loss: 1.6348 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2090 - val_loss: 1.6346 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.1844 - val_loss: 1.6345 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2377 - val_loss: 1.6344 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2213 - val_loss: 1.6342 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.1967 - val_loss: 1.6341 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2500 - val_loss: 1.6340 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2049 - val_loss: 1.6339 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2254 - val_loss: 1.6337 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2254 - val_loss: 1.6336 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2213 - val_loss: 1.6334 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2254 - val_loss: 1.6333 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2295 - val_loss: 1.6332 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2418 - val_loss: 1.6331 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2295 - val_loss: 1.6330 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.1967 - val_loss: 1.6330 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2336 - val_loss: 1.6329 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2049 - val_loss: 1.6328 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2131 - val_loss: 1.6327 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2254 - val_loss: 1.6325 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2213 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2049 - val_loss: 1.6323 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.1967 - val_loss: 1.6321 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2295 - val_loss: 1.6320 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.1885 - val_loss: 1.6319 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2090 - val_loss: 1.6317 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2459 - val_loss: 1.6316 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2213 - val_loss: 1.6314 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2090 - val_loss: 1.6313 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2418 - val_loss: 1.6312 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.1967 - val_loss: 1.6311 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.1762 - val_loss: 1.6310 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2131 - val_loss: 1.6309 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2295 - val_loss: 1.6308 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.1885 - val_loss: 1.6306 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2295 - val_loss: 1.6306 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2295 - val_loss: 1.6305 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2090 - val_loss: 1.6304 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2336 - val_loss: 1.6303 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2090 - val_loss: 1.6302 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2295 - val_loss: 1.6301 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2295 - val_loss: 1.6301 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.1926 - val_loss: 1.6299 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2254 - val_loss: 1.6298 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2172 - val_loss: 1.6297 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2090 - val_loss: 1.6296 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.1885 - val_loss: 1.6295 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2172 - val_loss: 1.6294 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.1967 - val_loss: 1.6293 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.1885 - val_loss: 1.6292 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2131 - val_loss: 1.6290 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2705 - val_loss: 1.6290 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2295 - val_loss: 1.6289 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2254 - val_loss: 1.6288 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 57ms/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2418 - val_loss: 1.6287 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2623 - val_loss: 1.6286 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2254 - val_loss: 1.6285 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.1926 - val_loss: 1.6283 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2418 - val_loss: 1.6282 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2336 - val_loss: 1.6282 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2172 - val_loss: 1.6281 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2295 - val_loss: 1.6280 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2131 - val_loss: 1.6279 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2377 - val_loss: 1.6278 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2008 - val_loss: 1.6277 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2910 - val_loss: 1.6276 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2336 - val_loss: 1.6275 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2295 - val_loss: 1.6274 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2254 - val_loss: 1.6273 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2418 - val_loss: 1.6272 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.1926 - val_loss: 1.6271 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2500 - val_loss: 1.6271 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2582 - val_loss: 1.6270 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2172 - val_loss: 1.6269 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2131 - val_loss: 1.6269 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2582 - val_loss: 1.6268 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2336 - val_loss: 1.6267 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2500 - val_loss: 1.6266 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.1844 - val_loss: 1.6264 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2090 - val_loss: 1.6264 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2336 - val_loss: 1.6263 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2213 - val_loss: 1.6263 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2418 - val_loss: 1.6262 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2459 - val_loss: 1.6261 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2582 - val_loss: 1.6260 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2664 - val_loss: 1.6260 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2623 - val_loss: 1.6260 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2459 - val_loss: 1.6259 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2377 - val_loss: 1.6259 - val_accuracy: 0.1311 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2418 - val_loss: 1.6259 - val_accuracy: 0.1311 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2418 - val_loss: 1.6259 - val_accuracy: 0.1311 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2254 - val_loss: 1.6258 - val_accuracy: 0.1311 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Node 2 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6588 - accuracy: 0.2418 - val_loss: 1.6592 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 2s/epoch - 156ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6597 - accuracy: 0.2213 - val_loss: 1.6583 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6607 - accuracy: 0.1762 - val_loss: 1.6576 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6586 - accuracy: 0.2377 - val_loss: 1.6570 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6569 - accuracy: 0.2213 - val_loss: 1.6564 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6564 - accuracy: 0.2254 - val_loss: 1.6559 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6558 - accuracy: 0.2131 - val_loss: 1.6555 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6541 - accuracy: 0.2254 - val_loss: 1.6548 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6539 - accuracy: 0.2377 - val_loss: 1.6540 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6518 - accuracy: 0.2418 - val_loss: 1.6534 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6530 - accuracy: 0.2172 - val_loss: 1.6530 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6529 - accuracy: 0.2377 - val_loss: 1.6524 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6497 - accuracy: 0.2377 - val_loss: 1.6519 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6508 - accuracy: 0.1926 - val_loss: 1.6515 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6522 - accuracy: 0.2131 - val_loss: 1.6510 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6490 - accuracy: 0.2213 - val_loss: 1.6506 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6493 - accuracy: 0.2172 - val_loss: 1.6501 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6460 - accuracy: 0.2582 - val_loss: 1.6495 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6486 - accuracy: 0.2172 - val_loss: 1.6489 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2336 - val_loss: 1.6484 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6452 - accuracy: 0.2172 - val_loss: 1.6478 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6454 - accuracy: 0.2377 - val_loss: 1.6473 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6451 - accuracy: 0.2377 - val_loss: 1.6468 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6443 - accuracy: 0.2418 - val_loss: 1.6462 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6422 - accuracy: 0.2869 - val_loss: 1.6458 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6438 - accuracy: 0.2459 - val_loss: 1.6454 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6446 - accuracy: 0.2459 - val_loss: 1.6449 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6410 - accuracy: 0.2336 - val_loss: 1.6444 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6405 - accuracy: 0.2418 - val_loss: 1.6440 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6400 - accuracy: 0.2254 - val_loss: 1.6437 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6423 - accuracy: 0.2131 - val_loss: 1.6433 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6388 - accuracy: 0.2377 - val_loss: 1.6429 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6390 - accuracy: 0.2172 - val_loss: 1.6424 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6370 - accuracy: 0.2500 - val_loss: 1.6419 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.2500 - val_loss: 1.6416 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6369 - accuracy: 0.2131 - val_loss: 1.6412 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6362 - accuracy: 0.2541 - val_loss: 1.6410 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2623 - val_loss: 1.6407 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6350 - accuracy: 0.2582 - val_loss: 1.6404 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6381 - accuracy: 0.2213 - val_loss: 1.6399 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6336 - accuracy: 0.2377 - val_loss: 1.6394 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6341 - accuracy: 0.2377 - val_loss: 1.6390 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2295 - val_loss: 1.6387 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2541 - val_loss: 1.6382 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2377 - val_loss: 1.6379 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2787 - val_loss: 1.6377 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 83ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6299 - accuracy: 0.2418 - val_loss: 1.6372 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2418 - val_loss: 1.6369 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2377 - val_loss: 1.6368 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.2418 - val_loss: 1.6366 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2664 - val_loss: 1.6363 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2787 - val_loss: 1.6360 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2418 - val_loss: 1.6356 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2705 - val_loss: 1.6352 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2664 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2541 - val_loss: 1.6347 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.3197 - val_loss: 1.6344 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2500 - val_loss: 1.6341 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2910 - val_loss: 1.6339 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2664 - val_loss: 1.6337 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2828 - val_loss: 1.6333 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6212 - accuracy: 0.2541 - val_loss: 1.6331 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2418 - val_loss: 1.6330 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2705 - val_loss: 1.6329 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2459 - val_loss: 1.6327 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2746 - val_loss: 1.6325 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2910 - val_loss: 1.6325 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6228 - accuracy: 0.2623 - val_loss: 1.6326 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2705 - val_loss: 1.6327 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2459 - val_loss: 1.6326 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2336 - val_loss: 1.6324 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6180 - accuracy: 0.2746 - val_loss: 1.6322 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2582 - val_loss: 1.6321 - val_accuracy: 0.1803 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2541 - val_loss: 1.6319 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2500 - val_loss: 1.6318 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2582 - val_loss: 1.6317 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2828 - val_loss: 1.6317 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2541 - val_loss: 1.6315 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2582 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2787 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2500 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6094 - accuracy: 0.2869 - val_loss: 1.6312 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2746 - val_loss: 1.6311 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2828 - val_loss: 1.6310 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2746 - val_loss: 1.6310 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6086 - accuracy: 0.2746 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6122 - accuracy: 0.2623 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6081 - accuracy: 0.2869 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6072 - accuracy: 0.2582 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6083 - accuracy: 0.2705 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2705 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6014 - accuracy: 0.2910 - val_loss: 1.6307 - val_accuracy: 0.1967 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6100 - accuracy: 0.2582 - val_loss: 1.6307 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2500 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2828 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2541 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 1.2500e-05 - 85ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2459 - val_loss: 1.6308 - val_accuracy: 0.1967 - lr: 1.2500e-05 - 64ms/epoch - 4ms/step\n",
      "Node 2 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6610 - accuracy: 0.1721 - val_loss: 1.6602 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 3s/epoch - 325ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.2295 - val_loss: 1.6597 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6604 - accuracy: 0.2049 - val_loss: 1.6591 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6578 - accuracy: 0.2172 - val_loss: 1.6587 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6573 - accuracy: 0.2008 - val_loss: 1.6582 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.2541 - val_loss: 1.6577 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2213 - val_loss: 1.6573 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6558 - accuracy: 0.2500 - val_loss: 1.6569 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2377 - val_loss: 1.6565 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6548 - accuracy: 0.2295 - val_loss: 1.6562 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6543 - accuracy: 0.2541 - val_loss: 1.6558 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2377 - val_loss: 1.6554 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6539 - accuracy: 0.2664 - val_loss: 1.6551 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6517 - accuracy: 0.2459 - val_loss: 1.6547 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6532 - accuracy: 0.2049 - val_loss: 1.6543 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6517 - accuracy: 0.2254 - val_loss: 1.6539 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2459 - val_loss: 1.6535 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2500 - val_loss: 1.6531 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2541 - val_loss: 1.6527 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6500 - accuracy: 0.2500 - val_loss: 1.6523 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.1803 - val_loss: 1.6519 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2254 - val_loss: 1.6516 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2746 - val_loss: 1.6512 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2664 - val_loss: 1.6508 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6489 - accuracy: 0.2295 - val_loss: 1.6505 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2213 - val_loss: 1.6503 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2623 - val_loss: 1.6498 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.2664 - val_loss: 1.6496 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2418 - val_loss: 1.6492 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2910 - val_loss: 1.6490 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2459 - val_loss: 1.6486 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.1844 - val_loss: 1.6482 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2418 - val_loss: 1.6479 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2418 - val_loss: 1.6476 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2828 - val_loss: 1.6473 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2418 - val_loss: 1.6470 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2295 - val_loss: 1.6468 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2869 - val_loss: 1.6464 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2172 - val_loss: 1.6461 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.2869 - val_loss: 1.6458 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.3033 - val_loss: 1.6455 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2787 - val_loss: 1.6452 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2090 - val_loss: 1.6449 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2787 - val_loss: 1.6446 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2623 - val_loss: 1.6443 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.2623 - val_loss: 1.6441 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6360 - accuracy: 0.2664 - val_loss: 1.6438 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2623 - val_loss: 1.6435 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.2541 - val_loss: 1.6433 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2500 - val_loss: 1.6431 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.3074 - val_loss: 1.6429 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2418 - val_loss: 1.6427 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.3197 - val_loss: 1.6425 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2623 - val_loss: 1.6423 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2828 - val_loss: 1.6420 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2869 - val_loss: 1.6418 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2869 - val_loss: 1.6415 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.3033 - val_loss: 1.6413 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2377 - val_loss: 1.6410 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2213 - val_loss: 1.6408 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2664 - val_loss: 1.6405 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2705 - val_loss: 1.6402 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2869 - val_loss: 1.6399 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2377 - val_loss: 1.6397 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2951 - val_loss: 1.6396 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2869 - val_loss: 1.6394 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.3033 - val_loss: 1.6392 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2746 - val_loss: 1.6390 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.3033 - val_loss: 1.6387 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2828 - val_loss: 1.6385 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2828 - val_loss: 1.6382 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2213 - val_loss: 1.6380 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.3279 - val_loss: 1.6378 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.3607 - val_loss: 1.6377 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2295 - val_loss: 1.6375 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2869 - val_loss: 1.6373 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2992 - val_loss: 1.6372 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2951 - val_loss: 1.6371 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2992 - val_loss: 1.6370 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.3115 - val_loss: 1.6369 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2705 - val_loss: 1.6367 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2623 - val_loss: 1.6366 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2377 - val_loss: 1.6364 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2705 - val_loss: 1.6363 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2869 - val_loss: 1.6362 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2582 - val_loss: 1.6361 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2623 - val_loss: 1.6359 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.3033 - val_loss: 1.6357 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2828 - val_loss: 1.6355 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6111 - accuracy: 0.3197 - val_loss: 1.6354 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2664 - val_loss: 1.6353 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2869 - val_loss: 1.6352 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2869 - val_loss: 1.6352 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.3115 - val_loss: 1.6352 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2828 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.3197 - val_loss: 1.6349 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2705 - val_loss: 1.6347 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2500 - val_loss: 1.6346 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2951 - val_loss: 1.6343 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2705 - val_loss: 1.6342 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Node 2 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 2 - Best Validation Accuracy: 0.3115\n",
      "Best model saved for Node 2 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_2.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_3_dataset.csv\n",
      "Node 3 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6366 - accuracy: 0.1822 - val_loss: 1.6361 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 2s/epoch - 146ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6358 - accuracy: 0.2065 - val_loss: 1.6357 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6344 - accuracy: 0.2267 - val_loss: 1.6352 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6355 - accuracy: 0.2267 - val_loss: 1.6350 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6346 - accuracy: 0.1943 - val_loss: 1.6347 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.1822 - val_loss: 1.6344 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6350 - accuracy: 0.2065 - val_loss: 1.6343 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.1984 - val_loss: 1.6339 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.1741 - val_loss: 1.6335 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2146 - val_loss: 1.6333 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2105 - val_loss: 1.6330 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2186 - val_loss: 1.6327 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2348 - val_loss: 1.6323 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6302 - accuracy: 0.2429 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2146 - val_loss: 1.6318 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2348 - val_loss: 1.6316 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2429 - val_loss: 1.6314 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2267 - val_loss: 1.6311 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2389 - val_loss: 1.6309 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2024 - val_loss: 1.6307 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2308 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2105 - val_loss: 1.6302 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2389 - val_loss: 1.6301 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2429 - val_loss: 1.6299 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2308 - val_loss: 1.6296 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2429 - val_loss: 1.6293 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2308 - val_loss: 1.6291 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2267 - val_loss: 1.6289 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2267 - val_loss: 1.6287 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2389 - val_loss: 1.6285 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2429 - val_loss: 1.6282 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2186 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.1943 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2551 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2024 - val_loss: 1.6279 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2105 - val_loss: 1.6277 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2186 - val_loss: 1.6275 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2024 - val_loss: 1.6274 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2470 - val_loss: 1.6271 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2308 - val_loss: 1.6269 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2429 - val_loss: 1.6268 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2146 - val_loss: 1.6266 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2146 - val_loss: 1.6266 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2227 - val_loss: 1.6264 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2024 - val_loss: 1.6262 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2227 - val_loss: 1.6261 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2308 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2267 - val_loss: 1.6257 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2308 - val_loss: 1.6257 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2470 - val_loss: 1.6256 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2227 - val_loss: 1.6256 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2267 - val_loss: 1.6255 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2267 - val_loss: 1.6253 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2429 - val_loss: 1.6253 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2267 - val_loss: 1.6254 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2510 - val_loss: 1.6253 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2389 - val_loss: 1.6252 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2308 - val_loss: 1.6252 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2389 - val_loss: 1.6252 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2308 - val_loss: 1.6253 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2389 - val_loss: 1.6253 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2227 - val_loss: 1.6253 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6135 - accuracy: 0.2551 - val_loss: 1.6253 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6163 - accuracy: 0.2389 - val_loss: 1.6253 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2389 - val_loss: 1.6253 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Node 3 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6338 - accuracy: 0.2186 - val_loss: 1.6361 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 3s/epoch - 341ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2227 - val_loss: 1.6358 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2024 - val_loss: 1.6358 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2389 - val_loss: 1.6356 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2632 - val_loss: 1.6353 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.1984 - val_loss: 1.6350 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.1700 - val_loss: 1.6348 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2672 - val_loss: 1.6345 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2146 - val_loss: 1.6343 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2389 - val_loss: 1.6341 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.1862 - val_loss: 1.6339 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2348 - val_loss: 1.6337 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.1498 - val_loss: 1.6334 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2308 - val_loss: 1.6331 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.1943 - val_loss: 1.6330 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2308 - val_loss: 1.6330 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2024 - val_loss: 1.6329 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.1943 - val_loss: 1.6328 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2146 - val_loss: 1.6325 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2065 - val_loss: 1.6324 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2429 - val_loss: 1.6324 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.1984 - val_loss: 1.6323 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2065 - val_loss: 1.6320 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2146 - val_loss: 1.6319 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2510 - val_loss: 1.6317 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2632 - val_loss: 1.6315 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2267 - val_loss: 1.6313 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2470 - val_loss: 1.6311 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2227 - val_loss: 1.6310 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2753 - val_loss: 1.6310 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2186 - val_loss: 1.6309 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2389 - val_loss: 1.6308 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2267 - val_loss: 1.6307 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2065 - val_loss: 1.6305 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2389 - val_loss: 1.6303 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2348 - val_loss: 1.6302 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2308 - val_loss: 1.6301 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2267 - val_loss: 1.6299 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2024 - val_loss: 1.6297 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.1984 - val_loss: 1.6296 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2065 - val_loss: 1.6295 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.1984 - val_loss: 1.6294 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2591 - val_loss: 1.6294 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2146 - val_loss: 1.6293 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2713 - val_loss: 1.6292 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2389 - val_loss: 1.6291 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2389 - val_loss: 1.6290 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2632 - val_loss: 1.6289 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2186 - val_loss: 1.6289 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2227 - val_loss: 1.6288 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2186 - val_loss: 1.6288 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2267 - val_loss: 1.6287 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2510 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2389 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 5.0000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2308 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 5.0000e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.1984 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2389 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 2.5000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2389 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2146 - val_loss: 1.6288 - val_accuracy: 0.1774 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Node 3 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6606 - accuracy: 0.1862 - val_loss: 1.6601 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 2s/epoch - 149ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6596 - accuracy: 0.2105 - val_loss: 1.6592 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6570 - accuracy: 0.2227 - val_loss: 1.6582 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6566 - accuracy: 0.2146 - val_loss: 1.6572 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6571 - accuracy: 0.2146 - val_loss: 1.6564 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6550 - accuracy: 0.1984 - val_loss: 1.6555 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6542 - accuracy: 0.2186 - val_loss: 1.6547 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6537 - accuracy: 0.2348 - val_loss: 1.6539 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6533 - accuracy: 0.2065 - val_loss: 1.6530 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6507 - accuracy: 0.2227 - val_loss: 1.6522 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6502 - accuracy: 0.2227 - val_loss: 1.6516 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6500 - accuracy: 0.1903 - val_loss: 1.6510 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6468 - accuracy: 0.2510 - val_loss: 1.6502 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6456 - accuracy: 0.2429 - val_loss: 1.6496 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6491 - accuracy: 0.2024 - val_loss: 1.6491 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6459 - accuracy: 0.2470 - val_loss: 1.6486 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6470 - accuracy: 0.2227 - val_loss: 1.6482 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6433 - accuracy: 0.2348 - val_loss: 1.6476 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6445 - accuracy: 0.1943 - val_loss: 1.6472 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6433 - accuracy: 0.2389 - val_loss: 1.6471 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6424 - accuracy: 0.2227 - val_loss: 1.6467 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6413 - accuracy: 0.2470 - val_loss: 1.6465 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 84ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6411 - accuracy: 0.2227 - val_loss: 1.6464 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6378 - accuracy: 0.2348 - val_loss: 1.6457 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6403 - accuracy: 0.2470 - val_loss: 1.6453 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6374 - accuracy: 0.2348 - val_loss: 1.6454 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6392 - accuracy: 0.2146 - val_loss: 1.6451 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6394 - accuracy: 0.2065 - val_loss: 1.6447 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6336 - accuracy: 0.2429 - val_loss: 1.6447 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2672 - val_loss: 1.6448 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.2267 - val_loss: 1.6445 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6352 - accuracy: 0.2429 - val_loss: 1.6446 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6304 - accuracy: 0.2510 - val_loss: 1.6443 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2065 - val_loss: 1.6441 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6291 - accuracy: 0.2470 - val_loss: 1.6439 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2389 - val_loss: 1.6439 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2591 - val_loss: 1.6441 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2308 - val_loss: 1.6439 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2227 - val_loss: 1.6438 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2753 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2348 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2308 - val_loss: 1.6438 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2105 - val_loss: 1.6437 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2551 - val_loss: 1.6437 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2348 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2186 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2308 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2227 - val_loss: 1.6438 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2551 - val_loss: 1.6438 - val_accuracy: 0.1935 - lr: 1.2500e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2024 - val_loss: 1.6438 - val_accuracy: 0.1935 - lr: 6.2500e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2389 - val_loss: 1.6438 - val_accuracy: 0.1935 - lr: 6.2500e-06 - 62ms/epoch - 4ms/step\n",
      "Node 3 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6614 - accuracy: 0.1862 - val_loss: 1.6605 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 2s/epoch - 291ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6603 - accuracy: 0.2146 - val_loss: 1.6601 - val_accuracy: 0.1290 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6590 - accuracy: 0.2065 - val_loss: 1.6597 - val_accuracy: 0.1290 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6578 - accuracy: 0.2186 - val_loss: 1.6592 - val_accuracy: 0.1290 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2227 - val_loss: 1.6588 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6578 - accuracy: 0.2024 - val_loss: 1.6584 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2024 - val_loss: 1.6580 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2955 - val_loss: 1.6576 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2065 - val_loss: 1.6572 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6553 - accuracy: 0.2429 - val_loss: 1.6569 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2308 - val_loss: 1.6565 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6545 - accuracy: 0.2429 - val_loss: 1.6560 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2308 - val_loss: 1.6556 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2470 - val_loss: 1.6551 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2308 - val_loss: 1.6548 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2429 - val_loss: 1.6545 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6520 - accuracy: 0.2308 - val_loss: 1.6542 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2146 - val_loss: 1.6540 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6504 - accuracy: 0.2389 - val_loss: 1.6538 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.2632 - val_loss: 1.6535 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2429 - val_loss: 1.6531 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6489 - accuracy: 0.2105 - val_loss: 1.6528 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2267 - val_loss: 1.6524 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6473 - accuracy: 0.2227 - val_loss: 1.6522 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2348 - val_loss: 1.6517 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2389 - val_loss: 1.6513 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6439 - accuracy: 0.2672 - val_loss: 1.6509 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2146 - val_loss: 1.6506 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2267 - val_loss: 1.6503 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2591 - val_loss: 1.6499 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6419 - accuracy: 0.2308 - val_loss: 1.6498 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2186 - val_loss: 1.6496 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6439 - accuracy: 0.2429 - val_loss: 1.6493 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2105 - val_loss: 1.6489 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2591 - val_loss: 1.6486 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2429 - val_loss: 1.6482 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2713 - val_loss: 1.6480 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2065 - val_loss: 1.6478 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2429 - val_loss: 1.6475 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2308 - val_loss: 1.6474 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.2267 - val_loss: 1.6471 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2551 - val_loss: 1.6470 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2389 - val_loss: 1.6469 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2470 - val_loss: 1.6467 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2105 - val_loss: 1.6466 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.2146 - val_loss: 1.6463 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2591 - val_loss: 1.6461 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6396 - accuracy: 0.1943 - val_loss: 1.6459 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2105 - val_loss: 1.6457 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2227 - val_loss: 1.6455 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2753 - val_loss: 1.6453 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2227 - val_loss: 1.6451 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2429 - val_loss: 1.6450 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2105 - val_loss: 1.6447 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2470 - val_loss: 1.6446 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2874 - val_loss: 1.6444 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2753 - val_loss: 1.6443 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2591 - val_loss: 1.6442 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2267 - val_loss: 1.6441 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2753 - val_loss: 1.6438 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2429 - val_loss: 1.6437 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2794 - val_loss: 1.6437 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 60ms/epoch - 8ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2470 - val_loss: 1.6436 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2308 - val_loss: 1.6433 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2470 - val_loss: 1.6432 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2713 - val_loss: 1.6431 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2713 - val_loss: 1.6431 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2672 - val_loss: 1.6428 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2429 - val_loss: 1.6426 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2105 - val_loss: 1.6424 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2348 - val_loss: 1.6421 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2672 - val_loss: 1.6419 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2955 - val_loss: 1.6419 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2996 - val_loss: 1.6419 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2632 - val_loss: 1.6419 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2834 - val_loss: 1.6419 - val_accuracy: 0.1774 - lr: 5.0000e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2672 - val_loss: 1.6419 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2591 - val_loss: 1.6419 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2632 - val_loss: 1.6419 - val_accuracy: 0.1935 - lr: 2.5000e-05 - 41ms/epoch - 5ms/step\n",
      "Node 3 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 3 - Best Validation Accuracy: 0.2258\n",
      "Best model saved for Node 3 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_3.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_4_dataset.csv\n",
      "Node 4 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6342 - accuracy: 0.2016 - val_loss: 1.6335 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 3s/epoch - 168ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6340 - accuracy: 0.2174 - val_loss: 1.6330 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6353 - accuracy: 0.2174 - val_loss: 1.6327 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2174 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6336 - accuracy: 0.2292 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.1897 - val_loss: 1.6318 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2213 - val_loss: 1.6316 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2174 - val_loss: 1.6313 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2253 - val_loss: 1.6310 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2095 - val_loss: 1.6307 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.1937 - val_loss: 1.6305 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2490 - val_loss: 1.6302 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6304 - accuracy: 0.2372 - val_loss: 1.6299 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2292 - val_loss: 1.6296 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2411 - val_loss: 1.6294 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2490 - val_loss: 1.6292 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2253 - val_loss: 1.6289 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2332 - val_loss: 1.6287 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2253 - val_loss: 1.6285 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2411 - val_loss: 1.6283 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2727 - val_loss: 1.6281 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2292 - val_loss: 1.6280 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2292 - val_loss: 1.6278 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2292 - val_loss: 1.6275 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2411 - val_loss: 1.6273 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2332 - val_loss: 1.6271 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2332 - val_loss: 1.6269 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2332 - val_loss: 1.6267 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2411 - val_loss: 1.6265 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2332 - val_loss: 1.6264 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2451 - val_loss: 1.6262 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2332 - val_loss: 1.6260 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2372 - val_loss: 1.6258 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2372 - val_loss: 1.6256 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2332 - val_loss: 1.6255 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2372 - val_loss: 1.6253 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2372 - val_loss: 1.6250 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2372 - val_loss: 1.6248 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2372 - val_loss: 1.6247 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2332 - val_loss: 1.6245 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2372 - val_loss: 1.6243 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2372 - val_loss: 1.6242 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2372 - val_loss: 1.6240 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2292 - val_loss: 1.6237 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2411 - val_loss: 1.6235 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2332 - val_loss: 1.6233 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2411 - val_loss: 1.6232 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2372 - val_loss: 1.6231 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2372 - val_loss: 1.6229 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2372 - val_loss: 1.6227 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2372 - val_loss: 1.6226 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2372 - val_loss: 1.6225 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2372 - val_loss: 1.6224 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2372 - val_loss: 1.6223 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2372 - val_loss: 1.6221 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2332 - val_loss: 1.6220 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2372 - val_loss: 1.6219 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6170 - accuracy: 0.2372 - val_loss: 1.6217 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2372 - val_loss: 1.6216 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6195 - accuracy: 0.2372 - val_loss: 1.6216 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.2372 - val_loss: 1.6215 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2372 - val_loss: 1.6214 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2332 - val_loss: 1.6213 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6180 - accuracy: 0.2372 - val_loss: 1.6211 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2372 - val_loss: 1.6209 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2372 - val_loss: 1.6209 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2411 - val_loss: 1.6207 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2372 - val_loss: 1.6205 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2451 - val_loss: 1.6204 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2372 - val_loss: 1.6204 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2372 - val_loss: 1.6203 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2372 - val_loss: 1.6202 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2332 - val_loss: 1.6201 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2372 - val_loss: 1.6200 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2451 - val_loss: 1.6198 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2332 - val_loss: 1.6197 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2372 - val_loss: 1.6197 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2372 - val_loss: 1.6196 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2372 - val_loss: 1.6194 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2372 - val_loss: 1.6193 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2372 - val_loss: 1.6192 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6145 - accuracy: 0.2372 - val_loss: 1.6191 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6138 - accuracy: 0.2372 - val_loss: 1.6190 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2332 - val_loss: 1.6188 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2372 - val_loss: 1.6188 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2372 - val_loss: 1.6187 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.2372 - val_loss: 1.6186 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2411 - val_loss: 1.6185 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2451 - val_loss: 1.6185 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2332 - val_loss: 1.6185 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2372 - val_loss: 1.6185 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2372 - val_loss: 1.6184 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2292 - val_loss: 1.6184 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2411 - val_loss: 1.6183 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2372 - val_loss: 1.6183 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2332 - val_loss: 1.6182 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2372 - val_loss: 1.6182 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2372 - val_loss: 1.6182 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6108 - accuracy: 0.2411 - val_loss: 1.6181 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2372 - val_loss: 1.6181 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Node 4 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6368 - accuracy: 0.1542 - val_loss: 1.6372 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 2s/epoch - 296ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.1976 - val_loss: 1.6370 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.1542 - val_loss: 1.6368 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.1818 - val_loss: 1.6366 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.1897 - val_loss: 1.6363 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2016 - val_loss: 1.6361 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.1937 - val_loss: 1.6359 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.1779 - val_loss: 1.6357 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.1502 - val_loss: 1.6355 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.1660 - val_loss: 1.6352 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.1700 - val_loss: 1.6350 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2253 - val_loss: 1.6348 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2016 - val_loss: 1.6346 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2055 - val_loss: 1.6345 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2174 - val_loss: 1.6344 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2055 - val_loss: 1.6342 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2095 - val_loss: 1.6341 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2016 - val_loss: 1.6339 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2213 - val_loss: 1.6337 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2451 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2174 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2055 - val_loss: 1.6331 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2332 - val_loss: 1.6329 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2451 - val_loss: 1.6328 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2213 - val_loss: 1.6326 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2372 - val_loss: 1.6324 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2490 - val_loss: 1.6323 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2530 - val_loss: 1.6321 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2372 - val_loss: 1.6319 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2372 - val_loss: 1.6317 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2451 - val_loss: 1.6316 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2490 - val_loss: 1.6314 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2332 - val_loss: 1.6312 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2134 - val_loss: 1.6311 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2451 - val_loss: 1.6310 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2688 - val_loss: 1.6309 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2253 - val_loss: 1.6308 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2292 - val_loss: 1.6306 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2174 - val_loss: 1.6305 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2253 - val_loss: 1.6303 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2648 - val_loss: 1.6302 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2372 - val_loss: 1.6300 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2569 - val_loss: 1.6299 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2372 - val_loss: 1.6298 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2332 - val_loss: 1.6296 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2451 - val_loss: 1.6295 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2530 - val_loss: 1.6294 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2490 - val_loss: 1.6292 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2213 - val_loss: 1.6291 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2174 - val_loss: 1.6290 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2253 - val_loss: 1.6288 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2332 - val_loss: 1.6287 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2727 - val_loss: 1.6285 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2530 - val_loss: 1.6284 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2292 - val_loss: 1.6283 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2332 - val_loss: 1.6282 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2372 - val_loss: 1.6281 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2451 - val_loss: 1.6280 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2372 - val_loss: 1.6279 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2332 - val_loss: 1.6278 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2490 - val_loss: 1.6276 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2451 - val_loss: 1.6275 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2530 - val_loss: 1.6274 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2292 - val_loss: 1.6274 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2372 - val_loss: 1.6273 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2451 - val_loss: 1.6273 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2411 - val_loss: 1.6272 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2292 - val_loss: 1.6270 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2490 - val_loss: 1.6269 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2253 - val_loss: 1.6268 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2490 - val_loss: 1.6267 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2372 - val_loss: 1.6266 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2490 - val_loss: 1.6265 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2253 - val_loss: 1.6263 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2451 - val_loss: 1.6262 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2372 - val_loss: 1.6261 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2372 - val_loss: 1.6260 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2372 - val_loss: 1.6259 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2332 - val_loss: 1.6258 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2372 - val_loss: 1.6257 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2411 - val_loss: 1.6255 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2411 - val_loss: 1.6254 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2332 - val_loss: 1.6253 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2451 - val_loss: 1.6253 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2372 - val_loss: 1.6252 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2411 - val_loss: 1.6252 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2372 - val_loss: 1.6251 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2213 - val_loss: 1.6249 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2292 - val_loss: 1.6248 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2727 - val_loss: 1.6247 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2253 - val_loss: 1.6248 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2490 - val_loss: 1.6247 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2332 - val_loss: 1.6247 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2372 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2490 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 28ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2569 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2490 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2451 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2490 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 27ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2253 - val_loss: 1.6246 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 28ms/epoch - 3ms/step\n",
      "Node 4 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6619 - accuracy: 0.2213 - val_loss: 1.6600 - val_accuracy: 0.3281 - lr: 1.0000e-04 - 3s/epoch - 164ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6618 - accuracy: 0.2055 - val_loss: 1.6593 - val_accuracy: 0.2812 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6608 - accuracy: 0.1858 - val_loss: 1.6587 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6591 - accuracy: 0.2095 - val_loss: 1.6579 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6577 - accuracy: 0.2253 - val_loss: 1.6573 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6575 - accuracy: 0.2292 - val_loss: 1.6565 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6560 - accuracy: 0.1937 - val_loss: 1.6558 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6543 - accuracy: 0.2411 - val_loss: 1.6550 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6546 - accuracy: 0.2253 - val_loss: 1.6544 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6546 - accuracy: 0.1897 - val_loss: 1.6537 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6538 - accuracy: 0.2332 - val_loss: 1.6531 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6526 - accuracy: 0.2134 - val_loss: 1.6526 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6536 - accuracy: 0.2095 - val_loss: 1.6519 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6520 - accuracy: 0.2332 - val_loss: 1.6513 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6497 - accuracy: 0.2609 - val_loss: 1.6507 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6492 - accuracy: 0.2451 - val_loss: 1.6503 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6483 - accuracy: 0.2530 - val_loss: 1.6497 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6488 - accuracy: 0.2174 - val_loss: 1.6491 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6459 - accuracy: 0.2451 - val_loss: 1.6484 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6459 - accuracy: 0.2292 - val_loss: 1.6477 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6463 - accuracy: 0.2372 - val_loss: 1.6473 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6450 - accuracy: 0.2411 - val_loss: 1.6468 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6462 - accuracy: 0.2213 - val_loss: 1.6462 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6419 - accuracy: 0.2411 - val_loss: 1.6457 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6419 - accuracy: 0.2530 - val_loss: 1.6450 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6432 - accuracy: 0.2332 - val_loss: 1.6444 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6422 - accuracy: 0.2292 - val_loss: 1.6440 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6402 - accuracy: 0.2332 - val_loss: 1.6433 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6397 - accuracy: 0.2451 - val_loss: 1.6427 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6366 - accuracy: 0.2332 - val_loss: 1.6423 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6421 - accuracy: 0.2332 - val_loss: 1.6416 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6405 - accuracy: 0.2490 - val_loss: 1.6414 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 83ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6373 - accuracy: 0.2332 - val_loss: 1.6409 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6396 - accuracy: 0.2411 - val_loss: 1.6406 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6359 - accuracy: 0.2569 - val_loss: 1.6401 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6354 - accuracy: 0.2411 - val_loss: 1.6399 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6360 - accuracy: 0.2372 - val_loss: 1.6396 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6361 - accuracy: 0.2490 - val_loss: 1.6394 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2332 - val_loss: 1.6390 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6370 - accuracy: 0.2411 - val_loss: 1.6388 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2411 - val_loss: 1.6385 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2490 - val_loss: 1.6382 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2372 - val_loss: 1.6377 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2332 - val_loss: 1.6376 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2332 - val_loss: 1.6373 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2411 - val_loss: 1.6371 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2332 - val_loss: 1.6368 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2411 - val_loss: 1.6366 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6324 - accuracy: 0.2451 - val_loss: 1.6363 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6283 - accuracy: 0.2411 - val_loss: 1.6360 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.2411 - val_loss: 1.6359 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2292 - val_loss: 1.6357 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2332 - val_loss: 1.6354 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2411 - val_loss: 1.6354 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2372 - val_loss: 1.6352 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2372 - val_loss: 1.6351 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2451 - val_loss: 1.6349 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2490 - val_loss: 1.6349 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2451 - val_loss: 1.6348 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2530 - val_loss: 1.6348 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2490 - val_loss: 1.6346 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2411 - val_loss: 1.6344 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2292 - val_loss: 1.6343 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2292 - val_loss: 1.6341 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2451 - val_loss: 1.6339 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2372 - val_loss: 1.6338 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2253 - val_loss: 1.6337 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2372 - val_loss: 1.6337 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2411 - val_loss: 1.6337 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2372 - val_loss: 1.6336 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2451 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2569 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2292 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2569 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2372 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2451 - val_loss: 1.6334 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2292 - val_loss: 1.6334 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2411 - val_loss: 1.6334 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2569 - val_loss: 1.6334 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2490 - val_loss: 1.6334 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 81ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2411 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2490 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2372 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 6.2500e-06 - 64ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2372 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 6.2500e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 6.2500e-06 - 64ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2411 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 3.1250e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 3.1250e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2411 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 3.1250e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.5625e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.5625e-06 - 63ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2372 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 1.5625e-06 - 61ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2292 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 7.8125e-07 - 64ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2451 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 7.8125e-07 - 60ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2332 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 7.8125e-07 - 65ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2411 - val_loss: 1.6333 - val_accuracy: 0.2344 - lr: 3.9062e-07 - 64ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2490 - val_loss: 1.6332 - val_accuracy: 0.2344 - lr: 3.9062e-07 - 63ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2451 - val_loss: 1.6332 - val_accuracy: 0.2344 - lr: 3.9062e-07 - 64ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2451 - val_loss: 1.6332 - val_accuracy: 0.2344 - lr: 3.9062e-07 - 61ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2411 - val_loss: 1.6332 - val_accuracy: 0.2344 - lr: 3.9062e-07 - 62ms/epoch - 4ms/step\n",
      "Node 4 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6599 - accuracy: 0.1937 - val_loss: 1.6600 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 2s/epoch - 291ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6595 - accuracy: 0.2016 - val_loss: 1.6595 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6608 - accuracy: 0.1976 - val_loss: 1.6590 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6590 - accuracy: 0.2213 - val_loss: 1.6585 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.2451 - val_loss: 1.6580 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.2134 - val_loss: 1.6576 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.1937 - val_loss: 1.6571 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2055 - val_loss: 1.6566 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2055 - val_loss: 1.6562 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6552 - accuracy: 0.2213 - val_loss: 1.6558 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2213 - val_loss: 1.6554 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2569 - val_loss: 1.6550 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6542 - accuracy: 0.2490 - val_loss: 1.6546 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2411 - val_loss: 1.6542 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2213 - val_loss: 1.6538 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2292 - val_loss: 1.6534 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2174 - val_loss: 1.6530 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6520 - accuracy: 0.2451 - val_loss: 1.6527 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2372 - val_loss: 1.6524 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2688 - val_loss: 1.6520 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2213 - val_loss: 1.6516 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2411 - val_loss: 1.6512 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2530 - val_loss: 1.6507 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2213 - val_loss: 1.6503 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2490 - val_loss: 1.6500 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2292 - val_loss: 1.6496 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.2372 - val_loss: 1.6493 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2372 - val_loss: 1.6490 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2490 - val_loss: 1.6487 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6444 - accuracy: 0.2411 - val_loss: 1.6483 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2530 - val_loss: 1.6479 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2569 - val_loss: 1.6476 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2292 - val_loss: 1.6473 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2451 - val_loss: 1.6470 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.2292 - val_loss: 1.6467 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2490 - val_loss: 1.6463 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2372 - val_loss: 1.6460 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2451 - val_loss: 1.6457 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.2411 - val_loss: 1.6454 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2451 - val_loss: 1.6451 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2332 - val_loss: 1.6448 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2292 - val_loss: 1.6446 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6389 - accuracy: 0.2372 - val_loss: 1.6443 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2332 - val_loss: 1.6440 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6397 - accuracy: 0.2451 - val_loss: 1.6437 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2372 - val_loss: 1.6434 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2411 - val_loss: 1.6431 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6380 - accuracy: 0.2332 - val_loss: 1.6428 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2253 - val_loss: 1.6425 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 356ms/epoch - 45ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2411 - val_loss: 1.6423 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2490 - val_loss: 1.6420 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2490 - val_loss: 1.6418 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2490 - val_loss: 1.6416 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2411 - val_loss: 1.6414 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2411 - val_loss: 1.6412 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2292 - val_loss: 1.6410 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2451 - val_loss: 1.6408 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2372 - val_loss: 1.6406 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2451 - val_loss: 1.6404 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2490 - val_loss: 1.6402 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 62ms/epoch - 8ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2490 - val_loss: 1.6399 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2411 - val_loss: 1.6397 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2411 - val_loss: 1.6395 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2372 - val_loss: 1.6393 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2411 - val_loss: 1.6391 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2411 - val_loss: 1.6391 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2332 - val_loss: 1.6390 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2411 - val_loss: 1.6390 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2372 - val_loss: 1.6388 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2451 - val_loss: 1.6387 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2490 - val_loss: 1.6387 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2372 - val_loss: 1.6386 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2292 - val_loss: 1.6385 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2292 - val_loss: 1.6384 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2253 - val_loss: 1.6383 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2372 - val_loss: 1.6381 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2490 - val_loss: 1.6379 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2411 - val_loss: 1.6379 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2451 - val_loss: 1.6378 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2332 - val_loss: 1.6377 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2451 - val_loss: 1.6376 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2372 - val_loss: 1.6375 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2332 - val_loss: 1.6374 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2451 - val_loss: 1.6373 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2332 - val_loss: 1.6372 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2372 - val_loss: 1.6371 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2213 - val_loss: 1.6370 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2292 - val_loss: 1.6371 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2411 - val_loss: 1.6370 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2332 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 39ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2411 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2451 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2451 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 5.0000e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2451 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2372 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2292 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 2.5000e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2332 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2451 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 40ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2372 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 1.2500e-05 - 41ms/epoch - 5ms/step\n",
      "Node 4 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 4 - Best Validation Accuracy: 0.3281\n",
      "Best model saved for Node 4 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_4.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_5_dataset.csv\n",
      "Node 5 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6362 - accuracy: 0.2119 - val_loss: 1.6357 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 2s/epoch - 159ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6360 - accuracy: 0.1822 - val_loss: 1.6353 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2415 - val_loss: 1.6349 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2203 - val_loss: 1.6347 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6370 - accuracy: 0.1695 - val_loss: 1.6345 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.2034 - val_loss: 1.6342 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.1907 - val_loss: 1.6339 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.2373 - val_loss: 1.6335 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.1907 - val_loss: 1.6332 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2246 - val_loss: 1.6329 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6313 - accuracy: 0.2415 - val_loss: 1.6325 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2373 - val_loss: 1.6322 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2331 - val_loss: 1.6319 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2373 - val_loss: 1.6317 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2458 - val_loss: 1.6314 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2500 - val_loss: 1.6310 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2373 - val_loss: 1.6308 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2373 - val_loss: 1.6306 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2203 - val_loss: 1.6303 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2415 - val_loss: 1.6300 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.1992 - val_loss: 1.6298 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2288 - val_loss: 1.6295 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2246 - val_loss: 1.6292 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2797 - val_loss: 1.6289 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2161 - val_loss: 1.6287 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2331 - val_loss: 1.6283 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2246 - val_loss: 1.6280 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2246 - val_loss: 1.6278 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2203 - val_loss: 1.6275 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2331 - val_loss: 1.6273 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2246 - val_loss: 1.6272 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2203 - val_loss: 1.6269 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2203 - val_loss: 1.6266 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2839 - val_loss: 1.6262 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2119 - val_loss: 1.6258 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2415 - val_loss: 1.6255 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2458 - val_loss: 1.6252 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2373 - val_loss: 1.6250 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2331 - val_loss: 1.6247 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2034 - val_loss: 1.6245 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2076 - val_loss: 1.6242 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2839 - val_loss: 1.6239 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2585 - val_loss: 1.6237 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2500 - val_loss: 1.6234 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2331 - val_loss: 1.6231 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2458 - val_loss: 1.6228 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2585 - val_loss: 1.6226 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2585 - val_loss: 1.6224 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2331 - val_loss: 1.6222 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2288 - val_loss: 1.6218 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6158 - accuracy: 0.2585 - val_loss: 1.6216 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.1907 - val_loss: 1.6214 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2034 - val_loss: 1.6212 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2458 - val_loss: 1.6211 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2246 - val_loss: 1.6209 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2881 - val_loss: 1.6207 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2288 - val_loss: 1.6205 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2669 - val_loss: 1.6203 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2669 - val_loss: 1.6202 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2500 - val_loss: 1.6200 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2627 - val_loss: 1.6198 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2246 - val_loss: 1.6196 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2161 - val_loss: 1.6195 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2119 - val_loss: 1.6193 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2500 - val_loss: 1.6191 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2542 - val_loss: 1.6189 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2458 - val_loss: 1.6187 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2203 - val_loss: 1.6186 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2500 - val_loss: 1.6185 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2542 - val_loss: 1.6184 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2203 - val_loss: 1.6183 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2203 - val_loss: 1.6182 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2585 - val_loss: 1.6180 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2331 - val_loss: 1.6179 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2288 - val_loss: 1.6177 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2034 - val_loss: 1.6175 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2288 - val_loss: 1.6174 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2203 - val_loss: 1.6173 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6135 - accuracy: 0.2669 - val_loss: 1.6172 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2331 - val_loss: 1.6170 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2500 - val_loss: 1.6169 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2585 - val_loss: 1.6168 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2627 - val_loss: 1.6167 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2288 - val_loss: 1.6166 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2881 - val_loss: 1.6165 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2203 - val_loss: 1.6164 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2500 - val_loss: 1.6162 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2458 - val_loss: 1.6161 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2203 - val_loss: 1.6160 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2288 - val_loss: 1.6160 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2458 - val_loss: 1.6160 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6133 - accuracy: 0.2288 - val_loss: 1.6159 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6115 - accuracy: 0.2712 - val_loss: 1.6158 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2542 - val_loss: 1.6156 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2627 - val_loss: 1.6154 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2331 - val_loss: 1.6154 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6113 - accuracy: 0.2500 - val_loss: 1.6152 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2627 - val_loss: 1.6152 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6116 - accuracy: 0.2585 - val_loss: 1.6149 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2542 - val_loss: 1.6148 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Node 5 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6365 - accuracy: 0.1610 - val_loss: 1.6362 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 3s/epoch - 341ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.1780 - val_loss: 1.6359 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.1949 - val_loss: 1.6357 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.1992 - val_loss: 1.6354 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2161 - val_loss: 1.6352 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2331 - val_loss: 1.6351 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2076 - val_loss: 1.6350 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.1610 - val_loss: 1.6349 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2034 - val_loss: 1.6348 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2076 - val_loss: 1.6346 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1949 - val_loss: 1.6344 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2246 - val_loss: 1.6343 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2415 - val_loss: 1.6341 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2331 - val_loss: 1.6338 - val_accuracy: 0.1186 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2034 - val_loss: 1.6337 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2161 - val_loss: 1.6335 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.1949 - val_loss: 1.6334 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2458 - val_loss: 1.6333 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2203 - val_loss: 1.6330 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2331 - val_loss: 1.6327 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2161 - val_loss: 1.6325 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2500 - val_loss: 1.6322 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2246 - val_loss: 1.6320 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.1949 - val_loss: 1.6316 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.1992 - val_loss: 1.6311 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2246 - val_loss: 1.6308 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2246 - val_loss: 1.6307 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2373 - val_loss: 1.6305 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.1992 - val_loss: 1.6304 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2500 - val_loss: 1.6303 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2161 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2373 - val_loss: 1.6301 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2500 - val_loss: 1.6300 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2373 - val_loss: 1.6298 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2076 - val_loss: 1.6296 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2246 - val_loss: 1.6293 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2246 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2331 - val_loss: 1.6291 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2669 - val_loss: 1.6290 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2627 - val_loss: 1.6289 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2627 - val_loss: 1.6288 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2669 - val_loss: 1.6286 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2119 - val_loss: 1.6284 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2458 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2246 - val_loss: 1.6280 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2119 - val_loss: 1.6277 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2458 - val_loss: 1.6275 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2288 - val_loss: 1.6274 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2627 - val_loss: 1.6272 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2034 - val_loss: 1.6271 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2712 - val_loss: 1.6269 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2415 - val_loss: 1.6268 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2161 - val_loss: 1.6266 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.1949 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2458 - val_loss: 1.6263 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2288 - val_loss: 1.6261 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2373 - val_loss: 1.6260 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2542 - val_loss: 1.6258 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2415 - val_loss: 1.6257 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2458 - val_loss: 1.6256 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2246 - val_loss: 1.6254 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2373 - val_loss: 1.6252 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2034 - val_loss: 1.6250 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2627 - val_loss: 1.6249 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2076 - val_loss: 1.6248 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2797 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 56ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2627 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2331 - val_loss: 1.6246 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2542 - val_loss: 1.6244 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.1992 - val_loss: 1.6243 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2373 - val_loss: 1.6242 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2246 - val_loss: 1.6241 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2712 - val_loss: 1.6240 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2585 - val_loss: 1.6238 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2119 - val_loss: 1.6236 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2669 - val_loss: 1.6235 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2585 - val_loss: 1.6235 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2161 - val_loss: 1.6234 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2415 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2669 - val_loss: 1.6231 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2415 - val_loss: 1.6230 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2415 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2458 - val_loss: 1.6227 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2161 - val_loss: 1.6225 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2458 - val_loss: 1.6223 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2203 - val_loss: 1.6222 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2458 - val_loss: 1.6221 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2246 - val_loss: 1.6219 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2246 - val_loss: 1.6218 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2458 - val_loss: 1.6216 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2331 - val_loss: 1.6215 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2627 - val_loss: 1.6214 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2458 - val_loss: 1.6212 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2288 - val_loss: 1.6211 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2754 - val_loss: 1.6209 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2500 - val_loss: 1.6208 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.1949 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2500 - val_loss: 1.6206 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Node 5 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6615 - accuracy: 0.1525 - val_loss: 1.6597 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 2s/epoch - 159ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6596 - accuracy: 0.2288 - val_loss: 1.6588 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6576 - accuracy: 0.2415 - val_loss: 1.6577 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6570 - accuracy: 0.2246 - val_loss: 1.6566 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6565 - accuracy: 0.2203 - val_loss: 1.6556 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6534 - accuracy: 0.2542 - val_loss: 1.6546 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6561 - accuracy: 0.2161 - val_loss: 1.6538 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6537 - accuracy: 0.2500 - val_loss: 1.6532 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6528 - accuracy: 0.2415 - val_loss: 1.6523 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6504 - accuracy: 0.2373 - val_loss: 1.6515 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6526 - accuracy: 0.2331 - val_loss: 1.6508 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6513 - accuracy: 0.2161 - val_loss: 1.6500 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6486 - accuracy: 0.2373 - val_loss: 1.6491 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6474 - accuracy: 0.2331 - val_loss: 1.6484 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6464 - accuracy: 0.2288 - val_loss: 1.6477 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6478 - accuracy: 0.2373 - val_loss: 1.6469 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.2288 - val_loss: 1.6462 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6453 - accuracy: 0.2331 - val_loss: 1.6456 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6461 - accuracy: 0.2331 - val_loss: 1.6448 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6438 - accuracy: 0.2288 - val_loss: 1.6441 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2331 - val_loss: 1.6435 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6442 - accuracy: 0.2415 - val_loss: 1.6429 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6427 - accuracy: 0.2373 - val_loss: 1.6422 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6425 - accuracy: 0.2331 - val_loss: 1.6418 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6394 - accuracy: 0.2373 - val_loss: 1.6409 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6388 - accuracy: 0.2373 - val_loss: 1.6402 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6401 - accuracy: 0.2246 - val_loss: 1.6397 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6365 - accuracy: 0.2415 - val_loss: 1.6391 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6349 - accuracy: 0.2373 - val_loss: 1.6386 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6398 - accuracy: 0.2288 - val_loss: 1.6380 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6370 - accuracy: 0.2331 - val_loss: 1.6375 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6379 - accuracy: 0.2458 - val_loss: 1.6370 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2373 - val_loss: 1.6366 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.2246 - val_loss: 1.6359 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2415 - val_loss: 1.6355 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2331 - val_loss: 1.6351 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.2373 - val_loss: 1.6346 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2373 - val_loss: 1.6341 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2373 - val_loss: 1.6335 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2373 - val_loss: 1.6332 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2373 - val_loss: 1.6328 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2712 - val_loss: 1.6324 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2331 - val_loss: 1.6320 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2585 - val_loss: 1.6318 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2331 - val_loss: 1.6313 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 83ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2415 - val_loss: 1.6309 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2246 - val_loss: 1.6305 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2500 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2458 - val_loss: 1.6299 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2458 - val_loss: 1.6295 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2542 - val_loss: 1.6290 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2669 - val_loss: 1.6285 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2288 - val_loss: 1.6280 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2669 - val_loss: 1.6278 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2373 - val_loss: 1.6274 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2458 - val_loss: 1.6270 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2203 - val_loss: 1.6267 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2627 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2458 - val_loss: 1.6261 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2585 - val_loss: 1.6256 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2669 - val_loss: 1.6253 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2542 - val_loss: 1.6251 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2415 - val_loss: 1.6249 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2331 - val_loss: 1.6248 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2500 - val_loss: 1.6244 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2542 - val_loss: 1.6242 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2500 - val_loss: 1.6240 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6137 - accuracy: 0.2542 - val_loss: 1.6236 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2373 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2458 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2754 - val_loss: 1.6232 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2415 - val_loss: 1.6231 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2542 - val_loss: 1.6230 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2331 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2458 - val_loss: 1.6226 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2627 - val_loss: 1.6223 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2373 - val_loss: 1.6219 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6115 - accuracy: 0.2669 - val_loss: 1.6216 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6058 - accuracy: 0.2500 - val_loss: 1.6215 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6081 - accuracy: 0.2500 - val_loss: 1.6215 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2458 - val_loss: 1.6214 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6076 - accuracy: 0.2712 - val_loss: 1.6215 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6001 - accuracy: 0.2415 - val_loss: 1.6211 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6065 - accuracy: 0.2627 - val_loss: 1.6209 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.2373 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6035 - accuracy: 0.2627 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6061 - accuracy: 0.2881 - val_loss: 1.6208 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2585 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.5987 - accuracy: 0.2542 - val_loss: 1.6204 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 81ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2500 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6089 - accuracy: 0.2500 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6069 - accuracy: 0.2585 - val_loss: 1.6205 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2415 - val_loss: 1.6203 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2331 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5971 - accuracy: 0.2839 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6044 - accuracy: 0.2627 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.5947 - accuracy: 0.2373 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.2627 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2627 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6054 - accuracy: 0.2627 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 1.2500e-05 - 61ms/epoch - 4ms/step\n",
      "Node 5 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6573 - accuracy: 0.2542 - val_loss: 1.6578 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 3s/epoch - 334ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2585 - val_loss: 1.6571 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.1992 - val_loss: 1.6564 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6568 - accuracy: 0.2415 - val_loss: 1.6557 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2119 - val_loss: 1.6549 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6548 - accuracy: 0.2458 - val_loss: 1.6542 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2542 - val_loss: 1.6536 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2458 - val_loss: 1.6530 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2373 - val_loss: 1.6524 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6520 - accuracy: 0.2542 - val_loss: 1.6517 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2203 - val_loss: 1.6510 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2203 - val_loss: 1.6505 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2373 - val_loss: 1.6501 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6482 - accuracy: 0.2373 - val_loss: 1.6496 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2246 - val_loss: 1.6491 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2246 - val_loss: 1.6486 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2500 - val_loss: 1.6481 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2373 - val_loss: 1.6476 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2415 - val_loss: 1.6471 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6456 - accuracy: 0.2288 - val_loss: 1.6466 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2331 - val_loss: 1.6460 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2458 - val_loss: 1.6455 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6469 - accuracy: 0.2331 - val_loss: 1.6452 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6443 - accuracy: 0.2458 - val_loss: 1.6447 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6449 - accuracy: 0.2458 - val_loss: 1.6443 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2246 - val_loss: 1.6440 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2415 - val_loss: 1.6436 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6427 - accuracy: 0.2458 - val_loss: 1.6432 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.2415 - val_loss: 1.6428 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2246 - val_loss: 1.6425 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2331 - val_loss: 1.6421 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2458 - val_loss: 1.6417 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2669 - val_loss: 1.6412 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2331 - val_loss: 1.6407 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2288 - val_loss: 1.6402 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2373 - val_loss: 1.6398 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2542 - val_loss: 1.6393 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2415 - val_loss: 1.6390 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2331 - val_loss: 1.6387 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2415 - val_loss: 1.6383 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2500 - val_loss: 1.6380 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2415 - val_loss: 1.6376 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.2246 - val_loss: 1.6374 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2669 - val_loss: 1.6371 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2373 - val_loss: 1.6368 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2203 - val_loss: 1.6364 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2585 - val_loss: 1.6362 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2331 - val_loss: 1.6360 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 61ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2373 - val_loss: 1.6358 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2288 - val_loss: 1.6354 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2415 - val_loss: 1.6352 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2288 - val_loss: 1.6348 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2203 - val_loss: 1.6345 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2500 - val_loss: 1.6341 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2331 - val_loss: 1.6336 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2161 - val_loss: 1.6334 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2585 - val_loss: 1.6331 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2500 - val_loss: 1.6327 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2415 - val_loss: 1.6326 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2542 - val_loss: 1.6324 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2331 - val_loss: 1.6322 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2585 - val_loss: 1.6320 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2246 - val_loss: 1.6318 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2458 - val_loss: 1.6315 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2373 - val_loss: 1.6310 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2246 - val_loss: 1.6306 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2458 - val_loss: 1.6303 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2331 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2373 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2458 - val_loss: 1.6300 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2627 - val_loss: 1.6299 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2415 - val_loss: 1.6296 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2500 - val_loss: 1.6293 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2288 - val_loss: 1.6290 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2331 - val_loss: 1.6287 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2331 - val_loss: 1.6285 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2669 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2500 - val_loss: 1.6280 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2415 - val_loss: 1.6278 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2500 - val_loss: 1.6277 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2585 - val_loss: 1.6275 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2627 - val_loss: 1.6272 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2119 - val_loss: 1.6271 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2627 - val_loss: 1.6270 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2458 - val_loss: 1.6269 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2542 - val_loss: 1.6267 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6264 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2288 - val_loss: 1.6262 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2924 - val_loss: 1.6260 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2542 - val_loss: 1.6258 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2712 - val_loss: 1.6255 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2542 - val_loss: 1.6253 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2627 - val_loss: 1.6252 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2331 - val_loss: 1.6250 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.2627 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2500 - val_loss: 1.6244 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.2458 - val_loss: 1.6241 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2500 - val_loss: 1.6237 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6072 - accuracy: 0.2881 - val_loss: 1.6234 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 60ms/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6129 - accuracy: 0.2627 - val_loss: 1.6232 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Node 5 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 5 - Best Validation Accuracy: 0.2712\n",
      "Best model saved for Node 5 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_5.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_6_dataset.csv\n",
      "Node 6 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6356 - accuracy: 0.2500 - val_loss: 1.6353 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 2s/epoch - 122ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6357 - accuracy: 0.2277 - val_loss: 1.6351 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 27ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6359 - accuracy: 0.1830 - val_loss: 1.6348 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 26ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6336 - accuracy: 0.2188 - val_loss: 1.6346 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 28ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6342 - accuracy: 0.2545 - val_loss: 1.6343 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 28ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6339 - accuracy: 0.2098 - val_loss: 1.6340 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 28ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6326 - accuracy: 0.2455 - val_loss: 1.6338 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6331 - accuracy: 0.2009 - val_loss: 1.6336 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2455 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6326 - accuracy: 0.2589 - val_loss: 1.6332 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2366 - val_loss: 1.6329 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2277 - val_loss: 1.6327 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2232 - val_loss: 1.6324 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2232 - val_loss: 1.6322 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2143 - val_loss: 1.6320 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2545 - val_loss: 1.6317 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2500 - val_loss: 1.6315 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2188 - val_loss: 1.6312 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2321 - val_loss: 1.6310 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6270 - accuracy: 0.2455 - val_loss: 1.6307 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2411 - val_loss: 1.6306 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2500 - val_loss: 1.6305 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2411 - val_loss: 1.6303 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2366 - val_loss: 1.6301 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2857 - val_loss: 1.6300 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2366 - val_loss: 1.6298 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2411 - val_loss: 1.6297 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2411 - val_loss: 1.6296 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6249 - accuracy: 0.2366 - val_loss: 1.6294 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2634 - val_loss: 1.6293 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6292 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2054 - val_loss: 1.6291 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2411 - val_loss: 1.6290 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2589 - val_loss: 1.6288 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2768 - val_loss: 1.6287 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2411 - val_loss: 1.6287 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2634 - val_loss: 1.6287 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6209 - accuracy: 0.2634 - val_loss: 1.6285 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2455 - val_loss: 1.6285 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2589 - val_loss: 1.6284 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2679 - val_loss: 1.6282 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6199 - accuracy: 0.2812 - val_loss: 1.6280 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2768 - val_loss: 1.6280 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2321 - val_loss: 1.6279 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6223 - accuracy: 0.2411 - val_loss: 1.6279 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2679 - val_loss: 1.6278 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6223 - accuracy: 0.2455 - val_loss: 1.6278 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2232 - val_loss: 1.6277 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2634 - val_loss: 1.6277 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6181 - accuracy: 0.2723 - val_loss: 1.6276 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2366 - val_loss: 1.6276 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2455 - val_loss: 1.6276 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6159 - accuracy: 0.2455 - val_loss: 1.6276 - val_accuracy: 0.1579 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2455 - val_loss: 1.6275 - val_accuracy: 0.1579 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6197 - accuracy: 0.2679 - val_loss: 1.6275 - val_accuracy: 0.1579 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6128 - accuracy: 0.3036 - val_loss: 1.6275 - val_accuracy: 0.1579 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2321 - val_loss: 1.6275 - val_accuracy: 0.1579 - lr: 2.5000e-05 - 33ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2812 - val_loss: 1.6275 - val_accuracy: 0.1579 - lr: 2.5000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2366 - val_loss: 1.6275 - val_accuracy: 0.1754 - lr: 2.5000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2857 - val_loss: 1.6275 - val_accuracy: 0.1754 - lr: 1.2500e-05 - 33ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2455 - val_loss: 1.6275 - val_accuracy: 0.1754 - lr: 1.2500e-05 - 35ms/epoch - 3ms/step\n",
      "Node 6 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6337 - accuracy: 0.2321 - val_loss: 1.6346 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 2s/epoch - 301ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.1473 - val_loss: 1.6344 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.1875 - val_loss: 1.6343 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 18ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2232 - val_loss: 1.6342 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 18ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.2366 - val_loss: 1.6341 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 17ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.1964 - val_loss: 1.6339 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.1696 - val_loss: 1.6337 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 18ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6339 - accuracy: 0.2411 - val_loss: 1.6336 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.2500 - val_loss: 1.6335 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.2188 - val_loss: 1.6334 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2054 - val_loss: 1.6333 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.1964 - val_loss: 1.6332 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2500 - val_loss: 1.6330 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.1786 - val_loss: 1.6328 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.1920 - val_loss: 1.6327 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6324 - accuracy: 0.2366 - val_loss: 1.6325 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2589 - val_loss: 1.6323 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2321 - val_loss: 1.6321 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6301 - accuracy: 0.2500 - val_loss: 1.6320 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2500 - val_loss: 1.6318 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2009 - val_loss: 1.6317 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2232 - val_loss: 1.6315 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2455 - val_loss: 1.6314 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6305 - accuracy: 0.2589 - val_loss: 1.6313 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2366 - val_loss: 1.6312 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2321 - val_loss: 1.6311 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2321 - val_loss: 1.6310 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2500 - val_loss: 1.6308 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2098 - val_loss: 1.6307 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2679 - val_loss: 1.6305 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2277 - val_loss: 1.6304 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2589 - val_loss: 1.6304 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2455 - val_loss: 1.6303 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6293 - accuracy: 0.1875 - val_loss: 1.6302 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2143 - val_loss: 1.6301 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2366 - val_loss: 1.6300 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2188 - val_loss: 1.6298 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2277 - val_loss: 1.6297 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2902 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2366 - val_loss: 1.6295 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6282 - accuracy: 0.2321 - val_loss: 1.6293 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2455 - val_loss: 1.6292 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2188 - val_loss: 1.6291 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2455 - val_loss: 1.6289 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2545 - val_loss: 1.6288 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2277 - val_loss: 1.6286 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2411 - val_loss: 1.6285 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2455 - val_loss: 1.6283 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2455 - val_loss: 1.6282 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2321 - val_loss: 1.6280 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.2411 - val_loss: 1.6279 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2589 - val_loss: 1.6278 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2455 - val_loss: 1.6277 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2232 - val_loss: 1.6277 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2500 - val_loss: 1.6276 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2366 - val_loss: 1.6275 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2411 - val_loss: 1.6273 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2500 - val_loss: 1.6272 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2366 - val_loss: 1.6271 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2277 - val_loss: 1.6270 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2455 - val_loss: 1.6269 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2277 - val_loss: 1.6268 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2545 - val_loss: 1.6267 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2500 - val_loss: 1.6266 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2455 - val_loss: 1.6265 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6243 - accuracy: 0.2277 - val_loss: 1.6264 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2232 - val_loss: 1.6263 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2232 - val_loss: 1.6262 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2098 - val_loss: 1.6261 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2321 - val_loss: 1.6260 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2589 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2634 - val_loss: 1.6259 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2723 - val_loss: 1.6259 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6222 - accuracy: 0.2455 - val_loss: 1.6258 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2500 - val_loss: 1.6257 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2500 - val_loss: 1.6257 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2277 - val_loss: 1.6256 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6222 - accuracy: 0.2455 - val_loss: 1.6255 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2411 - val_loss: 1.6255 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2411 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6226 - accuracy: 0.2277 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2455 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2277 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2232 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6227 - accuracy: 0.2366 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2411 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6204 - accuracy: 0.2634 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2679 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2321 - val_loss: 1.6247 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6193 - accuracy: 0.2589 - val_loss: 1.6246 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2411 - val_loss: 1.6245 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2455 - val_loss: 1.6245 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6198 - accuracy: 0.2411 - val_loss: 1.6245 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2679 - val_loss: 1.6244 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2366 - val_loss: 1.6243 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2589 - val_loss: 1.6243 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2411 - val_loss: 1.6242 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2679 - val_loss: 1.6242 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2500 - val_loss: 1.6240 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6179 - accuracy: 0.2232 - val_loss: 1.6240 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Node 6 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6574 - accuracy: 0.2455 - val_loss: 1.6577 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 2s/epoch - 124ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6572 - accuracy: 0.2679 - val_loss: 1.6571 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6564 - accuracy: 0.2366 - val_loss: 1.6564 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6551 - accuracy: 0.2321 - val_loss: 1.6557 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6546 - accuracy: 0.2277 - val_loss: 1.6550 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6531 - accuracy: 0.2054 - val_loss: 1.6544 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6500 - accuracy: 0.2455 - val_loss: 1.6537 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6510 - accuracy: 0.2589 - val_loss: 1.6532 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6514 - accuracy: 0.2321 - val_loss: 1.6528 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6481 - accuracy: 0.2366 - val_loss: 1.6523 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6468 - accuracy: 0.2589 - val_loss: 1.6518 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6472 - accuracy: 0.2500 - val_loss: 1.6513 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6474 - accuracy: 0.2455 - val_loss: 1.6507 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6466 - accuracy: 0.2411 - val_loss: 1.6503 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6434 - accuracy: 0.2411 - val_loss: 1.6498 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6485 - accuracy: 0.2143 - val_loss: 1.6493 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6392 - accuracy: 0.2723 - val_loss: 1.6489 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6421 - accuracy: 0.2188 - val_loss: 1.6485 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6418 - accuracy: 0.2634 - val_loss: 1.6481 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6431 - accuracy: 0.2411 - val_loss: 1.6478 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6426 - accuracy: 0.2679 - val_loss: 1.6474 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6413 - accuracy: 0.2321 - val_loss: 1.6470 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6440 - accuracy: 0.2366 - val_loss: 1.6466 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6380 - accuracy: 0.2411 - val_loss: 1.6462 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6386 - accuracy: 0.2455 - val_loss: 1.6459 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6396 - accuracy: 0.2366 - val_loss: 1.6455 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6348 - accuracy: 0.3080 - val_loss: 1.6452 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6377 - accuracy: 0.2500 - val_loss: 1.6449 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6347 - accuracy: 0.2768 - val_loss: 1.6446 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6398 - accuracy: 0.2232 - val_loss: 1.6444 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6361 - accuracy: 0.2366 - val_loss: 1.6442 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6348 - accuracy: 0.2321 - val_loss: 1.6440 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6335 - accuracy: 0.2545 - val_loss: 1.6437 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6324 - accuracy: 0.2679 - val_loss: 1.6435 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6308 - accuracy: 0.2455 - val_loss: 1.6435 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2411 - val_loss: 1.6434 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.2679 - val_loss: 1.6433 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6339 - accuracy: 0.2679 - val_loss: 1.6431 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2455 - val_loss: 1.6427 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6310 - accuracy: 0.2366 - val_loss: 1.6426 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6307 - accuracy: 0.2366 - val_loss: 1.6424 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6278 - accuracy: 0.2366 - val_loss: 1.6422 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2455 - val_loss: 1.6420 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2455 - val_loss: 1.6420 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2812 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2679 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6232 - accuracy: 0.2634 - val_loss: 1.6419 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 51ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2188 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 51ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2545 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2589 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 2.5000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6266 - accuracy: 0.2143 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 2.5000e-05 - 51ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2366 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 2.5000e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2679 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 1.2500e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6262 - accuracy: 0.2232 - val_loss: 1.6420 - val_accuracy: 0.2105 - lr: 1.2500e-05 - 52ms/epoch - 4ms/step\n",
      "Node 6 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6620 - accuracy: 0.1786 - val_loss: 1.6623 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 2s/epoch - 292ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6601 - accuracy: 0.1920 - val_loss: 1.6620 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6597 - accuracy: 0.2098 - val_loss: 1.6616 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6593 - accuracy: 0.2098 - val_loss: 1.6612 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6578 - accuracy: 0.2679 - val_loss: 1.6607 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6570 - accuracy: 0.2143 - val_loss: 1.6601 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6573 - accuracy: 0.2455 - val_loss: 1.6595 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6546 - accuracy: 0.2723 - val_loss: 1.6590 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6539 - accuracy: 0.2455 - val_loss: 1.6584 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6551 - accuracy: 0.2545 - val_loss: 1.6579 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6540 - accuracy: 0.2634 - val_loss: 1.6575 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6542 - accuracy: 0.2500 - val_loss: 1.6572 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6523 - accuracy: 0.2143 - val_loss: 1.6568 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6496 - accuracy: 0.2277 - val_loss: 1.6563 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6500 - accuracy: 0.2679 - val_loss: 1.6560 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6515 - accuracy: 0.2545 - val_loss: 1.6557 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6496 - accuracy: 0.2545 - val_loss: 1.6555 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6491 - accuracy: 0.2455 - val_loss: 1.6551 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6506 - accuracy: 0.2098 - val_loss: 1.6548 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6474 - accuracy: 0.2455 - val_loss: 1.6544 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6450 - accuracy: 0.2634 - val_loss: 1.6541 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6462 - accuracy: 0.2232 - val_loss: 1.6538 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6474 - accuracy: 0.2679 - val_loss: 1.6535 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 54ms/epoch - 8ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2321 - val_loss: 1.6532 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2679 - val_loss: 1.6529 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6450 - accuracy: 0.2411 - val_loss: 1.6527 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6388 - accuracy: 0.2723 - val_loss: 1.6525 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6442 - accuracy: 0.2812 - val_loss: 1.6524 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6432 - accuracy: 0.2455 - val_loss: 1.6523 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6431 - accuracy: 0.2455 - val_loss: 1.6521 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6401 - accuracy: 0.2277 - val_loss: 1.6519 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6431 - accuracy: 0.2054 - val_loss: 1.6517 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6413 - accuracy: 0.2679 - val_loss: 1.6515 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6376 - accuracy: 0.2768 - val_loss: 1.6513 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6397 - accuracy: 0.2277 - val_loss: 1.6511 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.2277 - val_loss: 1.6510 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6362 - accuracy: 0.2545 - val_loss: 1.6508 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6409 - accuracy: 0.2054 - val_loss: 1.6507 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6402 - accuracy: 0.2634 - val_loss: 1.6506 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6399 - accuracy: 0.2500 - val_loss: 1.6505 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6430 - accuracy: 0.2143 - val_loss: 1.6503 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6406 - accuracy: 0.2277 - val_loss: 1.6501 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6385 - accuracy: 0.2723 - val_loss: 1.6500 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6390 - accuracy: 0.2411 - val_loss: 1.6499 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6362 - accuracy: 0.2411 - val_loss: 1.6497 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6361 - accuracy: 0.2366 - val_loss: 1.6495 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.2634 - val_loss: 1.6495 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.2455 - val_loss: 1.6494 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.2321 - val_loss: 1.6493 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6305 - accuracy: 0.2634 - val_loss: 1.6493 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2723 - val_loss: 1.6492 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6366 - accuracy: 0.2545 - val_loss: 1.6491 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6363 - accuracy: 0.2723 - val_loss: 1.6491 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2455 - val_loss: 1.6491 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2768 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2321 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2902 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6282 - accuracy: 0.2768 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2321 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 5.0000e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 5.0000e-05 - 34ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6352 - accuracy: 0.2589 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 5.0000e-05 - 37ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2500 - val_loss: 1.6489 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 35ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2679 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2366 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2589 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 35ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6324 - accuracy: 0.2321 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2411 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 2.5000e-05 - 37ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6282 - accuracy: 0.2545 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.2500e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2545 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.2500e-05 - 35ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "7/7 - 0s - loss: 1.6227 - accuracy: 0.2679 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.2500e-05 - 36ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2545 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 6.2500e-06 - 34ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2589 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 6.2500e-06 - 38ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2500 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 6.2500e-06 - 36ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2455 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 3.1250e-06 - 36ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2634 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 3.1250e-06 - 35ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2455 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 3.1250e-06 - 54ms/epoch - 8ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2812 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.5625e-06 - 36ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2411 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.5625e-06 - 35ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "7/7 - 0s - loss: 1.6222 - accuracy: 0.2679 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 1.5625e-06 - 35ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2545 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 7.8125e-07 - 35ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.3036 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 7.8125e-07 - 35ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2812 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 7.8125e-07 - 35ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2455 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 3.9062e-07 - 34ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2589 - val_loss: 1.6488 - val_accuracy: 0.1930 - lr: 3.9062e-07 - 36ms/epoch - 5ms/step\n",
      "Node 6 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 6 - Best Validation Accuracy: 0.2632\n",
      "Best model saved for Node 6 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_6.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_7_dataset.csv\n",
      "Node 7 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6364 - accuracy: 0.2208 - val_loss: 1.6355 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 2s/epoch - 114ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.1958 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.1917 - val_loss: 1.6346 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2042 - val_loss: 1.6342 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2167 - val_loss: 1.6338 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.2083 - val_loss: 1.6337 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.2125 - val_loss: 1.6334 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6328 - accuracy: 0.1917 - val_loss: 1.6329 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.2125 - val_loss: 1.6326 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2000 - val_loss: 1.6320 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.2292 - val_loss: 1.6316 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2167 - val_loss: 1.6312 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2375 - val_loss: 1.6308 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.1958 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2042 - val_loss: 1.6303 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2042 - val_loss: 1.6300 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2125 - val_loss: 1.6297 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2292 - val_loss: 1.6295 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2208 - val_loss: 1.6292 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2208 - val_loss: 1.6289 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2000 - val_loss: 1.6286 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2042 - val_loss: 1.6284 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2250 - val_loss: 1.6280 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2000 - val_loss: 1.6277 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2000 - val_loss: 1.6274 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2208 - val_loss: 1.6271 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2208 - val_loss: 1.6268 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2417 - val_loss: 1.6266 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2250 - val_loss: 1.6265 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2125 - val_loss: 1.6263 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2250 - val_loss: 1.6262 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2167 - val_loss: 1.6260 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.1958 - val_loss: 1.6261 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2208 - val_loss: 1.6261 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2250 - val_loss: 1.6260 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2167 - val_loss: 1.6258 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2167 - val_loss: 1.6257 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2333 - val_loss: 1.6256 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2250 - val_loss: 1.6255 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.1958 - val_loss: 1.6252 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2083 - val_loss: 1.6251 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2208 - val_loss: 1.6250 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2042 - val_loss: 1.6249 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2333 - val_loss: 1.6248 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.1833 - val_loss: 1.6247 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2458 - val_loss: 1.6247 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2167 - val_loss: 1.6246 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2208 - val_loss: 1.6245 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2083 - val_loss: 1.6244 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.1833 - val_loss: 1.6242 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2042 - val_loss: 1.6241 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2250 - val_loss: 1.6241 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2083 - val_loss: 1.6240 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2292 - val_loss: 1.6239 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2333 - val_loss: 1.6238 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2292 - val_loss: 1.6237 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2167 - val_loss: 1.6236 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.1917 - val_loss: 1.6236 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.1958 - val_loss: 1.6236 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2292 - val_loss: 1.6235 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 37ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2083 - val_loss: 1.6235 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6137 - accuracy: 0.2500 - val_loss: 1.6234 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2167 - val_loss: 1.6234 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2417 - val_loss: 1.6234 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.2333 - val_loss: 1.6234 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2292 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 2.5000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2208 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.2500e-05 - 37ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2250 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.2500e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2208 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.2500e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2250 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 6.2500e-06 - 37ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2167 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 6.2500e-06 - 36ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2167 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 6.2500e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2333 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 3.1250e-06 - 55ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2500 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 3.1250e-06 - 36ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2417 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 3.1250e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2167 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.5625e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2375 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.5625e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2458 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.5625e-06 - 39ms/epoch - 3ms/step\n",
      "Node 7 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6358 - accuracy: 0.1917 - val_loss: 1.6344 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 3s/epoch - 337ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2042 - val_loss: 1.6340 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2000 - val_loss: 1.6336 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.1583 - val_loss: 1.6333 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.1917 - val_loss: 1.6330 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2208 - val_loss: 1.6327 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2292 - val_loss: 1.6325 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2000 - val_loss: 1.6322 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.1792 - val_loss: 1.6320 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2333 - val_loss: 1.6317 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2208 - val_loss: 1.6315 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2083 - val_loss: 1.6313 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2292 - val_loss: 1.6310 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2333 - val_loss: 1.6306 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2292 - val_loss: 1.6303 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2667 - val_loss: 1.6300 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2333 - val_loss: 1.6297 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2625 - val_loss: 1.6295 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2333 - val_loss: 1.6293 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.1875 - val_loss: 1.6291 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2458 - val_loss: 1.6289 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.1958 - val_loss: 1.6286 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2083 - val_loss: 1.6282 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2958 - val_loss: 1.6278 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2417 - val_loss: 1.6275 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2250 - val_loss: 1.6271 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2042 - val_loss: 1.6268 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2250 - val_loss: 1.6265 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2333 - val_loss: 1.6263 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2417 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2042 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2375 - val_loss: 1.6256 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2375 - val_loss: 1.6253 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2250 - val_loss: 1.6251 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2000 - val_loss: 1.6248 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2333 - val_loss: 1.6246 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2708 - val_loss: 1.6244 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2458 - val_loss: 1.6241 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2125 - val_loss: 1.6239 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2542 - val_loss: 1.6237 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2333 - val_loss: 1.6236 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2167 - val_loss: 1.6234 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2042 - val_loss: 1.6232 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.1917 - val_loss: 1.6231 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2125 - val_loss: 1.6230 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2375 - val_loss: 1.6229 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2250 - val_loss: 1.6228 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2000 - val_loss: 1.6227 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2500 - val_loss: 1.6225 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2125 - val_loss: 1.6223 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2417 - val_loss: 1.6221 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2250 - val_loss: 1.6220 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.3000 - val_loss: 1.6217 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2042 - val_loss: 1.6215 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2208 - val_loss: 1.6214 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.1958 - val_loss: 1.6212 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2458 - val_loss: 1.6210 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2333 - val_loss: 1.6208 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2667 - val_loss: 1.6207 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.2250 - val_loss: 1.6205 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2167 - val_loss: 1.6203 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2375 - val_loss: 1.6202 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2417 - val_loss: 1.6201 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2500 - val_loss: 1.6199 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2208 - val_loss: 1.6198 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2417 - val_loss: 1.6196 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2375 - val_loss: 1.6194 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2417 - val_loss: 1.6192 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2250 - val_loss: 1.6191 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2375 - val_loss: 1.6189 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2250 - val_loss: 1.6188 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.1792 - val_loss: 1.6187 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6102 - accuracy: 0.2958 - val_loss: 1.6186 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6143 - accuracy: 0.2125 - val_loss: 1.6185 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2083 - val_loss: 1.6184 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.1833 - val_loss: 1.6183 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2458 - val_loss: 1.6182 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2250 - val_loss: 1.6181 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2292 - val_loss: 1.6180 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2292 - val_loss: 1.6179 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.1917 - val_loss: 1.6178 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2667 - val_loss: 1.6176 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6121 - accuracy: 0.2708 - val_loss: 1.6174 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2458 - val_loss: 1.6173 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2792 - val_loss: 1.6172 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2583 - val_loss: 1.6171 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2125 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6081 - accuracy: 0.2292 - val_loss: 1.6169 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.2208 - val_loss: 1.6168 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6116 - accuracy: 0.2208 - val_loss: 1.6167 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6085 - accuracy: 0.2792 - val_loss: 1.6165 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6080 - accuracy: 0.2250 - val_loss: 1.6164 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6098 - accuracy: 0.2667 - val_loss: 1.6163 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2167 - val_loss: 1.6163 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.2333 - val_loss: 1.6162 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2125 - val_loss: 1.6161 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2208 - val_loss: 1.6160 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2333 - val_loss: 1.6160 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6043 - accuracy: 0.2625 - val_loss: 1.6159 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6026 - accuracy: 0.2542 - val_loss: 1.6157 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Node 7 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6605 - accuracy: 0.1833 - val_loss: 1.6593 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 2s/epoch - 114ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6584 - accuracy: 0.2167 - val_loss: 1.6584 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6572 - accuracy: 0.2083 - val_loss: 1.6574 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6575 - accuracy: 0.2083 - val_loss: 1.6564 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6541 - accuracy: 0.2375 - val_loss: 1.6554 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6551 - accuracy: 0.2333 - val_loss: 1.6543 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6513 - accuracy: 0.2292 - val_loss: 1.6535 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6520 - accuracy: 0.2417 - val_loss: 1.6525 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6525 - accuracy: 0.1917 - val_loss: 1.6516 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6510 - accuracy: 0.2292 - val_loss: 1.6507 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6480 - accuracy: 0.2083 - val_loss: 1.6497 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6486 - accuracy: 0.2250 - val_loss: 1.6488 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6455 - accuracy: 0.2667 - val_loss: 1.6479 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6460 - accuracy: 0.2083 - val_loss: 1.6469 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6445 - accuracy: 0.2500 - val_loss: 1.6461 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6455 - accuracy: 0.2417 - val_loss: 1.6452 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6396 - accuracy: 0.2500 - val_loss: 1.6444 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2208 - val_loss: 1.6437 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6391 - accuracy: 0.2583 - val_loss: 1.6431 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6425 - accuracy: 0.2333 - val_loss: 1.6423 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6355 - accuracy: 0.2583 - val_loss: 1.6416 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6405 - accuracy: 0.2292 - val_loss: 1.6411 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6380 - accuracy: 0.2667 - val_loss: 1.6405 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6359 - accuracy: 0.2167 - val_loss: 1.6397 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.2458 - val_loss: 1.6392 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6328 - accuracy: 0.2333 - val_loss: 1.6384 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2625 - val_loss: 1.6379 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6358 - accuracy: 0.2458 - val_loss: 1.6373 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.2375 - val_loss: 1.6367 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2292 - val_loss: 1.6363 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.2333 - val_loss: 1.6359 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2417 - val_loss: 1.6354 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6318 - accuracy: 0.2375 - val_loss: 1.6349 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2542 - val_loss: 1.6344 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2500 - val_loss: 1.6340 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2500 - val_loss: 1.6335 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2292 - val_loss: 1.6330 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6251 - accuracy: 0.2083 - val_loss: 1.6327 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2375 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2125 - val_loss: 1.6320 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2375 - val_loss: 1.6317 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.2375 - val_loss: 1.6314 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2208 - val_loss: 1.6309 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2375 - val_loss: 1.6308 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2250 - val_loss: 1.6305 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2500 - val_loss: 1.6302 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2417 - val_loss: 1.6298 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2458 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6166 - accuracy: 0.2583 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2292 - val_loss: 1.6289 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2375 - val_loss: 1.6288 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2250 - val_loss: 1.6287 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2667 - val_loss: 1.6286 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2333 - val_loss: 1.6285 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2167 - val_loss: 1.6280 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.2417 - val_loss: 1.6276 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2417 - val_loss: 1.6271 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2500 - val_loss: 1.6270 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2625 - val_loss: 1.6269 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6069 - accuracy: 0.2375 - val_loss: 1.6266 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6152 - accuracy: 0.2208 - val_loss: 1.6266 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2333 - val_loss: 1.6266 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6136 - accuracy: 0.2500 - val_loss: 1.6265 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2542 - val_loss: 1.6264 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 56ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2458 - val_loss: 1.6263 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 56ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2292 - val_loss: 1.6263 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2625 - val_loss: 1.6264 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2417 - val_loss: 1.6263 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 57ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6010 - accuracy: 0.2875 - val_loss: 1.6262 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6140 - accuracy: 0.2333 - val_loss: 1.6262 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6059 - accuracy: 0.2625 - val_loss: 1.6262 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6136 - accuracy: 0.2667 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 2.5000e-05 - 76ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2542 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 56ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2542 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2667 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6020 - accuracy: 0.2875 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6039 - accuracy: 0.2625 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 56ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6065 - accuracy: 0.2333 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 58ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6062 - accuracy: 0.2667 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 56ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6025 - accuracy: 0.2625 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 57ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.2417 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 58ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6078 - accuracy: 0.2833 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 55ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2625 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 6.2500e-06 - 68ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6080 - accuracy: 0.2625 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 3.1250e-06 - 60ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2417 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 3.1250e-06 - 58ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.5980 - accuracy: 0.3083 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 3.1250e-06 - 57ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.5995 - accuracy: 0.2583 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.5625e-06 - 62ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2167 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.5625e-06 - 61ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2250 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.5625e-06 - 58ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6099 - accuracy: 0.2708 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 7.8125e-07 - 58ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2750 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 7.8125e-07 - 58ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2250 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 7.8125e-07 - 56ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2250 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 3.9062e-07 - 55ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2167 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 3.9062e-07 - 54ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2583 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 3.9062e-07 - 56ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2583 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.9531e-07 - 57ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6019 - accuracy: 0.2917 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.9531e-07 - 55ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2375 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.9531e-07 - 57ms/epoch - 4ms/step\n",
      "Node 7 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6596 - accuracy: 0.2250 - val_loss: 1.6587 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 3s/epoch - 349ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.1958 - val_loss: 1.6580 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6567 - accuracy: 0.2292 - val_loss: 1.6574 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6572 - accuracy: 0.2208 - val_loss: 1.6567 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2417 - val_loss: 1.6560 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6556 - accuracy: 0.2208 - val_loss: 1.6555 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6537 - accuracy: 0.2417 - val_loss: 1.6550 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6546 - accuracy: 0.2375 - val_loss: 1.6544 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6503 - accuracy: 0.2500 - val_loss: 1.6538 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6529 - accuracy: 0.2500 - val_loss: 1.6533 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2583 - val_loss: 1.6527 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2125 - val_loss: 1.6522 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 8ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2250 - val_loss: 1.6516 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2500 - val_loss: 1.6510 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2375 - val_loss: 1.6504 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2167 - val_loss: 1.6500 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2292 - val_loss: 1.6495 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2167 - val_loss: 1.6488 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2167 - val_loss: 1.6482 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2292 - val_loss: 1.6476 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2417 - val_loss: 1.6471 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2375 - val_loss: 1.6467 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2333 - val_loss: 1.6462 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2333 - val_loss: 1.6458 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2208 - val_loss: 1.6453 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2292 - val_loss: 1.6449 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6398 - accuracy: 0.2375 - val_loss: 1.6445 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2208 - val_loss: 1.6440 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2250 - val_loss: 1.6436 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2083 - val_loss: 1.6431 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6387 - accuracy: 0.2292 - val_loss: 1.6427 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6366 - accuracy: 0.2458 - val_loss: 1.6423 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 77ms/epoch - 10ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2375 - val_loss: 1.6420 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2458 - val_loss: 1.6416 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6389 - accuracy: 0.2208 - val_loss: 1.6413 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2458 - val_loss: 1.6408 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2542 - val_loss: 1.6405 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2250 - val_loss: 1.6401 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2333 - val_loss: 1.6396 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2250 - val_loss: 1.6391 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2042 - val_loss: 1.6389 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2833 - val_loss: 1.6385 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2125 - val_loss: 1.6382 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2208 - val_loss: 1.6379 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2083 - val_loss: 1.6376 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2458 - val_loss: 1.6373 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6371 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2250 - val_loss: 1.6368 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2333 - val_loss: 1.6365 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2500 - val_loss: 1.6362 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2292 - val_loss: 1.6360 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2417 - val_loss: 1.6358 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.1958 - val_loss: 1.6355 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2333 - val_loss: 1.6352 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2625 - val_loss: 1.6349 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2583 - val_loss: 1.6346 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2292 - val_loss: 1.6343 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2542 - val_loss: 1.6342 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2333 - val_loss: 1.6340 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2250 - val_loss: 1.6338 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2292 - val_loss: 1.6336 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2417 - val_loss: 1.6334 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2500 - val_loss: 1.6332 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2375 - val_loss: 1.6331 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2375 - val_loss: 1.6330 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2292 - val_loss: 1.6327 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2375 - val_loss: 1.6325 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2292 - val_loss: 1.6323 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2500 - val_loss: 1.6321 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2333 - val_loss: 1.6319 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2375 - val_loss: 1.6318 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2250 - val_loss: 1.6317 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2083 - val_loss: 1.6316 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2542 - val_loss: 1.6314 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6131 - accuracy: 0.2583 - val_loss: 1.6312 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2375 - val_loss: 1.6310 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2625 - val_loss: 1.6309 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2500 - val_loss: 1.6308 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2375 - val_loss: 1.6307 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2583 - val_loss: 1.6306 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2167 - val_loss: 1.6305 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2333 - val_loss: 1.6303 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6131 - accuracy: 0.2583 - val_loss: 1.6302 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2583 - val_loss: 1.6301 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.2208 - val_loss: 1.6300 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2250 - val_loss: 1.6299 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2125 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6073 - accuracy: 0.2500 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6138 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6083 - accuracy: 0.2583 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6072 - accuracy: 0.2417 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6087 - accuracy: 0.2417 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2125 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2625 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 48ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2292 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6093 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2250 - val_loss: 1.6294 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6052 - accuracy: 0.2458 - val_loss: 1.6293 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 48ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6063 - accuracy: 0.2458 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Node 7 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 7 - Best Validation Accuracy: 0.3115\n",
      "Best model saved for Node 7 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_7.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_8_dataset.csv\n",
      "Node 8 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6367 - accuracy: 0.1741 - val_loss: 1.6364 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 2s/epoch - 131ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6364 - accuracy: 0.1920 - val_loss: 1.6361 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6358 - accuracy: 0.2321 - val_loss: 1.6357 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 28ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6356 - accuracy: 0.2054 - val_loss: 1.6355 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6348 - accuracy: 0.1741 - val_loss: 1.6352 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6350 - accuracy: 0.2232 - val_loss: 1.6351 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6347 - accuracy: 0.2188 - val_loss: 1.6347 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6334 - accuracy: 0.1741 - val_loss: 1.6345 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6341 - accuracy: 0.2455 - val_loss: 1.6342 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6323 - accuracy: 0.2366 - val_loss: 1.6338 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6327 - accuracy: 0.2232 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2589 - val_loss: 1.6331 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6317 - accuracy: 0.2143 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2366 - val_loss: 1.6325 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2455 - val_loss: 1.6323 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6308 - accuracy: 0.2098 - val_loss: 1.6318 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6315 - accuracy: 0.2232 - val_loss: 1.6316 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2411 - val_loss: 1.6314 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6291 - accuracy: 0.2411 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6304 - accuracy: 0.2232 - val_loss: 1.6308 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6296 - accuracy: 0.2545 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2277 - val_loss: 1.6302 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2321 - val_loss: 1.6299 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6280 - accuracy: 0.2366 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2455 - val_loss: 1.6291 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6266 - accuracy: 0.2009 - val_loss: 1.6288 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6276 - accuracy: 0.2232 - val_loss: 1.6286 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6242 - accuracy: 0.2634 - val_loss: 1.6283 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2098 - val_loss: 1.6281 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6258 - accuracy: 0.1964 - val_loss: 1.6278 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2723 - val_loss: 1.6275 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2054 - val_loss: 1.6273 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.2232 - val_loss: 1.6271 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.1964 - val_loss: 1.6271 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2321 - val_loss: 1.6270 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2188 - val_loss: 1.6267 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2500 - val_loss: 1.6266 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6262 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6234 - accuracy: 0.2143 - val_loss: 1.6260 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6247 - accuracy: 0.2143 - val_loss: 1.6258 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2321 - val_loss: 1.6256 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6276 - accuracy: 0.2366 - val_loss: 1.6255 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2634 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2232 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2366 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2500 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2589 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6235 - accuracy: 0.2634 - val_loss: 1.6246 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6234 - accuracy: 0.2009 - val_loss: 1.6246 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2679 - val_loss: 1.6244 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2768 - val_loss: 1.6241 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6209 - accuracy: 0.2545 - val_loss: 1.6239 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2411 - val_loss: 1.6238 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2679 - val_loss: 1.6236 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6203 - accuracy: 0.2366 - val_loss: 1.6236 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2589 - val_loss: 1.6235 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.2188 - val_loss: 1.6233 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2455 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2277 - val_loss: 1.6227 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2366 - val_loss: 1.6226 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2768 - val_loss: 1.6223 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2366 - val_loss: 1.6224 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2455 - val_loss: 1.6224 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2321 - val_loss: 1.6223 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2143 - val_loss: 1.6222 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2411 - val_loss: 1.6222 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2589 - val_loss: 1.6221 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6140 - accuracy: 0.2455 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6185 - accuracy: 0.2589 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2411 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 36ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6180 - accuracy: 0.2545 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 35ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2188 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6170 - accuracy: 0.2768 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6163 - accuracy: 0.2455 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2634 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6170 - accuracy: 0.2857 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2679 - val_loss: 1.6217 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 36ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2277 - val_loss: 1.6217 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2366 - val_loss: 1.6217 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 36ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2589 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2455 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2634 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2634 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6173 - accuracy: 0.2768 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2143 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 33ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2634 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 35ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2188 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 35ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2321 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "14/14 - 0s - loss: 1.6181 - accuracy: 0.2589 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 34ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2366 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.5625e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6169 - accuracy: 0.2679 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.5625e-06 - 35ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "14/14 - 0s - loss: 1.6150 - accuracy: 0.2500 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.5625e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2545 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 7.8125e-07 - 56ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2679 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 7.8125e-07 - 34ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2589 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 7.8125e-07 - 36ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6184 - accuracy: 0.2455 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 35ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2634 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 35ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "14/14 - 0s - loss: 1.6143 - accuracy: 0.2768 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 35ms/epoch - 2ms/step\n",
      "Node 8 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6363 - accuracy: 0.1741 - val_loss: 1.6343 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 2s/epoch - 330ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.2098 - val_loss: 1.6340 - val_accuracy: 0.3158 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2098 - val_loss: 1.6338 - val_accuracy: 0.2807 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6353 - accuracy: 0.2009 - val_loss: 1.6337 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.2054 - val_loss: 1.6335 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6352 - accuracy: 0.1964 - val_loss: 1.6334 - val_accuracy: 0.2807 - lr: 1.0000e-04 - 19ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6359 - accuracy: 0.1518 - val_loss: 1.6332 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.2589 - val_loss: 1.6331 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2321 - val_loss: 1.6329 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.1920 - val_loss: 1.6328 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2188 - val_loss: 1.6326 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.2098 - val_loss: 1.6325 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2366 - val_loss: 1.6323 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2098 - val_loss: 1.6322 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.1696 - val_loss: 1.6320 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2411 - val_loss: 1.6318 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2054 - val_loss: 1.6317 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2321 - val_loss: 1.6315 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6326 - accuracy: 0.2232 - val_loss: 1.6314 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2188 - val_loss: 1.6312 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2545 - val_loss: 1.6311 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2679 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2500 - val_loss: 1.6307 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2143 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2143 - val_loss: 1.6304 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2589 - val_loss: 1.6302 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.2143 - val_loss: 1.6301 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2277 - val_loss: 1.6299 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.2277 - val_loss: 1.6298 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2411 - val_loss: 1.6297 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2143 - val_loss: 1.6295 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6293 - accuracy: 0.2188 - val_loss: 1.6293 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2411 - val_loss: 1.6291 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2500 - val_loss: 1.6289 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.1964 - val_loss: 1.6288 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2545 - val_loss: 1.6286 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2143 - val_loss: 1.6285 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2545 - val_loss: 1.6283 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2500 - val_loss: 1.6283 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2589 - val_loss: 1.6282 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2232 - val_loss: 1.6282 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2321 - val_loss: 1.6281 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2143 - val_loss: 1.6280 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6292 - accuracy: 0.2277 - val_loss: 1.6279 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2188 - val_loss: 1.6278 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2188 - val_loss: 1.6277 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2366 - val_loss: 1.6276 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2545 - val_loss: 1.6275 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2634 - val_loss: 1.6274 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2366 - val_loss: 1.6272 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2232 - val_loss: 1.6271 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6269 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2500 - val_loss: 1.6268 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2366 - val_loss: 1.6266 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2098 - val_loss: 1.6265 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2321 - val_loss: 1.6263 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.2321 - val_loss: 1.6262 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2411 - val_loss: 1.6261 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2188 - val_loss: 1.6260 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2188 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2366 - val_loss: 1.6257 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2188 - val_loss: 1.6256 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2411 - val_loss: 1.6255 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2232 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2188 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2098 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 64ms/epoch - 9ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2098 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2589 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2545 - val_loss: 1.6249 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2232 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6240 - accuracy: 0.2277 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2232 - val_loss: 1.6247 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2455 - val_loss: 1.6245 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2366 - val_loss: 1.6244 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2366 - val_loss: 1.6243 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2321 - val_loss: 1.6241 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2277 - val_loss: 1.6240 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2321 - val_loss: 1.6239 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2455 - val_loss: 1.6238 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2500 - val_loss: 1.6237 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2679 - val_loss: 1.6236 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2232 - val_loss: 1.6235 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2277 - val_loss: 1.6233 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6198 - accuracy: 0.2768 - val_loss: 1.6232 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2321 - val_loss: 1.6232 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2411 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2500 - val_loss: 1.6230 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2500 - val_loss: 1.6229 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2634 - val_loss: 1.6228 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2455 - val_loss: 1.6226 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.1875 - val_loss: 1.6225 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2545 - val_loss: 1.6224 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2366 - val_loss: 1.6223 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6182 - accuracy: 0.2366 - val_loss: 1.6222 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2455 - val_loss: 1.6221 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2232 - val_loss: 1.6220 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2277 - val_loss: 1.6219 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2500 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2411 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2634 - val_loss: 1.6217 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Node 8 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6605 - accuracy: 0.1518 - val_loss: 1.6592 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 2s/epoch - 138ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6602 - accuracy: 0.1696 - val_loss: 1.6584 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6576 - accuracy: 0.2098 - val_loss: 1.6576 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6577 - accuracy: 0.2232 - val_loss: 1.6568 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6557 - accuracy: 0.2545 - val_loss: 1.6562 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6563 - accuracy: 0.1518 - val_loss: 1.6555 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6554 - accuracy: 0.2143 - val_loss: 1.6547 - val_accuracy: 0.1404 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6546 - accuracy: 0.2188 - val_loss: 1.6539 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6541 - accuracy: 0.2098 - val_loss: 1.6533 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6550 - accuracy: 0.1920 - val_loss: 1.6526 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6515 - accuracy: 0.2455 - val_loss: 1.6522 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 77ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6507 - accuracy: 0.2277 - val_loss: 1.6513 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 88ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6503 - accuracy: 0.2455 - val_loss: 1.6505 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6499 - accuracy: 0.2411 - val_loss: 1.6499 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6481 - accuracy: 0.2321 - val_loss: 1.6490 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6490 - accuracy: 0.2232 - val_loss: 1.6484 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6472 - accuracy: 0.2277 - val_loss: 1.6478 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6455 - accuracy: 0.2321 - val_loss: 1.6471 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6458 - accuracy: 0.2188 - val_loss: 1.6465 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6446 - accuracy: 0.2188 - val_loss: 1.6458 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6465 - accuracy: 0.2321 - val_loss: 1.6452 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6458 - accuracy: 0.2188 - val_loss: 1.6446 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6437 - accuracy: 0.2277 - val_loss: 1.6442 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6443 - accuracy: 0.2277 - val_loss: 1.6436 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6438 - accuracy: 0.2321 - val_loss: 1.6432 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6422 - accuracy: 0.2098 - val_loss: 1.6428 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6424 - accuracy: 0.2277 - val_loss: 1.6422 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6405 - accuracy: 0.2277 - val_loss: 1.6416 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6376 - accuracy: 0.2321 - val_loss: 1.6410 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6372 - accuracy: 0.2411 - val_loss: 1.6406 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6413 - accuracy: 0.2232 - val_loss: 1.6402 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6373 - accuracy: 0.2366 - val_loss: 1.6397 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6379 - accuracy: 0.2366 - val_loss: 1.6390 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6378 - accuracy: 0.2188 - val_loss: 1.6385 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6369 - accuracy: 0.2232 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6387 - accuracy: 0.2321 - val_loss: 1.6377 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6353 - accuracy: 0.2143 - val_loss: 1.6375 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6367 - accuracy: 0.2232 - val_loss: 1.6371 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6355 - accuracy: 0.2232 - val_loss: 1.6369 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2321 - val_loss: 1.6365 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6365 - accuracy: 0.2232 - val_loss: 1.6362 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2277 - val_loss: 1.6359 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6346 - accuracy: 0.2277 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6327 - accuracy: 0.2188 - val_loss: 1.6353 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2277 - val_loss: 1.6348 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6302 - accuracy: 0.2188 - val_loss: 1.6344 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6305 - accuracy: 0.2366 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6319 - accuracy: 0.2455 - val_loss: 1.6336 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6271 - accuracy: 0.2411 - val_loss: 1.6332 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.2277 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6236 - accuracy: 0.2455 - val_loss: 1.6324 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2411 - val_loss: 1.6321 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6243 - accuracy: 0.2500 - val_loss: 1.6317 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2188 - val_loss: 1.6314 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2232 - val_loss: 1.6311 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.2321 - val_loss: 1.6309 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2411 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2455 - val_loss: 1.6302 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2232 - val_loss: 1.6300 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2277 - val_loss: 1.6295 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2366 - val_loss: 1.6290 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.2321 - val_loss: 1.6286 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6242 - accuracy: 0.2277 - val_loss: 1.6284 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.2321 - val_loss: 1.6282 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6223 - accuracy: 0.2321 - val_loss: 1.6278 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6227 - accuracy: 0.2411 - val_loss: 1.6274 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2366 - val_loss: 1.6270 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6197 - accuracy: 0.2321 - val_loss: 1.6268 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2366 - val_loss: 1.6266 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2143 - val_loss: 1.6264 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2277 - val_loss: 1.6263 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6200 - accuracy: 0.2277 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6192 - accuracy: 0.2411 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.2321 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2366 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6124 - accuracy: 0.2411 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6159 - accuracy: 0.2768 - val_loss: 1.6245 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2411 - val_loss: 1.6240 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2500 - val_loss: 1.6237 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6166 - accuracy: 0.2545 - val_loss: 1.6234 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2366 - val_loss: 1.6232 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6073 - accuracy: 0.2366 - val_loss: 1.6229 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6095 - accuracy: 0.2321 - val_loss: 1.6229 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6085 - accuracy: 0.2500 - val_loss: 1.6227 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6093 - accuracy: 0.2411 - val_loss: 1.6225 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2188 - val_loss: 1.6222 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6082 - accuracy: 0.2545 - val_loss: 1.6220 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6071 - accuracy: 0.2545 - val_loss: 1.6214 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6113 - accuracy: 0.2500 - val_loss: 1.6212 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2500 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6073 - accuracy: 0.2500 - val_loss: 1.6218 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6079 - accuracy: 0.2500 - val_loss: 1.6215 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6083 - accuracy: 0.2589 - val_loss: 1.6214 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6064 - accuracy: 0.2589 - val_loss: 1.6211 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6012 - accuracy: 0.2634 - val_loss: 1.6208 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6047 - accuracy: 0.2902 - val_loss: 1.6208 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 55ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6037 - accuracy: 0.2589 - val_loss: 1.6206 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 57ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6053 - accuracy: 0.2723 - val_loss: 1.6206 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 75ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6171 - accuracy: 0.2366 - val_loss: 1.6205 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6115 - accuracy: 0.2232 - val_loss: 1.6203 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Node 8 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6614 - accuracy: 0.1920 - val_loss: 1.6608 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 2s/epoch - 297ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6603 - accuracy: 0.2411 - val_loss: 1.6603 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6603 - accuracy: 0.2098 - val_loss: 1.6599 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6600 - accuracy: 0.1920 - val_loss: 1.6595 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6580 - accuracy: 0.2589 - val_loss: 1.6592 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6582 - accuracy: 0.2009 - val_loss: 1.6588 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6576 - accuracy: 0.1964 - val_loss: 1.6584 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6576 - accuracy: 0.2277 - val_loss: 1.6580 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6577 - accuracy: 0.2366 - val_loss: 1.6576 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6563 - accuracy: 0.1964 - val_loss: 1.6572 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2232 - val_loss: 1.6567 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6541 - accuracy: 0.2589 - val_loss: 1.6563 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6546 - accuracy: 0.2411 - val_loss: 1.6558 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6545 - accuracy: 0.2366 - val_loss: 1.6554 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6557 - accuracy: 0.2277 - val_loss: 1.6551 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6538 - accuracy: 0.2321 - val_loss: 1.6548 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6535 - accuracy: 0.2232 - val_loss: 1.6544 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6525 - accuracy: 0.2098 - val_loss: 1.6540 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6509 - accuracy: 0.2277 - val_loss: 1.6536 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6513 - accuracy: 0.2232 - val_loss: 1.6532 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6515 - accuracy: 0.2321 - val_loss: 1.6529 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6509 - accuracy: 0.2411 - val_loss: 1.6525 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6494 - accuracy: 0.2411 - val_loss: 1.6521 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6506 - accuracy: 0.2143 - val_loss: 1.6518 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6496 - accuracy: 0.2411 - val_loss: 1.6515 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6501 - accuracy: 0.2143 - val_loss: 1.6511 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6489 - accuracy: 0.2232 - val_loss: 1.6508 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6491 - accuracy: 0.2232 - val_loss: 1.6504 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6470 - accuracy: 0.2366 - val_loss: 1.6501 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6479 - accuracy: 0.2634 - val_loss: 1.6498 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6464 - accuracy: 0.2277 - val_loss: 1.6494 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6447 - accuracy: 0.2366 - val_loss: 1.6490 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6462 - accuracy: 0.2143 - val_loss: 1.6487 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6458 - accuracy: 0.2277 - val_loss: 1.6484 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6446 - accuracy: 0.2232 - val_loss: 1.6480 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6472 - accuracy: 0.2232 - val_loss: 1.6476 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2545 - val_loss: 1.6473 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6464 - accuracy: 0.2098 - val_loss: 1.6469 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6414 - accuracy: 0.2455 - val_loss: 1.6466 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6427 - accuracy: 0.2321 - val_loss: 1.6463 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2277 - val_loss: 1.6460 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2411 - val_loss: 1.6457 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6373 - accuracy: 0.2188 - val_loss: 1.6454 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6430 - accuracy: 0.2188 - val_loss: 1.6450 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6430 - accuracy: 0.2366 - val_loss: 1.6447 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6412 - accuracy: 0.2277 - val_loss: 1.6445 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6412 - accuracy: 0.2321 - val_loss: 1.6443 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6401 - accuracy: 0.2188 - val_loss: 1.6440 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6383 - accuracy: 0.2277 - val_loss: 1.6437 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2321 - val_loss: 1.6434 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6427 - accuracy: 0.2143 - val_loss: 1.6430 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6377 - accuracy: 0.2188 - val_loss: 1.6427 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6377 - accuracy: 0.2321 - val_loss: 1.6424 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6387 - accuracy: 0.2411 - val_loss: 1.6421 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6353 - accuracy: 0.2411 - val_loss: 1.6418 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6357 - accuracy: 0.2321 - val_loss: 1.6415 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.2321 - val_loss: 1.6412 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2366 - val_loss: 1.6409 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6326 - accuracy: 0.2411 - val_loss: 1.6406 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6374 - accuracy: 0.2366 - val_loss: 1.6405 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6367 - accuracy: 0.2366 - val_loss: 1.6402 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6355 - accuracy: 0.2321 - val_loss: 1.6400 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.2366 - val_loss: 1.6398 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6353 - accuracy: 0.2232 - val_loss: 1.6397 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2232 - val_loss: 1.6395 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2232 - val_loss: 1.6393 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6326 - accuracy: 0.2321 - val_loss: 1.6391 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2321 - val_loss: 1.6388 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2143 - val_loss: 1.6385 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 56ms/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.2366 - val_loss: 1.6383 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2143 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.2366 - val_loss: 1.6379 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2455 - val_loss: 1.6376 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2411 - val_loss: 1.6375 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2455 - val_loss: 1.6372 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2411 - val_loss: 1.6370 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2411 - val_loss: 1.6369 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2500 - val_loss: 1.6367 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.2366 - val_loss: 1.6365 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2500 - val_loss: 1.6363 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2321 - val_loss: 1.6361 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2455 - val_loss: 1.6361 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2545 - val_loss: 1.6359 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2143 - val_loss: 1.6358 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2321 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2232 - val_loss: 1.6354 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2366 - val_loss: 1.6352 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2232 - val_loss: 1.6349 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2411 - val_loss: 1.6348 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2545 - val_loss: 1.6346 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2143 - val_loss: 1.6344 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2277 - val_loss: 1.6342 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2366 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2321 - val_loss: 1.6339 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2232 - val_loss: 1.6337 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2232 - val_loss: 1.6336 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2232 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6193 - accuracy: 0.2232 - val_loss: 1.6333 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6249 - accuracy: 0.2455 - val_loss: 1.6332 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2232 - val_loss: 1.6330 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 5ms/step\n",
      "Node 8 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 8 - Best Validation Accuracy: 0.3158\n",
      "Best model saved for Node 8 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_8.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_9_dataset.csv\n",
      "Node 9 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6347 - accuracy: 0.2188 - val_loss: 1.6347 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 2s/epoch - 111ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2266 - val_loss: 1.6343 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2109 - val_loss: 1.6339 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2500 - val_loss: 1.6335 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.2227 - val_loss: 1.6330 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6324 - accuracy: 0.2422 - val_loss: 1.6326 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2266 - val_loss: 1.6322 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2734 - val_loss: 1.6319 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2578 - val_loss: 1.6316 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2109 - val_loss: 1.6313 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2422 - val_loss: 1.6310 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2188 - val_loss: 1.6308 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6291 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2578 - val_loss: 1.6302 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2578 - val_loss: 1.6299 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2188 - val_loss: 1.6296 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2344 - val_loss: 1.6293 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2383 - val_loss: 1.6291 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2305 - val_loss: 1.6289 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2422 - val_loss: 1.6286 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2461 - val_loss: 1.6284 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2461 - val_loss: 1.6280 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2383 - val_loss: 1.6278 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2773 - val_loss: 1.6275 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2539 - val_loss: 1.6273 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2461 - val_loss: 1.6270 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2344 - val_loss: 1.6267 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6264 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2227 - val_loss: 1.6261 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2539 - val_loss: 1.6258 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2383 - val_loss: 1.6256 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2578 - val_loss: 1.6254 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2695 - val_loss: 1.6252 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2500 - val_loss: 1.6250 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2383 - val_loss: 1.6248 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2383 - val_loss: 1.6246 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2305 - val_loss: 1.6244 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2461 - val_loss: 1.6242 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2383 - val_loss: 1.6241 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2266 - val_loss: 1.6238 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2617 - val_loss: 1.6236 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2656 - val_loss: 1.6235 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2266 - val_loss: 1.6233 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6231 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2539 - val_loss: 1.6229 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2305 - val_loss: 1.6228 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2188 - val_loss: 1.6226 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2422 - val_loss: 1.6225 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2578 - val_loss: 1.6223 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2109 - val_loss: 1.6222 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2539 - val_loss: 1.6221 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6219 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2539 - val_loss: 1.6217 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2617 - val_loss: 1.6215 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2539 - val_loss: 1.6214 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2266 - val_loss: 1.6213 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6112 - accuracy: 0.2578 - val_loss: 1.6211 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2344 - val_loss: 1.6210 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2344 - val_loss: 1.6208 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2266 - val_loss: 1.6207 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2734 - val_loss: 1.6206 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2539 - val_loss: 1.6205 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2422 - val_loss: 1.6204 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2344 - val_loss: 1.6203 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6136 - accuracy: 0.2930 - val_loss: 1.6202 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2227 - val_loss: 1.6201 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6140 - accuracy: 0.2461 - val_loss: 1.6200 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2383 - val_loss: 1.6199 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2422 - val_loss: 1.6198 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6049 - accuracy: 0.2461 - val_loss: 1.6196 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6080 - accuracy: 0.2617 - val_loss: 1.6196 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6135 - accuracy: 0.2422 - val_loss: 1.6195 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2383 - val_loss: 1.6194 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2539 - val_loss: 1.6192 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2656 - val_loss: 1.6191 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6074 - accuracy: 0.2500 - val_loss: 1.6190 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2422 - val_loss: 1.6189 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2422 - val_loss: 1.6187 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2578 - val_loss: 1.6186 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6142 - accuracy: 0.2656 - val_loss: 1.6185 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6078 - accuracy: 0.2500 - val_loss: 1.6184 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.1953 - val_loss: 1.6183 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6106 - accuracy: 0.2617 - val_loss: 1.6182 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2500 - val_loss: 1.6182 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6040 - accuracy: 0.2578 - val_loss: 1.6181 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2617 - val_loss: 1.6180 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6084 - accuracy: 0.2695 - val_loss: 1.6180 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6029 - accuracy: 0.2773 - val_loss: 1.6179 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6078 - accuracy: 0.2617 - val_loss: 1.6177 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2500 - val_loss: 1.6176 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2578 - val_loss: 1.6175 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2617 - val_loss: 1.6174 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2578 - val_loss: 1.6173 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2344 - val_loss: 1.6172 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6120 - accuracy: 0.2031 - val_loss: 1.6170 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6092 - accuracy: 0.2266 - val_loss: 1.6169 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6116 - accuracy: 0.2422 - val_loss: 1.6169 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2461 - val_loss: 1.6168 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6060 - accuracy: 0.2539 - val_loss: 1.6169 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6021 - accuracy: 0.2422 - val_loss: 1.6168 - val_accuracy: 0.2462 - lr: 5.0000e-05 - 59ms/epoch - 4ms/step\n",
      "Node 9 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6357 - accuracy: 0.1758 - val_loss: 1.6346 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 2s/epoch - 257ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2070 - val_loss: 1.6344 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2227 - val_loss: 1.6341 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2148 - val_loss: 1.6338 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1992 - val_loss: 1.6334 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 20ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2070 - val_loss: 1.6330 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2031 - val_loss: 1.6326 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2227 - val_loss: 1.6324 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2344 - val_loss: 1.6321 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2148 - val_loss: 1.6318 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.1992 - val_loss: 1.6315 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 21ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2383 - val_loss: 1.6312 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2383 - val_loss: 1.6309 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2188 - val_loss: 1.6307 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2695 - val_loss: 1.6302 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2305 - val_loss: 1.6300 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2695 - val_loss: 1.6298 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2539 - val_loss: 1.6296 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2070 - val_loss: 1.6293 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2148 - val_loss: 1.6291 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2422 - val_loss: 1.6288 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2500 - val_loss: 1.6286 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2305 - val_loss: 1.6284 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2422 - val_loss: 1.6282 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2305 - val_loss: 1.6279 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2188 - val_loss: 1.6277 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2383 - val_loss: 1.6275 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2188 - val_loss: 1.6273 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2031 - val_loss: 1.6271 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2148 - val_loss: 1.6269 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2266 - val_loss: 1.6267 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2227 - val_loss: 1.6266 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2266 - val_loss: 1.6264 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2188 - val_loss: 1.6262 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2578 - val_loss: 1.6261 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2500 - val_loss: 1.6260 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2148 - val_loss: 1.6258 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2266 - val_loss: 1.6256 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2656 - val_loss: 1.6255 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2344 - val_loss: 1.6254 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2500 - val_loss: 1.6253 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2383 - val_loss: 1.6252 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2227 - val_loss: 1.6250 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2422 - val_loss: 1.6249 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2305 - val_loss: 1.6248 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2266 - val_loss: 1.6246 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2461 - val_loss: 1.6245 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2109 - val_loss: 1.6243 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2539 - val_loss: 1.6241 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2148 - val_loss: 1.6238 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2344 - val_loss: 1.6236 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2383 - val_loss: 1.6234 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2344 - val_loss: 1.6232 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2188 - val_loss: 1.6231 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2461 - val_loss: 1.6230 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2461 - val_loss: 1.6228 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2578 - val_loss: 1.6227 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2266 - val_loss: 1.6226 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2070 - val_loss: 1.6225 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2500 - val_loss: 1.6223 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2500 - val_loss: 1.6222 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2578 - val_loss: 1.6219 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2461 - val_loss: 1.6218 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2305 - val_loss: 1.6217 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2656 - val_loss: 1.6215 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2188 - val_loss: 1.6214 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2148 - val_loss: 1.6213 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2344 - val_loss: 1.6212 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2148 - val_loss: 1.6211 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2461 - val_loss: 1.6210 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2031 - val_loss: 1.6208 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2344 - val_loss: 1.6207 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2148 - val_loss: 1.6205 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2031 - val_loss: 1.6203 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2344 - val_loss: 1.6202 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2227 - val_loss: 1.6201 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2266 - val_loss: 1.6199 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2227 - val_loss: 1.6198 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6149 - accuracy: 0.2070 - val_loss: 1.6197 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2422 - val_loss: 1.6196 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2227 - val_loss: 1.6195 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.2188 - val_loss: 1.6194 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2383 - val_loss: 1.6193 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6129 - accuracy: 0.2461 - val_loss: 1.6192 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6088 - accuracy: 0.2500 - val_loss: 1.6191 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2266 - val_loss: 1.6190 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2305 - val_loss: 1.6189 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2266 - val_loss: 1.6188 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.2305 - val_loss: 1.6187 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6079 - accuracy: 0.2344 - val_loss: 1.6185 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2188 - val_loss: 1.6184 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2539 - val_loss: 1.6183 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2500 - val_loss: 1.6182 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2539 - val_loss: 1.6181 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6143 - accuracy: 0.2344 - val_loss: 1.6180 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2148 - val_loss: 1.6179 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2188 - val_loss: 1.6178 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2188 - val_loss: 1.6177 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Node 9 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6608 - accuracy: 0.1641 - val_loss: 1.6592 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 2s/epoch - 112ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6590 - accuracy: 0.2539 - val_loss: 1.6579 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6585 - accuracy: 0.2461 - val_loss: 1.6569 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6572 - accuracy: 0.2461 - val_loss: 1.6560 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6537 - accuracy: 0.2656 - val_loss: 1.6548 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6540 - accuracy: 0.2422 - val_loss: 1.6538 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6535 - accuracy: 0.2422 - val_loss: 1.6530 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6486 - accuracy: 0.2500 - val_loss: 1.6520 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6501 - accuracy: 0.2070 - val_loss: 1.6514 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6462 - accuracy: 0.2344 - val_loss: 1.6505 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6455 - accuracy: 0.2539 - val_loss: 1.6497 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6459 - accuracy: 0.2344 - val_loss: 1.6488 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6449 - accuracy: 0.2617 - val_loss: 1.6482 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6458 - accuracy: 0.2461 - val_loss: 1.6476 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6419 - accuracy: 0.2461 - val_loss: 1.6470 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6413 - accuracy: 0.2578 - val_loss: 1.6464 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6429 - accuracy: 0.2344 - val_loss: 1.6459 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6367 - accuracy: 0.2578 - val_loss: 1.6453 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6406 - accuracy: 0.2344 - val_loss: 1.6449 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6370 - accuracy: 0.2422 - val_loss: 1.6445 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6367 - accuracy: 0.2656 - val_loss: 1.6440 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2578 - val_loss: 1.6436 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6344 - accuracy: 0.2500 - val_loss: 1.6432 - val_accuracy: 0.2154 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6346 - accuracy: 0.2656 - val_loss: 1.6427 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6380 - accuracy: 0.2266 - val_loss: 1.6421 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2656 - val_loss: 1.6417 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.2656 - val_loss: 1.6412 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6347 - accuracy: 0.2422 - val_loss: 1.6409 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6307 - accuracy: 0.2422 - val_loss: 1.6406 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6344 - accuracy: 0.2383 - val_loss: 1.6401 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6294 - accuracy: 0.2344 - val_loss: 1.6396 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2422 - val_loss: 1.6395 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2461 - val_loss: 1.6389 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2578 - val_loss: 1.6383 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6378 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2461 - val_loss: 1.6373 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2070 - val_loss: 1.6368 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2422 - val_loss: 1.6367 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2734 - val_loss: 1.6363 - val_accuracy: 0.2923 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2969 - val_loss: 1.6360 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2539 - val_loss: 1.6355 - val_accuracy: 0.2923 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2734 - val_loss: 1.6349 - val_accuracy: 0.2923 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2578 - val_loss: 1.6348 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2461 - val_loss: 1.6344 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2578 - val_loss: 1.6339 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6330 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2578 - val_loss: 1.6323 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2812 - val_loss: 1.6321 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2539 - val_loss: 1.6319 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2773 - val_loss: 1.6318 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2812 - val_loss: 1.6317 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.2500 - val_loss: 1.6315 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2617 - val_loss: 1.6307 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2656 - val_loss: 1.6305 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6167 - accuracy: 0.2539 - val_loss: 1.6303 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6121 - accuracy: 0.2852 - val_loss: 1.6301 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6152 - accuracy: 0.2539 - val_loss: 1.6296 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2344 - val_loss: 1.6297 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2734 - val_loss: 1.6293 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6081 - accuracy: 0.2734 - val_loss: 1.6292 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2773 - val_loss: 1.6294 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2500 - val_loss: 1.6288 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2891 - val_loss: 1.6284 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2891 - val_loss: 1.6284 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6114 - accuracy: 0.2695 - val_loss: 1.6277 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2773 - val_loss: 1.6276 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6097 - accuracy: 0.2773 - val_loss: 1.6275 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6069 - accuracy: 0.2656 - val_loss: 1.6272 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2695 - val_loss: 1.6268 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2773 - val_loss: 1.6264 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6083 - accuracy: 0.2773 - val_loss: 1.6265 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2734 - val_loss: 1.6262 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6065 - accuracy: 0.2539 - val_loss: 1.6259 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2539 - val_loss: 1.6251 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2695 - val_loss: 1.6248 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6083 - accuracy: 0.2734 - val_loss: 1.6240 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6042 - accuracy: 0.3047 - val_loss: 1.6242 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.5992 - accuracy: 0.2773 - val_loss: 1.6247 - val_accuracy: 0.2769 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2539 - val_loss: 1.6249 - val_accuracy: 0.2615 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6009 - accuracy: 0.3047 - val_loss: 1.6251 - val_accuracy: 0.2615 - lr: 5.0000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6048 - accuracy: 0.2461 - val_loss: 1.6247 - val_accuracy: 0.2769 - lr: 5.0000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6163 - accuracy: 0.2344 - val_loss: 1.6250 - val_accuracy: 0.2615 - lr: 5.0000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.5985 - accuracy: 0.2656 - val_loss: 1.6249 - val_accuracy: 0.2615 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Node 9 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6591 - accuracy: 0.2305 - val_loss: 1.6586 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 2s/epoch - 259ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.2422 - val_loss: 1.6578 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2305 - val_loss: 1.6568 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6565 - accuracy: 0.2383 - val_loss: 1.6559 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2344 - val_loss: 1.6550 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6528 - accuracy: 0.2422 - val_loss: 1.6542 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2383 - val_loss: 1.6534 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2383 - val_loss: 1.6528 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2422 - val_loss: 1.6521 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2266 - val_loss: 1.6515 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.2422 - val_loss: 1.6510 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.2383 - val_loss: 1.6504 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6499 - accuracy: 0.2344 - val_loss: 1.6500 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2422 - val_loss: 1.6495 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6484 - accuracy: 0.2344 - val_loss: 1.6490 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6476 - accuracy: 0.2422 - val_loss: 1.6486 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2422 - val_loss: 1.6482 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2344 - val_loss: 1.6479 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2383 - val_loss: 1.6476 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6471 - accuracy: 0.2305 - val_loss: 1.6472 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2383 - val_loss: 1.6469 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2344 - val_loss: 1.6466 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2305 - val_loss: 1.6462 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6444 - accuracy: 0.2422 - val_loss: 1.6459 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2383 - val_loss: 1.6455 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2461 - val_loss: 1.6452 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2383 - val_loss: 1.6448 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2383 - val_loss: 1.6445 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2344 - val_loss: 1.6441 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2383 - val_loss: 1.6438 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2305 - val_loss: 1.6435 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2500 - val_loss: 1.6432 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2344 - val_loss: 1.6429 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2383 - val_loss: 1.6426 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6371 - accuracy: 0.2500 - val_loss: 1.6424 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2383 - val_loss: 1.6420 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6371 - accuracy: 0.2422 - val_loss: 1.6417 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2305 - val_loss: 1.6414 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2461 - val_loss: 1.6411 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2461 - val_loss: 1.6408 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6389 - accuracy: 0.2422 - val_loss: 1.6406 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2539 - val_loss: 1.6404 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2305 - val_loss: 1.6402 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2422 - val_loss: 1.6399 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2500 - val_loss: 1.6397 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2305 - val_loss: 1.6394 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2461 - val_loss: 1.6390 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2578 - val_loss: 1.6387 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2383 - val_loss: 1.6385 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2383 - val_loss: 1.6383 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 61ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2305 - val_loss: 1.6381 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2422 - val_loss: 1.6379 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2461 - val_loss: 1.6377 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2344 - val_loss: 1.6374 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2578 - val_loss: 1.6371 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2344 - val_loss: 1.6369 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2617 - val_loss: 1.6366 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2461 - val_loss: 1.6363 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2578 - val_loss: 1.6361 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2383 - val_loss: 1.6358 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2344 - val_loss: 1.6357 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2461 - val_loss: 1.6356 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2578 - val_loss: 1.6354 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6351 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2500 - val_loss: 1.6348 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2500 - val_loss: 1.6345 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2578 - val_loss: 1.6343 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2305 - val_loss: 1.6340 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2500 - val_loss: 1.6337 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2500 - val_loss: 1.6335 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6334 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2539 - val_loss: 1.6332 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2344 - val_loss: 1.6330 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2578 - val_loss: 1.6328 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2539 - val_loss: 1.6326 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2656 - val_loss: 1.6325 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2539 - val_loss: 1.6325 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2617 - val_loss: 1.6323 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2773 - val_loss: 1.6320 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2500 - val_loss: 1.6316 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2422 - val_loss: 1.6313 - val_accuracy: 0.2462 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2461 - val_loss: 1.6310 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2695 - val_loss: 1.6308 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2734 - val_loss: 1.6307 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2539 - val_loss: 1.6305 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2734 - val_loss: 1.6302 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2617 - val_loss: 1.6299 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2852 - val_loss: 1.6297 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6106 - accuracy: 0.2383 - val_loss: 1.6297 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2695 - val_loss: 1.6294 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2422 - val_loss: 1.6296 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2500 - val_loss: 1.6293 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2773 - val_loss: 1.6294 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2461 - val_loss: 1.6291 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2500 - val_loss: 1.6287 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2500 - val_loss: 1.6286 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2266 - val_loss: 1.6281 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2617 - val_loss: 1.6276 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2578 - val_loss: 1.6274 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2773 - val_loss: 1.6275 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Node 9 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 9 - Best Validation Accuracy: 0.2923\n",
      "Best model saved for Node 9 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_9.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_10_dataset.csv\n",
      "Node 10 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6343 - accuracy: 0.2341 - val_loss: 1.6344 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 3s/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2341 - val_loss: 1.6342 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.2460 - val_loss: 1.6337 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2341 - val_loss: 1.6333 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2341 - val_loss: 1.6331 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2460 - val_loss: 1.6326 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2302 - val_loss: 1.6323 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6307 - accuracy: 0.2341 - val_loss: 1.6320 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2183 - val_loss: 1.6316 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6324 - accuracy: 0.1944 - val_loss: 1.6313 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2103 - val_loss: 1.6311 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6302 - accuracy: 0.2460 - val_loss: 1.6309 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2460 - val_loss: 1.6306 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2579 - val_loss: 1.6304 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2183 - val_loss: 1.6301 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2341 - val_loss: 1.6299 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2579 - val_loss: 1.6297 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6299 - accuracy: 0.2302 - val_loss: 1.6295 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2381 - val_loss: 1.6292 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2302 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2183 - val_loss: 1.6288 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2143 - val_loss: 1.6285 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2619 - val_loss: 1.6283 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2262 - val_loss: 1.6281 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2500 - val_loss: 1.6279 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2579 - val_loss: 1.6277 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6257 - accuracy: 0.2421 - val_loss: 1.6274 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2302 - val_loss: 1.6272 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2500 - val_loss: 1.6270 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2381 - val_loss: 1.6268 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2302 - val_loss: 1.6266 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2619 - val_loss: 1.6265 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2222 - val_loss: 1.6264 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2262 - val_loss: 1.6262 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2222 - val_loss: 1.6260 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2341 - val_loss: 1.6259 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2381 - val_loss: 1.6256 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.2579 - val_loss: 1.6253 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2540 - val_loss: 1.6252 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2421 - val_loss: 1.6250 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2460 - val_loss: 1.6249 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2540 - val_loss: 1.6246 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2659 - val_loss: 1.6245 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2540 - val_loss: 1.6244 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2619 - val_loss: 1.6243 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2262 - val_loss: 1.6241 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2579 - val_loss: 1.6239 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2619 - val_loss: 1.6238 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6202 - accuracy: 0.2341 - val_loss: 1.6236 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6189 - accuracy: 0.2540 - val_loss: 1.6235 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2500 - val_loss: 1.6233 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2619 - val_loss: 1.6232 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2500 - val_loss: 1.6231 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6228 - accuracy: 0.2381 - val_loss: 1.6230 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2540 - val_loss: 1.6230 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6152 - accuracy: 0.2421 - val_loss: 1.6229 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2460 - val_loss: 1.6228 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2302 - val_loss: 1.6227 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2738 - val_loss: 1.6226 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6123 - accuracy: 0.2540 - val_loss: 1.6224 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2579 - val_loss: 1.6223 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2460 - val_loss: 1.6222 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2460 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2262 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6137 - accuracy: 0.2619 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6155 - accuracy: 0.2341 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2778 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2302 - val_loss: 1.6218 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2183 - val_loss: 1.6217 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6122 - accuracy: 0.2698 - val_loss: 1.6217 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2659 - val_loss: 1.6216 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6112 - accuracy: 0.2698 - val_loss: 1.6215 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2302 - val_loss: 1.6214 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6106 - accuracy: 0.2341 - val_loss: 1.6213 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2183 - val_loss: 1.6213 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6114 - accuracy: 0.2500 - val_loss: 1.6212 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6155 - accuracy: 0.2698 - val_loss: 1.6212 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2579 - val_loss: 1.6211 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2460 - val_loss: 1.6210 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2500 - val_loss: 1.6210 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2460 - val_loss: 1.6209 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2460 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6095 - accuracy: 0.2619 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2540 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2381 - val_loss: 1.6208 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2302 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6088 - accuracy: 0.2460 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2579 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6077 - accuracy: 0.2381 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6054 - accuracy: 0.2659 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2619 - val_loss: 1.6208 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6103 - accuracy: 0.2302 - val_loss: 1.6208 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Node 10 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6336 - accuracy: 0.2143 - val_loss: 1.6339 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 2s/epoch - 308ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2341 - val_loss: 1.6336 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2024 - val_loss: 1.6333 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2381 - val_loss: 1.6331 - val_accuracy: 0.3333 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.1905 - val_loss: 1.6329 - val_accuracy: 0.3016 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2500 - val_loss: 1.6327 - val_accuracy: 0.3016 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2500 - val_loss: 1.6324 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.1944 - val_loss: 1.6321 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2579 - val_loss: 1.6319 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2460 - val_loss: 1.6316 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2063 - val_loss: 1.6314 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2460 - val_loss: 1.6312 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2540 - val_loss: 1.6310 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2341 - val_loss: 1.6307 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2698 - val_loss: 1.6304 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2619 - val_loss: 1.6302 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2302 - val_loss: 1.6300 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2579 - val_loss: 1.6298 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2421 - val_loss: 1.6297 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2302 - val_loss: 1.6295 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2302 - val_loss: 1.6293 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2540 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2183 - val_loss: 1.6288 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2698 - val_loss: 1.6286 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2302 - val_loss: 1.6283 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6282 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2460 - val_loss: 1.6281 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2698 - val_loss: 1.6279 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2381 - val_loss: 1.6277 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2460 - val_loss: 1.6276 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2262 - val_loss: 1.6274 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2341 - val_loss: 1.6272 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6271 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2460 - val_loss: 1.6269 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2460 - val_loss: 1.6268 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2460 - val_loss: 1.6266 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2302 - val_loss: 1.6264 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2262 - val_loss: 1.6263 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2302 - val_loss: 1.6262 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2500 - val_loss: 1.6261 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2341 - val_loss: 1.6259 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2381 - val_loss: 1.6257 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2421 - val_loss: 1.6256 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2302 - val_loss: 1.6254 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2341 - val_loss: 1.6254 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2500 - val_loss: 1.6252 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2381 - val_loss: 1.6251 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2302 - val_loss: 1.6250 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2460 - val_loss: 1.6249 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2460 - val_loss: 1.6247 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2460 - val_loss: 1.6246 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2341 - val_loss: 1.6245 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2381 - val_loss: 1.6243 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2500 - val_loss: 1.6242 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2421 - val_loss: 1.6241 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2381 - val_loss: 1.6240 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2341 - val_loss: 1.6239 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2222 - val_loss: 1.6238 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2183 - val_loss: 1.6237 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2222 - val_loss: 1.6236 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2381 - val_loss: 1.6236 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2341 - val_loss: 1.6235 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2579 - val_loss: 1.6235 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2579 - val_loss: 1.6234 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2500 - val_loss: 1.6234 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2302 - val_loss: 1.6233 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2341 - val_loss: 1.6232 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2421 - val_loss: 1.6231 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2421 - val_loss: 1.6230 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2579 - val_loss: 1.6230 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2381 - val_loss: 1.6229 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2421 - val_loss: 1.6229 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2222 - val_loss: 1.6228 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2579 - val_loss: 1.6228 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2302 - val_loss: 1.6227 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2341 - val_loss: 1.6227 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6136 - accuracy: 0.2500 - val_loss: 1.6226 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2381 - val_loss: 1.6225 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2341 - val_loss: 1.6224 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2302 - val_loss: 1.6224 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2421 - val_loss: 1.6223 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2421 - val_loss: 1.6223 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2500 - val_loss: 1.6222 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6116 - accuracy: 0.2540 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6099 - accuracy: 0.2421 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6115 - accuracy: 0.2500 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2381 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2341 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2262 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2540 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2460 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2302 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2222 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6115 - accuracy: 0.2421 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2540 - val_loss: 1.6220 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2500 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 49ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2421 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6121 - accuracy: 0.2619 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2302 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.2659 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 30ms/epoch - 4ms/step\n",
      "Node 10 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6565 - accuracy: 0.2183 - val_loss: 1.6562 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 3s/epoch - 169ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6551 - accuracy: 0.2460 - val_loss: 1.6553 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6551 - accuracy: 0.2500 - val_loss: 1.6545 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6534 - accuracy: 0.2460 - val_loss: 1.6537 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6527 - accuracy: 0.2619 - val_loss: 1.6527 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6517 - accuracy: 0.2421 - val_loss: 1.6520 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6504 - accuracy: 0.2262 - val_loss: 1.6514 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6501 - accuracy: 0.2302 - val_loss: 1.6508 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6490 - accuracy: 0.2302 - val_loss: 1.6499 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6469 - accuracy: 0.2460 - val_loss: 1.6492 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2421 - val_loss: 1.6485 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 87ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6441 - accuracy: 0.2460 - val_loss: 1.6480 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6457 - accuracy: 0.2302 - val_loss: 1.6474 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6449 - accuracy: 0.2540 - val_loss: 1.6467 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6438 - accuracy: 0.2183 - val_loss: 1.6461 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6420 - accuracy: 0.2421 - val_loss: 1.6454 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6410 - accuracy: 0.2540 - val_loss: 1.6449 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6434 - accuracy: 0.2500 - val_loss: 1.6443 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6386 - accuracy: 0.2659 - val_loss: 1.6437 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6392 - accuracy: 0.2619 - val_loss: 1.6432 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6381 - accuracy: 0.2619 - val_loss: 1.6426 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6414 - accuracy: 0.2302 - val_loss: 1.6422 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6394 - accuracy: 0.2540 - val_loss: 1.6416 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6379 - accuracy: 0.2460 - val_loss: 1.6411 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6383 - accuracy: 0.2579 - val_loss: 1.6406 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2381 - val_loss: 1.6402 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2698 - val_loss: 1.6398 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6361 - accuracy: 0.2500 - val_loss: 1.6394 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6360 - accuracy: 0.2341 - val_loss: 1.6391 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.2540 - val_loss: 1.6387 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2500 - val_loss: 1.6384 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2460 - val_loss: 1.6381 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2460 - val_loss: 1.6376 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2698 - val_loss: 1.6372 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2460 - val_loss: 1.6369 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2738 - val_loss: 1.6364 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2421 - val_loss: 1.6361 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2579 - val_loss: 1.6357 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2659 - val_loss: 1.6354 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6349 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2262 - val_loss: 1.6348 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2540 - val_loss: 1.6346 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2500 - val_loss: 1.6343 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2341 - val_loss: 1.6340 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2460 - val_loss: 1.6338 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2341 - val_loss: 1.6336 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2778 - val_loss: 1.6334 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6330 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2659 - val_loss: 1.6327 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2381 - val_loss: 1.6326 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6202 - accuracy: 0.2540 - val_loss: 1.6324 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2341 - val_loss: 1.6321 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2659 - val_loss: 1.6319 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2619 - val_loss: 1.6317 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2500 - val_loss: 1.6316 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2302 - val_loss: 1.6314 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2619 - val_loss: 1.6313 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2063 - val_loss: 1.6312 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 87ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6170 - accuracy: 0.2659 - val_loss: 1.6311 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2698 - val_loss: 1.6311 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2817 - val_loss: 1.6312 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2897 - val_loss: 1.6311 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6133 - accuracy: 0.2460 - val_loss: 1.6311 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2579 - val_loss: 1.6311 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2381 - val_loss: 1.6310 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2738 - val_loss: 1.6310 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2381 - val_loss: 1.6310 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2381 - val_loss: 1.6310 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2500 - val_loss: 1.6309 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2421 - val_loss: 1.6309 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2460 - val_loss: 1.6308 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2778 - val_loss: 1.6308 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6102 - accuracy: 0.2659 - val_loss: 1.6308 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2540 - val_loss: 1.6308 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2778 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2341 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6114 - accuracy: 0.2619 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2341 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6077 - accuracy: 0.2659 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2619 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 67ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2778 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6144 - accuracy: 0.2698 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2619 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 69ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2778 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 68ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2500 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 69ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6081 - accuracy: 0.2857 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 68ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2460 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 69ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6091 - accuracy: 0.2341 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 68ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2500 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 67ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2579 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 66ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2738 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.9062e-07 - 68ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6068 - accuracy: 0.2579 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.9062e-07 - 67ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "16/16 - 0s - loss: 1.6092 - accuracy: 0.2698 - val_loss: 1.6307 - val_accuracy: 0.2222 - lr: 3.9062e-07 - 67ms/epoch - 4ms/step\n",
      "Node 10 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6621 - accuracy: 0.1786 - val_loss: 1.6614 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 3s/epoch - 329ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6606 - accuracy: 0.2222 - val_loss: 1.6608 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6610 - accuracy: 0.1944 - val_loss: 1.6602 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6583 - accuracy: 0.1825 - val_loss: 1.6597 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2222 - val_loss: 1.6591 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6589 - accuracy: 0.1905 - val_loss: 1.6586 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.2063 - val_loss: 1.6582 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6568 - accuracy: 0.2222 - val_loss: 1.6577 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2024 - val_loss: 1.6573 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2540 - val_loss: 1.6569 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6538 - accuracy: 0.2381 - val_loss: 1.6566 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6552 - accuracy: 0.2143 - val_loss: 1.6562 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2103 - val_loss: 1.6557 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2421 - val_loss: 1.6552 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2103 - val_loss: 1.6547 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2421 - val_loss: 1.6543 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2341 - val_loss: 1.6539 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2302 - val_loss: 1.6534 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2262 - val_loss: 1.6530 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.2302 - val_loss: 1.6526 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2024 - val_loss: 1.6522 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2103 - val_loss: 1.6517 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6480 - accuracy: 0.1984 - val_loss: 1.6513 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2460 - val_loss: 1.6509 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6480 - accuracy: 0.2579 - val_loss: 1.6504 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2500 - val_loss: 1.6500 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2143 - val_loss: 1.6496 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6449 - accuracy: 0.2381 - val_loss: 1.6491 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2143 - val_loss: 1.6487 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2103 - val_loss: 1.6483 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2341 - val_loss: 1.6479 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2262 - val_loss: 1.6475 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2183 - val_loss: 1.6471 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2063 - val_loss: 1.6467 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2302 - val_loss: 1.6464 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2024 - val_loss: 1.6461 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2540 - val_loss: 1.6458 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2500 - val_loss: 1.6455 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2183 - val_loss: 1.6453 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2500 - val_loss: 1.6449 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2817 - val_loss: 1.6446 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2262 - val_loss: 1.6443 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2659 - val_loss: 1.6440 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2579 - val_loss: 1.6437 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2262 - val_loss: 1.6434 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2183 - val_loss: 1.6431 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2421 - val_loss: 1.6429 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.2778 - val_loss: 1.6425 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2381 - val_loss: 1.6421 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2143 - val_loss: 1.6419 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2500 - val_loss: 1.6417 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2262 - val_loss: 1.6415 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2619 - val_loss: 1.6413 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2540 - val_loss: 1.6409 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2460 - val_loss: 1.6407 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2381 - val_loss: 1.6405 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2540 - val_loss: 1.6403 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2222 - val_loss: 1.6401 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2381 - val_loss: 1.6399 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2381 - val_loss: 1.6396 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2540 - val_loss: 1.6394 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2460 - val_loss: 1.6392 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2738 - val_loss: 1.6390 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2500 - val_loss: 1.6387 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2381 - val_loss: 1.6385 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2619 - val_loss: 1.6383 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2302 - val_loss: 1.6381 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2302 - val_loss: 1.6379 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2540 - val_loss: 1.6376 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2738 - val_loss: 1.6374 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2579 - val_loss: 1.6372 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2103 - val_loss: 1.6370 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2540 - val_loss: 1.6368 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2738 - val_loss: 1.6367 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2381 - val_loss: 1.6366 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2222 - val_loss: 1.6365 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2460 - val_loss: 1.6364 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2381 - val_loss: 1.6363 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2540 - val_loss: 1.6361 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2698 - val_loss: 1.6359 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2421 - val_loss: 1.6358 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2540 - val_loss: 1.6356 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2500 - val_loss: 1.6355 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2262 - val_loss: 1.6353 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2579 - val_loss: 1.6352 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2857 - val_loss: 1.6352 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2421 - val_loss: 1.6352 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2540 - val_loss: 1.6352 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2698 - val_loss: 1.6351 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2500 - val_loss: 1.6351 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2540 - val_loss: 1.6351 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2579 - val_loss: 1.6351 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2659 - val_loss: 1.6351 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2262 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2341 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2262 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.2540 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 49ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2500 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2659 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 44ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2540 - val_loss: 1.6350 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 44ms/epoch - 6ms/step\n",
      "Node 10 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 10 - Best Validation Accuracy: 0.3333\n",
      "Best model saved for Node 10 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_10.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_11_dataset.csv\n",
      "Node 11 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6355 - accuracy: 0.2016 - val_loss: 1.6345 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 2s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2056 - val_loss: 1.6343 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6357 - accuracy: 0.1855 - val_loss: 1.6341 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6365 - accuracy: 0.1734 - val_loss: 1.6339 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.1976 - val_loss: 1.6336 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2137 - val_loss: 1.6333 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6331 - accuracy: 0.2177 - val_loss: 1.6330 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6335 - accuracy: 0.2177 - val_loss: 1.6328 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2016 - val_loss: 1.6325 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.2298 - val_loss: 1.6322 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.2097 - val_loss: 1.6320 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.1935 - val_loss: 1.6317 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.1895 - val_loss: 1.6315 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2500 - val_loss: 1.6313 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2137 - val_loss: 1.6310 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.1855 - val_loss: 1.6308 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2177 - val_loss: 1.6306 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.2218 - val_loss: 1.6303 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6291 - accuracy: 0.2379 - val_loss: 1.6304 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6313 - accuracy: 0.2137 - val_loss: 1.6303 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2581 - val_loss: 1.6301 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2056 - val_loss: 1.6299 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.1734 - val_loss: 1.6298 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2137 - val_loss: 1.6296 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2056 - val_loss: 1.6294 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2218 - val_loss: 1.6292 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2218 - val_loss: 1.6290 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2258 - val_loss: 1.6287 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2016 - val_loss: 1.6285 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.1855 - val_loss: 1.6285 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2298 - val_loss: 1.6283 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.1855 - val_loss: 1.6280 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2056 - val_loss: 1.6278 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2218 - val_loss: 1.6277 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6260 - accuracy: 0.2137 - val_loss: 1.6275 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.1895 - val_loss: 1.6273 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2177 - val_loss: 1.6272 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6267 - accuracy: 0.2298 - val_loss: 1.6271 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.1935 - val_loss: 1.6270 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2177 - val_loss: 1.6269 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2016 - val_loss: 1.6268 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.1653 - val_loss: 1.6266 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2218 - val_loss: 1.6265 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2097 - val_loss: 1.6263 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2379 - val_loss: 1.6261 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2016 - val_loss: 1.6260 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2339 - val_loss: 1.6258 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2177 - val_loss: 1.6256 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2056 - val_loss: 1.6255 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2419 - val_loss: 1.6254 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2379 - val_loss: 1.6252 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2339 - val_loss: 1.6250 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.1573 - val_loss: 1.6250 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2258 - val_loss: 1.6250 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2258 - val_loss: 1.6248 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2177 - val_loss: 1.6247 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2258 - val_loss: 1.6245 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6184 - accuracy: 0.2258 - val_loss: 1.6244 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2339 - val_loss: 1.6243 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2177 - val_loss: 1.6242 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2500 - val_loss: 1.6242 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2298 - val_loss: 1.6240 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2339 - val_loss: 1.6239 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2218 - val_loss: 1.6238 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2500 - val_loss: 1.6238 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2379 - val_loss: 1.6237 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.1976 - val_loss: 1.6237 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.1855 - val_loss: 1.6237 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2379 - val_loss: 1.6237 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2218 - val_loss: 1.6236 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2097 - val_loss: 1.6235 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2540 - val_loss: 1.6234 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2097 - val_loss: 1.6234 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.2419 - val_loss: 1.6234 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2177 - val_loss: 1.6233 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2702 - val_loss: 1.6233 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2500 - val_loss: 1.6233 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6145 - accuracy: 0.2581 - val_loss: 1.6233 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2298 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2540 - val_loss: 1.6232 - val_accuracy: 0.2063 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2258 - val_loss: 1.6232 - val_accuracy: 0.2063 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2298 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2056 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2258 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2419 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2056 - val_loss: 1.6232 - val_accuracy: 0.2063 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6212 - accuracy: 0.2137 - val_loss: 1.6232 - val_accuracy: 0.2063 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6180 - accuracy: 0.2298 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2258 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2379 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2379 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6170 - accuracy: 0.2742 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2258 - val_loss: 1.6232 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 47ms/epoch - 3ms/step\n",
      "Node 11 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6328 - accuracy: 0.2137 - val_loss: 1.6331 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 3s/epoch - 352ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2621 - val_loss: 1.6328 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2137 - val_loss: 1.6326 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2218 - val_loss: 1.6324 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2177 - val_loss: 1.6322 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2056 - val_loss: 1.6321 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2298 - val_loss: 1.6319 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.1895 - val_loss: 1.6318 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2218 - val_loss: 1.6317 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2016 - val_loss: 1.6316 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2298 - val_loss: 1.6315 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.1855 - val_loss: 1.6314 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2298 - val_loss: 1.6312 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.1935 - val_loss: 1.6310 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2137 - val_loss: 1.6309 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2460 - val_loss: 1.6308 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2218 - val_loss: 1.6308 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2218 - val_loss: 1.6306 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2581 - val_loss: 1.6305 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2016 - val_loss: 1.6303 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2218 - val_loss: 1.6301 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2298 - val_loss: 1.6299 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2258 - val_loss: 1.6296 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2097 - val_loss: 1.6294 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2298 - val_loss: 1.6293 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2379 - val_loss: 1.6292 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2339 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2218 - val_loss: 1.6289 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2621 - val_loss: 1.6288 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2500 - val_loss: 1.6288 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.1976 - val_loss: 1.6288 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2218 - val_loss: 1.6286 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2460 - val_loss: 1.6285 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2298 - val_loss: 1.6283 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2379 - val_loss: 1.6281 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2016 - val_loss: 1.6279 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2137 - val_loss: 1.6278 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2218 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2298 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2419 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2097 - val_loss: 1.6273 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2097 - val_loss: 1.6272 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2177 - val_loss: 1.6270 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2379 - val_loss: 1.6269 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2016 - val_loss: 1.6269 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2177 - val_loss: 1.6269 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2339 - val_loss: 1.6268 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2137 - val_loss: 1.6267 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2419 - val_loss: 1.6266 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2137 - val_loss: 1.6264 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2419 - val_loss: 1.6263 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2298 - val_loss: 1.6263 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2298 - val_loss: 1.6262 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2218 - val_loss: 1.6261 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2339 - val_loss: 1.6261 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2702 - val_loss: 1.6261 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2419 - val_loss: 1.6260 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2218 - val_loss: 1.6259 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2218 - val_loss: 1.6258 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2218 - val_loss: 1.6257 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2419 - val_loss: 1.6256 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2298 - val_loss: 1.6255 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2339 - val_loss: 1.6254 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2379 - val_loss: 1.6253 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2298 - val_loss: 1.6252 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2540 - val_loss: 1.6251 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2419 - val_loss: 1.6250 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2177 - val_loss: 1.6249 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2298 - val_loss: 1.6249 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2137 - val_loss: 1.6248 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2460 - val_loss: 1.6248 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2339 - val_loss: 1.6248 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2379 - val_loss: 1.6248 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6248 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2540 - val_loss: 1.6247 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2056 - val_loss: 1.6247 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2258 - val_loss: 1.6247 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2177 - val_loss: 1.6247 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2460 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2177 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2782 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2460 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2419 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2218 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2500 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2298 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2540 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2258 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2500 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2258 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2218 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2419 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2258 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2661 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2500 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2702 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2298 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2500 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2621 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 29ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2460 - val_loss: 1.6245 - val_accuracy: 0.2222 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Node 11 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 1.6593 - accuracy: 0.1734 - val_loss: 1.6587 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 2s/epoch - 153ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6591 - accuracy: 0.1855 - val_loss: 1.6579 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6582 - accuracy: 0.2097 - val_loss: 1.6570 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6569 - accuracy: 0.1734 - val_loss: 1.6565 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6567 - accuracy: 0.1815 - val_loss: 1.6558 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6549 - accuracy: 0.2258 - val_loss: 1.6550 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6550 - accuracy: 0.2097 - val_loss: 1.6545 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6536 - accuracy: 0.2016 - val_loss: 1.6539 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6525 - accuracy: 0.2218 - val_loss: 1.6531 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6506 - accuracy: 0.2298 - val_loss: 1.6524 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6507 - accuracy: 0.2097 - val_loss: 1.6518 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6500 - accuracy: 0.2298 - val_loss: 1.6512 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6492 - accuracy: 0.2097 - val_loss: 1.6506 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6473 - accuracy: 0.2177 - val_loss: 1.6501 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6483 - accuracy: 0.2177 - val_loss: 1.6496 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6454 - accuracy: 0.2177 - val_loss: 1.6490 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6481 - accuracy: 0.2137 - val_loss: 1.6484 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6432 - accuracy: 0.2137 - val_loss: 1.6478 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6439 - accuracy: 0.2177 - val_loss: 1.6473 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6426 - accuracy: 0.2379 - val_loss: 1.6469 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6425 - accuracy: 0.2218 - val_loss: 1.6464 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6426 - accuracy: 0.2218 - val_loss: 1.6459 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6412 - accuracy: 0.2097 - val_loss: 1.6456 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6395 - accuracy: 0.2258 - val_loss: 1.6452 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6397 - accuracy: 0.2258 - val_loss: 1.6448 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6424 - accuracy: 0.2339 - val_loss: 1.6444 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 84ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6381 - accuracy: 0.2137 - val_loss: 1.6440 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6390 - accuracy: 0.2339 - val_loss: 1.6436 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6377 - accuracy: 0.2298 - val_loss: 1.6432 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6386 - accuracy: 0.2298 - val_loss: 1.6429 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6385 - accuracy: 0.2419 - val_loss: 1.6426 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6373 - accuracy: 0.2137 - val_loss: 1.6422 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6360 - accuracy: 0.2177 - val_loss: 1.6418 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6364 - accuracy: 0.2137 - val_loss: 1.6413 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2258 - val_loss: 1.6409 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2419 - val_loss: 1.6406 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6335 - accuracy: 0.2298 - val_loss: 1.6402 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2379 - val_loss: 1.6399 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6356 - accuracy: 0.2177 - val_loss: 1.6397 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2339 - val_loss: 1.6393 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.2419 - val_loss: 1.6391 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2298 - val_loss: 1.6388 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2258 - val_loss: 1.6385 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2460 - val_loss: 1.6382 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2339 - val_loss: 1.6380 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2177 - val_loss: 1.6377 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2258 - val_loss: 1.6376 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2056 - val_loss: 1.6373 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2298 - val_loss: 1.6372 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2137 - val_loss: 1.6370 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.2298 - val_loss: 1.6368 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2540 - val_loss: 1.6368 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2419 - val_loss: 1.6366 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2177 - val_loss: 1.6365 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2177 - val_loss: 1.6363 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2339 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2137 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2379 - val_loss: 1.6359 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2419 - val_loss: 1.6359 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6170 - accuracy: 0.2339 - val_loss: 1.6358 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2339 - val_loss: 1.6357 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6133 - accuracy: 0.2419 - val_loss: 1.6355 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2379 - val_loss: 1.6356 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6163 - accuracy: 0.2419 - val_loss: 1.6356 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2298 - val_loss: 1.6355 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2298 - val_loss: 1.6354 - val_accuracy: 0.2540 - lr: 5.0000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2460 - val_loss: 1.6353 - val_accuracy: 0.2540 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2379 - val_loss: 1.6353 - val_accuracy: 0.2540 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2419 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6120 - accuracy: 0.2298 - val_loss: 1.6353 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2379 - val_loss: 1.6353 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2218 - val_loss: 1.6353 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6152 - accuracy: 0.2218 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 84ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2460 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2581 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2581 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2460 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2500 - val_loss: 1.6354 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 65ms/epoch - 4ms/step\n",
      "Node 11 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6610 - accuracy: 0.1694 - val_loss: 1.6605 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 3s/epoch - 348ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6602 - accuracy: 0.2097 - val_loss: 1.6599 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6598 - accuracy: 0.1976 - val_loss: 1.6595 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6596 - accuracy: 0.1976 - val_loss: 1.6588 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.2621 - val_loss: 1.6583 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.2379 - val_loss: 1.6578 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2097 - val_loss: 1.6574 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2097 - val_loss: 1.6568 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6565 - accuracy: 0.1855 - val_loss: 1.6563 - val_accuracy: 0.3016 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.2097 - val_loss: 1.6558 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.1976 - val_loss: 1.6553 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2460 - val_loss: 1.6548 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6543 - accuracy: 0.2218 - val_loss: 1.6544 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6565 - accuracy: 0.1694 - val_loss: 1.6540 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2218 - val_loss: 1.6536 - val_accuracy: 0.3016 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6534 - accuracy: 0.1774 - val_loss: 1.6532 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2339 - val_loss: 1.6528 - val_accuracy: 0.3175 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6516 - accuracy: 0.2258 - val_loss: 1.6523 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6509 - accuracy: 0.2379 - val_loss: 1.6519 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6509 - accuracy: 0.2500 - val_loss: 1.6515 - val_accuracy: 0.3016 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2218 - val_loss: 1.6511 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.1976 - val_loss: 1.6508 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6509 - accuracy: 0.1855 - val_loss: 1.6505 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2540 - val_loss: 1.6501 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6503 - accuracy: 0.2097 - val_loss: 1.6497 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6475 - accuracy: 0.2379 - val_loss: 1.6493 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6471 - accuracy: 0.2258 - val_loss: 1.6489 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6473 - accuracy: 0.2460 - val_loss: 1.6485 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6475 - accuracy: 0.2500 - val_loss: 1.6481 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2339 - val_loss: 1.6478 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2298 - val_loss: 1.6474 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2500 - val_loss: 1.6470 - val_accuracy: 0.2698 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2137 - val_loss: 1.6468 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2258 - val_loss: 1.6466 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2419 - val_loss: 1.6463 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2218 - val_loss: 1.6460 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2581 - val_loss: 1.6458 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2661 - val_loss: 1.6454 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2258 - val_loss: 1.6452 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2379 - val_loss: 1.6449 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2621 - val_loss: 1.6446 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.2419 - val_loss: 1.6443 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2177 - val_loss: 1.6440 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2137 - val_loss: 1.6437 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2298 - val_loss: 1.6433 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2258 - val_loss: 1.6430 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.1734 - val_loss: 1.6427 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2379 - val_loss: 1.6425 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.1895 - val_loss: 1.6423 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2540 - val_loss: 1.6420 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2298 - val_loss: 1.6418 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2258 - val_loss: 1.6417 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2460 - val_loss: 1.6415 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2500 - val_loss: 1.6412 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2379 - val_loss: 1.6409 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2097 - val_loss: 1.6406 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6360 - accuracy: 0.2258 - val_loss: 1.6404 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 63ms/epoch - 8ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2137 - val_loss: 1.6403 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2581 - val_loss: 1.6401 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2540 - val_loss: 1.6398 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.1815 - val_loss: 1.6395 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2177 - val_loss: 1.6394 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2460 - val_loss: 1.6391 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2742 - val_loss: 1.6390 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2460 - val_loss: 1.6388 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2661 - val_loss: 1.6386 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2460 - val_loss: 1.6386 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2500 - val_loss: 1.6384 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2581 - val_loss: 1.6384 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2419 - val_loss: 1.6384 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2823 - val_loss: 1.6382 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2379 - val_loss: 1.6381 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2258 - val_loss: 1.6379 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2500 - val_loss: 1.6377 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2581 - val_loss: 1.6374 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2177 - val_loss: 1.6373 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2460 - val_loss: 1.6373 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2661 - val_loss: 1.6370 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2782 - val_loss: 1.6368 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2621 - val_loss: 1.6367 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2621 - val_loss: 1.6366 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2500 - val_loss: 1.6364 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2742 - val_loss: 1.6362 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2379 - val_loss: 1.6362 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2339 - val_loss: 1.6361 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.3185 - val_loss: 1.6363 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2742 - val_loss: 1.6363 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2863 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2419 - val_loss: 1.6362 - val_accuracy: 0.2381 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2339 - val_loss: 1.6362 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2540 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2782 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 2.5000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2460 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2661 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2863 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2500 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2460 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2540 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2540 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2419 - val_loss: 1.6360 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 42ms/epoch - 5ms/step\n",
      "Node 11 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 11 - Best Validation Accuracy: 0.3175\n",
      "Best model saved for Node 11 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_11.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_12_dataset.csv\n",
      "Node 12 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 - 2s - loss: 1.6349 - accuracy: 0.2418 - val_loss: 1.6360 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 2s/epoch - 135ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 1.6344 - accuracy: 0.2527 - val_loss: 1.6356 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 44ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 1.6329 - accuracy: 0.2930 - val_loss: 1.6352 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 43ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 1.6341 - accuracy: 0.1978 - val_loss: 1.6347 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 44ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 1.6313 - accuracy: 0.2747 - val_loss: 1.6342 - val_accuracy: 0.2174 - lr: 1.0000e-04 - 45ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 1.6327 - accuracy: 0.2344 - val_loss: 1.6336 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 1.6322 - accuracy: 0.2454 - val_loss: 1.6331 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 1.6318 - accuracy: 0.2381 - val_loss: 1.6325 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 1.6291 - accuracy: 0.2527 - val_loss: 1.6322 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 1.6303 - accuracy: 0.2308 - val_loss: 1.6317 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 1.6301 - accuracy: 0.2234 - val_loss: 1.6313 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 1.6270 - accuracy: 0.2747 - val_loss: 1.6307 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 1.6287 - accuracy: 0.2564 - val_loss: 1.6300 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 1.6287 - accuracy: 0.2161 - val_loss: 1.6292 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 1.6283 - accuracy: 0.2125 - val_loss: 1.6286 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 1.6289 - accuracy: 0.2344 - val_loss: 1.6283 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 1.6270 - accuracy: 0.2344 - val_loss: 1.6278 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 1.6278 - accuracy: 0.2161 - val_loss: 1.6275 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 1.6248 - accuracy: 0.2601 - val_loss: 1.6272 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 1.6272 - accuracy: 0.2344 - val_loss: 1.6268 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 1.6259 - accuracy: 0.2271 - val_loss: 1.6264 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 1.6278 - accuracy: 0.2125 - val_loss: 1.6263 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 1.6261 - accuracy: 0.2418 - val_loss: 1.6258 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 1.6241 - accuracy: 0.2564 - val_loss: 1.6254 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 1.6233 - accuracy: 0.2491 - val_loss: 1.6252 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 1.6232 - accuracy: 0.2308 - val_loss: 1.6248 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 1.6239 - accuracy: 0.2454 - val_loss: 1.6244 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 1.6222 - accuracy: 0.2234 - val_loss: 1.6239 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 1.6234 - accuracy: 0.2125 - val_loss: 1.6235 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 1.6266 - accuracy: 0.2418 - val_loss: 1.6232 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 1.6227 - accuracy: 0.2198 - val_loss: 1.6230 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 1.6234 - accuracy: 0.2234 - val_loss: 1.6229 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 1.6239 - accuracy: 0.2418 - val_loss: 1.6226 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 1.6227 - accuracy: 0.2381 - val_loss: 1.6223 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 1.6251 - accuracy: 0.2198 - val_loss: 1.6219 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 1.6198 - accuracy: 0.2344 - val_loss: 1.6217 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 1.6211 - accuracy: 0.2125 - val_loss: 1.6215 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 1.6207 - accuracy: 0.2454 - val_loss: 1.6213 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 1.6197 - accuracy: 0.2454 - val_loss: 1.6210 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 1.6214 - accuracy: 0.2418 - val_loss: 1.6207 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 1.6228 - accuracy: 0.2161 - val_loss: 1.6203 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 1.6183 - accuracy: 0.2271 - val_loss: 1.6201 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 1.6180 - accuracy: 0.2344 - val_loss: 1.6199 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 1.6196 - accuracy: 0.2637 - val_loss: 1.6196 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 1.6172 - accuracy: 0.2418 - val_loss: 1.6191 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 1.6202 - accuracy: 0.2601 - val_loss: 1.6189 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 1.6165 - accuracy: 0.2711 - val_loss: 1.6185 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 1.6176 - accuracy: 0.2601 - val_loss: 1.6181 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 1.6186 - accuracy: 0.2271 - val_loss: 1.6178 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 1.6200 - accuracy: 0.2381 - val_loss: 1.6175 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 1.6173 - accuracy: 0.2601 - val_loss: 1.6171 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 1.6165 - accuracy: 0.2344 - val_loss: 1.6168 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 1.6209 - accuracy: 0.2344 - val_loss: 1.6165 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 1.6105 - accuracy: 0.2601 - val_loss: 1.6163 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 1.6158 - accuracy: 0.2527 - val_loss: 1.6161 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 1.6106 - accuracy: 0.2857 - val_loss: 1.6156 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 1.6162 - accuracy: 0.2527 - val_loss: 1.6155 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 1.6157 - accuracy: 0.2381 - val_loss: 1.6154 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 1.6193 - accuracy: 0.2637 - val_loss: 1.6154 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 1.6164 - accuracy: 0.2527 - val_loss: 1.6156 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 1.6191 - accuracy: 0.2234 - val_loss: 1.6156 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "18/18 - 0s - loss: 1.6170 - accuracy: 0.2198 - val_loss: 1.6156 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 1.6161 - accuracy: 0.2637 - val_loss: 1.6156 - val_accuracy: 0.2609 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 1.6133 - accuracy: 0.2527 - val_loss: 1.6155 - val_accuracy: 0.2609 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "18/18 - 0s - loss: 1.6164 - accuracy: 0.2344 - val_loss: 1.6154 - val_accuracy: 0.2609 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 1.6141 - accuracy: 0.2857 - val_loss: 1.6153 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 1.6180 - accuracy: 0.2271 - val_loss: 1.6152 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 1.6170 - accuracy: 0.2344 - val_loss: 1.6151 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 1.6140 - accuracy: 0.2564 - val_loss: 1.6151 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 1.6152 - accuracy: 0.2491 - val_loss: 1.6151 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 1.6082 - accuracy: 0.2381 - val_loss: 1.6150 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 1.6139 - accuracy: 0.2637 - val_loss: 1.6149 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 1.6139 - accuracy: 0.2747 - val_loss: 1.6148 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "18/18 - 0s - loss: 1.6113 - accuracy: 0.2601 - val_loss: 1.6148 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "18/18 - 0s - loss: 1.6143 - accuracy: 0.2454 - val_loss: 1.6147 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "18/18 - 0s - loss: 1.6168 - accuracy: 0.2637 - val_loss: 1.6146 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "18/18 - 0s - loss: 1.6172 - accuracy: 0.2308 - val_loss: 1.6145 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "18/18 - 0s - loss: 1.6169 - accuracy: 0.2711 - val_loss: 1.6145 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "18/18 - 0s - loss: 1.6195 - accuracy: 0.2344 - val_loss: 1.6144 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "18/18 - 0s - loss: 1.6101 - accuracy: 0.2821 - val_loss: 1.6144 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "18/18 - 0s - loss: 1.6159 - accuracy: 0.2527 - val_loss: 1.6144 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "18/18 - 0s - loss: 1.6162 - accuracy: 0.2491 - val_loss: 1.6143 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "18/18 - 0s - loss: 1.6133 - accuracy: 0.2308 - val_loss: 1.6143 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "18/18 - 0s - loss: 1.6118 - accuracy: 0.2601 - val_loss: 1.6142 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "18/18 - 0s - loss: 1.6179 - accuracy: 0.2454 - val_loss: 1.6142 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "18/18 - 0s - loss: 1.6099 - accuracy: 0.2381 - val_loss: 1.6141 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "18/18 - 0s - loss: 1.6138 - accuracy: 0.2454 - val_loss: 1.6140 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "18/18 - 0s - loss: 1.6135 - accuracy: 0.2674 - val_loss: 1.6140 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "18/18 - 0s - loss: 1.6158 - accuracy: 0.2527 - val_loss: 1.6140 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "18/18 - 0s - loss: 1.6101 - accuracy: 0.2637 - val_loss: 1.6140 - val_accuracy: 0.2609 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "18/18 - 0s - loss: 1.6102 - accuracy: 0.2674 - val_loss: 1.6140 - val_accuracy: 0.2609 - lr: 1.2500e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "18/18 - 0s - loss: 1.6129 - accuracy: 0.2308 - val_loss: 1.6139 - val_accuracy: 0.2609 - lr: 1.2500e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "18/18 - 0s - loss: 1.6120 - accuracy: 0.2821 - val_loss: 1.6139 - val_accuracy: 0.2609 - lr: 1.2500e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "18/18 - 0s - loss: 1.6129 - accuracy: 0.2527 - val_loss: 1.6139 - val_accuracy: 0.2609 - lr: 1.2500e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "18/18 - 0s - loss: 1.6157 - accuracy: 0.2711 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 1.2500e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "18/18 - 0s - loss: 1.6100 - accuracy: 0.2601 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "18/18 - 0s - loss: 1.6144 - accuracy: 0.2491 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "18/18 - 0s - loss: 1.6146 - accuracy: 0.2234 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 6.2500e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "18/18 - 0s - loss: 1.6205 - accuracy: 0.2418 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "18/18 - 0s - loss: 1.6156 - accuracy: 0.2418 - val_loss: 1.6138 - val_accuracy: 0.2609 - lr: 6.2500e-06 - 52ms/epoch - 3ms/step\n",
      "Node 12 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 2s - loss: 1.6376 - accuracy: 0.1758 - val_loss: 1.6357 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 2s/epoch - 275ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2125 - val_loss: 1.6352 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6355 - accuracy: 0.1941 - val_loss: 1.6349 - val_accuracy: 0.2174 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6346 - accuracy: 0.2161 - val_loss: 1.6345 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6340 - accuracy: 0.2125 - val_loss: 1.6342 - val_accuracy: 0.1739 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6342 - accuracy: 0.1795 - val_loss: 1.6339 - val_accuracy: 0.1739 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.2161 - val_loss: 1.6336 - val_accuracy: 0.1594 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6337 - accuracy: 0.2271 - val_loss: 1.6333 - val_accuracy: 0.1884 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.2637 - val_loss: 1.6331 - val_accuracy: 0.1884 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6326 - accuracy: 0.2161 - val_loss: 1.6329 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6329 - accuracy: 0.2234 - val_loss: 1.6327 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6330 - accuracy: 0.1941 - val_loss: 1.6325 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.1978 - val_loss: 1.6323 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.2271 - val_loss: 1.6321 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6316 - accuracy: 0.2491 - val_loss: 1.6319 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2601 - val_loss: 1.6317 - val_accuracy: 0.2174 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2418 - val_loss: 1.6314 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2088 - val_loss: 1.6310 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2454 - val_loss: 1.6307 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6310 - accuracy: 0.2344 - val_loss: 1.6305 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6307 - accuracy: 0.2234 - val_loss: 1.6302 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6298 - accuracy: 0.2381 - val_loss: 1.6299 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2271 - val_loss: 1.6296 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2198 - val_loss: 1.6294 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.1941 - val_loss: 1.6292 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6298 - accuracy: 0.2637 - val_loss: 1.6290 - val_accuracy: 0.2174 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6294 - accuracy: 0.2418 - val_loss: 1.6289 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2308 - val_loss: 1.6287 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2454 - val_loss: 1.6285 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2381 - val_loss: 1.6282 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2271 - val_loss: 1.6281 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6280 - accuracy: 0.2381 - val_loss: 1.6280 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6280 - accuracy: 0.2454 - val_loss: 1.6278 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2454 - val_loss: 1.6276 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2088 - val_loss: 1.6274 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2601 - val_loss: 1.6272 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2125 - val_loss: 1.6270 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2454 - val_loss: 1.6268 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6280 - accuracy: 0.2344 - val_loss: 1.6267 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6268 - accuracy: 0.2637 - val_loss: 1.6265 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.2527 - val_loss: 1.6262 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.2527 - val_loss: 1.6260 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.2051 - val_loss: 1.6258 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.2308 - val_loss: 1.6257 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2454 - val_loss: 1.6255 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6282 - accuracy: 0.2198 - val_loss: 1.6253 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2381 - val_loss: 1.6251 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6243 - accuracy: 0.2784 - val_loss: 1.6249 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2491 - val_loss: 1.6246 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.2711 - val_loss: 1.6243 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2784 - val_loss: 1.6241 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2821 - val_loss: 1.6238 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6199 - accuracy: 0.2784 - val_loss: 1.6236 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6226 - accuracy: 0.2527 - val_loss: 1.6233 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2564 - val_loss: 1.6231 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2711 - val_loss: 1.6228 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2381 - val_loss: 1.6226 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6209 - accuracy: 0.2857 - val_loss: 1.6225 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2527 - val_loss: 1.6223 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6213 - accuracy: 0.2674 - val_loss: 1.6221 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6201 - accuracy: 0.2564 - val_loss: 1.6219 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2674 - val_loss: 1.6217 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2454 - val_loss: 1.6215 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2308 - val_loss: 1.6213 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2564 - val_loss: 1.6212 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.2418 - val_loss: 1.6212 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6203 - accuracy: 0.2418 - val_loss: 1.6210 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2527 - val_loss: 1.6208 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2418 - val_loss: 1.6205 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6213 - accuracy: 0.2051 - val_loss: 1.6203 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6195 - accuracy: 0.2418 - val_loss: 1.6202 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6216 - accuracy: 0.2308 - val_loss: 1.6200 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6171 - accuracy: 0.2564 - val_loss: 1.6197 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6175 - accuracy: 0.2930 - val_loss: 1.6195 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2308 - val_loss: 1.6194 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2491 - val_loss: 1.6192 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6198 - accuracy: 0.2674 - val_loss: 1.6190 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6173 - accuracy: 0.2601 - val_loss: 1.6189 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6194 - accuracy: 0.2637 - val_loss: 1.6187 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6158 - accuracy: 0.2491 - val_loss: 1.6185 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6207 - accuracy: 0.2491 - val_loss: 1.6183 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2308 - val_loss: 1.6182 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6187 - accuracy: 0.2454 - val_loss: 1.6181 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6185 - accuracy: 0.2271 - val_loss: 1.6179 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6167 - accuracy: 0.2601 - val_loss: 1.6177 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6165 - accuracy: 0.2637 - val_loss: 1.6175 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6169 - accuracy: 0.2564 - val_loss: 1.6173 - val_accuracy: 0.2899 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6151 - accuracy: 0.2527 - val_loss: 1.6171 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6198 - accuracy: 0.2564 - val_loss: 1.6170 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.2308 - val_loss: 1.6169 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2637 - val_loss: 1.6168 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6150 - accuracy: 0.2821 - val_loss: 1.6167 - val_accuracy: 0.2899 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6199 - accuracy: 0.2125 - val_loss: 1.6165 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6138 - accuracy: 0.2784 - val_loss: 1.6163 - val_accuracy: 0.3188 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6159 - accuracy: 0.2418 - val_loss: 1.6162 - val_accuracy: 0.3188 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6122 - accuracy: 0.2637 - val_loss: 1.6160 - val_accuracy: 0.3188 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6147 - accuracy: 0.2601 - val_loss: 1.6158 - val_accuracy: 0.3188 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6148 - accuracy: 0.2308 - val_loss: 1.6156 - val_accuracy: 0.3043 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6137 - accuracy: 0.2784 - val_loss: 1.6154 - val_accuracy: 0.3188 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6134 - accuracy: 0.2381 - val_loss: 1.6152 - val_accuracy: 0.3333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Node 12 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 - 3s - loss: 1.6613 - accuracy: 0.1868 - val_loss: 1.6595 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 3s/epoch - 157ms/step\n",
      "Epoch 2/100\n",
      "18/18 - 0s - loss: 1.6593 - accuracy: 0.2198 - val_loss: 1.6580 - val_accuracy: 0.2029 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "18/18 - 0s - loss: 1.6589 - accuracy: 0.2308 - val_loss: 1.6569 - val_accuracy: 0.1739 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "18/18 - 0s - loss: 1.6567 - accuracy: 0.2161 - val_loss: 1.6553 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "18/18 - 0s - loss: 1.6560 - accuracy: 0.2418 - val_loss: 1.6542 - val_accuracy: 0.1884 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "18/18 - 0s - loss: 1.6551 - accuracy: 0.2271 - val_loss: 1.6531 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "18/18 - 0s - loss: 1.6527 - accuracy: 0.2454 - val_loss: 1.6515 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "18/18 - 0s - loss: 1.6512 - accuracy: 0.2308 - val_loss: 1.6500 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "18/18 - 0s - loss: 1.6502 - accuracy: 0.2234 - val_loss: 1.6487 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "18/18 - 0s - loss: 1.6489 - accuracy: 0.2381 - val_loss: 1.6479 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "18/18 - 0s - loss: 1.6489 - accuracy: 0.2344 - val_loss: 1.6468 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "18/18 - 0s - loss: 1.6493 - accuracy: 0.2418 - val_loss: 1.6458 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "18/18 - 0s - loss: 1.6457 - accuracy: 0.2161 - val_loss: 1.6447 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "18/18 - 0s - loss: 1.6442 - accuracy: 0.2418 - val_loss: 1.6442 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "18/18 - 0s - loss: 1.6478 - accuracy: 0.2601 - val_loss: 1.6435 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "18/18 - 0s - loss: 1.6464 - accuracy: 0.2527 - val_loss: 1.6430 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "18/18 - 0s - loss: 1.6446 - accuracy: 0.2344 - val_loss: 1.6427 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "18/18 - 0s - loss: 1.6435 - accuracy: 0.2418 - val_loss: 1.6418 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "18/18 - 0s - loss: 1.6433 - accuracy: 0.2308 - val_loss: 1.6409 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "18/18 - 0s - loss: 1.6423 - accuracy: 0.2418 - val_loss: 1.6399 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "18/18 - 0s - loss: 1.6434 - accuracy: 0.2418 - val_loss: 1.6394 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "18/18 - 0s - loss: 1.6389 - accuracy: 0.2308 - val_loss: 1.6385 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "18/18 - 0s - loss: 1.6406 - accuracy: 0.2381 - val_loss: 1.6377 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "18/18 - 0s - loss: 1.6420 - accuracy: 0.2381 - val_loss: 1.6373 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "18/18 - 0s - loss: 1.6383 - accuracy: 0.2454 - val_loss: 1.6363 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "18/18 - 0s - loss: 1.6367 - accuracy: 0.2381 - val_loss: 1.6354 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "18/18 - 0s - loss: 1.6352 - accuracy: 0.2344 - val_loss: 1.6347 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "18/18 - 0s - loss: 1.6355 - accuracy: 0.2381 - val_loss: 1.6341 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "18/18 - 0s - loss: 1.6328 - accuracy: 0.2381 - val_loss: 1.6335 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "18/18 - 0s - loss: 1.6371 - accuracy: 0.2418 - val_loss: 1.6328 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "18/18 - 0s - loss: 1.6396 - accuracy: 0.2271 - val_loss: 1.6322 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "18/18 - 0s - loss: 1.6364 - accuracy: 0.2381 - val_loss: 1.6315 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "18/18 - 0s - loss: 1.6359 - accuracy: 0.2161 - val_loss: 1.6309 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "18/18 - 0s - loss: 1.6329 - accuracy: 0.2308 - val_loss: 1.6304 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "18/18 - 0s - loss: 1.6368 - accuracy: 0.2418 - val_loss: 1.6298 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "18/18 - 0s - loss: 1.6308 - accuracy: 0.2674 - val_loss: 1.6292 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "18/18 - 0s - loss: 1.6352 - accuracy: 0.2381 - val_loss: 1.6289 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "18/18 - 0s - loss: 1.6291 - accuracy: 0.2308 - val_loss: 1.6284 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "18/18 - 0s - loss: 1.6320 - accuracy: 0.2418 - val_loss: 1.6281 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "18/18 - 0s - loss: 1.6334 - accuracy: 0.2454 - val_loss: 1.6280 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 79ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "18/18 - 0s - loss: 1.6265 - accuracy: 0.2418 - val_loss: 1.6276 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "18/18 - 0s - loss: 1.6283 - accuracy: 0.2454 - val_loss: 1.6271 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "18/18 - 0s - loss: 1.6307 - accuracy: 0.2418 - val_loss: 1.6266 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "18/18 - 0s - loss: 1.6295 - accuracy: 0.2308 - val_loss: 1.6262 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "18/18 - 0s - loss: 1.6319 - accuracy: 0.2344 - val_loss: 1.6257 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "18/18 - 0s - loss: 1.6237 - accuracy: 0.2308 - val_loss: 1.6252 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "18/18 - 0s - loss: 1.6267 - accuracy: 0.2344 - val_loss: 1.6250 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "18/18 - 0s - loss: 1.6302 - accuracy: 0.2418 - val_loss: 1.6247 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "18/18 - 0s - loss: 1.6249 - accuracy: 0.2418 - val_loss: 1.6246 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "18/18 - 0s - loss: 1.6238 - accuracy: 0.2454 - val_loss: 1.6238 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 96ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "18/18 - 0s - loss: 1.6236 - accuracy: 0.2454 - val_loss: 1.6233 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "18/18 - 0s - loss: 1.6267 - accuracy: 0.2308 - val_loss: 1.6228 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "18/18 - 0s - loss: 1.6253 - accuracy: 0.2491 - val_loss: 1.6226 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "18/18 - 0s - loss: 1.6231 - accuracy: 0.2418 - val_loss: 1.6222 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "18/18 - 0s - loss: 1.6268 - accuracy: 0.2381 - val_loss: 1.6218 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "18/18 - 0s - loss: 1.6261 - accuracy: 0.2344 - val_loss: 1.6214 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "18/18 - 0s - loss: 1.6266 - accuracy: 0.2637 - val_loss: 1.6211 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "18/18 - 0s - loss: 1.6257 - accuracy: 0.2454 - val_loss: 1.6209 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "18/18 - 0s - loss: 1.6288 - accuracy: 0.2418 - val_loss: 1.6209 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "18/18 - 0s - loss: 1.6244 - accuracy: 0.2454 - val_loss: 1.6204 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "18/18 - 0s - loss: 1.6234 - accuracy: 0.2747 - val_loss: 1.6199 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "18/18 - 0s - loss: 1.6219 - accuracy: 0.2711 - val_loss: 1.6194 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "18/18 - 0s - loss: 1.6270 - accuracy: 0.2491 - val_loss: 1.6191 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "18/18 - 0s - loss: 1.6196 - accuracy: 0.2344 - val_loss: 1.6186 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "18/18 - 0s - loss: 1.6228 - accuracy: 0.2454 - val_loss: 1.6182 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "18/18 - 0s - loss: 1.6200 - accuracy: 0.2344 - val_loss: 1.6178 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "18/18 - 0s - loss: 1.6218 - accuracy: 0.2454 - val_loss: 1.6174 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "18/18 - 0s - loss: 1.6182 - accuracy: 0.2381 - val_loss: 1.6172 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "18/18 - 0s - loss: 1.6205 - accuracy: 0.2601 - val_loss: 1.6169 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 77ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "18/18 - 0s - loss: 1.6196 - accuracy: 0.2271 - val_loss: 1.6166 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "18/18 - 0s - loss: 1.6232 - accuracy: 0.2308 - val_loss: 1.6164 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "18/18 - 0s - loss: 1.6189 - accuracy: 0.2564 - val_loss: 1.6162 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "18/18 - 0s - loss: 1.6175 - accuracy: 0.2491 - val_loss: 1.6158 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "18/18 - 0s - loss: 1.6212 - accuracy: 0.2308 - val_loss: 1.6152 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "18/18 - 0s - loss: 1.6183 - accuracy: 0.2564 - val_loss: 1.6150 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "18/18 - 0s - loss: 1.6160 - accuracy: 0.2674 - val_loss: 1.6149 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "18/18 - 0s - loss: 1.6159 - accuracy: 0.2747 - val_loss: 1.6146 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "18/18 - 0s - loss: 1.6191 - accuracy: 0.2674 - val_loss: 1.6143 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "18/18 - 0s - loss: 1.6128 - accuracy: 0.2454 - val_loss: 1.6140 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "18/18 - 0s - loss: 1.6148 - accuracy: 0.2344 - val_loss: 1.6135 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "18/18 - 0s - loss: 1.6172 - accuracy: 0.2491 - val_loss: 1.6131 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "18/18 - 0s - loss: 1.6130 - accuracy: 0.2564 - val_loss: 1.6130 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "18/18 - 0s - loss: 1.6125 - accuracy: 0.2637 - val_loss: 1.6128 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 79ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "18/18 - 0s - loss: 1.6183 - accuracy: 0.2564 - val_loss: 1.6125 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "18/18 - 0s - loss: 1.6145 - accuracy: 0.2418 - val_loss: 1.6125 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "18/18 - 0s - loss: 1.6140 - accuracy: 0.2601 - val_loss: 1.6121 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "18/18 - 0s - loss: 1.6111 - accuracy: 0.2491 - val_loss: 1.6121 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "18/18 - 0s - loss: 1.6119 - accuracy: 0.2527 - val_loss: 1.6117 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "18/18 - 0s - loss: 1.6157 - accuracy: 0.2454 - val_loss: 1.6119 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 77ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "18/18 - 0s - loss: 1.6165 - accuracy: 0.2564 - val_loss: 1.6118 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "18/18 - 0s - loss: 1.6153 - accuracy: 0.2821 - val_loss: 1.6114 - val_accuracy: 0.2899 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "18/18 - 0s - loss: 1.6097 - accuracy: 0.2784 - val_loss: 1.6110 - val_accuracy: 0.2899 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "18/18 - 0s - loss: 1.6107 - accuracy: 0.3004 - val_loss: 1.6105 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "18/18 - 0s - loss: 1.6116 - accuracy: 0.2637 - val_loss: 1.6099 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "18/18 - 0s - loss: 1.6080 - accuracy: 0.2784 - val_loss: 1.6096 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "18/18 - 0s - loss: 1.6104 - accuracy: 0.2674 - val_loss: 1.6094 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "18/18 - 0s - loss: 1.6089 - accuracy: 0.2857 - val_loss: 1.6092 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "18/18 - 0s - loss: 1.6105 - accuracy: 0.2564 - val_loss: 1.6089 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "18/18 - 0s - loss: 1.6089 - accuracy: 0.2711 - val_loss: 1.6088 - val_accuracy: 0.2754 - lr: 1.0000e-04 - 95ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "18/18 - 0s - loss: 1.6129 - accuracy: 0.2527 - val_loss: 1.6086 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Node 12 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 2s - loss: 1.6590 - accuracy: 0.2015 - val_loss: 1.6591 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 2s/epoch - 273ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6587 - accuracy: 0.2198 - val_loss: 1.6581 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6569 - accuracy: 0.1941 - val_loss: 1.6569 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6546 - accuracy: 0.2418 - val_loss: 1.6561 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6565 - accuracy: 0.2198 - val_loss: 1.6553 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6546 - accuracy: 0.2308 - val_loss: 1.6542 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6541 - accuracy: 0.2454 - val_loss: 1.6532 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6517 - accuracy: 0.2418 - val_loss: 1.6522 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6528 - accuracy: 0.2198 - val_loss: 1.6514 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6523 - accuracy: 0.2344 - val_loss: 1.6506 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6500 - accuracy: 0.2234 - val_loss: 1.6498 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6482 - accuracy: 0.2344 - val_loss: 1.6489 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6507 - accuracy: 0.2344 - val_loss: 1.6483 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6486 - accuracy: 0.2234 - val_loss: 1.6476 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6478 - accuracy: 0.2308 - val_loss: 1.6469 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6477 - accuracy: 0.2344 - val_loss: 1.6462 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6470 - accuracy: 0.2418 - val_loss: 1.6455 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6463 - accuracy: 0.2198 - val_loss: 1.6448 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6477 - accuracy: 0.2271 - val_loss: 1.6443 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6443 - accuracy: 0.2161 - val_loss: 1.6438 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6408 - accuracy: 0.2271 - val_loss: 1.6430 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6463 - accuracy: 0.2418 - val_loss: 1.6424 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6433 - accuracy: 0.2271 - val_loss: 1.6418 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6442 - accuracy: 0.2234 - val_loss: 1.6412 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6402 - accuracy: 0.2454 - val_loss: 1.6407 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6428 - accuracy: 0.2308 - val_loss: 1.6401 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6380 - accuracy: 0.2418 - val_loss: 1.6395 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6410 - accuracy: 0.2234 - val_loss: 1.6390 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6381 - accuracy: 0.2198 - val_loss: 1.6384 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6404 - accuracy: 0.2271 - val_loss: 1.6379 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6413 - accuracy: 0.2125 - val_loss: 1.6374 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6406 - accuracy: 0.2234 - val_loss: 1.6370 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6398 - accuracy: 0.2344 - val_loss: 1.6364 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2015 - val_loss: 1.6359 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6371 - accuracy: 0.2234 - val_loss: 1.6355 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6392 - accuracy: 0.2088 - val_loss: 1.6351 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6379 - accuracy: 0.2344 - val_loss: 1.6347 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6371 - accuracy: 0.2527 - val_loss: 1.6342 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6350 - accuracy: 0.2527 - val_loss: 1.6338 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6357 - accuracy: 0.2381 - val_loss: 1.6333 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6333 - accuracy: 0.2381 - val_loss: 1.6328 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2234 - val_loss: 1.6325 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6338 - accuracy: 0.2564 - val_loss: 1.6321 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6329 - accuracy: 0.2857 - val_loss: 1.6318 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6346 - accuracy: 0.2601 - val_loss: 1.6314 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.2418 - val_loss: 1.6311 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.2418 - val_loss: 1.6306 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6296 - accuracy: 0.2344 - val_loss: 1.6303 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6352 - accuracy: 0.2088 - val_loss: 1.6300 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.2418 - val_loss: 1.6297 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.2161 - val_loss: 1.6293 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.2198 - val_loss: 1.6290 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2564 - val_loss: 1.6287 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.2491 - val_loss: 1.6284 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6268 - accuracy: 0.2527 - val_loss: 1.6281 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6286 - accuracy: 0.2198 - val_loss: 1.6278 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6316 - accuracy: 0.2308 - val_loss: 1.6275 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2454 - val_loss: 1.6272 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 65ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6271 - accuracy: 0.2527 - val_loss: 1.6270 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6292 - accuracy: 0.2161 - val_loss: 1.6267 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6311 - accuracy: 0.2381 - val_loss: 1.6263 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2711 - val_loss: 1.6260 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2271 - val_loss: 1.6259 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.1905 - val_loss: 1.6256 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2418 - val_loss: 1.6254 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6236 - accuracy: 0.2491 - val_loss: 1.6250 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6269 - accuracy: 0.2271 - val_loss: 1.6248 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6271 - accuracy: 0.2601 - val_loss: 1.6245 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2271 - val_loss: 1.6241 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2418 - val_loss: 1.6238 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.2344 - val_loss: 1.6236 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2271 - val_loss: 1.6233 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2381 - val_loss: 1.6231 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6250 - accuracy: 0.2381 - val_loss: 1.6227 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6264 - accuracy: 0.2125 - val_loss: 1.6226 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6300 - accuracy: 0.2051 - val_loss: 1.6226 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2344 - val_loss: 1.6225 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2088 - val_loss: 1.6223 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6225 - accuracy: 0.2601 - val_loss: 1.6221 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6225 - accuracy: 0.2527 - val_loss: 1.6219 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2161 - val_loss: 1.6217 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2418 - val_loss: 1.6214 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2198 - val_loss: 1.6212 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2381 - val_loss: 1.6210 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6209 - accuracy: 0.2527 - val_loss: 1.6207 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2527 - val_loss: 1.6205 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6207 - accuracy: 0.2491 - val_loss: 1.6203 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6175 - accuracy: 0.2454 - val_loss: 1.6200 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6203 - accuracy: 0.2674 - val_loss: 1.6196 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6183 - accuracy: 0.2857 - val_loss: 1.6194 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2308 - val_loss: 1.6193 - val_accuracy: 0.2319 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2491 - val_loss: 1.6191 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6147 - accuracy: 0.2711 - val_loss: 1.6189 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.2344 - val_loss: 1.6187 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2454 - val_loss: 1.6184 - val_accuracy: 0.2464 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6116 - accuracy: 0.2601 - val_loss: 1.6180 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2601 - val_loss: 1.6177 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6175 - accuracy: 0.2564 - val_loss: 1.6175 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6140 - accuracy: 0.2784 - val_loss: 1.6173 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6140 - accuracy: 0.2601 - val_loss: 1.6171 - val_accuracy: 0.2609 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Node 12 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 12 - Best Validation Accuracy: 0.3333\n",
      "Best model saved for Node 12 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_12.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_13_dataset.csv\n",
      "Node 13 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6327 - accuracy: 0.2038 - val_loss: 1.6345 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 3s/epoch - 165ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6343 - accuracy: 0.1654 - val_loss: 1.6343 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6328 - accuracy: 0.1769 - val_loss: 1.6340 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6340 - accuracy: 0.2154 - val_loss: 1.6339 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6322 - accuracy: 0.2346 - val_loss: 1.6337 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6324 - accuracy: 0.2000 - val_loss: 1.6335 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6334 - accuracy: 0.1885 - val_loss: 1.6333 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6315 - accuracy: 0.2192 - val_loss: 1.6330 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6322 - accuracy: 0.2115 - val_loss: 1.6327 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6329 - accuracy: 0.2154 - val_loss: 1.6323 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6321 - accuracy: 0.2077 - val_loss: 1.6322 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6305 - accuracy: 0.2346 - val_loss: 1.6320 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6315 - accuracy: 0.2077 - val_loss: 1.6318 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6310 - accuracy: 0.2077 - val_loss: 1.6316 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6311 - accuracy: 0.2077 - val_loss: 1.6315 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2269 - val_loss: 1.6311 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2423 - val_loss: 1.6309 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6287 - accuracy: 0.2346 - val_loss: 1.6307 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6285 - accuracy: 0.2423 - val_loss: 1.6306 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6291 - accuracy: 0.2385 - val_loss: 1.6305 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.2577 - val_loss: 1.6303 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6269 - accuracy: 0.2923 - val_loss: 1.6303 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6303 - accuracy: 0.1885 - val_loss: 1.6301 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6265 - accuracy: 0.2308 - val_loss: 1.6299 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6284 - accuracy: 0.2385 - val_loss: 1.6295 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6267 - accuracy: 0.2423 - val_loss: 1.6292 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6292 - accuracy: 0.2423 - val_loss: 1.6292 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6261 - accuracy: 0.2269 - val_loss: 1.6290 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6271 - accuracy: 0.2077 - val_loss: 1.6288 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6239 - accuracy: 0.2615 - val_loss: 1.6287 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6269 - accuracy: 0.2192 - val_loss: 1.6286 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2538 - val_loss: 1.6283 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6268 - accuracy: 0.2269 - val_loss: 1.6281 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6255 - accuracy: 0.2500 - val_loss: 1.6280 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6259 - accuracy: 0.2231 - val_loss: 1.6279 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2615 - val_loss: 1.6277 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6218 - accuracy: 0.2962 - val_loss: 1.6275 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6231 - accuracy: 0.2385 - val_loss: 1.6272 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.2192 - val_loss: 1.6270 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6244 - accuracy: 0.2346 - val_loss: 1.6270 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2423 - val_loss: 1.6267 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2346 - val_loss: 1.6265 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2308 - val_loss: 1.6265 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6265 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6248 - accuracy: 0.2423 - val_loss: 1.6265 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2423 - val_loss: 1.6265 - val_accuracy: 0.2727 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2346 - val_loss: 1.6263 - val_accuracy: 0.2879 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6205 - accuracy: 0.2731 - val_loss: 1.6262 - val_accuracy: 0.2727 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6215 - accuracy: 0.2538 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2038 - val_loss: 1.6261 - val_accuracy: 0.2576 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2577 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2615 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6233 - accuracy: 0.2077 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2192 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6242 - accuracy: 0.2346 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.2500e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6240 - accuracy: 0.2038 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2462 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.2500e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6223 - accuracy: 0.2192 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 6.2500e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6211 - accuracy: 0.2115 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2115 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2000 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 3.1250e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2462 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 3.1250e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2154 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 3.1250e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6240 - accuracy: 0.2115 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.5625e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6190 - accuracy: 0.2846 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.5625e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "17/17 - 0s - loss: 1.6198 - accuracy: 0.2692 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 1.5625e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2615 - val_loss: 1.6261 - val_accuracy: 0.2727 - lr: 7.8125e-07 - 51ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6234 - accuracy: 0.2231 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 7.8125e-07 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2385 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2231 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "17/17 - 0s - loss: 1.6227 - accuracy: 0.2192 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 7.8125e-07 - 70ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2385 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2500 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2577 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6220 - accuracy: 0.2500 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2269 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.9531e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2423 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.9531e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2577 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 9.7656e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2308 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 9.7656e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2231 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6194 - accuracy: 0.2577 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2038 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2615 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 4.8828e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6199 - accuracy: 0.2500 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 2.4414e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2808 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 2.4414e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "17/17 - 0s - loss: 1.6243 - accuracy: 0.2231 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 2.4414e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6196 - accuracy: 0.2731 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.2207e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6227 - accuracy: 0.2500 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.2207e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "17/17 - 0s - loss: 1.6186 - accuracy: 0.2769 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.2207e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6212 - accuracy: 0.2462 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 6.1035e-09 - 48ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6208 - accuracy: 0.2538 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2115 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.1846 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.0518e-09 - 48ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.6223 - accuracy: 0.2385 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.0518e-09 - 48ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "17/17 - 0s - loss: 1.6211 - accuracy: 0.3000 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 3.0518e-09 - 50ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6209 - accuracy: 0.2769 - val_loss: 1.6260 - val_accuracy: 0.2727 - lr: 1.5259e-09 - 50ms/epoch - 3ms/step\n",
      "Node 13 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6340 - accuracy: 0.2269 - val_loss: 1.6346 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 3s/epoch - 310ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2462 - val_loss: 1.6344 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2731 - val_loss: 1.6342 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6326 - accuracy: 0.2115 - val_loss: 1.6341 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.1962 - val_loss: 1.6339 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6324 - accuracy: 0.1731 - val_loss: 1.6336 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6332 - accuracy: 0.2038 - val_loss: 1.6334 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6330 - accuracy: 0.2154 - val_loss: 1.6331 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2423 - val_loss: 1.6329 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.1846 - val_loss: 1.6328 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6316 - accuracy: 0.1769 - val_loss: 1.6327 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6307 - accuracy: 0.1846 - val_loss: 1.6326 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.2654 - val_loss: 1.6324 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.1923 - val_loss: 1.6322 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2000 - val_loss: 1.6321 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6334 - accuracy: 0.1538 - val_loss: 1.6320 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2308 - val_loss: 1.6318 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2192 - val_loss: 1.6316 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6308 - accuracy: 0.1923 - val_loss: 1.6314 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6306 - accuracy: 0.2115 - val_loss: 1.6313 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2231 - val_loss: 1.6312 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.2346 - val_loss: 1.6311 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.1500 - val_loss: 1.6311 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6292 - accuracy: 0.1692 - val_loss: 1.6310 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2038 - val_loss: 1.6309 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2269 - val_loss: 1.6307 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2423 - val_loss: 1.6307 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2038 - val_loss: 1.6306 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2308 - val_loss: 1.6304 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2462 - val_loss: 1.6303 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2308 - val_loss: 1.6302 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6294 - accuracy: 0.2077 - val_loss: 1.6301 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6286 - accuracy: 0.2192 - val_loss: 1.6300 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6282 - accuracy: 0.2538 - val_loss: 1.6297 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6284 - accuracy: 0.2231 - val_loss: 1.6295 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6285 - accuracy: 0.2154 - val_loss: 1.6294 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6283 - accuracy: 0.2115 - val_loss: 1.6293 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2615 - val_loss: 1.6292 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.1923 - val_loss: 1.6291 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6258 - accuracy: 0.2462 - val_loss: 1.6290 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2385 - val_loss: 1.6288 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2615 - val_loss: 1.6288 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2385 - val_loss: 1.6286 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6282 - accuracy: 0.2423 - val_loss: 1.6285 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.2731 - val_loss: 1.6284 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2154 - val_loss: 1.6282 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6285 - accuracy: 0.2077 - val_loss: 1.6281 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6292 - accuracy: 0.1731 - val_loss: 1.6280 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2115 - val_loss: 1.6279 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2000 - val_loss: 1.6279 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.2038 - val_loss: 1.6278 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2308 - val_loss: 1.6277 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.2038 - val_loss: 1.6276 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 37ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2538 - val_loss: 1.6274 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6243 - accuracy: 0.2192 - val_loss: 1.6273 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.2192 - val_loss: 1.6272 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6271 - accuracy: 0.2154 - val_loss: 1.6271 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2077 - val_loss: 1.6270 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2346 - val_loss: 1.6269 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6243 - accuracy: 0.2346 - val_loss: 1.6268 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6261 - accuracy: 0.2000 - val_loss: 1.6268 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6244 - accuracy: 0.2346 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.1962 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6272 - accuracy: 0.2231 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2115 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2269 - val_loss: 1.6265 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.1846 - val_loss: 1.6264 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2154 - val_loss: 1.6264 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2346 - val_loss: 1.6264 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6226 - accuracy: 0.2269 - val_loss: 1.6263 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2308 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2000 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2192 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2154 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6244 - accuracy: 0.2038 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2346 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6252 - accuracy: 0.2038 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6205 - accuracy: 0.2423 - val_loss: 1.6259 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2308 - val_loss: 1.6259 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2154 - val_loss: 1.6259 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 35ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2038 - val_loss: 1.6259 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6208 - accuracy: 0.2385 - val_loss: 1.6259 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2115 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "9/9 - 0s - loss: 1.6223 - accuracy: 0.1962 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2346 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6225 - accuracy: 0.2346 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2000 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2538 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.1846 - val_loss: 1.6258 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6232 - accuracy: 0.1846 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.1846 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6206 - accuracy: 0.2462 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 31ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6225 - accuracy: 0.2154 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2385 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 55ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6206 - accuracy: 0.2192 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6240 - accuracy: 0.2269 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "9/9 - 0s - loss: 1.6211 - accuracy: 0.2192 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6232 - accuracy: 0.2385 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 33ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2577 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 32ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "9/9 - 0s - loss: 1.6216 - accuracy: 0.2269 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 33ms/epoch - 4ms/step\n",
      "Node 13 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6597 - accuracy: 0.2269 - val_loss: 1.6590 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 3s/epoch - 147ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6612 - accuracy: 0.1846 - val_loss: 1.6582 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6577 - accuracy: 0.2615 - val_loss: 1.6576 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6590 - accuracy: 0.1885 - val_loss: 1.6567 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6557 - accuracy: 0.2346 - val_loss: 1.6561 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6556 - accuracy: 0.2038 - val_loss: 1.6554 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6567 - accuracy: 0.2192 - val_loss: 1.6549 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6548 - accuracy: 0.2192 - val_loss: 1.6543 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6540 - accuracy: 0.2231 - val_loss: 1.6536 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6553 - accuracy: 0.2115 - val_loss: 1.6530 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6524 - accuracy: 0.2115 - val_loss: 1.6525 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6528 - accuracy: 0.2154 - val_loss: 1.6519 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6518 - accuracy: 0.2115 - val_loss: 1.6513 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6527 - accuracy: 0.2077 - val_loss: 1.6506 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6498 - accuracy: 0.2231 - val_loss: 1.6499 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6488 - accuracy: 0.2192 - val_loss: 1.6493 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6494 - accuracy: 0.2038 - val_loss: 1.6487 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6488 - accuracy: 0.2231 - val_loss: 1.6483 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6466 - accuracy: 0.2308 - val_loss: 1.6477 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6472 - accuracy: 0.2385 - val_loss: 1.6472 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6488 - accuracy: 0.2192 - val_loss: 1.6466 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6455 - accuracy: 0.2192 - val_loss: 1.6462 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6465 - accuracy: 0.2231 - val_loss: 1.6458 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6454 - accuracy: 0.2231 - val_loss: 1.6454 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6423 - accuracy: 0.2308 - val_loss: 1.6449 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6462 - accuracy: 0.2115 - val_loss: 1.6445 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6425 - accuracy: 0.2385 - val_loss: 1.6439 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6418 - accuracy: 0.2269 - val_loss: 1.6434 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6405 - accuracy: 0.2192 - val_loss: 1.6429 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6407 - accuracy: 0.2077 - val_loss: 1.6424 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6414 - accuracy: 0.2500 - val_loss: 1.6419 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6414 - accuracy: 0.2154 - val_loss: 1.6416 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6394 - accuracy: 0.2269 - val_loss: 1.6411 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6402 - accuracy: 0.2115 - val_loss: 1.6407 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6404 - accuracy: 0.2346 - val_loss: 1.6404 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6383 - accuracy: 0.2077 - val_loss: 1.6398 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6381 - accuracy: 0.2577 - val_loss: 1.6394 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6353 - accuracy: 0.2500 - val_loss: 1.6390 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6349 - accuracy: 0.2308 - val_loss: 1.6385 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6359 - accuracy: 0.2385 - val_loss: 1.6382 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6358 - accuracy: 0.2154 - val_loss: 1.6379 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6347 - accuracy: 0.2115 - val_loss: 1.6374 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6316 - accuracy: 0.2654 - val_loss: 1.6370 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6357 - accuracy: 0.2308 - val_loss: 1.6366 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6338 - accuracy: 0.2462 - val_loss: 1.6364 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6325 - accuracy: 0.2538 - val_loss: 1.6359 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6333 - accuracy: 0.2308 - val_loss: 1.6355 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6316 - accuracy: 0.2423 - val_loss: 1.6352 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2500 - val_loss: 1.6348 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2423 - val_loss: 1.6345 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2115 - val_loss: 1.6340 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6307 - accuracy: 0.2115 - val_loss: 1.6338 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6274 - accuracy: 0.2577 - val_loss: 1.6335 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6280 - accuracy: 0.2385 - val_loss: 1.6330 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6263 - accuracy: 0.2462 - val_loss: 1.6327 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6285 - accuracy: 0.2308 - val_loss: 1.6324 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6284 - accuracy: 0.2462 - val_loss: 1.6322 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2692 - val_loss: 1.6319 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6273 - accuracy: 0.2346 - val_loss: 1.6317 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6267 - accuracy: 0.2231 - val_loss: 1.6315 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2808 - val_loss: 1.6312 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6260 - accuracy: 0.2654 - val_loss: 1.6309 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2385 - val_loss: 1.6306 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6251 - accuracy: 0.2385 - val_loss: 1.6304 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2000 - val_loss: 1.6301 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2654 - val_loss: 1.6297 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6223 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2577 - val_loss: 1.6292 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6261 - accuracy: 0.2538 - val_loss: 1.6291 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2308 - val_loss: 1.6288 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2731 - val_loss: 1.6287 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2115 - val_loss: 1.6285 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6198 - accuracy: 0.2462 - val_loss: 1.6285 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2731 - val_loss: 1.6283 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6199 - accuracy: 0.2346 - val_loss: 1.6280 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6185 - accuracy: 0.2500 - val_loss: 1.6278 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6174 - accuracy: 0.2692 - val_loss: 1.6278 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6189 - accuracy: 0.2654 - val_loss: 1.6275 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6196 - accuracy: 0.2500 - val_loss: 1.6274 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6139 - accuracy: 0.2769 - val_loss: 1.6270 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6194 - accuracy: 0.2692 - val_loss: 1.6269 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6169 - accuracy: 0.2731 - val_loss: 1.6267 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6127 - accuracy: 0.2846 - val_loss: 1.6264 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6205 - accuracy: 0.2269 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6172 - accuracy: 0.2538 - val_loss: 1.6258 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6156 - accuracy: 0.2500 - val_loss: 1.6258 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6120 - accuracy: 0.3077 - val_loss: 1.6256 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6159 - accuracy: 0.2346 - val_loss: 1.6254 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6164 - accuracy: 0.2538 - val_loss: 1.6254 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6121 - accuracy: 0.2692 - val_loss: 1.6253 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6132 - accuracy: 0.2615 - val_loss: 1.6253 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2077 - val_loss: 1.6253 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6124 - accuracy: 0.2654 - val_loss: 1.6252 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.6112 - accuracy: 0.2500 - val_loss: 1.6251 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6061 - accuracy: 0.2808 - val_loss: 1.6250 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6121 - accuracy: 0.2385 - val_loss: 1.6247 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 1.6109 - accuracy: 0.2500 - val_loss: 1.6242 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 96ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.6113 - accuracy: 0.2692 - val_loss: 1.6241 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.6075 - accuracy: 0.2654 - val_loss: 1.6240 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 1.6090 - accuracy: 0.2615 - val_loss: 1.6240 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Node 13 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6611 - accuracy: 0.1692 - val_loss: 1.6614 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 3s/epoch - 302ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6607 - accuracy: 0.1962 - val_loss: 1.6609 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6599 - accuracy: 0.1731 - val_loss: 1.6602 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6597 - accuracy: 0.1846 - val_loss: 1.6597 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6602 - accuracy: 0.1731 - val_loss: 1.6592 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6587 - accuracy: 0.1731 - val_loss: 1.6587 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6568 - accuracy: 0.2038 - val_loss: 1.6583 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6582 - accuracy: 0.2038 - val_loss: 1.6581 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6577 - accuracy: 0.1769 - val_loss: 1.6577 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6566 - accuracy: 0.2231 - val_loss: 1.6574 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6556 - accuracy: 0.2192 - val_loss: 1.6569 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6550 - accuracy: 0.2769 - val_loss: 1.6564 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6552 - accuracy: 0.2346 - val_loss: 1.6560 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6540 - accuracy: 0.2500 - val_loss: 1.6555 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6545 - accuracy: 0.2000 - val_loss: 1.6549 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6537 - accuracy: 0.1962 - val_loss: 1.6546 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6527 - accuracy: 0.2538 - val_loss: 1.6542 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6528 - accuracy: 0.2462 - val_loss: 1.6539 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6531 - accuracy: 0.1885 - val_loss: 1.6534 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6518 - accuracy: 0.2115 - val_loss: 1.6530 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6516 - accuracy: 0.1923 - val_loss: 1.6526 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6511 - accuracy: 0.2308 - val_loss: 1.6522 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6515 - accuracy: 0.1846 - val_loss: 1.6517 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6494 - accuracy: 0.2462 - val_loss: 1.6513 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6506 - accuracy: 0.2038 - val_loss: 1.6511 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6493 - accuracy: 0.2038 - val_loss: 1.6508 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6495 - accuracy: 0.2538 - val_loss: 1.6505 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6485 - accuracy: 0.2462 - val_loss: 1.6501 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6490 - accuracy: 0.2192 - val_loss: 1.6496 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6469 - accuracy: 0.2731 - val_loss: 1.6495 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6485 - accuracy: 0.2115 - val_loss: 1.6493 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6480 - accuracy: 0.2192 - val_loss: 1.6490 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6458 - accuracy: 0.2538 - val_loss: 1.6488 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6462 - accuracy: 0.1923 - val_loss: 1.6484 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6461 - accuracy: 0.2231 - val_loss: 1.6480 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6452 - accuracy: 0.2385 - val_loss: 1.6476 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6459 - accuracy: 0.2000 - val_loss: 1.6473 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6449 - accuracy: 0.2231 - val_loss: 1.6469 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6441 - accuracy: 0.2269 - val_loss: 1.6466 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6439 - accuracy: 0.2462 - val_loss: 1.6464 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6437 - accuracy: 0.2385 - val_loss: 1.6461 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6434 - accuracy: 0.2385 - val_loss: 1.6457 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6441 - accuracy: 0.1962 - val_loss: 1.6453 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6412 - accuracy: 0.2654 - val_loss: 1.6448 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6435 - accuracy: 0.2385 - val_loss: 1.6446 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6412 - accuracy: 0.2500 - val_loss: 1.6444 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6413 - accuracy: 0.2538 - val_loss: 1.6442 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6402 - accuracy: 0.2269 - val_loss: 1.6438 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6405 - accuracy: 0.2385 - val_loss: 1.6435 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6414 - accuracy: 0.2192 - val_loss: 1.6432 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6404 - accuracy: 0.2385 - val_loss: 1.6429 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6407 - accuracy: 0.1846 - val_loss: 1.6425 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6391 - accuracy: 0.2808 - val_loss: 1.6423 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 68ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6386 - accuracy: 0.2346 - val_loss: 1.6423 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6396 - accuracy: 0.2115 - val_loss: 1.6422 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6370 - accuracy: 0.2308 - val_loss: 1.6419 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6375 - accuracy: 0.2538 - val_loss: 1.6416 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6380 - accuracy: 0.2346 - val_loss: 1.6413 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6375 - accuracy: 0.2308 - val_loss: 1.6412 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6362 - accuracy: 0.2308 - val_loss: 1.6409 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6370 - accuracy: 0.2231 - val_loss: 1.6407 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2538 - val_loss: 1.6404 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6347 - accuracy: 0.2423 - val_loss: 1.6402 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6352 - accuracy: 0.2192 - val_loss: 1.6400 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6335 - accuracy: 0.2500 - val_loss: 1.6398 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6367 - accuracy: 0.2231 - val_loss: 1.6396 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6348 - accuracy: 0.2154 - val_loss: 1.6393 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6340 - accuracy: 0.2423 - val_loss: 1.6391 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2038 - val_loss: 1.6390 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6357 - accuracy: 0.2423 - val_loss: 1.6388 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6355 - accuracy: 0.2038 - val_loss: 1.6386 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6363 - accuracy: 0.2115 - val_loss: 1.6383 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6329 - accuracy: 0.2192 - val_loss: 1.6381 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.2769 - val_loss: 1.6378 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2654 - val_loss: 1.6377 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6345 - accuracy: 0.2231 - val_loss: 1.6376 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6325 - accuracy: 0.2077 - val_loss: 1.6374 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6325 - accuracy: 0.2231 - val_loss: 1.6373 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.2423 - val_loss: 1.6372 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2500 - val_loss: 1.6370 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.2846 - val_loss: 1.6367 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2654 - val_loss: 1.6365 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2500 - val_loss: 1.6363 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2692 - val_loss: 1.6363 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6284 - accuracy: 0.2500 - val_loss: 1.6362 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2808 - val_loss: 1.6361 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2385 - val_loss: 1.6358 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2462 - val_loss: 1.6355 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6289 - accuracy: 0.2269 - val_loss: 1.6351 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6309 - accuracy: 0.2346 - val_loss: 1.6349 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.2115 - val_loss: 1.6346 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2385 - val_loss: 1.6344 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6268 - accuracy: 0.2577 - val_loss: 1.6344 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6277 - accuracy: 0.2577 - val_loss: 1.6344 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6284 - accuracy: 0.2308 - val_loss: 1.6344 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2269 - val_loss: 1.6343 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 49ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6249 - accuracy: 0.2423 - val_loss: 1.6342 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 50ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6271 - accuracy: 0.2154 - val_loss: 1.6342 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 71ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2577 - val_loss: 1.6341 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 52ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2462 - val_loss: 1.6341 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 50ms/epoch - 6ms/step\n",
      "Node 13 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 13 - Best Validation Accuracy: 0.2879\n",
      "Best model saved for Node 13 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_13.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_14_dataset.csv\n",
      "Node 14 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6345 - accuracy: 0.2395 - val_loss: 1.6336 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 2s/epoch - 161ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.1765 - val_loss: 1.6335 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.1765 - val_loss: 1.6332 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6356 - accuracy: 0.1807 - val_loss: 1.6329 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.1933 - val_loss: 1.6327 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2353 - val_loss: 1.6325 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.1933 - val_loss: 1.6324 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.1471 - val_loss: 1.6322 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2059 - val_loss: 1.6321 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.1975 - val_loss: 1.6319 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2311 - val_loss: 1.6318 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6319 - accuracy: 0.1891 - val_loss: 1.6316 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2437 - val_loss: 1.6314 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2311 - val_loss: 1.6312 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6319 - accuracy: 0.2101 - val_loss: 1.6311 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2059 - val_loss: 1.6309 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6318 - accuracy: 0.2227 - val_loss: 1.6308 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6314 - accuracy: 0.2059 - val_loss: 1.6307 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.1975 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6304 - accuracy: 0.2269 - val_loss: 1.6304 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2353 - val_loss: 1.6302 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2059 - val_loss: 1.6301 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2311 - val_loss: 1.6300 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2017 - val_loss: 1.6299 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6313 - accuracy: 0.2059 - val_loss: 1.6298 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2563 - val_loss: 1.6298 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.1765 - val_loss: 1.6296 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2059 - val_loss: 1.6296 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2311 - val_loss: 1.6295 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2143 - val_loss: 1.6294 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2101 - val_loss: 1.6292 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2017 - val_loss: 1.6291 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2059 - val_loss: 1.6290 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2059 - val_loss: 1.6289 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2227 - val_loss: 1.6287 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2311 - val_loss: 1.6286 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2731 - val_loss: 1.6286 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2353 - val_loss: 1.6285 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2689 - val_loss: 1.6284 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2269 - val_loss: 1.6283 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2521 - val_loss: 1.6282 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2857 - val_loss: 1.6281 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2059 - val_loss: 1.6280 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2269 - val_loss: 1.6278 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2605 - val_loss: 1.6278 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2353 - val_loss: 1.6277 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2269 - val_loss: 1.6275 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2101 - val_loss: 1.6274 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2899 - val_loss: 1.6274 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2395 - val_loss: 1.6273 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2605 - val_loss: 1.6272 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2983 - val_loss: 1.6271 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2521 - val_loss: 1.6270 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2017 - val_loss: 1.6269 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2563 - val_loss: 1.6268 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2059 - val_loss: 1.6268 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2353 - val_loss: 1.6268 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2395 - val_loss: 1.6267 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2815 - val_loss: 1.6265 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2311 - val_loss: 1.6264 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2731 - val_loss: 1.6264 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2017 - val_loss: 1.6264 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2185 - val_loss: 1.6263 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2479 - val_loss: 1.6264 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2521 - val_loss: 1.6263 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2479 - val_loss: 1.6262 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2227 - val_loss: 1.6262 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2815 - val_loss: 1.6261 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2479 - val_loss: 1.6261 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2899 - val_loss: 1.6261 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2647 - val_loss: 1.6260 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2395 - val_loss: 1.6260 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2815 - val_loss: 1.6260 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2479 - val_loss: 1.6260 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2563 - val_loss: 1.6259 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2437 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2353 - val_loss: 1.6259 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2857 - val_loss: 1.6259 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2521 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2269 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2353 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2605 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2605 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2437 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2773 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2689 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2143 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2731 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2521 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2521 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2479 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2773 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2437 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2605 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2437 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2605 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6212 - accuracy: 0.2101 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2899 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2479 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 46ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2689 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.9531e-07 - 66ms/epoch - 4ms/step\n",
      "Node 14 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6355 - accuracy: 0.2017 - val_loss: 1.6341 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 3s/epoch - 363ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2311 - val_loss: 1.6339 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1891 - val_loss: 1.6338 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.1849 - val_loss: 1.6338 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.1975 - val_loss: 1.6337 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2311 - val_loss: 1.6337 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2437 - val_loss: 1.6336 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.1975 - val_loss: 1.6336 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.1975 - val_loss: 1.6335 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.1933 - val_loss: 1.6334 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2395 - val_loss: 1.6333 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.1975 - val_loss: 1.6332 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2143 - val_loss: 1.6331 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2017 - val_loss: 1.6331 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.1891 - val_loss: 1.6330 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2101 - val_loss: 1.6329 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.1807 - val_loss: 1.6328 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.1891 - val_loss: 1.6327 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.1975 - val_loss: 1.6326 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2143 - val_loss: 1.6326 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2185 - val_loss: 1.6325 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2437 - val_loss: 1.6325 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2521 - val_loss: 1.6324 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2395 - val_loss: 1.6324 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2353 - val_loss: 1.6324 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2227 - val_loss: 1.6323 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2899 - val_loss: 1.6322 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2143 - val_loss: 1.6321 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2185 - val_loss: 1.6320 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2143 - val_loss: 1.6320 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2269 - val_loss: 1.6319 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2185 - val_loss: 1.6318 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.1765 - val_loss: 1.6317 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2311 - val_loss: 1.6317 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2437 - val_loss: 1.6316 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2647 - val_loss: 1.6315 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2437 - val_loss: 1.6314 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2395 - val_loss: 1.6313 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2689 - val_loss: 1.6313 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2101 - val_loss: 1.6313 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2689 - val_loss: 1.6313 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.1975 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2017 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2269 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2521 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2143 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2269 - val_loss: 1.6312 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2185 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2395 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2311 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.1933 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2311 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.1891 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2185 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 50ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2521 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2479 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2059 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2185 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2059 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2689 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2689 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2353 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2563 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2269 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2437 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.1975 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2521 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2017 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2395 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.1975 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2479 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 33ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2143 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2227 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2185 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2227 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2101 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 4.8828e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2563 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 4.8828e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2353 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 4.8828e-08 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2143 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 2.4414e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2311 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 2.4414e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2059 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 2.4414e-08 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2521 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2207e-08 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2185 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2269 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2311 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.1035e-09 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2647 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.1035e-09 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2143 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 6.1035e-09 - 31ms/epoch - 4ms/step\n",
      "Node 14 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6616 - accuracy: 0.1471 - val_loss: 1.6603 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 3s/epoch - 185ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6595 - accuracy: 0.1975 - val_loss: 1.6598 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6588 - accuracy: 0.2101 - val_loss: 1.6592 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6579 - accuracy: 0.2269 - val_loss: 1.6586 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6577 - accuracy: 0.1891 - val_loss: 1.6581 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6561 - accuracy: 0.2227 - val_loss: 1.6575 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6553 - accuracy: 0.2101 - val_loss: 1.6568 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6558 - accuracy: 0.2059 - val_loss: 1.6563 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6541 - accuracy: 0.2269 - val_loss: 1.6557 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6536 - accuracy: 0.2143 - val_loss: 1.6549 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.1975 - val_loss: 1.6544 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6522 - accuracy: 0.2185 - val_loss: 1.6538 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6500 - accuracy: 0.2227 - val_loss: 1.6531 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6528 - accuracy: 0.1891 - val_loss: 1.6526 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6500 - accuracy: 0.2185 - val_loss: 1.6520 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6492 - accuracy: 0.2227 - val_loss: 1.6515 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6487 - accuracy: 0.2059 - val_loss: 1.6510 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6489 - accuracy: 0.2017 - val_loss: 1.6505 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6483 - accuracy: 0.2353 - val_loss: 1.6500 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6465 - accuracy: 0.1975 - val_loss: 1.6494 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2101 - val_loss: 1.6488 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 87ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2101 - val_loss: 1.6485 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6448 - accuracy: 0.2227 - val_loss: 1.6480 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.2269 - val_loss: 1.6474 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2059 - val_loss: 1.6469 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6434 - accuracy: 0.2437 - val_loss: 1.6465 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6435 - accuracy: 0.2059 - val_loss: 1.6461 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6413 - accuracy: 0.2269 - val_loss: 1.6457 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6416 - accuracy: 0.2185 - val_loss: 1.6453 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6402 - accuracy: 0.2353 - val_loss: 1.6450 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6407 - accuracy: 0.2395 - val_loss: 1.6447 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6394 - accuracy: 0.1891 - val_loss: 1.6444 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6405 - accuracy: 0.2185 - val_loss: 1.6441 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6383 - accuracy: 0.2395 - val_loss: 1.6437 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6372 - accuracy: 0.2437 - val_loss: 1.6433 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6375 - accuracy: 0.2227 - val_loss: 1.6429 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.2353 - val_loss: 1.6425 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2143 - val_loss: 1.6422 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6363 - accuracy: 0.2269 - val_loss: 1.6420 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.2437 - val_loss: 1.6416 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6349 - accuracy: 0.2647 - val_loss: 1.6415 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.2815 - val_loss: 1.6413 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2395 - val_loss: 1.6409 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.2773 - val_loss: 1.6407 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2563 - val_loss: 1.6405 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2563 - val_loss: 1.6403 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2815 - val_loss: 1.6400 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2563 - val_loss: 1.6397 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2857 - val_loss: 1.6397 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2815 - val_loss: 1.6394 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2647 - val_loss: 1.6392 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2857 - val_loss: 1.6391 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2731 - val_loss: 1.6390 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2689 - val_loss: 1.6388 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2479 - val_loss: 1.6386 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2857 - val_loss: 1.6384 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2563 - val_loss: 1.6383 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6212 - accuracy: 0.2647 - val_loss: 1.6383 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2521 - val_loss: 1.6383 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2689 - val_loss: 1.6381 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2605 - val_loss: 1.6381 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2647 - val_loss: 1.6378 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2227 - val_loss: 1.6377 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2521 - val_loss: 1.6375 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2899 - val_loss: 1.6376 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2773 - val_loss: 1.6377 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2563 - val_loss: 1.6376 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2773 - val_loss: 1.6376 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 87ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2479 - val_loss: 1.6375 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6115 - accuracy: 0.2689 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2605 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2521 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2353 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2689 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2563 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2521 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2353 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.2500e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2605 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 65ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2605 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2395 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2479 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 64ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2353 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 64ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2437 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.1250e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2605 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2815 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2815 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.5625e-06 - 67ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2647 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 63ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2563 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 68ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2269 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 7.8125e-07 - 70ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2773 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 67ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2395 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 68ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2941 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 3.9062e-07 - 68ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6156 - accuracy: 0.2857 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 69ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2689 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 70ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2395 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.9531e-07 - 68ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2395 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 69ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2689 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 69ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2227 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 9.7656e-08 - 67ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2689 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 4.8828e-08 - 68ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2605 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 4.8828e-08 - 68ms/epoch - 5ms/step\n",
      "Node 14 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6602 - accuracy: 0.1807 - val_loss: 1.6599 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 2s/epoch - 308ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.2017 - val_loss: 1.6595 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.2269 - val_loss: 1.6591 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.2017 - val_loss: 1.6589 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2311 - val_loss: 1.6585 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.1933 - val_loss: 1.6581 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2017 - val_loss: 1.6577 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6583 - accuracy: 0.1723 - val_loss: 1.6574 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6558 - accuracy: 0.2101 - val_loss: 1.6571 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2185 - val_loss: 1.6568 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2227 - val_loss: 1.6565 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2143 - val_loss: 1.6562 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2437 - val_loss: 1.6558 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6524 - accuracy: 0.2269 - val_loss: 1.6555 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.1975 - val_loss: 1.6552 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2017 - val_loss: 1.6548 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6521 - accuracy: 0.2017 - val_loss: 1.6544 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2185 - val_loss: 1.6540 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2185 - val_loss: 1.6537 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6496 - accuracy: 0.2311 - val_loss: 1.6535 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2059 - val_loss: 1.6533 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 56ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.1891 - val_loss: 1.6530 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2143 - val_loss: 1.6527 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2185 - val_loss: 1.6523 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2395 - val_loss: 1.6519 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2227 - val_loss: 1.6517 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.1891 - val_loss: 1.6515 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6476 - accuracy: 0.2185 - val_loss: 1.6512 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2143 - val_loss: 1.6509 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.1975 - val_loss: 1.6506 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6468 - accuracy: 0.2059 - val_loss: 1.6504 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2059 - val_loss: 1.6502 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2269 - val_loss: 1.6501 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6439 - accuracy: 0.2101 - val_loss: 1.6499 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2395 - val_loss: 1.6497 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2311 - val_loss: 1.6495 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2227 - val_loss: 1.6493 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6427 - accuracy: 0.2101 - val_loss: 1.6491 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.1933 - val_loss: 1.6489 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6449 - accuracy: 0.2059 - val_loss: 1.6487 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2311 - val_loss: 1.6484 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2101 - val_loss: 1.6482 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2395 - val_loss: 1.6479 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6397 - accuracy: 0.2437 - val_loss: 1.6476 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2563 - val_loss: 1.6474 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2395 - val_loss: 1.6472 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6397 - accuracy: 0.2605 - val_loss: 1.6471 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2437 - val_loss: 1.6469 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6386 - accuracy: 0.2353 - val_loss: 1.6466 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2143 - val_loss: 1.6464 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.2101 - val_loss: 1.6462 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2353 - val_loss: 1.6460 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2395 - val_loss: 1.6459 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2395 - val_loss: 1.6457 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2353 - val_loss: 1.6455 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.2227 - val_loss: 1.6454 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2269 - val_loss: 1.6452 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2479 - val_loss: 1.6450 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2185 - val_loss: 1.6449 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2605 - val_loss: 1.6448 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2311 - val_loss: 1.6447 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2479 - val_loss: 1.6445 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2311 - val_loss: 1.6444 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2311 - val_loss: 1.6443 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2605 - val_loss: 1.6443 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2731 - val_loss: 1.6442 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2395 - val_loss: 1.6442 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2143 - val_loss: 1.6440 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2647 - val_loss: 1.6439 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2689 - val_loss: 1.6437 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2479 - val_loss: 1.6437 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2269 - val_loss: 1.6436 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2353 - val_loss: 1.6435 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2353 - val_loss: 1.6435 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.3067 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2857 - val_loss: 1.6435 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2563 - val_loss: 1.6435 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2479 - val_loss: 1.6435 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2437 - val_loss: 1.6435 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2605 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2101 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2731 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2521 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2479 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2353 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2689 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2353 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2269 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 42ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2479 - val_loss: 1.6434 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 45ms/epoch - 6ms/step\n",
      "Node 14 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 14 - Best Validation Accuracy: 0.2500\n",
      "Best model saved for Node 14 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_14.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_15_dataset.csv\n",
      "Node 15 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6365 - accuracy: 0.1535 - val_loss: 1.6345 - val_accuracy: 0.1481 - lr: 1.0000e-04 - 3s/epoch - 207ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6347 - accuracy: 0.2047 - val_loss: 1.6342 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2140 - val_loss: 1.6340 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6339 - accuracy: 0.2326 - val_loss: 1.6336 - val_accuracy: 0.2778 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6333 - accuracy: 0.1860 - val_loss: 1.6334 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2372 - val_loss: 1.6332 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6334 - accuracy: 0.2186 - val_loss: 1.6331 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6320 - accuracy: 0.2372 - val_loss: 1.6329 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2140 - val_loss: 1.6327 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6331 - accuracy: 0.2140 - val_loss: 1.6326 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6321 - accuracy: 0.2047 - val_loss: 1.6323 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2419 - val_loss: 1.6321 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6315 - accuracy: 0.2558 - val_loss: 1.6319 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6308 - accuracy: 0.2605 - val_loss: 1.6316 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2326 - val_loss: 1.6315 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.2465 - val_loss: 1.6313 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6313 - accuracy: 0.2372 - val_loss: 1.6309 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6306 - accuracy: 0.2419 - val_loss: 1.6307 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6298 - accuracy: 0.2558 - val_loss: 1.6305 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6296 - accuracy: 0.2093 - val_loss: 1.6303 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.1907 - val_loss: 1.6300 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6279 - accuracy: 0.2372 - val_loss: 1.6298 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6287 - accuracy: 0.2651 - val_loss: 1.6296 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2279 - val_loss: 1.6293 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.2279 - val_loss: 1.6292 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.2186 - val_loss: 1.6291 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6279 - accuracy: 0.2651 - val_loss: 1.6289 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.2279 - val_loss: 1.6287 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2233 - val_loss: 1.6285 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6250 - accuracy: 0.2512 - val_loss: 1.6283 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2512 - val_loss: 1.6281 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2279 - val_loss: 1.6279 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2372 - val_loss: 1.6277 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2233 - val_loss: 1.6275 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2326 - val_loss: 1.6273 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2372 - val_loss: 1.6271 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2605 - val_loss: 1.6269 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.2419 - val_loss: 1.6266 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2419 - val_loss: 1.6265 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2605 - val_loss: 1.6263 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2233 - val_loss: 1.6262 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6261 - accuracy: 0.2326 - val_loss: 1.6260 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2465 - val_loss: 1.6258 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2465 - val_loss: 1.6257 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2512 - val_loss: 1.6254 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2233 - val_loss: 1.6252 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2605 - val_loss: 1.6250 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6233 - accuracy: 0.2419 - val_loss: 1.6249 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2419 - val_loss: 1.6248 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.2512 - val_loss: 1.6247 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2651 - val_loss: 1.6245 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2651 - val_loss: 1.6243 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2512 - val_loss: 1.6242 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2465 - val_loss: 1.6241 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6229 - accuracy: 0.2512 - val_loss: 1.6240 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2326 - val_loss: 1.6239 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2465 - val_loss: 1.6237 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2465 - val_loss: 1.6237 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2512 - val_loss: 1.6234 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2419 - val_loss: 1.6232 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2512 - val_loss: 1.6231 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2558 - val_loss: 1.6230 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2279 - val_loss: 1.6230 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2465 - val_loss: 1.6228 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2605 - val_loss: 1.6226 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2326 - val_loss: 1.6225 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6208 - accuracy: 0.2465 - val_loss: 1.6223 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2512 - val_loss: 1.6223 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6181 - accuracy: 0.2372 - val_loss: 1.6222 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6185 - accuracy: 0.2372 - val_loss: 1.6221 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2512 - val_loss: 1.6219 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6155 - accuracy: 0.2465 - val_loss: 1.6217 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6181 - accuracy: 0.2558 - val_loss: 1.6217 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6161 - accuracy: 0.2465 - val_loss: 1.6216 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2512 - val_loss: 1.6215 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6163 - accuracy: 0.2558 - val_loss: 1.6215 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6149 - accuracy: 0.2512 - val_loss: 1.6214 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6137 - accuracy: 0.2558 - val_loss: 1.6212 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6163 - accuracy: 0.2605 - val_loss: 1.6212 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2651 - val_loss: 1.6211 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6171 - accuracy: 0.2372 - val_loss: 1.6210 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6130 - accuracy: 0.2558 - val_loss: 1.6210 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6125 - accuracy: 0.2512 - val_loss: 1.6210 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6117 - accuracy: 0.2791 - val_loss: 1.6210 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2419 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6122 - accuracy: 0.2605 - val_loss: 1.6207 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6142 - accuracy: 0.2512 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2558 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2558 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6166 - accuracy: 0.2558 - val_loss: 1.6207 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 40ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6135 - accuracy: 0.2605 - val_loss: 1.6207 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2605 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6114 - accuracy: 0.2698 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6148 - accuracy: 0.2558 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6161 - accuracy: 0.2558 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6106 - accuracy: 0.2651 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 40ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6101 - accuracy: 0.2791 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "14/14 - 0s - loss: 1.6139 - accuracy: 0.2605 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2512 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 6.2500e-06 - 40ms/epoch - 3ms/step\n",
      "Node 15 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6342 - accuracy: 0.2186 - val_loss: 1.6344 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 2s/epoch - 357ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.1953 - val_loss: 1.6342 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2512 - val_loss: 1.6340 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.1767 - val_loss: 1.6338 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.1814 - val_loss: 1.6336 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.1907 - val_loss: 1.6333 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2512 - val_loss: 1.6331 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2047 - val_loss: 1.6329 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2372 - val_loss: 1.6328 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.1953 - val_loss: 1.6326 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2558 - val_loss: 1.6325 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2140 - val_loss: 1.6323 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6329 - accuracy: 0.2093 - val_loss: 1.6321 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2419 - val_loss: 1.6319 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2233 - val_loss: 1.6317 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2093 - val_loss: 1.6315 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2698 - val_loss: 1.6314 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.2140 - val_loss: 1.6313 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2512 - val_loss: 1.6311 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6324 - accuracy: 0.2140 - val_loss: 1.6309 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2744 - val_loss: 1.6308 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2140 - val_loss: 1.6306 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2605 - val_loss: 1.6304 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2419 - val_loss: 1.6303 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2512 - val_loss: 1.6302 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2558 - val_loss: 1.6301 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6261 - accuracy: 0.2465 - val_loss: 1.6300 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6306 - accuracy: 0.2512 - val_loss: 1.6299 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2093 - val_loss: 1.6298 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2186 - val_loss: 1.6297 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2465 - val_loss: 1.6296 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2512 - val_loss: 1.6294 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2186 - val_loss: 1.6293 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2372 - val_loss: 1.6292 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2419 - val_loss: 1.6291 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2047 - val_loss: 1.6290 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2837 - val_loss: 1.6289 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2791 - val_loss: 1.6288 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.1814 - val_loss: 1.6286 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6238 - accuracy: 0.2512 - val_loss: 1.6285 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6240 - accuracy: 0.2279 - val_loss: 1.6284 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2372 - val_loss: 1.6283 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2791 - val_loss: 1.6282 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2326 - val_loss: 1.6281 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2558 - val_loss: 1.6281 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2558 - val_loss: 1.6280 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2651 - val_loss: 1.6279 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2047 - val_loss: 1.6278 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2140 - val_loss: 1.6277 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2651 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2372 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2186 - val_loss: 1.6274 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2419 - val_loss: 1.6273 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6242 - accuracy: 0.2465 - val_loss: 1.6273 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2465 - val_loss: 1.6273 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2140 - val_loss: 1.6272 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2233 - val_loss: 1.6270 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6234 - accuracy: 0.2558 - val_loss: 1.6270 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2233 - val_loss: 1.6269 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2744 - val_loss: 1.6268 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.2233 - val_loss: 1.6267 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2465 - val_loss: 1.6266 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6199 - accuracy: 0.2605 - val_loss: 1.6265 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2512 - val_loss: 1.6264 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2279 - val_loss: 1.6263 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2605 - val_loss: 1.6262 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6176 - accuracy: 0.2186 - val_loss: 1.6261 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2419 - val_loss: 1.6260 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6238 - accuracy: 0.2465 - val_loss: 1.6259 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2977 - val_loss: 1.6258 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6207 - accuracy: 0.2512 - val_loss: 1.6258 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2186 - val_loss: 1.6257 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2326 - val_loss: 1.6257 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6187 - accuracy: 0.2140 - val_loss: 1.6257 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6146 - accuracy: 0.2465 - val_loss: 1.6256 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2791 - val_loss: 1.6255 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2512 - val_loss: 1.6255 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2419 - val_loss: 1.6255 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2558 - val_loss: 1.6254 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2419 - val_loss: 1.6253 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6150 - accuracy: 0.3023 - val_loss: 1.6252 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6173 - accuracy: 0.2558 - val_loss: 1.6251 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2512 - val_loss: 1.6251 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2651 - val_loss: 1.6251 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6189 - accuracy: 0.2372 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2605 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6171 - accuracy: 0.2279 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6187 - accuracy: 0.2744 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2186 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6184 - accuracy: 0.2791 - val_loss: 1.6250 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6141 - accuracy: 0.2512 - val_loss: 1.6249 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6172 - accuracy: 0.2651 - val_loss: 1.6249 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6226 - accuracy: 0.2465 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6104 - accuracy: 0.2651 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2465 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2419 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 2.5000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2512 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 2.5000e-05 - 49ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6174 - accuracy: 0.2744 - val_loss: 1.6248 - val_accuracy: 0.2037 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6161 - accuracy: 0.2558 - val_loss: 1.6247 - val_accuracy: 0.2037 - lr: 2.5000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6175 - accuracy: 0.2791 - val_loss: 1.6247 - val_accuracy: 0.1852 - lr: 1.2500e-05 - 28ms/epoch - 4ms/step\n",
      "Node 15 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6590 - accuracy: 0.1395 - val_loss: 1.6584 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 3s/epoch - 205ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6573 - accuracy: 0.2093 - val_loss: 1.6576 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6574 - accuracy: 0.1907 - val_loss: 1.6567 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6555 - accuracy: 0.2233 - val_loss: 1.6560 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6551 - accuracy: 0.2651 - val_loss: 1.6553 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6542 - accuracy: 0.2512 - val_loss: 1.6546 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6538 - accuracy: 0.2186 - val_loss: 1.6537 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6530 - accuracy: 0.2558 - val_loss: 1.6530 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6498 - accuracy: 0.2698 - val_loss: 1.6521 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6509 - accuracy: 0.2605 - val_loss: 1.6513 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6480 - accuracy: 0.2744 - val_loss: 1.6506 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6488 - accuracy: 0.2465 - val_loss: 1.6499 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6513 - accuracy: 0.2233 - val_loss: 1.6493 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6481 - accuracy: 0.2419 - val_loss: 1.6489 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6471 - accuracy: 0.2419 - val_loss: 1.6484 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6461 - accuracy: 0.2419 - val_loss: 1.6477 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6445 - accuracy: 0.2465 - val_loss: 1.6470 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6462 - accuracy: 0.2419 - val_loss: 1.6465 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6445 - accuracy: 0.2465 - val_loss: 1.6458 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6433 - accuracy: 0.2558 - val_loss: 1.6453 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6425 - accuracy: 0.2512 - val_loss: 1.6448 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6435 - accuracy: 0.2419 - val_loss: 1.6442 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6393 - accuracy: 0.2419 - val_loss: 1.6436 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6391 - accuracy: 0.2372 - val_loss: 1.6432 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6398 - accuracy: 0.2558 - val_loss: 1.6426 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6412 - accuracy: 0.2372 - val_loss: 1.6422 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6374 - accuracy: 0.2326 - val_loss: 1.6419 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6373 - accuracy: 0.2512 - val_loss: 1.6415 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6367 - accuracy: 0.2558 - val_loss: 1.6413 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6390 - accuracy: 0.2419 - val_loss: 1.6410 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6367 - accuracy: 0.2372 - val_loss: 1.6406 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6339 - accuracy: 0.2512 - val_loss: 1.6402 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6334 - accuracy: 0.2419 - val_loss: 1.6396 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6380 - accuracy: 0.2465 - val_loss: 1.6393 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6349 - accuracy: 0.2465 - val_loss: 1.6391 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6354 - accuracy: 0.2512 - val_loss: 1.6387 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6341 - accuracy: 0.2465 - val_loss: 1.6385 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6321 - accuracy: 0.2465 - val_loss: 1.6383 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6360 - accuracy: 0.2465 - val_loss: 1.6382 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6344 - accuracy: 0.2419 - val_loss: 1.6380 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6288 - accuracy: 0.2372 - val_loss: 1.6376 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2465 - val_loss: 1.6373 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2558 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2372 - val_loss: 1.6366 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2512 - val_loss: 1.6364 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6280 - accuracy: 0.2512 - val_loss: 1.6361 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2372 - val_loss: 1.6360 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6273 - accuracy: 0.2465 - val_loss: 1.6357 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2558 - val_loss: 1.6355 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 81ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2465 - val_loss: 1.6353 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6293 - accuracy: 0.2558 - val_loss: 1.6352 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2465 - val_loss: 1.6351 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2512 - val_loss: 1.6349 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.2605 - val_loss: 1.6348 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6242 - accuracy: 0.2465 - val_loss: 1.6347 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2651 - val_loss: 1.6346 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6248 - accuracy: 0.2651 - val_loss: 1.6343 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2651 - val_loss: 1.6341 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6281 - accuracy: 0.2372 - val_loss: 1.6340 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2372 - val_loss: 1.6338 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2651 - val_loss: 1.6341 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2558 - val_loss: 1.6342 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6199 - accuracy: 0.2465 - val_loss: 1.6345 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6251 - accuracy: 0.2605 - val_loss: 1.6346 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6127 - accuracy: 0.2651 - val_loss: 1.6347 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6237 - accuracy: 0.2558 - val_loss: 1.6346 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2558 - val_loss: 1.6346 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Node 15 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6605 - accuracy: 0.1628 - val_loss: 1.6587 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 2s/epoch - 350ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6596 - accuracy: 0.2047 - val_loss: 1.6582 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6589 - accuracy: 0.1953 - val_loss: 1.6578 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6578 - accuracy: 0.2047 - val_loss: 1.6573 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6578 - accuracy: 0.2419 - val_loss: 1.6568 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2651 - val_loss: 1.6563 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6555 - accuracy: 0.2279 - val_loss: 1.6559 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6550 - accuracy: 0.2651 - val_loss: 1.6555 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6542 - accuracy: 0.2605 - val_loss: 1.6551 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6542 - accuracy: 0.2093 - val_loss: 1.6547 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6541 - accuracy: 0.2279 - val_loss: 1.6543 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6542 - accuracy: 0.2512 - val_loss: 1.6538 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6527 - accuracy: 0.2233 - val_loss: 1.6534 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6525 - accuracy: 0.2512 - val_loss: 1.6530 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6527 - accuracy: 0.2419 - val_loss: 1.6526 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6491 - accuracy: 0.2465 - val_loss: 1.6522 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6500 - accuracy: 0.2558 - val_loss: 1.6518 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6493 - accuracy: 0.2419 - val_loss: 1.6515 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6507 - accuracy: 0.2279 - val_loss: 1.6512 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6494 - accuracy: 0.2465 - val_loss: 1.6508 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6485 - accuracy: 0.2326 - val_loss: 1.6505 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6510 - accuracy: 0.2419 - val_loss: 1.6501 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6483 - accuracy: 0.2372 - val_loss: 1.6497 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6475 - accuracy: 0.2465 - val_loss: 1.6494 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6472 - accuracy: 0.2279 - val_loss: 1.6491 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6462 - accuracy: 0.2372 - val_loss: 1.6487 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6450 - accuracy: 0.2465 - val_loss: 1.6484 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6458 - accuracy: 0.2512 - val_loss: 1.6481 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6444 - accuracy: 0.2419 - val_loss: 1.6477 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6426 - accuracy: 0.2372 - val_loss: 1.6474 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6456 - accuracy: 0.2419 - val_loss: 1.6470 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6428 - accuracy: 0.2372 - val_loss: 1.6467 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6451 - accuracy: 0.2419 - val_loss: 1.6464 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6417 - accuracy: 0.2419 - val_loss: 1.6461 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6419 - accuracy: 0.2419 - val_loss: 1.6457 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2372 - val_loss: 1.6454 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6439 - accuracy: 0.2512 - val_loss: 1.6450 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6457 - accuracy: 0.2419 - val_loss: 1.6446 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6436 - accuracy: 0.2465 - val_loss: 1.6443 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6417 - accuracy: 0.2326 - val_loss: 1.6440 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6397 - accuracy: 0.2465 - val_loss: 1.6437 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.2465 - val_loss: 1.6434 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6402 - accuracy: 0.2419 - val_loss: 1.6431 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6403 - accuracy: 0.2419 - val_loss: 1.6429 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6399 - accuracy: 0.2419 - val_loss: 1.6426 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6373 - accuracy: 0.2372 - val_loss: 1.6424 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6379 - accuracy: 0.2512 - val_loss: 1.6422 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2512 - val_loss: 1.6420 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6348 - accuracy: 0.2465 - val_loss: 1.6418 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6386 - accuracy: 0.2419 - val_loss: 1.6415 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.2512 - val_loss: 1.6413 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6376 - accuracy: 0.2512 - val_loss: 1.6411 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6375 - accuracy: 0.2419 - val_loss: 1.6408 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6340 - accuracy: 0.2512 - val_loss: 1.6406 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6347 - accuracy: 0.2558 - val_loss: 1.6404 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2372 - val_loss: 1.6402 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6363 - accuracy: 0.2465 - val_loss: 1.6401 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.2465 - val_loss: 1.6398 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.2558 - val_loss: 1.6396 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.2419 - val_loss: 1.6395 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2372 - val_loss: 1.6393 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.2465 - val_loss: 1.6392 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6329 - accuracy: 0.2651 - val_loss: 1.6391 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.2279 - val_loss: 1.6390 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2372 - val_loss: 1.6389 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2605 - val_loss: 1.6387 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.2465 - val_loss: 1.6385 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2419 - val_loss: 1.6385 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2605 - val_loss: 1.6385 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2558 - val_loss: 1.6384 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2419 - val_loss: 1.6383 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2419 - val_loss: 1.6382 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2419 - val_loss: 1.6381 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2419 - val_loss: 1.6379 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2326 - val_loss: 1.6378 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2512 - val_loss: 1.6377 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2372 - val_loss: 1.6376 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2558 - val_loss: 1.6375 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2419 - val_loss: 1.6374 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2558 - val_loss: 1.6373 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2419 - val_loss: 1.6373 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6292 - accuracy: 0.2512 - val_loss: 1.6372 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2372 - val_loss: 1.6372 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2558 - val_loss: 1.6372 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2465 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2605 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 39ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2465 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2419 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2512 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 39ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2512 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2512 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 41ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2558 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 39ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2558 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2419 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 40ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2465 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 39ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2512 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 41ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2279 - val_loss: 1.6370 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 39ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "7/7 - 0s - loss: 1.6122 - accuracy: 0.2605 - val_loss: 1.6369 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 60ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2419 - val_loss: 1.6369 - val_accuracy: 0.2407 - lr: 6.2500e-06 - 41ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6196 - accuracy: 0.2558 - val_loss: 1.6369 - val_accuracy: 0.2407 - lr: 6.2500e-06 - 40ms/epoch - 6ms/step\n",
      "Node 15 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 15 - Best Validation Accuracy: 0.2963\n",
      "Best model saved for Node 15 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_15.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_16_dataset.csv\n",
      "Node 16 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6337 - accuracy: 0.2422 - val_loss: 1.6338 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 2s/epoch - 178ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6330 - accuracy: 0.1973 - val_loss: 1.6334 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6310 - accuracy: 0.2466 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6338 - accuracy: 0.2018 - val_loss: 1.6327 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6330 - accuracy: 0.2422 - val_loss: 1.6323 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2377 - val_loss: 1.6320 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2018 - val_loss: 1.6316 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6299 - accuracy: 0.2332 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.2332 - val_loss: 1.6308 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2422 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6308 - accuracy: 0.2466 - val_loss: 1.6302 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6293 - accuracy: 0.2377 - val_loss: 1.6299 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6306 - accuracy: 0.2197 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6278 - accuracy: 0.2197 - val_loss: 1.6291 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6305 - accuracy: 0.2422 - val_loss: 1.6287 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6288 - accuracy: 0.2018 - val_loss: 1.6285 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6280 - accuracy: 0.2466 - val_loss: 1.6282 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.3049 - val_loss: 1.6280 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6258 - accuracy: 0.2735 - val_loss: 1.6276 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6265 - accuracy: 0.2511 - val_loss: 1.6273 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2242 - val_loss: 1.6271 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6251 - accuracy: 0.2466 - val_loss: 1.6268 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2377 - val_loss: 1.6265 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2466 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2422 - val_loss: 1.6259 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2287 - val_loss: 1.6256 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6229 - accuracy: 0.2422 - val_loss: 1.6252 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2691 - val_loss: 1.6249 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6209 - accuracy: 0.2691 - val_loss: 1.6246 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2556 - val_loss: 1.6243 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2466 - val_loss: 1.6240 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2511 - val_loss: 1.6237 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2691 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2197 - val_loss: 1.6231 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2466 - val_loss: 1.6230 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2601 - val_loss: 1.6227 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2422 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2466 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6214 - accuracy: 0.2422 - val_loss: 1.6220 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2197 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6200 - accuracy: 0.2377 - val_loss: 1.6216 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2466 - val_loss: 1.6213 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2646 - val_loss: 1.6210 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2332 - val_loss: 1.6209 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2197 - val_loss: 1.6207 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2287 - val_loss: 1.6205 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2601 - val_loss: 1.6202 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2556 - val_loss: 1.6200 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2601 - val_loss: 1.6198 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2422 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2646 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.2332 - val_loss: 1.6193 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6161 - accuracy: 0.2422 - val_loss: 1.6191 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2466 - val_loss: 1.6187 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6147 - accuracy: 0.2556 - val_loss: 1.6185 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2466 - val_loss: 1.6184 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6150 - accuracy: 0.2332 - val_loss: 1.6182 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2735 - val_loss: 1.6180 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.2735 - val_loss: 1.6177 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6109 - accuracy: 0.2960 - val_loss: 1.6176 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2422 - val_loss: 1.6174 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6098 - accuracy: 0.2466 - val_loss: 1.6173 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2287 - val_loss: 1.6171 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2332 - val_loss: 1.6170 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6141 - accuracy: 0.2780 - val_loss: 1.6168 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6098 - accuracy: 0.2601 - val_loss: 1.6166 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6129 - accuracy: 0.2601 - val_loss: 1.6165 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6147 - accuracy: 0.2422 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2511 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6100 - accuracy: 0.2735 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6112 - accuracy: 0.2511 - val_loss: 1.6159 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2108 - val_loss: 1.6158 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6108 - accuracy: 0.2691 - val_loss: 1.6156 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.2556 - val_loss: 1.6154 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6113 - accuracy: 0.2646 - val_loss: 1.6152 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6137 - accuracy: 0.2466 - val_loss: 1.6152 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6112 - accuracy: 0.2556 - val_loss: 1.6151 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2556 - val_loss: 1.6150 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6114 - accuracy: 0.2601 - val_loss: 1.6149 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2646 - val_loss: 1.6147 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2825 - val_loss: 1.6146 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6112 - accuracy: 0.2556 - val_loss: 1.6143 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6062 - accuracy: 0.2422 - val_loss: 1.6143 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6123 - accuracy: 0.2511 - val_loss: 1.6143 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6113 - accuracy: 0.2287 - val_loss: 1.6143 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2646 - val_loss: 1.6141 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6132 - accuracy: 0.2332 - val_loss: 1.6140 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6134 - accuracy: 0.2511 - val_loss: 1.6139 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2511 - val_loss: 1.6138 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6107 - accuracy: 0.2197 - val_loss: 1.6138 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6123 - accuracy: 0.2332 - val_loss: 1.6137 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6147 - accuracy: 0.2691 - val_loss: 1.6137 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6103 - accuracy: 0.2556 - val_loss: 1.6136 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6092 - accuracy: 0.2646 - val_loss: 1.6136 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6136 - accuracy: 0.2735 - val_loss: 1.6135 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6110 - accuracy: 0.2601 - val_loss: 1.6134 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2735 - val_loss: 1.6133 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 63ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2511 - val_loss: 1.6133 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6041 - accuracy: 0.2870 - val_loss: 1.6132 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2691 - val_loss: 1.6131 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Node 16 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6330 - accuracy: 0.2108 - val_loss: 1.6343 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 3s/epoch - 403ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2197 - val_loss: 1.6340 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2152 - val_loss: 1.6338 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.1973 - val_loss: 1.6334 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2511 - val_loss: 1.6330 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6348 - accuracy: 0.1839 - val_loss: 1.6328 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2152 - val_loss: 1.6324 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2556 - val_loss: 1.6322 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2422 - val_loss: 1.6319 - val_accuracy: 0.3036 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2287 - val_loss: 1.6316 - val_accuracy: 0.3036 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2018 - val_loss: 1.6314 - val_accuracy: 0.3036 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2377 - val_loss: 1.6311 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2466 - val_loss: 1.6309 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2332 - val_loss: 1.6308 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6304 - accuracy: 0.2197 - val_loss: 1.6306 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6324 - accuracy: 0.2197 - val_loss: 1.6305 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2466 - val_loss: 1.6304 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2601 - val_loss: 1.6302 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2332 - val_loss: 1.6300 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2466 - val_loss: 1.6297 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2780 - val_loss: 1.6294 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2691 - val_loss: 1.6291 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2691 - val_loss: 1.6288 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2287 - val_loss: 1.6285 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2556 - val_loss: 1.6282 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2691 - val_loss: 1.6279 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2601 - val_loss: 1.6276 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2466 - val_loss: 1.6274 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2646 - val_loss: 1.6271 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2601 - val_loss: 1.6269 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2422 - val_loss: 1.6267 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6261 - accuracy: 0.2377 - val_loss: 1.6265 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2691 - val_loss: 1.6263 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2556 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2556 - val_loss: 1.6258 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2691 - val_loss: 1.6255 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.2691 - val_loss: 1.6253 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2511 - val_loss: 1.6252 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2646 - val_loss: 1.6251 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6238 - accuracy: 0.2556 - val_loss: 1.6249 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2466 - val_loss: 1.6247 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2466 - val_loss: 1.6245 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.2556 - val_loss: 1.6243 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2556 - val_loss: 1.6241 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2646 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2601 - val_loss: 1.6236 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2466 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6249 - accuracy: 0.2601 - val_loss: 1.6233 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2601 - val_loss: 1.6231 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6234 - accuracy: 0.2466 - val_loss: 1.6229 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2511 - val_loss: 1.6227 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6226 - accuracy: 0.2466 - val_loss: 1.6226 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6217 - accuracy: 0.2601 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2556 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2556 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2601 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2646 - val_loss: 1.6217 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2556 - val_loss: 1.6215 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2511 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2556 - val_loss: 1.6212 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2556 - val_loss: 1.6211 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2556 - val_loss: 1.6209 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2556 - val_loss: 1.6207 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6163 - accuracy: 0.2691 - val_loss: 1.6205 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6217 - accuracy: 0.2556 - val_loss: 1.6203 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2556 - val_loss: 1.6201 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6171 - accuracy: 0.2556 - val_loss: 1.6199 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2601 - val_loss: 1.6197 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2511 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6172 - accuracy: 0.2556 - val_loss: 1.6193 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6189 - accuracy: 0.2511 - val_loss: 1.6191 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2601 - val_loss: 1.6189 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2601 - val_loss: 1.6188 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2556 - val_loss: 1.6186 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2601 - val_loss: 1.6185 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6179 - accuracy: 0.2601 - val_loss: 1.6184 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2556 - val_loss: 1.6182 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2511 - val_loss: 1.6181 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6158 - accuracy: 0.2511 - val_loss: 1.6180 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2556 - val_loss: 1.6179 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2601 - val_loss: 1.6177 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6159 - accuracy: 0.2556 - val_loss: 1.6176 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6159 - accuracy: 0.2556 - val_loss: 1.6175 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6193 - accuracy: 0.2556 - val_loss: 1.6174 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2511 - val_loss: 1.6172 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2511 - val_loss: 1.6172 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6097 - accuracy: 0.2556 - val_loss: 1.6171 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2556 - val_loss: 1.6169 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6164 - accuracy: 0.2556 - val_loss: 1.6169 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6152 - accuracy: 0.2601 - val_loss: 1.6168 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6174 - accuracy: 0.2511 - val_loss: 1.6166 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6159 - accuracy: 0.2646 - val_loss: 1.6164 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6181 - accuracy: 0.2511 - val_loss: 1.6163 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6164 - accuracy: 0.2556 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6140 - accuracy: 0.2601 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6166 - accuracy: 0.2601 - val_loss: 1.6159 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2556 - val_loss: 1.6159 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6122 - accuracy: 0.2556 - val_loss: 1.6158 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6136 - accuracy: 0.2601 - val_loss: 1.6156 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6165 - accuracy: 0.2556 - val_loss: 1.6154 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Node 16 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 1.6604 - accuracy: 0.2063 - val_loss: 1.6593 - val_accuracy: 0.0893 - lr: 1.0000e-04 - 2s/epoch - 177ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6583 - accuracy: 0.1704 - val_loss: 1.6584 - val_accuracy: 0.1250 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6585 - accuracy: 0.1928 - val_loss: 1.6576 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6573 - accuracy: 0.1928 - val_loss: 1.6567 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6561 - accuracy: 0.2018 - val_loss: 1.6558 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6545 - accuracy: 0.2422 - val_loss: 1.6549 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6540 - accuracy: 0.2018 - val_loss: 1.6538 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6535 - accuracy: 0.2242 - val_loss: 1.6530 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6515 - accuracy: 0.2691 - val_loss: 1.6520 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6507 - accuracy: 0.2646 - val_loss: 1.6511 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6497 - accuracy: 0.2601 - val_loss: 1.6503 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6495 - accuracy: 0.2556 - val_loss: 1.6492 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6470 - accuracy: 0.2646 - val_loss: 1.6484 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6486 - accuracy: 0.2511 - val_loss: 1.6475 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6459 - accuracy: 0.2422 - val_loss: 1.6466 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6476 - accuracy: 0.2735 - val_loss: 1.6457 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6428 - accuracy: 0.2332 - val_loss: 1.6448 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6398 - accuracy: 0.2466 - val_loss: 1.6439 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6388 - accuracy: 0.2601 - val_loss: 1.6430 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6425 - accuracy: 0.2556 - val_loss: 1.6423 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6421 - accuracy: 0.2466 - val_loss: 1.6417 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6391 - accuracy: 0.2735 - val_loss: 1.6410 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6400 - accuracy: 0.2735 - val_loss: 1.6403 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6378 - accuracy: 0.2556 - val_loss: 1.6396 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6395 - accuracy: 0.2466 - val_loss: 1.6390 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6374 - accuracy: 0.2556 - val_loss: 1.6385 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6358 - accuracy: 0.2646 - val_loss: 1.6380 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6329 - accuracy: 0.2422 - val_loss: 1.6373 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6338 - accuracy: 0.2556 - val_loss: 1.6368 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2511 - val_loss: 1.6361 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6363 - accuracy: 0.2466 - val_loss: 1.6356 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2556 - val_loss: 1.6350 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6329 - accuracy: 0.2511 - val_loss: 1.6344 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6349 - accuracy: 0.2466 - val_loss: 1.6339 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6308 - accuracy: 0.2601 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6352 - accuracy: 0.2556 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.2556 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6319 - accuracy: 0.2466 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2556 - val_loss: 1.6317 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6249 - accuracy: 0.2601 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6251 - accuracy: 0.2691 - val_loss: 1.6307 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2646 - val_loss: 1.6302 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.2601 - val_loss: 1.6298 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2646 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2691 - val_loss: 1.6290 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2646 - val_loss: 1.6287 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.2511 - val_loss: 1.6283 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2780 - val_loss: 1.6279 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 81ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2691 - val_loss: 1.6275 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2556 - val_loss: 1.6272 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6281 - accuracy: 0.2422 - val_loss: 1.6270 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.2511 - val_loss: 1.6266 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2735 - val_loss: 1.6264 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6142 - accuracy: 0.2332 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2601 - val_loss: 1.6258 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6247 - accuracy: 0.2511 - val_loss: 1.6255 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6234 - accuracy: 0.2511 - val_loss: 1.6252 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6152 - accuracy: 0.2466 - val_loss: 1.6251 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6132 - accuracy: 0.2646 - val_loss: 1.6248 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6228 - accuracy: 0.2691 - val_loss: 1.6246 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6192 - accuracy: 0.2287 - val_loss: 1.6243 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2511 - val_loss: 1.6241 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6166 - accuracy: 0.2691 - val_loss: 1.6240 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2377 - val_loss: 1.6238 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.2601 - val_loss: 1.6237 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6064 - accuracy: 0.2601 - val_loss: 1.6235 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6097 - accuracy: 0.2691 - val_loss: 1.6231 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2556 - val_loss: 1.6228 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2511 - val_loss: 1.6226 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2377 - val_loss: 1.6224 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2691 - val_loss: 1.6224 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6135 - accuracy: 0.2646 - val_loss: 1.6222 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6114 - accuracy: 0.2601 - val_loss: 1.6220 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6143 - accuracy: 0.2691 - val_loss: 1.6219 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6124 - accuracy: 0.2870 - val_loss: 1.6216 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2556 - val_loss: 1.6215 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6102 - accuracy: 0.2646 - val_loss: 1.6214 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.5998 - accuracy: 0.2735 - val_loss: 1.6211 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6084 - accuracy: 0.2511 - val_loss: 1.6209 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2691 - val_loss: 1.6208 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6117 - accuracy: 0.2825 - val_loss: 1.6205 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6046 - accuracy: 0.2780 - val_loss: 1.6204 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6093 - accuracy: 0.2556 - val_loss: 1.6202 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6098 - accuracy: 0.2377 - val_loss: 1.6201 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.5985 - accuracy: 0.2960 - val_loss: 1.6201 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6094 - accuracy: 0.2691 - val_loss: 1.6202 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6131 - accuracy: 0.2511 - val_loss: 1.6202 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6026 - accuracy: 0.2780 - val_loss: 1.6201 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6141 - accuracy: 0.2511 - val_loss: 1.6201 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6078 - accuracy: 0.2332 - val_loss: 1.6201 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6101 - accuracy: 0.2511 - val_loss: 1.6200 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.5980 - accuracy: 0.2780 - val_loss: 1.6199 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6086 - accuracy: 0.2556 - val_loss: 1.6199 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2556 - val_loss: 1.6199 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6033 - accuracy: 0.2691 - val_loss: 1.6198 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 85ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2691 - val_loss: 1.6198 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6062 - accuracy: 0.2511 - val_loss: 1.6197 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6099 - accuracy: 0.2511 - val_loss: 1.6196 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.5993 - accuracy: 0.2780 - val_loss: 1.6196 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6185 - accuracy: 0.2377 - val_loss: 1.6197 - val_accuracy: 0.2143 - lr: 5.0000e-05 - 63ms/epoch - 5ms/step\n",
      "Node 16 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6587 - accuracy: 0.2108 - val_loss: 1.6579 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 3s/epoch - 394ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6595 - accuracy: 0.2197 - val_loss: 1.6573 - val_accuracy: 0.3036 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6579 - accuracy: 0.2197 - val_loss: 1.6567 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6557 - accuracy: 0.2825 - val_loss: 1.6562 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6566 - accuracy: 0.2511 - val_loss: 1.6555 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6540 - accuracy: 0.2735 - val_loss: 1.6549 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6545 - accuracy: 0.2556 - val_loss: 1.6543 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6531 - accuracy: 0.2422 - val_loss: 1.6536 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6537 - accuracy: 0.2735 - val_loss: 1.6530 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6520 - accuracy: 0.2377 - val_loss: 1.6524 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6517 - accuracy: 0.2556 - val_loss: 1.6518 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6510 - accuracy: 0.2691 - val_loss: 1.6513 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6502 - accuracy: 0.2646 - val_loss: 1.6507 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6498 - accuracy: 0.2556 - val_loss: 1.6502 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6498 - accuracy: 0.2466 - val_loss: 1.6496 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2511 - val_loss: 1.6489 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6499 - accuracy: 0.2556 - val_loss: 1.6483 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2422 - val_loss: 1.6478 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6452 - accuracy: 0.2556 - val_loss: 1.6473 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6468 - accuracy: 0.2601 - val_loss: 1.6468 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6461 - accuracy: 0.2511 - val_loss: 1.6463 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2556 - val_loss: 1.6456 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6432 - accuracy: 0.2556 - val_loss: 1.6451 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6445 - accuracy: 0.2511 - val_loss: 1.6445 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2601 - val_loss: 1.6440 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6454 - accuracy: 0.2556 - val_loss: 1.6435 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6431 - accuracy: 0.2511 - val_loss: 1.6431 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6433 - accuracy: 0.2556 - val_loss: 1.6427 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6428 - accuracy: 0.2601 - val_loss: 1.6422 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6421 - accuracy: 0.2511 - val_loss: 1.6418 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6386 - accuracy: 0.2556 - val_loss: 1.6413 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2556 - val_loss: 1.6409 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6399 - accuracy: 0.2601 - val_loss: 1.6406 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6349 - accuracy: 0.2556 - val_loss: 1.6401 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6406 - accuracy: 0.2556 - val_loss: 1.6397 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.2556 - val_loss: 1.6394 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.2556 - val_loss: 1.6390 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6367 - accuracy: 0.2601 - val_loss: 1.6386 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6360 - accuracy: 0.2646 - val_loss: 1.6383 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6394 - accuracy: 0.2556 - val_loss: 1.6379 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6350 - accuracy: 0.2556 - val_loss: 1.6376 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6375 - accuracy: 0.2511 - val_loss: 1.6373 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6389 - accuracy: 0.2556 - val_loss: 1.6369 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2556 - val_loss: 1.6367 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6354 - accuracy: 0.2556 - val_loss: 1.6364 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6350 - accuracy: 0.2556 - val_loss: 1.6361 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2556 - val_loss: 1.6358 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6367 - accuracy: 0.2556 - val_loss: 1.6354 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6359 - accuracy: 0.2556 - val_loss: 1.6352 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 9ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2556 - val_loss: 1.6350 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.2601 - val_loss: 1.6348 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2556 - val_loss: 1.6346 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2556 - val_loss: 1.6344 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6306 - accuracy: 0.2601 - val_loss: 1.6341 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6366 - accuracy: 0.2556 - val_loss: 1.6338 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2511 - val_loss: 1.6336 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2646 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2556 - val_loss: 1.6332 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2601 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.2556 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2466 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2556 - val_loss: 1.6323 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2511 - val_loss: 1.6320 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2556 - val_loss: 1.6317 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2556 - val_loss: 1.6315 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2601 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2511 - val_loss: 1.6310 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2556 - val_loss: 1.6307 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2556 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6304 - accuracy: 0.2601 - val_loss: 1.6304 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2511 - val_loss: 1.6301 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2556 - val_loss: 1.6299 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6226 - accuracy: 0.2646 - val_loss: 1.6297 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2601 - val_loss: 1.6296 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2556 - val_loss: 1.6294 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2556 - val_loss: 1.6292 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2511 - val_loss: 1.6291 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2556 - val_loss: 1.6289 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2556 - val_loss: 1.6288 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2556 - val_loss: 1.6287 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6261 - accuracy: 0.2646 - val_loss: 1.6285 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2511 - val_loss: 1.6283 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2511 - val_loss: 1.6281 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2601 - val_loss: 1.6279 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6178 - accuracy: 0.2556 - val_loss: 1.6277 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2556 - val_loss: 1.6275 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2511 - val_loss: 1.6274 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2556 - val_loss: 1.6272 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2556 - val_loss: 1.6269 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2601 - val_loss: 1.6268 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2511 - val_loss: 1.6268 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.2646 - val_loss: 1.6266 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2511 - val_loss: 1.6264 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2556 - val_loss: 1.6262 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6240 - accuracy: 0.2466 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 9ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2556 - val_loss: 1.6259 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6166 - accuracy: 0.2601 - val_loss: 1.6258 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2556 - val_loss: 1.6256 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6137 - accuracy: 0.2646 - val_loss: 1.6255 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2601 - val_loss: 1.6253 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Node 16 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 16 - Best Validation Accuracy: 0.3036\n",
      "Best model saved for Node 16 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_16.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_17_dataset.csv\n",
      "Node 17 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6358 - accuracy: 0.2125 - val_loss: 1.6348 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 2s/epoch - 119ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6354 - accuracy: 0.1958 - val_loss: 1.6345 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.1311 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6352 - accuracy: 0.1833 - val_loss: 1.6340 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.2083 - val_loss: 1.6334 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2125 - val_loss: 1.6330 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2708 - val_loss: 1.6323 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.1958 - val_loss: 1.6319 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.1958 - val_loss: 1.6317 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.2125 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.1958 - val_loss: 1.6311 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2250 - val_loss: 1.6307 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2167 - val_loss: 1.6304 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2458 - val_loss: 1.6300 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6309 - accuracy: 0.2458 - val_loss: 1.6297 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.1958 - val_loss: 1.6294 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2625 - val_loss: 1.6294 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2250 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2167 - val_loss: 1.6288 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2208 - val_loss: 1.6286 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2375 - val_loss: 1.6284 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2417 - val_loss: 1.6282 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2333 - val_loss: 1.6281 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2417 - val_loss: 1.6279 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2458 - val_loss: 1.6278 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2583 - val_loss: 1.6277 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2542 - val_loss: 1.6274 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2042 - val_loss: 1.6273 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2542 - val_loss: 1.6271 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2292 - val_loss: 1.6264 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2042 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2375 - val_loss: 1.6257 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2167 - val_loss: 1.6254 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2458 - val_loss: 1.6252 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2042 - val_loss: 1.6250 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2375 - val_loss: 1.6248 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2292 - val_loss: 1.6244 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2875 - val_loss: 1.6242 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.2375 - val_loss: 1.6241 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2500 - val_loss: 1.6238 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2542 - val_loss: 1.6236 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2250 - val_loss: 1.6234 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2458 - val_loss: 1.6233 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2458 - val_loss: 1.6231 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2167 - val_loss: 1.6229 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2500 - val_loss: 1.6226 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2500 - val_loss: 1.6224 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2125 - val_loss: 1.6223 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2375 - val_loss: 1.6221 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2333 - val_loss: 1.6220 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2417 - val_loss: 1.6218 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2250 - val_loss: 1.6217 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2500 - val_loss: 1.6215 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2750 - val_loss: 1.6214 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2375 - val_loss: 1.6212 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2833 - val_loss: 1.6211 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2583 - val_loss: 1.6208 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2458 - val_loss: 1.6207 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2625 - val_loss: 1.6205 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2125 - val_loss: 1.6204 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2417 - val_loss: 1.6203 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2333 - val_loss: 1.6201 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2500 - val_loss: 1.6200 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2375 - val_loss: 1.6197 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2667 - val_loss: 1.6195 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2292 - val_loss: 1.6193 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2333 - val_loss: 1.6190 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2500 - val_loss: 1.6188 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2333 - val_loss: 1.6187 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2500 - val_loss: 1.6188 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2542 - val_loss: 1.6187 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6156 - accuracy: 0.2958 - val_loss: 1.6186 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2292 - val_loss: 1.6185 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2375 - val_loss: 1.6183 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2208 - val_loss: 1.6183 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 37ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2292 - val_loss: 1.6182 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6126 - accuracy: 0.2542 - val_loss: 1.6181 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 40ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2542 - val_loss: 1.6180 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6154 - accuracy: 0.2083 - val_loss: 1.6178 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2333 - val_loss: 1.6177 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2542 - val_loss: 1.6177 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2667 - val_loss: 1.6175 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2208 - val_loss: 1.6174 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2042 - val_loss: 1.6174 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2750 - val_loss: 1.6174 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2500 - val_loss: 1.6173 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2500 - val_loss: 1.6172 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6133 - accuracy: 0.2500 - val_loss: 1.6171 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2042 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2500 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2458 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2500 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2125 - val_loss: 1.6170 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2542 - val_loss: 1.6169 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 36ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6140 - accuracy: 0.2125 - val_loss: 1.6169 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6158 - accuracy: 0.2583 - val_loss: 1.6169 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2583 - val_loss: 1.6169 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6091 - accuracy: 0.2917 - val_loss: 1.6168 - val_accuracy: 0.2295 - lr: 1.2500e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2708 - val_loss: 1.6168 - val_accuracy: 0.2295 - lr: 1.2500e-05 - 38ms/epoch - 3ms/step\n",
      "Node 17 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6343 - accuracy: 0.1708 - val_loss: 1.6326 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 3s/epoch - 362ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2292 - val_loss: 1.6324 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2000 - val_loss: 1.6323 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2000 - val_loss: 1.6322 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2125 - val_loss: 1.6321 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1958 - val_loss: 1.6320 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1792 - val_loss: 1.6320 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2375 - val_loss: 1.6318 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2583 - val_loss: 1.6316 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2583 - val_loss: 1.6314 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.1875 - val_loss: 1.6313 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2250 - val_loss: 1.6311 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.1833 - val_loss: 1.6309 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2250 - val_loss: 1.6308 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2417 - val_loss: 1.6306 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2125 - val_loss: 1.6304 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2292 - val_loss: 1.6303 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2375 - val_loss: 1.6301 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2125 - val_loss: 1.6300 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2208 - val_loss: 1.6299 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2125 - val_loss: 1.6297 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2667 - val_loss: 1.6296 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.1833 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2250 - val_loss: 1.6293 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2167 - val_loss: 1.6291 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2583 - val_loss: 1.6289 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2208 - val_loss: 1.6288 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2000 - val_loss: 1.6286 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2333 - val_loss: 1.6284 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2292 - val_loss: 1.6282 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2375 - val_loss: 1.6280 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2083 - val_loss: 1.6279 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2167 - val_loss: 1.6277 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2292 - val_loss: 1.6276 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2542 - val_loss: 1.6274 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2500 - val_loss: 1.6273 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2167 - val_loss: 1.6271 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2417 - val_loss: 1.6270 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2250 - val_loss: 1.6269 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2333 - val_loss: 1.6268 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2375 - val_loss: 1.6267 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2375 - val_loss: 1.6266 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2042 - val_loss: 1.6264 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2583 - val_loss: 1.6263 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2417 - val_loss: 1.6261 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2417 - val_loss: 1.6260 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2625 - val_loss: 1.6258 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2292 - val_loss: 1.6257 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2458 - val_loss: 1.6257 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2250 - val_loss: 1.6256 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2250 - val_loss: 1.6254 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2333 - val_loss: 1.6254 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2417 - val_loss: 1.6253 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2542 - val_loss: 1.6252 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2667 - val_loss: 1.6251 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2000 - val_loss: 1.6250 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2500 - val_loss: 1.6249 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2625 - val_loss: 1.6247 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2458 - val_loss: 1.6246 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2500 - val_loss: 1.6245 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2000 - val_loss: 1.6244 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2333 - val_loss: 1.6244 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2583 - val_loss: 1.6243 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2250 - val_loss: 1.6242 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2625 - val_loss: 1.6241 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2667 - val_loss: 1.6239 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2417 - val_loss: 1.6238 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2292 - val_loss: 1.6236 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2292 - val_loss: 1.6235 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2708 - val_loss: 1.6235 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2333 - val_loss: 1.6234 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2500 - val_loss: 1.6233 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2250 - val_loss: 1.6232 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2250 - val_loss: 1.6231 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2583 - val_loss: 1.6230 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2167 - val_loss: 1.6229 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2208 - val_loss: 1.6228 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2292 - val_loss: 1.6227 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2500 - val_loss: 1.6226 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2375 - val_loss: 1.6226 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2292 - val_loss: 1.6225 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2375 - val_loss: 1.6224 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2500 - val_loss: 1.6223 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2292 - val_loss: 1.6223 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2292 - val_loss: 1.6223 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2583 - val_loss: 1.6222 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2250 - val_loss: 1.6222 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2375 - val_loss: 1.6221 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2750 - val_loss: 1.6221 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2375 - val_loss: 1.6220 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2250 - val_loss: 1.6219 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2083 - val_loss: 1.6218 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2625 - val_loss: 1.6217 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2625 - val_loss: 1.6216 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2250 - val_loss: 1.6215 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2625 - val_loss: 1.6215 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2750 - val_loss: 1.6214 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2625 - val_loss: 1.6213 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2292 - val_loss: 1.6213 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2583 - val_loss: 1.6212 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 17 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6609 - accuracy: 0.1750 - val_loss: 1.6609 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 2s/epoch - 122ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6602 - accuracy: 0.1542 - val_loss: 1.6601 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6597 - accuracy: 0.1958 - val_loss: 1.6593 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6581 - accuracy: 0.2083 - val_loss: 1.6585 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6582 - accuracy: 0.1958 - val_loss: 1.6577 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6575 - accuracy: 0.2000 - val_loss: 1.6570 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6556 - accuracy: 0.2333 - val_loss: 1.6562 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6543 - accuracy: 0.2042 - val_loss: 1.6554 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6545 - accuracy: 0.2417 - val_loss: 1.6547 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6541 - accuracy: 0.2292 - val_loss: 1.6539 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6525 - accuracy: 0.2292 - val_loss: 1.6532 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6519 - accuracy: 0.2083 - val_loss: 1.6525 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6513 - accuracy: 0.2292 - val_loss: 1.6518 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6509 - accuracy: 0.2125 - val_loss: 1.6512 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6498 - accuracy: 0.2208 - val_loss: 1.6508 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2333 - val_loss: 1.6501 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6476 - accuracy: 0.2375 - val_loss: 1.6496 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2625 - val_loss: 1.6489 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6461 - accuracy: 0.2583 - val_loss: 1.6484 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2667 - val_loss: 1.6479 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6448 - accuracy: 0.2542 - val_loss: 1.6473 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2417 - val_loss: 1.6468 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6430 - accuracy: 0.2667 - val_loss: 1.6462 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6429 - accuracy: 0.2500 - val_loss: 1.6455 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6423 - accuracy: 0.2750 - val_loss: 1.6450 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6404 - accuracy: 0.2792 - val_loss: 1.6445 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6418 - accuracy: 0.2792 - val_loss: 1.6441 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6408 - accuracy: 0.2958 - val_loss: 1.6435 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6403 - accuracy: 0.2083 - val_loss: 1.6430 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6389 - accuracy: 0.2583 - val_loss: 1.6425 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6382 - accuracy: 0.2458 - val_loss: 1.6419 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2917 - val_loss: 1.6413 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2417 - val_loss: 1.6408 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6382 - accuracy: 0.2583 - val_loss: 1.6403 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6359 - accuracy: 0.2625 - val_loss: 1.6399 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2583 - val_loss: 1.6394 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6358 - accuracy: 0.2625 - val_loss: 1.6390 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2875 - val_loss: 1.6387 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2750 - val_loss: 1.6382 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2417 - val_loss: 1.6379 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2833 - val_loss: 1.6374 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2500 - val_loss: 1.6369 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2875 - val_loss: 1.6365 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.3000 - val_loss: 1.6361 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2458 - val_loss: 1.6358 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2958 - val_loss: 1.6355 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2833 - val_loss: 1.6353 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2458 - val_loss: 1.6350 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2458 - val_loss: 1.6347 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2625 - val_loss: 1.6344 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 83ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2625 - val_loss: 1.6340 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2708 - val_loss: 1.6337 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2750 - val_loss: 1.6334 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2708 - val_loss: 1.6331 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2833 - val_loss: 1.6328 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2792 - val_loss: 1.6328 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2458 - val_loss: 1.6326 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2667 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2917 - val_loss: 1.6322 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2792 - val_loss: 1.6320 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2833 - val_loss: 1.6319 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2833 - val_loss: 1.6318 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2667 - val_loss: 1.6316 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2625 - val_loss: 1.6313 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2750 - val_loss: 1.6312 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2917 - val_loss: 1.6311 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2792 - val_loss: 1.6307 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2792 - val_loss: 1.6307 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2958 - val_loss: 1.6307 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2625 - val_loss: 1.6306 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2958 - val_loss: 1.6305 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2542 - val_loss: 1.6305 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2583 - val_loss: 1.6303 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.3042 - val_loss: 1.6301 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2625 - val_loss: 1.6301 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2583 - val_loss: 1.6300 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6072 - accuracy: 0.2917 - val_loss: 1.6299 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2667 - val_loss: 1.6298 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2792 - val_loss: 1.6298 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6110 - accuracy: 0.2667 - val_loss: 1.6298 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2667 - val_loss: 1.6297 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2833 - val_loss: 1.6294 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2917 - val_loss: 1.6294 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6081 - accuracy: 0.2875 - val_loss: 1.6294 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6086 - accuracy: 0.2708 - val_loss: 1.6293 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6040 - accuracy: 0.3208 - val_loss: 1.6295 - val_accuracy: 0.2131 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6029 - accuracy: 0.2917 - val_loss: 1.6296 - val_accuracy: 0.2459 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2542 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6056 - accuracy: 0.2708 - val_loss: 1.6296 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6040 - accuracy: 0.3167 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.5944 - accuracy: 0.3375 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.5980 - accuracy: 0.3333 - val_loss: 1.6297 - val_accuracy: 0.2295 - lr: 1.2500e-05 - 60ms/epoch - 4ms/step\n",
      "Node 17 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6599 - accuracy: 0.2292 - val_loss: 1.6598 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 3s/epoch - 347ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6601 - accuracy: 0.2042 - val_loss: 1.6594 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6601 - accuracy: 0.1917 - val_loss: 1.6591 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6580 - accuracy: 0.2333 - val_loss: 1.6587 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.2250 - val_loss: 1.6583 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6574 - accuracy: 0.2500 - val_loss: 1.6579 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.1917 - val_loss: 1.6574 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.1667 - val_loss: 1.6570 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2458 - val_loss: 1.6566 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2250 - val_loss: 1.6562 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2708 - val_loss: 1.6558 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6538 - accuracy: 0.2333 - val_loss: 1.6553 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6548 - accuracy: 0.2042 - val_loss: 1.6549 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2500 - val_loss: 1.6545 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 8ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6528 - accuracy: 0.2458 - val_loss: 1.6542 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2042 - val_loss: 1.6539 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6537 - accuracy: 0.2250 - val_loss: 1.6535 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6523 - accuracy: 0.2292 - val_loss: 1.6531 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2292 - val_loss: 1.6528 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2625 - val_loss: 1.6525 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2583 - val_loss: 1.6522 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2125 - val_loss: 1.6518 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2333 - val_loss: 1.6514 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2333 - val_loss: 1.6511 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2333 - val_loss: 1.6508 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2458 - val_loss: 1.6504 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2333 - val_loss: 1.6501 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2458 - val_loss: 1.6498 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2333 - val_loss: 1.6497 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6473 - accuracy: 0.2167 - val_loss: 1.6494 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2292 - val_loss: 1.6492 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2625 - val_loss: 1.6489 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2375 - val_loss: 1.6486 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.3167 - val_loss: 1.6483 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2417 - val_loss: 1.6479 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2458 - val_loss: 1.6477 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2542 - val_loss: 1.6473 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2375 - val_loss: 1.6471 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.3083 - val_loss: 1.6468 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2667 - val_loss: 1.6466 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2625 - val_loss: 1.6463 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2292 - val_loss: 1.6461 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2792 - val_loss: 1.6458 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2583 - val_loss: 1.6454 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6397 - accuracy: 0.3000 - val_loss: 1.6452 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2333 - val_loss: 1.6449 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6374 - accuracy: 0.2958 - val_loss: 1.6446 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2833 - val_loss: 1.6444 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2708 - val_loss: 1.6442 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2708 - val_loss: 1.6439 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2292 - val_loss: 1.6437 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2375 - val_loss: 1.6436 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2583 - val_loss: 1.6434 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2792 - val_loss: 1.6432 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.2500 - val_loss: 1.6431 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2583 - val_loss: 1.6428 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2750 - val_loss: 1.6426 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.2625 - val_loss: 1.6424 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2792 - val_loss: 1.6421 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2792 - val_loss: 1.6419 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2542 - val_loss: 1.6416 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2833 - val_loss: 1.6414 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2542 - val_loss: 1.6413 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2542 - val_loss: 1.6412 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2500 - val_loss: 1.6410 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 66ms/epoch - 8ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2958 - val_loss: 1.6408 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2667 - val_loss: 1.6406 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2833 - val_loss: 1.6404 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2875 - val_loss: 1.6402 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2542 - val_loss: 1.6400 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2625 - val_loss: 1.6399 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2500 - val_loss: 1.6397 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2500 - val_loss: 1.6396 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2875 - val_loss: 1.6394 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2333 - val_loss: 1.6393 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2708 - val_loss: 1.6392 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.3000 - val_loss: 1.6390 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.3292 - val_loss: 1.6389 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2833 - val_loss: 1.6388 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2875 - val_loss: 1.6386 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2958 - val_loss: 1.6385 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2833 - val_loss: 1.6385 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2875 - val_loss: 1.6384 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2833 - val_loss: 1.6382 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2667 - val_loss: 1.6380 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2833 - val_loss: 1.6377 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.3000 - val_loss: 1.6375 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2875 - val_loss: 1.6373 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2833 - val_loss: 1.6372 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2750 - val_loss: 1.6370 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.3125 - val_loss: 1.6370 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2500 - val_loss: 1.6369 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.3125 - val_loss: 1.6368 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2792 - val_loss: 1.6366 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2833 - val_loss: 1.6366 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2833 - val_loss: 1.6365 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2458 - val_loss: 1.6365 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2792 - val_loss: 1.6366 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.3083 - val_loss: 1.6368 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2583 - val_loss: 1.6369 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Node 17 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 17 - Best Validation Accuracy: 0.3115\n",
      "Best model saved for Node 17 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_17.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_18_dataset.csv\n",
      "Node 18 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6363 - accuracy: 0.1916 - val_loss: 1.6336 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 3s/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.2222 - val_loss: 1.6334 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6325 - accuracy: 0.2567 - val_loss: 1.6332 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6344 - accuracy: 0.2146 - val_loss: 1.6330 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6319 - accuracy: 0.2299 - val_loss: 1.6328 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6343 - accuracy: 0.2146 - val_loss: 1.6326 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6343 - accuracy: 0.1916 - val_loss: 1.6324 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6331 - accuracy: 0.1992 - val_loss: 1.6322 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6307 - accuracy: 0.2222 - val_loss: 1.6321 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6342 - accuracy: 0.2184 - val_loss: 1.6319 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6331 - accuracy: 0.1916 - val_loss: 1.6317 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6318 - accuracy: 0.2069 - val_loss: 1.6316 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6309 - accuracy: 0.2299 - val_loss: 1.6314 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6302 - accuracy: 0.2184 - val_loss: 1.6312 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6320 - accuracy: 0.2146 - val_loss: 1.6310 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6307 - accuracy: 0.1992 - val_loss: 1.6309 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6300 - accuracy: 0.2414 - val_loss: 1.6307 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2031 - val_loss: 1.6305 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6305 - accuracy: 0.2222 - val_loss: 1.6303 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6307 - accuracy: 0.2107 - val_loss: 1.6301 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2222 - val_loss: 1.6300 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6293 - accuracy: 0.1992 - val_loss: 1.6298 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6291 - accuracy: 0.2337 - val_loss: 1.6297 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6286 - accuracy: 0.2069 - val_loss: 1.6295 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6290 - accuracy: 0.2375 - val_loss: 1.6294 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6292 - accuracy: 0.1992 - val_loss: 1.6291 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6293 - accuracy: 0.2069 - val_loss: 1.6288 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2146 - val_loss: 1.6287 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6284 - accuracy: 0.2184 - val_loss: 1.6285 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6264 - accuracy: 0.2107 - val_loss: 1.6284 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6254 - accuracy: 0.2682 - val_loss: 1.6283 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6268 - accuracy: 0.2299 - val_loss: 1.6283 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6279 - accuracy: 0.2222 - val_loss: 1.6282 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6276 - accuracy: 0.2222 - val_loss: 1.6281 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6278 - accuracy: 0.2529 - val_loss: 1.6277 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6278 - accuracy: 0.2107 - val_loss: 1.6275 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6270 - accuracy: 0.2222 - val_loss: 1.6274 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2184 - val_loss: 1.6273 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6266 - accuracy: 0.1954 - val_loss: 1.6272 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6240 - accuracy: 0.2452 - val_loss: 1.6271 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6270 - accuracy: 0.1954 - val_loss: 1.6270 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6269 - accuracy: 0.2031 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6254 - accuracy: 0.2375 - val_loss: 1.6266 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6273 - accuracy: 0.2031 - val_loss: 1.6265 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6253 - accuracy: 0.2184 - val_loss: 1.6264 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6268 - accuracy: 0.2069 - val_loss: 1.6264 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6240 - accuracy: 0.2146 - val_loss: 1.6264 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6250 - accuracy: 0.2299 - val_loss: 1.6264 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2835 - val_loss: 1.6263 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6255 - accuracy: 0.2069 - val_loss: 1.6263 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2069 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2490 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 5.0000e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2337 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2490 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6250 - accuracy: 0.1916 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2337 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2414 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2452 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2337 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6253 - accuracy: 0.2146 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.1839 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6277 - accuracy: 0.2031 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.1992 - val_loss: 1.6261 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2644 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6239 - accuracy: 0.2146 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6213 - accuracy: 0.2222 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "17/17 - 0s - loss: 1.6228 - accuracy: 0.2605 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.1250e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6244 - accuracy: 0.1954 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 52ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2605 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2529 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.5625e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6236 - accuracy: 0.2299 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.2069 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "17/17 - 0s - loss: 1.6218 - accuracy: 0.2261 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 7.8125e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2222 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6248 - accuracy: 0.2337 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.9062e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2414 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.9062e-07 - 51ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6246 - accuracy: 0.2031 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.9531e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2261 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2222 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6228 - accuracy: 0.2299 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 9.7656e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2337 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 9.7656e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "17/17 - 0s - loss: 1.6251 - accuracy: 0.2146 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6239 - accuracy: 0.2069 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 4.8828e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.1877 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 4.8828e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "17/17 - 0s - loss: 1.6233 - accuracy: 0.2107 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.2644 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 2.4414e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6231 - accuracy: 0.2414 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 2.4414e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2644 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 2.4414e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2031 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.2207e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.2299 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.2207e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2529 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.2207e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2222 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 6.1035e-09 - 51ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.1801 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "17/17 - 0s - loss: 1.6220 - accuracy: 0.2529 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2375 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.0518e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2452 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.0518e-09 - 51ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2337 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 3.0518e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.6223 - accuracy: 0.2261 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.5259e-09 - 50ms/epoch - 3ms/step\n",
      "Node 18 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 2s - loss: 1.6332 - accuracy: 0.2222 - val_loss: 1.6334 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 2s/epoch - 273ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6344 - accuracy: 0.1801 - val_loss: 1.6332 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.1954 - val_loss: 1.6331 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6326 - accuracy: 0.2490 - val_loss: 1.6330 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6326 - accuracy: 0.2261 - val_loss: 1.6329 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6322 - accuracy: 0.2107 - val_loss: 1.6328 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6339 - accuracy: 0.1762 - val_loss: 1.6327 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2146 - val_loss: 1.6326 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2107 - val_loss: 1.6325 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2375 - val_loss: 1.6324 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2490 - val_loss: 1.6323 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.2184 - val_loss: 1.6322 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2031 - val_loss: 1.6320 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.2490 - val_loss: 1.6319 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.1992 - val_loss: 1.6318 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6307 - accuracy: 0.1992 - val_loss: 1.6316 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2031 - val_loss: 1.6315 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6314 - accuracy: 0.2261 - val_loss: 1.6314 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.1762 - val_loss: 1.6313 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6307 - accuracy: 0.2222 - val_loss: 1.6311 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2299 - val_loss: 1.6310 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6311 - accuracy: 0.1954 - val_loss: 1.6309 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.2031 - val_loss: 1.6308 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.1877 - val_loss: 1.6308 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.1992 - val_loss: 1.6307 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6287 - accuracy: 0.2414 - val_loss: 1.6306 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2107 - val_loss: 1.6306 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6298 - accuracy: 0.2107 - val_loss: 1.6305 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2107 - val_loss: 1.6304 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6297 - accuracy: 0.1992 - val_loss: 1.6303 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2337 - val_loss: 1.6301 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.1992 - val_loss: 1.6300 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2337 - val_loss: 1.6300 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2184 - val_loss: 1.6299 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.1992 - val_loss: 1.6297 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.1916 - val_loss: 1.6296 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.2337 - val_loss: 1.6295 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2031 - val_loss: 1.6294 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6285 - accuracy: 0.1762 - val_loss: 1.6293 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6285 - accuracy: 0.1762 - val_loss: 1.6292 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6284 - accuracy: 0.1954 - val_loss: 1.6291 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2069 - val_loss: 1.6290 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2184 - val_loss: 1.6289 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2184 - val_loss: 1.6288 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2490 - val_loss: 1.6287 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2107 - val_loss: 1.6287 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2414 - val_loss: 1.6286 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2452 - val_loss: 1.6286 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.2222 - val_loss: 1.6285 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.2146 - val_loss: 1.6284 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2146 - val_loss: 1.6283 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.2146 - val_loss: 1.6283 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2414 - val_loss: 1.6282 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6249 - accuracy: 0.2605 - val_loss: 1.6280 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2490 - val_loss: 1.6279 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6251 - accuracy: 0.2337 - val_loss: 1.6278 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6258 - accuracy: 0.2490 - val_loss: 1.6277 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6263 - accuracy: 0.1839 - val_loss: 1.6276 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6257 - accuracy: 0.1648 - val_loss: 1.6274 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6258 - accuracy: 0.2452 - val_loss: 1.6273 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2107 - val_loss: 1.6273 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6234 - accuracy: 0.2682 - val_loss: 1.6273 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2299 - val_loss: 1.6272 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2682 - val_loss: 1.6270 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2567 - val_loss: 1.6269 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2184 - val_loss: 1.6268 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2759 - val_loss: 1.6268 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6208 - accuracy: 0.2337 - val_loss: 1.6267 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6236 - accuracy: 0.2720 - val_loss: 1.6266 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2299 - val_loss: 1.6265 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2069 - val_loss: 1.6264 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6223 - accuracy: 0.2375 - val_loss: 1.6263 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2069 - val_loss: 1.6264 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6245 - accuracy: 0.2452 - val_loss: 1.6264 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6223 - accuracy: 0.1839 - val_loss: 1.6264 - val_accuracy: 0.2121 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.2644 - val_loss: 1.6263 - val_accuracy: 0.1970 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "9/9 - 0s - loss: 1.6196 - accuracy: 0.2720 - val_loss: 1.6263 - val_accuracy: 0.2121 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2414 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 2.5000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2261 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 2.5000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2261 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 2.5000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2222 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2146 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2337 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.2500e-05 - 31ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "9/9 - 0s - loss: 1.6230 - accuracy: 0.2567 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.1877 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6194 - accuracy: 0.2682 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 6.2500e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "9/9 - 0s - loss: 1.6208 - accuracy: 0.2490 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 6.2500e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2299 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.1250e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6213 - accuracy: 0.2490 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.1250e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "9/9 - 0s - loss: 1.6250 - accuracy: 0.2261 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6217 - accuracy: 0.2146 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.5625e-06 - 34ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2337 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.5625e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2261 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.5625e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2261 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 7.8125e-07 - 34ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2529 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 7.8125e-07 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "9/9 - 0s - loss: 1.6234 - accuracy: 0.1954 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 7.8125e-07 - 32ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6207 - accuracy: 0.2299 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.9062e-07 - 52ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2107 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.9062e-07 - 33ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2414 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 3.9062e-07 - 33ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6225 - accuracy: 0.2069 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.9531e-07 - 33ms/epoch - 4ms/step\n",
      "Node 18 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6600 - accuracy: 0.2069 - val_loss: 1.6598 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 3s/epoch - 164ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6597 - accuracy: 0.1839 - val_loss: 1.6591 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6582 - accuracy: 0.2069 - val_loss: 1.6585 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6575 - accuracy: 0.2146 - val_loss: 1.6578 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6566 - accuracy: 0.1916 - val_loss: 1.6572 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6567 - accuracy: 0.1916 - val_loss: 1.6567 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6549 - accuracy: 0.2261 - val_loss: 1.6561 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6541 - accuracy: 0.2261 - val_loss: 1.6558 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6549 - accuracy: 0.2261 - val_loss: 1.6551 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6519 - accuracy: 0.2261 - val_loss: 1.6546 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6533 - accuracy: 0.2146 - val_loss: 1.6541 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6522 - accuracy: 0.2299 - val_loss: 1.6534 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6504 - accuracy: 0.2375 - val_loss: 1.6528 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6492 - accuracy: 0.2299 - val_loss: 1.6522 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6494 - accuracy: 0.2299 - val_loss: 1.6516 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6493 - accuracy: 0.1992 - val_loss: 1.6511 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6473 - accuracy: 0.2069 - val_loss: 1.6507 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6471 - accuracy: 0.2261 - val_loss: 1.6502 - val_accuracy: 0.1061 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6477 - accuracy: 0.2107 - val_loss: 1.6498 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6453 - accuracy: 0.2261 - val_loss: 1.6492 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6456 - accuracy: 0.2490 - val_loss: 1.6487 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6444 - accuracy: 0.2414 - val_loss: 1.6483 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6428 - accuracy: 0.2414 - val_loss: 1.6478 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6447 - accuracy: 0.2184 - val_loss: 1.6474 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6433 - accuracy: 0.2490 - val_loss: 1.6469 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6414 - accuracy: 0.2644 - val_loss: 1.6464 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6410 - accuracy: 0.2261 - val_loss: 1.6460 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6414 - accuracy: 0.2337 - val_loss: 1.6456 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6392 - accuracy: 0.2529 - val_loss: 1.6453 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6412 - accuracy: 0.2184 - val_loss: 1.6448 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6379 - accuracy: 0.2720 - val_loss: 1.6444 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6380 - accuracy: 0.2644 - val_loss: 1.6442 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6392 - accuracy: 0.2375 - val_loss: 1.6438 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6364 - accuracy: 0.2874 - val_loss: 1.6434 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6379 - accuracy: 0.2529 - val_loss: 1.6430 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6371 - accuracy: 0.2452 - val_loss: 1.6427 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6364 - accuracy: 0.2529 - val_loss: 1.6424 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.2682 - val_loss: 1.6420 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6341 - accuracy: 0.2912 - val_loss: 1.6418 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6335 - accuracy: 0.2759 - val_loss: 1.6415 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6338 - accuracy: 0.2605 - val_loss: 1.6412 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6331 - accuracy: 0.2452 - val_loss: 1.6408 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6328 - accuracy: 0.2874 - val_loss: 1.6406 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6330 - accuracy: 0.2720 - val_loss: 1.6404 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6313 - accuracy: 0.2950 - val_loss: 1.6401 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6296 - accuracy: 0.2797 - val_loss: 1.6398 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6317 - accuracy: 0.2452 - val_loss: 1.6397 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6319 - accuracy: 0.2644 - val_loss: 1.6395 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6301 - accuracy: 0.2414 - val_loss: 1.6393 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6292 - accuracy: 0.2682 - val_loss: 1.6391 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2452 - val_loss: 1.6389 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6280 - accuracy: 0.2605 - val_loss: 1.6387 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6287 - accuracy: 0.2720 - val_loss: 1.6386 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6268 - accuracy: 0.3218 - val_loss: 1.6386 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6270 - accuracy: 0.2682 - val_loss: 1.6384 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6262 - accuracy: 0.2759 - val_loss: 1.6382 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6265 - accuracy: 0.2375 - val_loss: 1.6380 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6235 - accuracy: 0.3142 - val_loss: 1.6380 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6276 - accuracy: 0.2069 - val_loss: 1.6380 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6266 - accuracy: 0.2337 - val_loss: 1.6377 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6260 - accuracy: 0.2529 - val_loss: 1.6374 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6245 - accuracy: 0.2682 - val_loss: 1.6372 - val_accuracy: 0.1212 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.2682 - val_loss: 1.6370 - val_accuracy: 0.1364 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6207 - accuracy: 0.2989 - val_loss: 1.6370 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2414 - val_loss: 1.6369 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2835 - val_loss: 1.6367 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6212 - accuracy: 0.2682 - val_loss: 1.6367 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6248 - accuracy: 0.2490 - val_loss: 1.6365 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2605 - val_loss: 1.6362 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2682 - val_loss: 1.6362 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6186 - accuracy: 0.2835 - val_loss: 1.6359 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2682 - val_loss: 1.6359 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2759 - val_loss: 1.6359 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2184 - val_loss: 1.6360 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6199 - accuracy: 0.2452 - val_loss: 1.6361 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 73ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6180 - accuracy: 0.2605 - val_loss: 1.6360 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6188 - accuracy: 0.2912 - val_loss: 1.6360 - val_accuracy: 0.1818 - lr: 5.0000e-05 - 73ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6228 - accuracy: 0.2414 - val_loss: 1.6360 - val_accuracy: 0.1818 - lr: 2.5000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6180 - accuracy: 0.2644 - val_loss: 1.6360 - val_accuracy: 0.1818 - lr: 2.5000e-05 - 76ms/epoch - 4ms/step\n",
      "Node 18 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6613 - accuracy: 0.1801 - val_loss: 1.6601 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 3s/epoch - 305ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6598 - accuracy: 0.1839 - val_loss: 1.6597 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6593 - accuracy: 0.2222 - val_loss: 1.6593 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6585 - accuracy: 0.1762 - val_loss: 1.6589 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6558 - accuracy: 0.2299 - val_loss: 1.6586 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6585 - accuracy: 0.1648 - val_loss: 1.6582 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6565 - accuracy: 0.1916 - val_loss: 1.6578 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6575 - accuracy: 0.2069 - val_loss: 1.6574 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6575 - accuracy: 0.2184 - val_loss: 1.6569 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6559 - accuracy: 0.1954 - val_loss: 1.6566 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6556 - accuracy: 0.2299 - val_loss: 1.6562 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 68ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6555 - accuracy: 0.2069 - val_loss: 1.6558 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6552 - accuracy: 0.2337 - val_loss: 1.6554 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6558 - accuracy: 0.1916 - val_loss: 1.6551 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6540 - accuracy: 0.1686 - val_loss: 1.6549 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6532 - accuracy: 0.2222 - val_loss: 1.6546 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6528 - accuracy: 0.1954 - val_loss: 1.6543 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6525 - accuracy: 0.2452 - val_loss: 1.6540 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6524 - accuracy: 0.2261 - val_loss: 1.6537 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6525 - accuracy: 0.2031 - val_loss: 1.6534 - val_accuracy: 0.1515 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6515 - accuracy: 0.2146 - val_loss: 1.6531 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6511 - accuracy: 0.2107 - val_loss: 1.6528 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6513 - accuracy: 0.2261 - val_loss: 1.6525 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6529 - accuracy: 0.1992 - val_loss: 1.6522 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6482 - accuracy: 0.2529 - val_loss: 1.6520 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6499 - accuracy: 0.2452 - val_loss: 1.6517 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6489 - accuracy: 0.2567 - val_loss: 1.6513 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6489 - accuracy: 0.2222 - val_loss: 1.6510 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6483 - accuracy: 0.2261 - val_loss: 1.6507 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6487 - accuracy: 0.2567 - val_loss: 1.6504 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6470 - accuracy: 0.2529 - val_loss: 1.6501 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6472 - accuracy: 0.2222 - val_loss: 1.6498 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6466 - accuracy: 0.2375 - val_loss: 1.6495 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6467 - accuracy: 0.2605 - val_loss: 1.6491 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6472 - accuracy: 0.1954 - val_loss: 1.6488 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6467 - accuracy: 0.2414 - val_loss: 1.6485 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6459 - accuracy: 0.2375 - val_loss: 1.6482 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6456 - accuracy: 0.2069 - val_loss: 1.6480 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6445 - accuracy: 0.2184 - val_loss: 1.6478 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6449 - accuracy: 0.2337 - val_loss: 1.6476 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6448 - accuracy: 0.2222 - val_loss: 1.6474 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6445 - accuracy: 0.2720 - val_loss: 1.6472 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6430 - accuracy: 0.2069 - val_loss: 1.6470 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6435 - accuracy: 0.2375 - val_loss: 1.6467 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6434 - accuracy: 0.2529 - val_loss: 1.6464 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6430 - accuracy: 0.2567 - val_loss: 1.6462 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6404 - accuracy: 0.2912 - val_loss: 1.6459 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6436 - accuracy: 0.2146 - val_loss: 1.6457 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6414 - accuracy: 0.2184 - val_loss: 1.6455 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6412 - accuracy: 0.2644 - val_loss: 1.6452 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6405 - accuracy: 0.2644 - val_loss: 1.6449 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6396 - accuracy: 0.2490 - val_loss: 1.6447 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6410 - accuracy: 0.2299 - val_loss: 1.6444 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6390 - accuracy: 0.2452 - val_loss: 1.6442 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6385 - accuracy: 0.2989 - val_loss: 1.6441 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6389 - accuracy: 0.2069 - val_loss: 1.6439 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6371 - accuracy: 0.2835 - val_loss: 1.6436 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6391 - accuracy: 0.2490 - val_loss: 1.6434 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2874 - val_loss: 1.6433 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6374 - accuracy: 0.2414 - val_loss: 1.6430 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6382 - accuracy: 0.2184 - val_loss: 1.6428 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 70ms/epoch - 8ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2720 - val_loss: 1.6425 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6363 - accuracy: 0.2490 - val_loss: 1.6422 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6375 - accuracy: 0.2184 - val_loss: 1.6420 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6377 - accuracy: 0.2337 - val_loss: 1.6417 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6366 - accuracy: 0.2375 - val_loss: 1.6415 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6356 - accuracy: 0.2184 - val_loss: 1.6412 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 46ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6353 - accuracy: 0.2184 - val_loss: 1.6409 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6353 - accuracy: 0.2490 - val_loss: 1.6407 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6332 - accuracy: 0.2605 - val_loss: 1.6405 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6342 - accuracy: 0.2759 - val_loss: 1.6404 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6352 - accuracy: 0.2682 - val_loss: 1.6402 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6363 - accuracy: 0.2299 - val_loss: 1.6401 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6329 - accuracy: 0.2682 - val_loss: 1.6398 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6329 - accuracy: 0.2337 - val_loss: 1.6396 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.2605 - val_loss: 1.6394 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6338 - accuracy: 0.2452 - val_loss: 1.6392 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2567 - val_loss: 1.6391 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6323 - accuracy: 0.2414 - val_loss: 1.6390 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2414 - val_loss: 1.6389 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6309 - accuracy: 0.2452 - val_loss: 1.6388 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2452 - val_loss: 1.6388 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2529 - val_loss: 1.6387 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2452 - val_loss: 1.6387 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2337 - val_loss: 1.6385 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2720 - val_loss: 1.6384 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6314 - accuracy: 0.2567 - val_loss: 1.6382 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6310 - accuracy: 0.2490 - val_loss: 1.6381 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6313 - accuracy: 0.2375 - val_loss: 1.6379 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2490 - val_loss: 1.6378 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2529 - val_loss: 1.6377 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2375 - val_loss: 1.6376 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6286 - accuracy: 0.2529 - val_loss: 1.6376 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2567 - val_loss: 1.6374 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2567 - val_loss: 1.6373 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.2605 - val_loss: 1.6372 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2490 - val_loss: 1.6371 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2835 - val_loss: 1.6370 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6264 - accuracy: 0.2567 - val_loss: 1.6369 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2414 - val_loss: 1.6367 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Node 18 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 18 - Best Validation Accuracy: 0.2879\n",
      "Best model saved for Node 18 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_18.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_19_dataset.csv\n",
      "Node 19 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6373 - accuracy: 0.1885 - val_loss: 1.6374 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 3s/epoch - 157ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6352 - accuracy: 0.2213 - val_loss: 1.6365 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6352 - accuracy: 0.2623 - val_loss: 1.6356 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2090 - val_loss: 1.6348 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2418 - val_loss: 1.6340 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6338 - accuracy: 0.2295 - val_loss: 1.6335 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2377 - val_loss: 1.6331 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2254 - val_loss: 1.6324 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2336 - val_loss: 1.6318 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2705 - val_loss: 1.6311 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2582 - val_loss: 1.6305 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2664 - val_loss: 1.6300 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2336 - val_loss: 1.6294 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2254 - val_loss: 1.6290 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2541 - val_loss: 1.6283 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2664 - val_loss: 1.6277 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6293 - accuracy: 0.2500 - val_loss: 1.6273 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2377 - val_loss: 1.6268 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2500 - val_loss: 1.6262 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2582 - val_loss: 1.6257 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2418 - val_loss: 1.6256 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6258 - accuracy: 0.2582 - val_loss: 1.6250 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2541 - val_loss: 1.6245 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2746 - val_loss: 1.6241 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2418 - val_loss: 1.6237 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2582 - val_loss: 1.6232 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6228 - accuracy: 0.2664 - val_loss: 1.6227 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2418 - val_loss: 1.6223 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2582 - val_loss: 1.6220 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2828 - val_loss: 1.6216 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2377 - val_loss: 1.6213 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2623 - val_loss: 1.6209 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2992 - val_loss: 1.6204 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6179 - accuracy: 0.2623 - val_loss: 1.6198 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6195 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2869 - val_loss: 1.6193 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2705 - val_loss: 1.6191 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2500 - val_loss: 1.6186 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2787 - val_loss: 1.6181 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2336 - val_loss: 1.6179 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2705 - val_loss: 1.6178 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6138 - accuracy: 0.2910 - val_loss: 1.6172 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2500 - val_loss: 1.6167 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2377 - val_loss: 1.6165 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6148 - accuracy: 0.2623 - val_loss: 1.6161 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2787 - val_loss: 1.6155 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2582 - val_loss: 1.6151 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2459 - val_loss: 1.6148 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2664 - val_loss: 1.6144 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2541 - val_loss: 1.6139 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2459 - val_loss: 1.6138 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2705 - val_loss: 1.6137 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2582 - val_loss: 1.6133 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.2418 - val_loss: 1.6130 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2500 - val_loss: 1.6126 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2787 - val_loss: 1.6124 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6122 - accuracy: 0.2500 - val_loss: 1.6124 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6119 - accuracy: 0.2541 - val_loss: 1.6121 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6064 - accuracy: 0.2951 - val_loss: 1.6119 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2910 - val_loss: 1.6114 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2705 - val_loss: 1.6110 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6100 - accuracy: 0.2746 - val_loss: 1.6106 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6112 - accuracy: 0.2828 - val_loss: 1.6106 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2787 - val_loss: 1.6108 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6082 - accuracy: 0.2828 - val_loss: 1.6105 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6067 - accuracy: 0.2787 - val_loss: 1.6105 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6085 - accuracy: 0.2869 - val_loss: 1.6103 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6049 - accuracy: 0.3115 - val_loss: 1.6102 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6100 - accuracy: 0.2582 - val_loss: 1.6100 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6013 - accuracy: 0.2705 - val_loss: 1.6099 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2254 - val_loss: 1.6098 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2623 - val_loss: 1.6097 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6070 - accuracy: 0.2787 - val_loss: 1.6096 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6049 - accuracy: 0.2787 - val_loss: 1.6095 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6095 - accuracy: 0.2582 - val_loss: 1.6093 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2828 - val_loss: 1.6093 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6076 - accuracy: 0.2541 - val_loss: 1.6092 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6038 - accuracy: 0.2787 - val_loss: 1.6089 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6064 - accuracy: 0.2705 - val_loss: 1.6088 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.5995 - accuracy: 0.2787 - val_loss: 1.6086 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6055 - accuracy: 0.2828 - val_loss: 1.6084 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6048 - accuracy: 0.2541 - val_loss: 1.6082 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6033 - accuracy: 0.2746 - val_loss: 1.6081 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6021 - accuracy: 0.2869 - val_loss: 1.6078 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6055 - accuracy: 0.2869 - val_loss: 1.6076 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6065 - accuracy: 0.2869 - val_loss: 1.6074 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6038 - accuracy: 0.2664 - val_loss: 1.6074 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2705 - val_loss: 1.6074 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6075 - accuracy: 0.2623 - val_loss: 1.6075 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6039 - accuracy: 0.2746 - val_loss: 1.6075 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6077 - accuracy: 0.2582 - val_loss: 1.6075 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6027 - accuracy: 0.2582 - val_loss: 1.6074 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6028 - accuracy: 0.2951 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6010 - accuracy: 0.2582 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6051 - accuracy: 0.2541 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6043 - accuracy: 0.2828 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6065 - accuracy: 0.2828 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6056 - accuracy: 0.2623 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6042 - accuracy: 0.2869 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6058 - accuracy: 0.2746 - val_loss: 1.6073 - val_accuracy: 0.2623 - lr: 3.1250e-06 - 47ms/epoch - 3ms/step\n",
      "Node 19 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6353 - accuracy: 0.1557 - val_loss: 1.6350 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 3s/epoch - 359ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.1680 - val_loss: 1.6340 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2254 - val_loss: 1.6332 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2377 - val_loss: 1.6323 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2377 - val_loss: 1.6315 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2500 - val_loss: 1.6308 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2377 - val_loss: 1.6301 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2377 - val_loss: 1.6294 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2377 - val_loss: 1.6288 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2500 - val_loss: 1.6282 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2418 - val_loss: 1.6277 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2418 - val_loss: 1.6271 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2541 - val_loss: 1.6266 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2541 - val_loss: 1.6260 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2500 - val_loss: 1.6254 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2705 - val_loss: 1.6249 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2500 - val_loss: 1.6243 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2418 - val_loss: 1.6237 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2582 - val_loss: 1.6232 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2459 - val_loss: 1.6229 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2500 - val_loss: 1.6224 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2705 - val_loss: 1.6219 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2500 - val_loss: 1.6213 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2664 - val_loss: 1.6208 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2459 - val_loss: 1.6203 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2623 - val_loss: 1.6198 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2582 - val_loss: 1.6194 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2664 - val_loss: 1.6188 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2541 - val_loss: 1.6182 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2664 - val_loss: 1.6175 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2623 - val_loss: 1.6170 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2664 - val_loss: 1.6166 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2541 - val_loss: 1.6163 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2582 - val_loss: 1.6157 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2582 - val_loss: 1.6152 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2500 - val_loss: 1.6150 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2500 - val_loss: 1.6146 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2705 - val_loss: 1.6143 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2541 - val_loss: 1.6139 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2582 - val_loss: 1.6136 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2582 - val_loss: 1.6132 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2541 - val_loss: 1.6128 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2541 - val_loss: 1.6124 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2664 - val_loss: 1.6121 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2582 - val_loss: 1.6117 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2582 - val_loss: 1.6114 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2541 - val_loss: 1.6111 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2664 - val_loss: 1.6106 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2623 - val_loss: 1.6103 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2582 - val_loss: 1.6099 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2623 - val_loss: 1.6095 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2582 - val_loss: 1.6091 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6116 - accuracy: 0.2582 - val_loss: 1.6087 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2541 - val_loss: 1.6085 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2541 - val_loss: 1.6082 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2541 - val_loss: 1.6080 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2623 - val_loss: 1.6079 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2623 - val_loss: 1.6077 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6136 - accuracy: 0.2500 - val_loss: 1.6075 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2459 - val_loss: 1.6072 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.2582 - val_loss: 1.6069 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6061 - accuracy: 0.2623 - val_loss: 1.6066 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2541 - val_loss: 1.6062 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6090 - accuracy: 0.2541 - val_loss: 1.6058 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.2623 - val_loss: 1.6055 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6059 - accuracy: 0.2582 - val_loss: 1.6050 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6106 - accuracy: 0.2623 - val_loss: 1.6046 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6097 - accuracy: 0.2582 - val_loss: 1.6044 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6067 - accuracy: 0.2582 - val_loss: 1.6041 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6057 - accuracy: 0.2582 - val_loss: 1.6037 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6065 - accuracy: 0.2582 - val_loss: 1.6033 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6098 - accuracy: 0.2582 - val_loss: 1.6030 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6124 - accuracy: 0.2582 - val_loss: 1.6029 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6069 - accuracy: 0.2582 - val_loss: 1.6026 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.5987 - accuracy: 0.2582 - val_loss: 1.6024 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2623 - val_loss: 1.6021 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6071 - accuracy: 0.2623 - val_loss: 1.6017 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2623 - val_loss: 1.6014 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6085 - accuracy: 0.2500 - val_loss: 1.6012 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6056 - accuracy: 0.2500 - val_loss: 1.6009 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6077 - accuracy: 0.2623 - val_loss: 1.6006 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2582 - val_loss: 1.6005 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6065 - accuracy: 0.2623 - val_loss: 1.6002 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6045 - accuracy: 0.2664 - val_loss: 1.6000 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6028 - accuracy: 0.2623 - val_loss: 1.5997 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6018 - accuracy: 0.2582 - val_loss: 1.5994 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6103 - accuracy: 0.2500 - val_loss: 1.5993 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6110 - accuracy: 0.2500 - val_loss: 1.5993 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6018 - accuracy: 0.2582 - val_loss: 1.5991 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6078 - accuracy: 0.2623 - val_loss: 1.5990 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6087 - accuracy: 0.2541 - val_loss: 1.5989 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6060 - accuracy: 0.2418 - val_loss: 1.5987 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6004 - accuracy: 0.2705 - val_loss: 1.5985 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6006 - accuracy: 0.2500 - val_loss: 1.5982 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6131 - accuracy: 0.2664 - val_loss: 1.5981 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6029 - accuracy: 0.2623 - val_loss: 1.5980 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6045 - accuracy: 0.2664 - val_loss: 1.5979 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6043 - accuracy: 0.2459 - val_loss: 1.5978 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6047 - accuracy: 0.2623 - val_loss: 1.5977 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6066 - accuracy: 0.2623 - val_loss: 1.5976 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Node 19 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6625 - accuracy: 0.1926 - val_loss: 1.6602 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 3s/epoch - 157ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6596 - accuracy: 0.2336 - val_loss: 1.6582 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6576 - accuracy: 0.2254 - val_loss: 1.6562 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6565 - accuracy: 0.2459 - val_loss: 1.6545 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6553 - accuracy: 0.2623 - val_loss: 1.6529 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6515 - accuracy: 0.3033 - val_loss: 1.6514 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6500 - accuracy: 0.2582 - val_loss: 1.6497 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6473 - accuracy: 0.2746 - val_loss: 1.6479 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6474 - accuracy: 0.2377 - val_loss: 1.6462 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6463 - accuracy: 0.2787 - val_loss: 1.6446 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6399 - accuracy: 0.2869 - val_loss: 1.6433 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6493 - accuracy: 0.2336 - val_loss: 1.6422 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6411 - accuracy: 0.2623 - val_loss: 1.6410 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6421 - accuracy: 0.2746 - val_loss: 1.6400 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6432 - accuracy: 0.2254 - val_loss: 1.6388 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6442 - accuracy: 0.2582 - val_loss: 1.6374 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6378 - accuracy: 0.3033 - val_loss: 1.6366 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6365 - accuracy: 0.2623 - val_loss: 1.6352 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2582 - val_loss: 1.6339 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2992 - val_loss: 1.6329 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.2951 - val_loss: 1.6318 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6348 - accuracy: 0.2336 - val_loss: 1.6311 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6313 - accuracy: 0.2336 - val_loss: 1.6307 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2787 - val_loss: 1.6298 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.3115 - val_loss: 1.6290 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2828 - val_loss: 1.6278 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2828 - val_loss: 1.6272 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.3156 - val_loss: 1.6264 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2869 - val_loss: 1.6255 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2090 - val_loss: 1.6246 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2746 - val_loss: 1.6241 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2623 - val_loss: 1.6231 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2623 - val_loss: 1.6225 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2664 - val_loss: 1.6220 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.3074 - val_loss: 1.6222 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6184 - accuracy: 0.2664 - val_loss: 1.6219 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2377 - val_loss: 1.6214 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2541 - val_loss: 1.6213 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2869 - val_loss: 1.6212 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2992 - val_loss: 1.6209 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6155 - accuracy: 0.3074 - val_loss: 1.6204 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.3238 - val_loss: 1.6199 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2869 - val_loss: 1.6197 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2992 - val_loss: 1.6191 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6137 - accuracy: 0.2500 - val_loss: 1.6190 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2623 - val_loss: 1.6187 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2664 - val_loss: 1.6187 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2664 - val_loss: 1.6184 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2828 - val_loss: 1.6180 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 89ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6019 - accuracy: 0.2746 - val_loss: 1.6174 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6103 - accuracy: 0.2746 - val_loss: 1.6168 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2787 - val_loss: 1.6167 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6042 - accuracy: 0.2541 - val_loss: 1.6164 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2910 - val_loss: 1.6159 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2910 - val_loss: 1.6157 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6106 - accuracy: 0.2992 - val_loss: 1.6156 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6010 - accuracy: 0.2992 - val_loss: 1.6153 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2664 - val_loss: 1.6154 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2828 - val_loss: 1.6156 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6010 - accuracy: 0.2869 - val_loss: 1.6152 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.5997 - accuracy: 0.2910 - val_loss: 1.6143 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6027 - accuracy: 0.2746 - val_loss: 1.6143 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6084 - accuracy: 0.2828 - val_loss: 1.6145 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6092 - accuracy: 0.2418 - val_loss: 1.6147 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6006 - accuracy: 0.2623 - val_loss: 1.6146 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.5998 - accuracy: 0.2500 - val_loss: 1.6144 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6055 - accuracy: 0.2787 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.5950 - accuracy: 0.2869 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6093 - accuracy: 0.2500 - val_loss: 1.6143 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6000 - accuracy: 0.3115 - val_loss: 1.6143 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6030 - accuracy: 0.2787 - val_loss: 1.6143 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.5995 - accuracy: 0.2951 - val_loss: 1.6143 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.5980 - accuracy: 0.2910 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.5982 - accuracy: 0.2582 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.5985 - accuracy: 0.2910 - val_loss: 1.6141 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.5975 - accuracy: 0.2910 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6008 - accuracy: 0.3156 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.5988 - accuracy: 0.3156 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 69ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.5956 - accuracy: 0.2869 - val_loss: 1.6141 - val_accuracy: 0.2623 - lr: 6.2500e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6029 - accuracy: 0.2951 - val_loss: 1.6141 - val_accuracy: 0.2623 - lr: 3.1250e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.5998 - accuracy: 0.2705 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 3.1250e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6098 - accuracy: 0.2418 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 3.1250e-06 - 68ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.3033 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.5625e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6050 - accuracy: 0.2828 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.5625e-06 - 68ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6037 - accuracy: 0.2951 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 1.5625e-06 - 71ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6025 - accuracy: 0.2787 - val_loss: 1.6142 - val_accuracy: 0.2623 - lr: 7.8125e-07 - 70ms/epoch - 4ms/step\n",
      "Node 19 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6599 - accuracy: 0.1926 - val_loss: 1.6592 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 3s/epoch - 359ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6586 - accuracy: 0.2213 - val_loss: 1.6581 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.2295 - val_loss: 1.6571 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.2418 - val_loss: 1.6561 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.2172 - val_loss: 1.6550 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6567 - accuracy: 0.2131 - val_loss: 1.6540 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6546 - accuracy: 0.2418 - val_loss: 1.6532 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2459 - val_loss: 1.6523 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6516 - accuracy: 0.2459 - val_loss: 1.6514 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6496 - accuracy: 0.2377 - val_loss: 1.6505 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6496 - accuracy: 0.2623 - val_loss: 1.6494 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2705 - val_loss: 1.6485 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6471 - accuracy: 0.2254 - val_loss: 1.6475 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2664 - val_loss: 1.6464 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6471 - accuracy: 0.2254 - val_loss: 1.6455 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2377 - val_loss: 1.6445 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2787 - val_loss: 1.6435 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2500 - val_loss: 1.6427 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2582 - val_loss: 1.6416 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2623 - val_loss: 1.6406 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2418 - val_loss: 1.6398 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2623 - val_loss: 1.6388 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2254 - val_loss: 1.6380 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6396 - accuracy: 0.2951 - val_loss: 1.6372 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2295 - val_loss: 1.6363 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2418 - val_loss: 1.6356 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2746 - val_loss: 1.6349 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2746 - val_loss: 1.6340 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2582 - val_loss: 1.6331 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2418 - val_loss: 1.6323 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2295 - val_loss: 1.6316 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2582 - val_loss: 1.6308 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2910 - val_loss: 1.6300 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2787 - val_loss: 1.6291 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2254 - val_loss: 1.6284 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2910 - val_loss: 1.6275 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2828 - val_loss: 1.6270 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2213 - val_loss: 1.6262 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2828 - val_loss: 1.6255 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2418 - val_loss: 1.6250 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2869 - val_loss: 1.6245 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2828 - val_loss: 1.6239 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2746 - val_loss: 1.6233 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2746 - val_loss: 1.6228 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2705 - val_loss: 1.6222 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2992 - val_loss: 1.6216 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2254 - val_loss: 1.6211 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2705 - val_loss: 1.6206 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.3033 - val_loss: 1.6201 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2746 - val_loss: 1.6196 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2664 - val_loss: 1.6194 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2705 - val_loss: 1.6188 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2787 - val_loss: 1.6184 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2541 - val_loss: 1.6180 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2418 - val_loss: 1.6177 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2746 - val_loss: 1.6174 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6154 - accuracy: 0.2869 - val_loss: 1.6167 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2869 - val_loss: 1.6163 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6158 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2828 - val_loss: 1.6155 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2664 - val_loss: 1.6150 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.3033 - val_loss: 1.6147 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2746 - val_loss: 1.6144 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2500 - val_loss: 1.6141 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6111 - accuracy: 0.2828 - val_loss: 1.6140 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2582 - val_loss: 1.6138 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2869 - val_loss: 1.6134 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.2418 - val_loss: 1.6132 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6092 - accuracy: 0.2336 - val_loss: 1.6132 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.2623 - val_loss: 1.6131 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6092 - accuracy: 0.2787 - val_loss: 1.6128 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.2541 - val_loss: 1.6127 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.2582 - val_loss: 1.6126 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6149 - accuracy: 0.2336 - val_loss: 1.6124 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2418 - val_loss: 1.6124 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6061 - accuracy: 0.2664 - val_loss: 1.6122 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2541 - val_loss: 1.6120 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6029 - accuracy: 0.2828 - val_loss: 1.6116 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6061 - accuracy: 0.2746 - val_loss: 1.6113 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2377 - val_loss: 1.6110 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2582 - val_loss: 1.6111 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6104 - accuracy: 0.2664 - val_loss: 1.6108 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6040 - accuracy: 0.2869 - val_loss: 1.6105 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2787 - val_loss: 1.6101 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6012 - accuracy: 0.2869 - val_loss: 1.6097 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6029 - accuracy: 0.2910 - val_loss: 1.6094 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6016 - accuracy: 0.2787 - val_loss: 1.6092 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6065 - accuracy: 0.2992 - val_loss: 1.6091 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6038 - accuracy: 0.2746 - val_loss: 1.6088 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.5989 - accuracy: 0.2951 - val_loss: 1.6084 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6085 - accuracy: 0.2541 - val_loss: 1.6082 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6072 - accuracy: 0.2582 - val_loss: 1.6078 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6048 - accuracy: 0.2746 - val_loss: 1.6076 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6098 - accuracy: 0.2869 - val_loss: 1.6077 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6016 - accuracy: 0.2992 - val_loss: 1.6076 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2746 - val_loss: 1.6076 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6090 - accuracy: 0.2295 - val_loss: 1.6076 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6056 - accuracy: 0.2541 - val_loss: 1.6076 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2541 - val_loss: 1.6077 - val_accuracy: 0.2623 - lr: 5.0000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6075 - accuracy: 0.2951 - val_loss: 1.6077 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Node 19 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 19 - Best Validation Accuracy: 0.3115\n",
      "Best model saved for Node 19 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_19.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_20_dataset.csv\n",
      "Node 20 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6342 - accuracy: 0.2241 - val_loss: 1.6334 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 2s/epoch - 164ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2284 - val_loss: 1.6332 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2457 - val_loss: 1.6328 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6331 - accuracy: 0.2284 - val_loss: 1.6325 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6324 - accuracy: 0.2026 - val_loss: 1.6322 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2371 - val_loss: 1.6318 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2284 - val_loss: 1.6314 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2198 - val_loss: 1.6311 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2198 - val_loss: 1.6307 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2328 - val_loss: 1.6304 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2457 - val_loss: 1.6301 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2543 - val_loss: 1.6297 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2457 - val_loss: 1.6294 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2586 - val_loss: 1.6291 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2112 - val_loss: 1.6286 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2284 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2328 - val_loss: 1.6277 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2586 - val_loss: 1.6275 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6273 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2586 - val_loss: 1.6268 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2112 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.1983 - val_loss: 1.6262 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2155 - val_loss: 1.6260 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2586 - val_loss: 1.6258 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2026 - val_loss: 1.6254 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2284 - val_loss: 1.6252 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6251 - accuracy: 0.2241 - val_loss: 1.6249 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2241 - val_loss: 1.6246 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2328 - val_loss: 1.6243 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2414 - val_loss: 1.6241 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2284 - val_loss: 1.6239 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2069 - val_loss: 1.6236 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2328 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2198 - val_loss: 1.6230 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2500 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2500 - val_loss: 1.6225 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2414 - val_loss: 1.6224 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2629 - val_loss: 1.6223 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2284 - val_loss: 1.6220 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2672 - val_loss: 1.6218 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2284 - val_loss: 1.6216 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2241 - val_loss: 1.6212 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.1940 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2198 - val_loss: 1.6209 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2112 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2414 - val_loss: 1.6205 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2586 - val_loss: 1.6204 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2241 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2500 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2328 - val_loss: 1.6199 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2155 - val_loss: 1.6197 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2500 - val_loss: 1.6196 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2629 - val_loss: 1.6195 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2155 - val_loss: 1.6194 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2371 - val_loss: 1.6193 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2629 - val_loss: 1.6191 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2284 - val_loss: 1.6189 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2500 - val_loss: 1.6187 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2198 - val_loss: 1.6185 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2026 - val_loss: 1.6184 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2371 - val_loss: 1.6182 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2672 - val_loss: 1.6181 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2155 - val_loss: 1.6179 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6114 - accuracy: 0.2198 - val_loss: 1.6177 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.2457 - val_loss: 1.6176 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2457 - val_loss: 1.6176 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2457 - val_loss: 1.6174 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2371 - val_loss: 1.6173 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2457 - val_loss: 1.6172 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2457 - val_loss: 1.6170 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2586 - val_loss: 1.6169 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2371 - val_loss: 1.6168 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6106 - accuracy: 0.2888 - val_loss: 1.6166 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2457 - val_loss: 1.6165 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.1940 - val_loss: 1.6165 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.2457 - val_loss: 1.6164 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2328 - val_loss: 1.6163 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2371 - val_loss: 1.6161 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2543 - val_loss: 1.6161 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6140 - accuracy: 0.2500 - val_loss: 1.6159 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6131 - accuracy: 0.2457 - val_loss: 1.6158 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6070 - accuracy: 0.2543 - val_loss: 1.6157 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6098 - accuracy: 0.2371 - val_loss: 1.6154 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2328 - val_loss: 1.6153 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2198 - val_loss: 1.6152 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6070 - accuracy: 0.2586 - val_loss: 1.6151 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2328 - val_loss: 1.6148 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2543 - val_loss: 1.6146 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2284 - val_loss: 1.6146 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6087 - accuracy: 0.2414 - val_loss: 1.6144 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6074 - accuracy: 0.2586 - val_loss: 1.6142 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2500 - val_loss: 1.6141 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2198 - val_loss: 1.6140 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2457 - val_loss: 1.6139 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6033 - accuracy: 0.2759 - val_loss: 1.6138 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2716 - val_loss: 1.6136 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2586 - val_loss: 1.6135 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2371 - val_loss: 1.6135 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6050 - accuracy: 0.2543 - val_loss: 1.6134 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6088 - accuracy: 0.2500 - val_loss: 1.6133 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Node 20 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6353 - accuracy: 0.2069 - val_loss: 1.6354 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 3s/epoch - 364ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.1853 - val_loss: 1.6352 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2069 - val_loss: 1.6350 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2112 - val_loss: 1.6348 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.1940 - val_loss: 1.6345 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.1940 - val_loss: 1.6343 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2284 - val_loss: 1.6341 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2500 - val_loss: 1.6340 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2112 - val_loss: 1.6338 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2112 - val_loss: 1.6335 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2241 - val_loss: 1.6333 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2284 - val_loss: 1.6330 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2328 - val_loss: 1.6327 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.1983 - val_loss: 1.6325 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2500 - val_loss: 1.6323 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2112 - val_loss: 1.6321 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2069 - val_loss: 1.6317 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2457 - val_loss: 1.6314 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2155 - val_loss: 1.6311 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2284 - val_loss: 1.6307 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2328 - val_loss: 1.6304 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2069 - val_loss: 1.6301 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2371 - val_loss: 1.6298 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2069 - val_loss: 1.6297 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2241 - val_loss: 1.6294 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2543 - val_loss: 1.6292 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2500 - val_loss: 1.6290 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2026 - val_loss: 1.6288 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2371 - val_loss: 1.6286 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2284 - val_loss: 1.6283 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2457 - val_loss: 1.6282 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2457 - val_loss: 1.6280 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2155 - val_loss: 1.6277 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2026 - val_loss: 1.6274 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2198 - val_loss: 1.6271 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.1681 - val_loss: 1.6269 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2586 - val_loss: 1.6267 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2241 - val_loss: 1.6265 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2112 - val_loss: 1.6262 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2198 - val_loss: 1.6259 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2198 - val_loss: 1.6256 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6253 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2457 - val_loss: 1.6251 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2414 - val_loss: 1.6249 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2371 - val_loss: 1.6248 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2586 - val_loss: 1.6246 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2500 - val_loss: 1.6244 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2112 - val_loss: 1.6242 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2543 - val_loss: 1.6241 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2112 - val_loss: 1.6239 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2155 - val_loss: 1.6238 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2414 - val_loss: 1.6236 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2112 - val_loss: 1.6233 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.1983 - val_loss: 1.6232 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2198 - val_loss: 1.6230 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2284 - val_loss: 1.6229 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2500 - val_loss: 1.6227 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2026 - val_loss: 1.6225 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2371 - val_loss: 1.6223 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2198 - val_loss: 1.6222 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2586 - val_loss: 1.6221 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2414 - val_loss: 1.6219 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2500 - val_loss: 1.6219 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2069 - val_loss: 1.6217 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2371 - val_loss: 1.6216 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2328 - val_loss: 1.6215 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2155 - val_loss: 1.6214 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2155 - val_loss: 1.6213 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2155 - val_loss: 1.6211 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2371 - val_loss: 1.6210 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2026 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2284 - val_loss: 1.6208 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2586 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2241 - val_loss: 1.6206 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2414 - val_loss: 1.6205 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2284 - val_loss: 1.6203 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2069 - val_loss: 1.6202 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2414 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2457 - val_loss: 1.6200 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2155 - val_loss: 1.6199 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2371 - val_loss: 1.6198 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2328 - val_loss: 1.6197 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2241 - val_loss: 1.6196 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2586 - val_loss: 1.6195 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2241 - val_loss: 1.6193 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2888 - val_loss: 1.6191 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2414 - val_loss: 1.6190 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2371 - val_loss: 1.6188 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2155 - val_loss: 1.6186 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2198 - val_loss: 1.6185 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2500 - val_loss: 1.6184 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6116 - accuracy: 0.2845 - val_loss: 1.6183 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2414 - val_loss: 1.6182 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2284 - val_loss: 1.6180 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2155 - val_loss: 1.6179 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2371 - val_loss: 1.6178 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2629 - val_loss: 1.6177 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2241 - val_loss: 1.6176 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2500 - val_loss: 1.6175 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2198 - val_loss: 1.6174 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 20 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6611 - accuracy: 0.2069 - val_loss: 1.6603 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 3s/epoch - 168ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6602 - accuracy: 0.1638 - val_loss: 1.6593 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6586 - accuracy: 0.2198 - val_loss: 1.6585 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6571 - accuracy: 0.2543 - val_loss: 1.6575 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6583 - accuracy: 0.2457 - val_loss: 1.6566 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6564 - accuracy: 0.1810 - val_loss: 1.6557 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6547 - accuracy: 0.2414 - val_loss: 1.6551 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6560 - accuracy: 0.2241 - val_loss: 1.6544 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 88ms/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.2328 - val_loss: 1.6536 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6525 - accuracy: 0.2241 - val_loss: 1.6526 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.2371 - val_loss: 1.6520 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6503 - accuracy: 0.2414 - val_loss: 1.6512 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6500 - accuracy: 0.2284 - val_loss: 1.6506 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6497 - accuracy: 0.2328 - val_loss: 1.6499 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2198 - val_loss: 1.6491 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6465 - accuracy: 0.2328 - val_loss: 1.6484 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6466 - accuracy: 0.2414 - val_loss: 1.6476 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6466 - accuracy: 0.2284 - val_loss: 1.6467 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6448 - accuracy: 0.2371 - val_loss: 1.6461 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6444 - accuracy: 0.2414 - val_loss: 1.6452 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6455 - accuracy: 0.2241 - val_loss: 1.6447 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6411 - accuracy: 0.2328 - val_loss: 1.6440 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2284 - val_loss: 1.6434 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6425 - accuracy: 0.2371 - val_loss: 1.6427 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6415 - accuracy: 0.2500 - val_loss: 1.6421 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6387 - accuracy: 0.2371 - val_loss: 1.6415 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6405 - accuracy: 0.2371 - val_loss: 1.6409 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6379 - accuracy: 0.2284 - val_loss: 1.6402 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6390 - accuracy: 0.2328 - val_loss: 1.6397 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.2371 - val_loss: 1.6390 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.2371 - val_loss: 1.6383 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6366 - accuracy: 0.2284 - val_loss: 1.6377 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2371 - val_loss: 1.6371 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6387 - accuracy: 0.2284 - val_loss: 1.6368 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2328 - val_loss: 1.6362 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.2500 - val_loss: 1.6358 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2371 - val_loss: 1.6355 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2414 - val_loss: 1.6351 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.2284 - val_loss: 1.6348 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2328 - val_loss: 1.6344 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2457 - val_loss: 1.6340 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2414 - val_loss: 1.6335 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2284 - val_loss: 1.6329 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2500 - val_loss: 1.6325 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2198 - val_loss: 1.6320 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2371 - val_loss: 1.6316 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2414 - val_loss: 1.6314 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2586 - val_loss: 1.6311 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2284 - val_loss: 1.6307 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2284 - val_loss: 1.6303 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2371 - val_loss: 1.6299 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2328 - val_loss: 1.6297 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2586 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2371 - val_loss: 1.6289 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2543 - val_loss: 1.6286 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2457 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 84ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2500 - val_loss: 1.6279 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2198 - val_loss: 1.6274 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2457 - val_loss: 1.6270 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2586 - val_loss: 1.6268 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2500 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2586 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2845 - val_loss: 1.6262 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6137 - accuracy: 0.2328 - val_loss: 1.6261 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2241 - val_loss: 1.6259 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2543 - val_loss: 1.6256 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2672 - val_loss: 1.6254 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2241 - val_loss: 1.6249 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2328 - val_loss: 1.6246 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2500 - val_loss: 1.6243 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6095 - accuracy: 0.2328 - val_loss: 1.6240 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2284 - val_loss: 1.6238 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6140 - accuracy: 0.2672 - val_loss: 1.6237 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6152 - accuracy: 0.2500 - val_loss: 1.6235 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6095 - accuracy: 0.2629 - val_loss: 1.6232 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6089 - accuracy: 0.2543 - val_loss: 1.6228 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2328 - val_loss: 1.6227 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.2888 - val_loss: 1.6228 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2629 - val_loss: 1.6225 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2328 - val_loss: 1.6222 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6078 - accuracy: 0.2543 - val_loss: 1.6221 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6118 - accuracy: 0.2284 - val_loss: 1.6218 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2586 - val_loss: 1.6217 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6046 - accuracy: 0.2845 - val_loss: 1.6220 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6078 - accuracy: 0.2543 - val_loss: 1.6217 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6014 - accuracy: 0.2629 - val_loss: 1.6216 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2586 - val_loss: 1.6213 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.5952 - accuracy: 0.2716 - val_loss: 1.6213 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6083 - accuracy: 0.2888 - val_loss: 1.6214 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6028 - accuracy: 0.2241 - val_loss: 1.6212 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6012 - accuracy: 0.2845 - val_loss: 1.6210 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6016 - accuracy: 0.2759 - val_loss: 1.6207 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6025 - accuracy: 0.2457 - val_loss: 1.6203 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.5940 - accuracy: 0.2931 - val_loss: 1.6203 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5963 - accuracy: 0.2629 - val_loss: 1.6203 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.2586 - val_loss: 1.6203 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2457 - val_loss: 1.6199 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.5869 - accuracy: 0.2931 - val_loss: 1.6199 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6015 - accuracy: 0.2759 - val_loss: 1.6198 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5925 - accuracy: 0.3060 - val_loss: 1.6197 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Node 20 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6592 - accuracy: 0.2069 - val_loss: 1.6591 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 3s/epoch - 357ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6597 - accuracy: 0.2155 - val_loss: 1.6585 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.1767 - val_loss: 1.6577 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6572 - accuracy: 0.2500 - val_loss: 1.6569 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2284 - val_loss: 1.6561 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6558 - accuracy: 0.2328 - val_loss: 1.6554 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6548 - accuracy: 0.2112 - val_loss: 1.6547 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2414 - val_loss: 1.6538 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6534 - accuracy: 0.2586 - val_loss: 1.6532 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6523 - accuracy: 0.2500 - val_loss: 1.6526 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2155 - val_loss: 1.6520 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6542 - accuracy: 0.2026 - val_loss: 1.6514 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6488 - accuracy: 0.2371 - val_loss: 1.6508 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2371 - val_loss: 1.6502 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6509 - accuracy: 0.2543 - val_loss: 1.6498 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2155 - val_loss: 1.6493 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2241 - val_loss: 1.6488 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2026 - val_loss: 1.6484 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2155 - val_loss: 1.6477 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.2457 - val_loss: 1.6472 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2155 - val_loss: 1.6467 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2241 - val_loss: 1.6463 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2672 - val_loss: 1.6458 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2371 - val_loss: 1.6453 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6460 - accuracy: 0.2457 - val_loss: 1.6448 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2198 - val_loss: 1.6443 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2284 - val_loss: 1.6438 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6443 - accuracy: 0.2198 - val_loss: 1.6434 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6409 - accuracy: 0.2543 - val_loss: 1.6429 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.1897 - val_loss: 1.6425 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2284 - val_loss: 1.6420 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6409 - accuracy: 0.2500 - val_loss: 1.6418 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2500 - val_loss: 1.6414 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2500 - val_loss: 1.6410 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2414 - val_loss: 1.6407 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2241 - val_loss: 1.6402 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6380 - accuracy: 0.2543 - val_loss: 1.6398 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6421 - accuracy: 0.2155 - val_loss: 1.6393 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.1940 - val_loss: 1.6389 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.2371 - val_loss: 1.6385 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2198 - val_loss: 1.6382 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2069 - val_loss: 1.6379 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6380 - accuracy: 0.2284 - val_loss: 1.6377 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2198 - val_loss: 1.6374 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2371 - val_loss: 1.6371 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2500 - val_loss: 1.6368 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2371 - val_loss: 1.6366 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2672 - val_loss: 1.6361 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2457 - val_loss: 1.6356 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2414 - val_loss: 1.6353 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2284 - val_loss: 1.6349 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2371 - val_loss: 1.6344 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2414 - val_loss: 1.6341 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2672 - val_loss: 1.6337 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2112 - val_loss: 1.6334 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2543 - val_loss: 1.6333 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2241 - val_loss: 1.6330 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2371 - val_loss: 1.6325 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2371 - val_loss: 1.6322 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2457 - val_loss: 1.6318 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2586 - val_loss: 1.6315 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2328 - val_loss: 1.6312 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2457 - val_loss: 1.6308 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2328 - val_loss: 1.6305 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2198 - val_loss: 1.6303 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2457 - val_loss: 1.6300 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2155 - val_loss: 1.6297 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2241 - val_loss: 1.6295 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2155 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2629 - val_loss: 1.6291 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2586 - val_loss: 1.6289 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2198 - val_loss: 1.6287 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2543 - val_loss: 1.6285 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2500 - val_loss: 1.6281 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2888 - val_loss: 1.6279 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2586 - val_loss: 1.6277 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2241 - val_loss: 1.6275 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2629 - val_loss: 1.6272 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2543 - val_loss: 1.6269 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.1983 - val_loss: 1.6267 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.3017 - val_loss: 1.6263 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2328 - val_loss: 1.6261 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6259 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2586 - val_loss: 1.6257 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2716 - val_loss: 1.6254 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2716 - val_loss: 1.6252 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2371 - val_loss: 1.6250 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2629 - val_loss: 1.6248 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2371 - val_loss: 1.6246 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2629 - val_loss: 1.6243 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2414 - val_loss: 1.6240 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2672 - val_loss: 1.6239 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.2586 - val_loss: 1.6237 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 66ms/epoch - 8ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2586 - val_loss: 1.6235 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2716 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2500 - val_loss: 1.6230 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2328 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2931 - val_loss: 1.6225 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.2586 - val_loss: 1.6223 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6080 - accuracy: 0.2586 - val_loss: 1.6221 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Node 20 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 20 - Best Validation Accuracy: 0.2712\n",
      "Best model saved for Node 20 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_20.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_21_dataset.csv\n",
      "Node 21 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6343 - accuracy: 0.1830 - val_loss: 1.6346 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 3s/epoch - 190ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.1830 - val_loss: 1.6342 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.1617 - val_loss: 1.6336 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2043 - val_loss: 1.6332 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.2511 - val_loss: 1.6329 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6324 - accuracy: 0.2128 - val_loss: 1.6327 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2213 - val_loss: 1.6323 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2511 - val_loss: 1.6321 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.1702 - val_loss: 1.6318 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.2553 - val_loss: 1.6316 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6318 - accuracy: 0.2000 - val_loss: 1.6312 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2213 - val_loss: 1.6309 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2511 - val_loss: 1.6306 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2255 - val_loss: 1.6302 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6285 - accuracy: 0.2170 - val_loss: 1.6299 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.1532 - val_loss: 1.6295 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2851 - val_loss: 1.6290 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2468 - val_loss: 1.6286 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2511 - val_loss: 1.6284 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2255 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2426 - val_loss: 1.6278 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2468 - val_loss: 1.6277 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2340 - val_loss: 1.6275 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2255 - val_loss: 1.6273 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2638 - val_loss: 1.6269 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2213 - val_loss: 1.6266 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2085 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6256 - accuracy: 0.2383 - val_loss: 1.6260 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2681 - val_loss: 1.6256 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2255 - val_loss: 1.6253 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2596 - val_loss: 1.6251 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2468 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.1915 - val_loss: 1.6244 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2553 - val_loss: 1.6240 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2383 - val_loss: 1.6238 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2511 - val_loss: 1.6234 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2298 - val_loss: 1.6232 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2468 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2255 - val_loss: 1.6226 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2426 - val_loss: 1.6223 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2553 - val_loss: 1.6220 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2383 - val_loss: 1.6217 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2213 - val_loss: 1.6214 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2340 - val_loss: 1.6211 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2340 - val_loss: 1.6208 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2170 - val_loss: 1.6204 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2553 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2511 - val_loss: 1.6200 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2511 - val_loss: 1.6199 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2426 - val_loss: 1.6196 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6113 - accuracy: 0.2298 - val_loss: 1.6194 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2596 - val_loss: 1.6192 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.2511 - val_loss: 1.6189 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6116 - accuracy: 0.2468 - val_loss: 1.6188 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2426 - val_loss: 1.6185 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6122 - accuracy: 0.2468 - val_loss: 1.6181 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2426 - val_loss: 1.6180 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2043 - val_loss: 1.6178 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2170 - val_loss: 1.6177 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2596 - val_loss: 1.6176 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2468 - val_loss: 1.6173 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2383 - val_loss: 1.6171 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2383 - val_loss: 1.6169 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6091 - accuracy: 0.2511 - val_loss: 1.6167 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2085 - val_loss: 1.6166 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6106 - accuracy: 0.2681 - val_loss: 1.6163 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2468 - val_loss: 1.6162 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2426 - val_loss: 1.6159 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2638 - val_loss: 1.6158 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2596 - val_loss: 1.6155 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6090 - accuracy: 0.2298 - val_loss: 1.6153 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6047 - accuracy: 0.2298 - val_loss: 1.6151 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2255 - val_loss: 1.6149 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2213 - val_loss: 1.6149 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2213 - val_loss: 1.6149 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2383 - val_loss: 1.6147 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6095 - accuracy: 0.2340 - val_loss: 1.6144 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2511 - val_loss: 1.6143 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6054 - accuracy: 0.2383 - val_loss: 1.6143 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6070 - accuracy: 0.2383 - val_loss: 1.6142 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6074 - accuracy: 0.2511 - val_loss: 1.6140 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6071 - accuracy: 0.2468 - val_loss: 1.6138 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6067 - accuracy: 0.2340 - val_loss: 1.6137 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6038 - accuracy: 0.2553 - val_loss: 1.6134 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6070 - accuracy: 0.2468 - val_loss: 1.6133 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6088 - accuracy: 0.2170 - val_loss: 1.6133 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6040 - accuracy: 0.2383 - val_loss: 1.6130 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2766 - val_loss: 1.6129 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6063 - accuracy: 0.2383 - val_loss: 1.6129 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.5997 - accuracy: 0.2596 - val_loss: 1.6128 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6043 - accuracy: 0.2553 - val_loss: 1.6128 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6071 - accuracy: 0.2383 - val_loss: 1.6127 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6006 - accuracy: 0.2468 - val_loss: 1.6126 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.5981 - accuracy: 0.2383 - val_loss: 1.6123 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6053 - accuracy: 0.2638 - val_loss: 1.6122 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.5938 - accuracy: 0.2255 - val_loss: 1.6120 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6044 - accuracy: 0.2596 - val_loss: 1.6120 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.5961 - accuracy: 0.2553 - val_loss: 1.6119 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.5959 - accuracy: 0.2809 - val_loss: 1.6119 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5988 - accuracy: 0.2809 - val_loss: 1.6117 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Node 21 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6326 - accuracy: 0.2426 - val_loss: 1.6338 - val_accuracy: 0.1186 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2340 - val_loss: 1.6336 - val_accuracy: 0.1186 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.1872 - val_loss: 1.6331 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2383 - val_loss: 1.6327 - val_accuracy: 0.1186 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2170 - val_loss: 1.6323 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2553 - val_loss: 1.6317 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2255 - val_loss: 1.6312 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2426 - val_loss: 1.6307 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2426 - val_loss: 1.6302 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2000 - val_loss: 1.6298 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2426 - val_loss: 1.6296 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2596 - val_loss: 1.6295 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2043 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2043 - val_loss: 1.6289 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2170 - val_loss: 1.6287 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2213 - val_loss: 1.6286 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2043 - val_loss: 1.6283 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2255 - val_loss: 1.6281 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2553 - val_loss: 1.6277 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2553 - val_loss: 1.6274 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2426 - val_loss: 1.6272 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2043 - val_loss: 1.6270 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2596 - val_loss: 1.6268 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2511 - val_loss: 1.6265 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2468 - val_loss: 1.6263 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2340 - val_loss: 1.6261 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2596 - val_loss: 1.6259 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2383 - val_loss: 1.6257 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2383 - val_loss: 1.6255 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2681 - val_loss: 1.6252 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2170 - val_loss: 1.6250 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2723 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2383 - val_loss: 1.6245 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2298 - val_loss: 1.6243 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2298 - val_loss: 1.6241 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2128 - val_loss: 1.6239 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2085 - val_loss: 1.6237 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2681 - val_loss: 1.6236 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2511 - val_loss: 1.6233 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2511 - val_loss: 1.6232 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2553 - val_loss: 1.6230 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2511 - val_loss: 1.6228 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2596 - val_loss: 1.6227 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2213 - val_loss: 1.6226 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2128 - val_loss: 1.6224 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2383 - val_loss: 1.6222 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2043 - val_loss: 1.6220 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2298 - val_loss: 1.6217 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2383 - val_loss: 1.6216 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2298 - val_loss: 1.6215 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2298 - val_loss: 1.6214 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2255 - val_loss: 1.6213 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2128 - val_loss: 1.6212 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2213 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2511 - val_loss: 1.6209 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2340 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2298 - val_loss: 1.6206 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2085 - val_loss: 1.6205 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2553 - val_loss: 1.6204 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2340 - val_loss: 1.6203 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2553 - val_loss: 1.6202 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2638 - val_loss: 1.6201 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6097 - accuracy: 0.2340 - val_loss: 1.6200 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2255 - val_loss: 1.6199 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2255 - val_loss: 1.6197 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2043 - val_loss: 1.6196 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2553 - val_loss: 1.6195 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2255 - val_loss: 1.6193 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2511 - val_loss: 1.6192 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2553 - val_loss: 1.6190 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2128 - val_loss: 1.6189 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2170 - val_loss: 1.6188 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2426 - val_loss: 1.6188 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2426 - val_loss: 1.6187 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2298 - val_loss: 1.6186 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2255 - val_loss: 1.6187 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2638 - val_loss: 1.6186 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2468 - val_loss: 1.6185 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2426 - val_loss: 1.6184 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2468 - val_loss: 1.6184 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2170 - val_loss: 1.6183 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2128 - val_loss: 1.6183 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2553 - val_loss: 1.6182 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2213 - val_loss: 1.6182 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6096 - accuracy: 0.2553 - val_loss: 1.6182 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6114 - accuracy: 0.2085 - val_loss: 1.6181 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2170 - val_loss: 1.6180 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2128 - val_loss: 1.6179 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6102 - accuracy: 0.3064 - val_loss: 1.6177 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6108 - accuracy: 0.2213 - val_loss: 1.6175 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2426 - val_loss: 1.6174 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2255 - val_loss: 1.6173 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6081 - accuracy: 0.2638 - val_loss: 1.6172 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2426 - val_loss: 1.6171 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6059 - accuracy: 0.2553 - val_loss: 1.6170 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6088 - accuracy: 0.2426 - val_loss: 1.6169 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2468 - val_loss: 1.6168 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6092 - accuracy: 0.2128 - val_loss: 1.6168 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2383 - val_loss: 1.6168 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2426 - val_loss: 1.6167 - val_accuracy: 0.2203 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Node 21 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6617 - accuracy: 0.2170 - val_loss: 1.6597 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 3s/epoch - 189ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6578 - accuracy: 0.2809 - val_loss: 1.6586 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6587 - accuracy: 0.1915 - val_loss: 1.6573 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6567 - accuracy: 0.2383 - val_loss: 1.6562 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6549 - accuracy: 0.2426 - val_loss: 1.6549 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6544 - accuracy: 0.2553 - val_loss: 1.6540 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6551 - accuracy: 0.2128 - val_loss: 1.6530 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6533 - accuracy: 0.2255 - val_loss: 1.6522 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6497 - accuracy: 0.2000 - val_loss: 1.6511 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6492 - accuracy: 0.2809 - val_loss: 1.6503 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6496 - accuracy: 0.2383 - val_loss: 1.6495 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6471 - accuracy: 0.2511 - val_loss: 1.6488 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6475 - accuracy: 0.2340 - val_loss: 1.6479 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6450 - accuracy: 0.2681 - val_loss: 1.6470 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6453 - accuracy: 0.2468 - val_loss: 1.6463 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6449 - accuracy: 0.2383 - val_loss: 1.6455 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6451 - accuracy: 0.2638 - val_loss: 1.6448 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2383 - val_loss: 1.6442 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6400 - accuracy: 0.2298 - val_loss: 1.6435 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6423 - accuracy: 0.2426 - val_loss: 1.6427 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6397 - accuracy: 0.2340 - val_loss: 1.6422 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6386 - accuracy: 0.2383 - val_loss: 1.6417 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2511 - val_loss: 1.6411 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6356 - accuracy: 0.2383 - val_loss: 1.6405 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6386 - accuracy: 0.2255 - val_loss: 1.6399 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6393 - accuracy: 0.2298 - val_loss: 1.6393 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2596 - val_loss: 1.6387 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2383 - val_loss: 1.6381 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6312 - accuracy: 0.2553 - val_loss: 1.6375 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2340 - val_loss: 1.6370 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2468 - val_loss: 1.6365 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.1957 - val_loss: 1.6361 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2426 - val_loss: 1.6355 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2383 - val_loss: 1.6350 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2723 - val_loss: 1.6346 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2383 - val_loss: 1.6341 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2383 - val_loss: 1.6335 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2468 - val_loss: 1.6331 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2766 - val_loss: 1.6328 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2511 - val_loss: 1.6325 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2851 - val_loss: 1.6322 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2340 - val_loss: 1.6318 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2383 - val_loss: 1.6314 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2596 - val_loss: 1.6311 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2766 - val_loss: 1.6308 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2213 - val_loss: 1.6304 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2511 - val_loss: 1.6299 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2723 - val_loss: 1.6296 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.1830 - val_loss: 1.6293 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6135 - accuracy: 0.2298 - val_loss: 1.6291 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2511 - val_loss: 1.6288 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 89ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2255 - val_loss: 1.6285 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2340 - val_loss: 1.6282 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2468 - val_loss: 1.6279 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2936 - val_loss: 1.6277 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2596 - val_loss: 1.6272 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2468 - val_loss: 1.6269 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2681 - val_loss: 1.6266 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.2596 - val_loss: 1.6263 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2213 - val_loss: 1.6260 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6154 - accuracy: 0.2128 - val_loss: 1.6257 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2596 - val_loss: 1.6254 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6106 - accuracy: 0.2255 - val_loss: 1.6252 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2596 - val_loss: 1.6248 - val_accuracy: 0.1356 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2766 - val_loss: 1.6244 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6065 - accuracy: 0.2426 - val_loss: 1.6242 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2043 - val_loss: 1.6240 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6070 - accuracy: 0.2170 - val_loss: 1.6240 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6040 - accuracy: 0.2383 - val_loss: 1.6236 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6085 - accuracy: 0.2170 - val_loss: 1.6232 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2000 - val_loss: 1.6230 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6009 - accuracy: 0.2851 - val_loss: 1.6227 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6017 - accuracy: 0.2511 - val_loss: 1.6226 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.5961 - accuracy: 0.2553 - val_loss: 1.6223 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6050 - accuracy: 0.2340 - val_loss: 1.6221 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.2213 - val_loss: 1.6221 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6044 - accuracy: 0.2596 - val_loss: 1.6221 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.5877 - accuracy: 0.2766 - val_loss: 1.6220 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.5927 - accuracy: 0.2553 - val_loss: 1.6220 - val_accuracy: 0.2034 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6060 - accuracy: 0.2170 - val_loss: 1.6219 - val_accuracy: 0.1864 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6013 - accuracy: 0.2596 - val_loss: 1.6219 - val_accuracy: 0.1864 - lr: 5.0000e-05 - 71ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.5990 - accuracy: 0.2553 - val_loss: 1.6219 - val_accuracy: 0.1864 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.5974 - accuracy: 0.2468 - val_loss: 1.6218 - val_accuracy: 0.1864 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.5912 - accuracy: 0.2851 - val_loss: 1.6218 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.5911 - accuracy: 0.2851 - val_loss: 1.6218 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.5864 - accuracy: 0.2809 - val_loss: 1.6217 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.5877 - accuracy: 0.3106 - val_loss: 1.6216 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.5885 - accuracy: 0.3106 - val_loss: 1.6215 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.5964 - accuracy: 0.2723 - val_loss: 1.6215 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6032 - accuracy: 0.2255 - val_loss: 1.6214 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.5927 - accuracy: 0.2468 - val_loss: 1.6214 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.5903 - accuracy: 0.2851 - val_loss: 1.6213 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.5986 - accuracy: 0.2553 - val_loss: 1.6213 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6000 - accuracy: 0.2553 - val_loss: 1.6212 - val_accuracy: 0.1695 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5962 - accuracy: 0.2638 - val_loss: 1.6212 - val_accuracy: 0.1695 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.5887 - accuracy: 0.2468 - val_loss: 1.6211 - val_accuracy: 0.1695 - lr: 2.5000e-05 - 89ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.5916 - accuracy: 0.2809 - val_loss: 1.6211 - val_accuracy: 0.1864 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.5895 - accuracy: 0.2383 - val_loss: 1.6211 - val_accuracy: 0.1864 - lr: 1.2500e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.5952 - accuracy: 0.2809 - val_loss: 1.6211 - val_accuracy: 0.1864 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5952 - accuracy: 0.2979 - val_loss: 1.6211 - val_accuracy: 0.1864 - lr: 1.2500e-05 - 68ms/epoch - 5ms/step\n",
      "Node 21 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6587 - accuracy: 0.2128 - val_loss: 1.6601 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 2s/epoch - 308ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2255 - val_loss: 1.6594 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6565 - accuracy: 0.2553 - val_loss: 1.6587 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6556 - accuracy: 0.2638 - val_loss: 1.6580 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6553 - accuracy: 0.2085 - val_loss: 1.6570 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6545 - accuracy: 0.2128 - val_loss: 1.6562 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2596 - val_loss: 1.6553 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2255 - val_loss: 1.6546 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6524 - accuracy: 0.2213 - val_loss: 1.6540 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2723 - val_loss: 1.6533 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2298 - val_loss: 1.6526 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2213 - val_loss: 1.6520 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2553 - val_loss: 1.6515 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2511 - val_loss: 1.6507 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2085 - val_loss: 1.6501 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2170 - val_loss: 1.6495 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2426 - val_loss: 1.6488 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2511 - val_loss: 1.6483 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2340 - val_loss: 1.6477 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2170 - val_loss: 1.6471 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2170 - val_loss: 1.6466 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2383 - val_loss: 1.6461 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2043 - val_loss: 1.6456 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2085 - val_loss: 1.6452 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2255 - val_loss: 1.6448 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2000 - val_loss: 1.6444 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2298 - val_loss: 1.6441 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2255 - val_loss: 1.6437 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2213 - val_loss: 1.6433 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2255 - val_loss: 1.6430 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2596 - val_loss: 1.6427 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2213 - val_loss: 1.6424 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2596 - val_loss: 1.6421 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2298 - val_loss: 1.6418 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2298 - val_loss: 1.6414 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2128 - val_loss: 1.6411 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2170 - val_loss: 1.6408 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2596 - val_loss: 1.6405 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2511 - val_loss: 1.6403 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.2043 - val_loss: 1.6400 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2340 - val_loss: 1.6397 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2170 - val_loss: 1.6394 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2213 - val_loss: 1.6392 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2213 - val_loss: 1.6391 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2213 - val_loss: 1.6388 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2638 - val_loss: 1.6386 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2255 - val_loss: 1.6383 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2340 - val_loss: 1.6382 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2511 - val_loss: 1.6379 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2298 - val_loss: 1.6376 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 68ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2340 - val_loss: 1.6373 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2553 - val_loss: 1.6370 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2128 - val_loss: 1.6367 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2638 - val_loss: 1.6365 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2851 - val_loss: 1.6364 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2340 - val_loss: 1.6361 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2553 - val_loss: 1.6359 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2468 - val_loss: 1.6356 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2511 - val_loss: 1.6353 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2468 - val_loss: 1.6350 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2213 - val_loss: 1.6348 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2596 - val_loss: 1.6346 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2638 - val_loss: 1.6344 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2340 - val_loss: 1.6343 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2468 - val_loss: 1.6340 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2468 - val_loss: 1.6338 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2213 - val_loss: 1.6337 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2340 - val_loss: 1.6334 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2340 - val_loss: 1.6332 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2723 - val_loss: 1.6330 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2596 - val_loss: 1.6327 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2851 - val_loss: 1.6325 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6138 - accuracy: 0.2553 - val_loss: 1.6323 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2936 - val_loss: 1.6321 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2340 - val_loss: 1.6319 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2468 - val_loss: 1.6317 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2511 - val_loss: 1.6314 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2723 - val_loss: 1.6312 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2596 - val_loss: 1.6309 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2426 - val_loss: 1.6307 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2170 - val_loss: 1.6305 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2596 - val_loss: 1.6303 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2553 - val_loss: 1.6300 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2596 - val_loss: 1.6299 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6143 - accuracy: 0.2426 - val_loss: 1.6298 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.2681 - val_loss: 1.6297 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2766 - val_loss: 1.6294 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6027 - accuracy: 0.3021 - val_loss: 1.6291 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6084 - accuracy: 0.2681 - val_loss: 1.6289 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2511 - val_loss: 1.6287 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2468 - val_loss: 1.6284 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6143 - accuracy: 0.2511 - val_loss: 1.6281 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6012 - accuracy: 0.2979 - val_loss: 1.6278 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6096 - accuracy: 0.2851 - val_loss: 1.6275 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6076 - accuracy: 0.2681 - val_loss: 1.6273 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6078 - accuracy: 0.2596 - val_loss: 1.6272 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2638 - val_loss: 1.6271 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2596 - val_loss: 1.6271 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 68ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2255 - val_loss: 1.6272 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2809 - val_loss: 1.6272 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Node 21 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 21 - Best Validation Accuracy: 0.2712\n",
      "Best model saved for Node 21 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_21.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_22_dataset.csv\n",
      "Node 22 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6346 - accuracy: 0.1822 - val_loss: 1.6347 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 3s/epoch - 196ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6358 - accuracy: 0.1511 - val_loss: 1.6345 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2311 - val_loss: 1.6343 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.2133 - val_loss: 1.6340 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2178 - val_loss: 1.6337 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2133 - val_loss: 1.6334 - val_accuracy: 0.2982 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.1956 - val_loss: 1.6332 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.1644 - val_loss: 1.6330 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.1911 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2844 - val_loss: 1.6323 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2222 - val_loss: 1.6319 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2622 - val_loss: 1.6315 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.2044 - val_loss: 1.6312 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6331 - accuracy: 0.2222 - val_loss: 1.6310 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2133 - val_loss: 1.6307 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2178 - val_loss: 1.6303 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.1956 - val_loss: 1.6301 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2667 - val_loss: 1.6301 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2533 - val_loss: 1.6299 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2489 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2756 - val_loss: 1.6295 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2311 - val_loss: 1.6293 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2311 - val_loss: 1.6290 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2222 - val_loss: 1.6288 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2222 - val_loss: 1.6287 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2667 - val_loss: 1.6285 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2178 - val_loss: 1.6283 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6309 - accuracy: 0.1956 - val_loss: 1.6282 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2356 - val_loss: 1.6281 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2356 - val_loss: 1.6280 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2356 - val_loss: 1.6278 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2133 - val_loss: 1.6277 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2622 - val_loss: 1.6277 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2178 - val_loss: 1.6275 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2667 - val_loss: 1.6272 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2222 - val_loss: 1.6269 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2356 - val_loss: 1.6267 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2400 - val_loss: 1.6265 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2622 - val_loss: 1.6263 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2178 - val_loss: 1.6263 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2444 - val_loss: 1.6263 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2356 - val_loss: 1.6261 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2222 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2356 - val_loss: 1.6257 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2267 - val_loss: 1.6256 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2400 - val_loss: 1.6255 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2356 - val_loss: 1.6255 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2400 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2933 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2311 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2356 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2356 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2622 - val_loss: 1.6250 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2711 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2267 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2800 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2578 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2400 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2267 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2756 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Node 22 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6348 - accuracy: 0.1867 - val_loss: 1.6351 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 3s/epoch - 357ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2222 - val_loss: 1.6349 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2533 - val_loss: 1.6347 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2178 - val_loss: 1.6347 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2356 - val_loss: 1.6345 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2311 - val_loss: 1.6343 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2089 - val_loss: 1.6341 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.1778 - val_loss: 1.6338 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2178 - val_loss: 1.6336 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2311 - val_loss: 1.6333 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2578 - val_loss: 1.6331 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.1733 - val_loss: 1.6330 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2489 - val_loss: 1.6331 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2044 - val_loss: 1.6331 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2267 - val_loss: 1.6331 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2311 - val_loss: 1.6330 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2133 - val_loss: 1.6329 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2267 - val_loss: 1.6329 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2356 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.1556 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2311 - val_loss: 1.6327 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2356 - val_loss: 1.6326 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2533 - val_loss: 1.6325 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2400 - val_loss: 1.6324 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.1778 - val_loss: 1.6322 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2667 - val_loss: 1.6321 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2356 - val_loss: 1.6320 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.1956 - val_loss: 1.6319 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 36ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2267 - val_loss: 1.6317 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2489 - val_loss: 1.6315 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2178 - val_loss: 1.6314 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2044 - val_loss: 1.6313 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2000 - val_loss: 1.6312 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2400 - val_loss: 1.6311 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2578 - val_loss: 1.6311 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2489 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2222 - val_loss: 1.6309 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2044 - val_loss: 1.6309 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2089 - val_loss: 1.6308 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2400 - val_loss: 1.6308 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2133 - val_loss: 1.6307 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2622 - val_loss: 1.6307 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2178 - val_loss: 1.6306 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2311 - val_loss: 1.6306 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2400 - val_loss: 1.6305 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2667 - val_loss: 1.6304 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2533 - val_loss: 1.6304 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2533 - val_loss: 1.6303 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2444 - val_loss: 1.6302 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.1867 - val_loss: 1.6302 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2044 - val_loss: 1.6301 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2444 - val_loss: 1.6301 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2178 - val_loss: 1.6300 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2533 - val_loss: 1.6300 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2889 - val_loss: 1.6299 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2578 - val_loss: 1.6299 - val_accuracy: 0.2456 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.1911 - val_loss: 1.6298 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2400 - val_loss: 1.6297 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2444 - val_loss: 1.6297 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2400 - val_loss: 1.6297 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2044 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2756 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2444 - val_loss: 1.6295 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2444 - val_loss: 1.6295 - val_accuracy: 0.2456 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2311 - val_loss: 1.6295 - val_accuracy: 0.2456 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2489 - val_loss: 1.6295 - val_accuracy: 0.2456 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.1956 - val_loss: 1.6295 - val_accuracy: 0.2456 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2356 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.1956 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2267 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2311 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2133 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2400 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.1250e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2311 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.1250e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2444 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2622 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2578 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2356 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2533 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2089 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2089 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2667 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2533 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2178 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.9062e-07 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.3200 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2222 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 3.9062e-07 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2311 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2978 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2222 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.9531e-07 - 32ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2444 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 9.7656e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2533 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 9.7656e-08 - 49ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2089 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 9.7656e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2267 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 4.8828e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2844 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 4.8828e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2089 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2578 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 2.4414e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2311 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 2.4414e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2178 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 2.4414e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2489 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.2207e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2222 - val_loss: 1.6294 - val_accuracy: 0.2456 - lr: 1.2207e-08 - 34ms/epoch - 4ms/step\n",
      "Node 22 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6597 - accuracy: 0.1956 - val_loss: 1.6590 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 3s/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6589 - accuracy: 0.2133 - val_loss: 1.6580 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6579 - accuracy: 0.2000 - val_loss: 1.6570 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6578 - accuracy: 0.2178 - val_loss: 1.6565 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6560 - accuracy: 0.2133 - val_loss: 1.6559 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6554 - accuracy: 0.1822 - val_loss: 1.6554 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6538 - accuracy: 0.2444 - val_loss: 1.6546 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6541 - accuracy: 0.1867 - val_loss: 1.6536 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6521 - accuracy: 0.2178 - val_loss: 1.6528 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6523 - accuracy: 0.2267 - val_loss: 1.6518 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6506 - accuracy: 0.2000 - val_loss: 1.6507 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6498 - accuracy: 0.1911 - val_loss: 1.6498 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6483 - accuracy: 0.2222 - val_loss: 1.6492 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6467 - accuracy: 0.2356 - val_loss: 1.6482 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6466 - accuracy: 0.2400 - val_loss: 1.6474 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6470 - accuracy: 0.2267 - val_loss: 1.6466 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6445 - accuracy: 0.2089 - val_loss: 1.6458 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.2311 - val_loss: 1.6450 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6453 - accuracy: 0.2089 - val_loss: 1.6442 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6381 - accuracy: 0.2756 - val_loss: 1.6433 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6387 - accuracy: 0.2844 - val_loss: 1.6427 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6401 - accuracy: 0.2356 - val_loss: 1.6421 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6391 - accuracy: 0.2622 - val_loss: 1.6419 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6381 - accuracy: 0.2667 - val_loss: 1.6415 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6361 - accuracy: 0.2222 - val_loss: 1.6409 - val_accuracy: 0.2807 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6374 - accuracy: 0.2356 - val_loss: 1.6405 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.2844 - val_loss: 1.6399 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2978 - val_loss: 1.6392 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.2267 - val_loss: 1.6386 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2756 - val_loss: 1.6382 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2667 - val_loss: 1.6378 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2533 - val_loss: 1.6376 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.2222 - val_loss: 1.6373 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2089 - val_loss: 1.6368 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2356 - val_loss: 1.6364 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2133 - val_loss: 1.6360 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2800 - val_loss: 1.6355 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2933 - val_loss: 1.6354 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2800 - val_loss: 1.6351 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2800 - val_loss: 1.6349 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2444 - val_loss: 1.6346 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2311 - val_loss: 1.6343 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2756 - val_loss: 1.6339 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6331 - accuracy: 0.2267 - val_loss: 1.6338 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2711 - val_loss: 1.6335 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2267 - val_loss: 1.6332 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2533 - val_loss: 1.6332 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2356 - val_loss: 1.6333 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2356 - val_loss: 1.6331 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 88ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2178 - val_loss: 1.6328 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6256 - accuracy: 0.2711 - val_loss: 1.6327 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2044 - val_loss: 1.6325 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2311 - val_loss: 1.6322 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2622 - val_loss: 1.6320 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.3022 - val_loss: 1.6318 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2844 - val_loss: 1.6317 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2311 - val_loss: 1.6314 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2222 - val_loss: 1.6311 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2711 - val_loss: 1.6309 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2356 - val_loss: 1.6310 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2356 - val_loss: 1.6308 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2578 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2089 - val_loss: 1.6311 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2000 - val_loss: 1.6310 - val_accuracy: 0.2105 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2667 - val_loss: 1.6308 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2933 - val_loss: 1.6307 - val_accuracy: 0.2105 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2222 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2356 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2089 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2489 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2667 - val_loss: 1.6306 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2044 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.1956 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2622 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2667 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 65ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2933 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 68ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2667 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 6.2500e-06 - 68ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6154 - accuracy: 0.2400 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 3.1250e-06 - 70ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2622 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 3.1250e-06 - 71ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2444 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 3.1250e-06 - 70ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2844 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 1.5625e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2711 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 1.5625e-06 - 65ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6136 - accuracy: 0.2667 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 1.5625e-06 - 65ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2311 - val_loss: 1.6305 - val_accuracy: 0.2105 - lr: 7.8125e-07 - 74ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2533 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 7.8125e-07 - 70ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2756 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 7.8125e-07 - 70ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2311 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 69ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2533 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 64ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2667 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 3.9062e-07 - 66ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6122 - accuracy: 0.2667 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.9531e-07 - 64ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2089 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.9531e-07 - 65ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2444 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 1.9531e-07 - 85ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2222 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 9.7656e-08 - 65ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2533 - val_loss: 1.6305 - val_accuracy: 0.2281 - lr: 9.7656e-08 - 66ms/epoch - 4ms/step\n",
      "Node 22 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6604 - accuracy: 0.2222 - val_loss: 1.6597 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 3s/epoch - 345ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2400 - val_loss: 1.6592 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6600 - accuracy: 0.1911 - val_loss: 1.6587 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.2533 - val_loss: 1.6583 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6569 - accuracy: 0.2356 - val_loss: 1.6578 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.2222 - val_loss: 1.6575 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6572 - accuracy: 0.2267 - val_loss: 1.6572 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6560 - accuracy: 0.2267 - val_loss: 1.6568 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6556 - accuracy: 0.2267 - val_loss: 1.6563 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6568 - accuracy: 0.2222 - val_loss: 1.6559 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6554 - accuracy: 0.2489 - val_loss: 1.6554 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2444 - val_loss: 1.6550 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2089 - val_loss: 1.6548 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6534 - accuracy: 0.2311 - val_loss: 1.6545 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2400 - val_loss: 1.6541 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.1911 - val_loss: 1.6536 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2267 - val_loss: 1.6533 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2800 - val_loss: 1.6530 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6528 - accuracy: 0.2311 - val_loss: 1.6526 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2489 - val_loss: 1.6522 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2711 - val_loss: 1.6519 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2178 - val_loss: 1.6516 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6493 - accuracy: 0.2578 - val_loss: 1.6512 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6505 - accuracy: 0.2400 - val_loss: 1.6509 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2533 - val_loss: 1.6506 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2533 - val_loss: 1.6504 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2756 - val_loss: 1.6500 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2533 - val_loss: 1.6496 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2756 - val_loss: 1.6492 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2667 - val_loss: 1.6488 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2622 - val_loss: 1.6485 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6469 - accuracy: 0.2756 - val_loss: 1.6483 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.1867 - val_loss: 1.6480 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2400 - val_loss: 1.6478 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6467 - accuracy: 0.2533 - val_loss: 1.6475 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2533 - val_loss: 1.6472 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6467 - accuracy: 0.2400 - val_loss: 1.6468 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2933 - val_loss: 1.6465 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2489 - val_loss: 1.6462 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.2489 - val_loss: 1.6459 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2489 - val_loss: 1.6455 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2489 - val_loss: 1.6450 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2533 - val_loss: 1.6446 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2267 - val_loss: 1.6443 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2311 - val_loss: 1.6441 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6427 - accuracy: 0.2222 - val_loss: 1.6439 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2178 - val_loss: 1.6438 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6389 - accuracy: 0.2711 - val_loss: 1.6436 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 9ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2622 - val_loss: 1.6432 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2222 - val_loss: 1.6429 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2444 - val_loss: 1.6426 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2178 - val_loss: 1.6423 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2356 - val_loss: 1.6421 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2356 - val_loss: 1.6418 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2311 - val_loss: 1.6417 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2267 - val_loss: 1.6416 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2444 - val_loss: 1.6415 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2444 - val_loss: 1.6413 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2489 - val_loss: 1.6412 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2311 - val_loss: 1.6410 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2311 - val_loss: 1.6407 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2444 - val_loss: 1.6405 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6380 - accuracy: 0.2444 - val_loss: 1.6401 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.2311 - val_loss: 1.6397 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2356 - val_loss: 1.6393 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2356 - val_loss: 1.6392 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2400 - val_loss: 1.6390 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2400 - val_loss: 1.6387 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.2578 - val_loss: 1.6387 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2222 - val_loss: 1.6386 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2311 - val_loss: 1.6384 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2444 - val_loss: 1.6382 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2622 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2622 - val_loss: 1.6378 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2622 - val_loss: 1.6376 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2533 - val_loss: 1.6373 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2800 - val_loss: 1.6371 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2711 - val_loss: 1.6368 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2622 - val_loss: 1.6366 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2311 - val_loss: 1.6365 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2489 - val_loss: 1.6361 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2622 - val_loss: 1.6358 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2622 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2267 - val_loss: 1.6354 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2356 - val_loss: 1.6352 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2400 - val_loss: 1.6350 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2622 - val_loss: 1.6347 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2578 - val_loss: 1.6345 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2622 - val_loss: 1.6343 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2444 - val_loss: 1.6342 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2444 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2356 - val_loss: 1.6338 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2222 - val_loss: 1.6337 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2444 - val_loss: 1.6335 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2267 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2222 - val_loss: 1.6332 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2489 - val_loss: 1.6331 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2400 - val_loss: 1.6328 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2533 - val_loss: 1.6326 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2178 - val_loss: 1.6324 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Node 22 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 22 - Best Validation Accuracy: 0.2982\n",
      "Best model saved for Node 22 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_22.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_23_dataset.csv\n",
      "Node 23 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6359 - accuracy: 0.1483 - val_loss: 1.6357 - val_accuracy: 0.1864 - lr: 1.0000e-04 - 2s/epoch - 164ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.2119 - val_loss: 1.6351 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2585 - val_loss: 1.6342 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2627 - val_loss: 1.6333 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6314 - accuracy: 0.1992 - val_loss: 1.6323 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2415 - val_loss: 1.6314 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.1907 - val_loss: 1.6308 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.1907 - val_loss: 1.6302 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6285 - accuracy: 0.2288 - val_loss: 1.6296 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2203 - val_loss: 1.6292 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.2585 - val_loss: 1.6288 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2458 - val_loss: 1.6283 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2373 - val_loss: 1.6279 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2500 - val_loss: 1.6276 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2669 - val_loss: 1.6271 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2458 - val_loss: 1.6266 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2203 - val_loss: 1.6262 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2034 - val_loss: 1.6258 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.1992 - val_loss: 1.6256 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2246 - val_loss: 1.6251 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2669 - val_loss: 1.6247 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2203 - val_loss: 1.6244 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2415 - val_loss: 1.6240 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2415 - val_loss: 1.6236 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2203 - val_loss: 1.6233 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2331 - val_loss: 1.6229 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2542 - val_loss: 1.6226 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2246 - val_loss: 1.6223 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2458 - val_loss: 1.6219 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2119 - val_loss: 1.6216 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2373 - val_loss: 1.6214 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2712 - val_loss: 1.6211 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2415 - val_loss: 1.6208 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.1949 - val_loss: 1.6207 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2331 - val_loss: 1.6205 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2373 - val_loss: 1.6204 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2797 - val_loss: 1.6201 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2119 - val_loss: 1.6199 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2458 - val_loss: 1.6197 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2119 - val_loss: 1.6195 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2373 - val_loss: 1.6193 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2288 - val_loss: 1.6192 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6104 - accuracy: 0.2500 - val_loss: 1.6189 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2331 - val_loss: 1.6186 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6112 - accuracy: 0.2415 - val_loss: 1.6183 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2458 - val_loss: 1.6181 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2585 - val_loss: 1.6180 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.2203 - val_loss: 1.6179 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6090 - accuracy: 0.2288 - val_loss: 1.6177 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2373 - val_loss: 1.6175 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6085 - accuracy: 0.2373 - val_loss: 1.6173 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2415 - val_loss: 1.6171 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2331 - val_loss: 1.6169 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2500 - val_loss: 1.6168 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.2331 - val_loss: 1.6166 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6090 - accuracy: 0.2458 - val_loss: 1.6165 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2458 - val_loss: 1.6163 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6072 - accuracy: 0.2415 - val_loss: 1.6162 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6112 - accuracy: 0.2415 - val_loss: 1.6160 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2627 - val_loss: 1.6157 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2458 - val_loss: 1.6155 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6062 - accuracy: 0.2246 - val_loss: 1.6153 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2203 - val_loss: 1.6151 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6005 - accuracy: 0.2373 - val_loss: 1.6149 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2585 - val_loss: 1.6147 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2415 - val_loss: 1.6145 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6045 - accuracy: 0.2458 - val_loss: 1.6144 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6043 - accuracy: 0.2288 - val_loss: 1.6143 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2585 - val_loss: 1.6142 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6088 - accuracy: 0.2161 - val_loss: 1.6140 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.5988 - accuracy: 0.2415 - val_loss: 1.6138 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6022 - accuracy: 0.2500 - val_loss: 1.6136 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.5984 - accuracy: 0.2458 - val_loss: 1.6134 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6041 - accuracy: 0.2373 - val_loss: 1.6132 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6046 - accuracy: 0.2415 - val_loss: 1.6129 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.5965 - accuracy: 0.2203 - val_loss: 1.6126 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2754 - val_loss: 1.6125 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6056 - accuracy: 0.2161 - val_loss: 1.6124 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.5989 - accuracy: 0.2585 - val_loss: 1.6122 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6080 - accuracy: 0.2415 - val_loss: 1.6121 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6133 - accuracy: 0.2246 - val_loss: 1.6121 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2542 - val_loss: 1.6119 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6046 - accuracy: 0.2161 - val_loss: 1.6119 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6003 - accuracy: 0.2542 - val_loss: 1.6117 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.5997 - accuracy: 0.2500 - val_loss: 1.6116 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.5937 - accuracy: 0.2627 - val_loss: 1.6114 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6054 - accuracy: 0.2415 - val_loss: 1.6113 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6013 - accuracy: 0.2373 - val_loss: 1.6111 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.5980 - accuracy: 0.2669 - val_loss: 1.6108 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6026 - accuracy: 0.2246 - val_loss: 1.6107 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.5971 - accuracy: 0.2669 - val_loss: 1.6106 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.5942 - accuracy: 0.2288 - val_loss: 1.6105 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6040 - accuracy: 0.2373 - val_loss: 1.6103 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.2627 - val_loss: 1.6101 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5978 - accuracy: 0.2712 - val_loss: 1.6099 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.5955 - accuracy: 0.2246 - val_loss: 1.6098 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.5982 - accuracy: 0.2458 - val_loss: 1.6095 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6001 - accuracy: 0.1949 - val_loss: 1.6092 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.5891 - accuracy: 0.2669 - val_loss: 1.6090 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5975 - accuracy: 0.2585 - val_loss: 1.6088 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Node 23 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6345 - accuracy: 0.2119 - val_loss: 1.6346 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 3s/epoch - 362ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.1949 - val_loss: 1.6344 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2373 - val_loss: 1.6342 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2331 - val_loss: 1.6340 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2288 - val_loss: 1.6338 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2119 - val_loss: 1.6337 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2458 - val_loss: 1.6335 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2500 - val_loss: 1.6333 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2415 - val_loss: 1.6331 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2246 - val_loss: 1.6329 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.1949 - val_loss: 1.6326 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2373 - val_loss: 1.6324 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2627 - val_loss: 1.6320 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2542 - val_loss: 1.6317 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2161 - val_loss: 1.6313 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2288 - val_loss: 1.6310 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2161 - val_loss: 1.6306 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2373 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2161 - val_loss: 1.6300 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2373 - val_loss: 1.6298 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2373 - val_loss: 1.6296 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2373 - val_loss: 1.6293 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2373 - val_loss: 1.6291 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2076 - val_loss: 1.6288 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2161 - val_loss: 1.6285 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2203 - val_loss: 1.6282 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2119 - val_loss: 1.6280 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2119 - val_loss: 1.6276 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2669 - val_loss: 1.6273 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2373 - val_loss: 1.6270 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2076 - val_loss: 1.6268 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2415 - val_loss: 1.6266 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2415 - val_loss: 1.6264 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2331 - val_loss: 1.6261 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2331 - val_loss: 1.6259 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2288 - val_loss: 1.6256 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2373 - val_loss: 1.6254 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2331 - val_loss: 1.6251 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2373 - val_loss: 1.6249 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2839 - val_loss: 1.6248 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2542 - val_loss: 1.6246 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2500 - val_loss: 1.6243 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2415 - val_loss: 1.6241 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2331 - val_loss: 1.6239 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.1949 - val_loss: 1.6238 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2627 - val_loss: 1.6237 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2246 - val_loss: 1.6235 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2288 - val_loss: 1.6233 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2542 - val_loss: 1.6232 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2076 - val_loss: 1.6230 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2627 - val_loss: 1.6229 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2203 - val_loss: 1.6227 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2627 - val_loss: 1.6225 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2500 - val_loss: 1.6224 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2161 - val_loss: 1.6222 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2458 - val_loss: 1.6220 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2415 - val_loss: 1.6219 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.2627 - val_loss: 1.6216 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2203 - val_loss: 1.6214 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2585 - val_loss: 1.6213 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2415 - val_loss: 1.6211 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2415 - val_loss: 1.6210 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2712 - val_loss: 1.6208 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2161 - val_loss: 1.6206 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2415 - val_loss: 1.6205 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2331 - val_loss: 1.6204 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2331 - val_loss: 1.6203 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2542 - val_loss: 1.6202 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6100 - accuracy: 0.2585 - val_loss: 1.6200 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2246 - val_loss: 1.6198 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6140 - accuracy: 0.2627 - val_loss: 1.6197 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2288 - val_loss: 1.6196 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6131 - accuracy: 0.2669 - val_loss: 1.6195 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2542 - val_loss: 1.6193 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2331 - val_loss: 1.6192 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2669 - val_loss: 1.6191 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2288 - val_loss: 1.6191 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2415 - val_loss: 1.6190 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6127 - accuracy: 0.2415 - val_loss: 1.6190 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2797 - val_loss: 1.6188 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.2458 - val_loss: 1.6188 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2585 - val_loss: 1.6187 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2500 - val_loss: 1.6186 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6096 - accuracy: 0.2373 - val_loss: 1.6184 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2331 - val_loss: 1.6183 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2415 - val_loss: 1.6182 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2203 - val_loss: 1.6181 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6063 - accuracy: 0.2669 - val_loss: 1.6180 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2542 - val_loss: 1.6179 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6127 - accuracy: 0.2331 - val_loss: 1.6178 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2500 - val_loss: 1.6178 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6103 - accuracy: 0.2627 - val_loss: 1.6177 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2542 - val_loss: 1.6176 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2500 - val_loss: 1.6175 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6119 - accuracy: 0.2669 - val_loss: 1.6174 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2585 - val_loss: 1.6173 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6065 - accuracy: 0.2458 - val_loss: 1.6172 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2415 - val_loss: 1.6172 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6079 - accuracy: 0.2373 - val_loss: 1.6171 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2331 - val_loss: 1.6171 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Node 23 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6613 - accuracy: 0.1822 - val_loss: 1.6604 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 2s/epoch - 166ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6588 - accuracy: 0.2076 - val_loss: 1.6594 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6591 - accuracy: 0.1864 - val_loss: 1.6586 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6579 - accuracy: 0.1992 - val_loss: 1.6577 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6553 - accuracy: 0.2373 - val_loss: 1.6569 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6552 - accuracy: 0.1949 - val_loss: 1.6561 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6518 - accuracy: 0.2119 - val_loss: 1.6551 - val_accuracy: 0.1695 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6514 - accuracy: 0.2203 - val_loss: 1.6544 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6523 - accuracy: 0.2458 - val_loss: 1.6536 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6508 - accuracy: 0.2076 - val_loss: 1.6529 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6470 - accuracy: 0.2373 - val_loss: 1.6522 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2542 - val_loss: 1.6514 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6484 - accuracy: 0.2500 - val_loss: 1.6504 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6480 - accuracy: 0.2288 - val_loss: 1.6499 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2415 - val_loss: 1.6494 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6424 - accuracy: 0.2415 - val_loss: 1.6485 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6446 - accuracy: 0.2415 - val_loss: 1.6479 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6420 - accuracy: 0.2288 - val_loss: 1.6473 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6393 - accuracy: 0.3093 - val_loss: 1.6467 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6416 - accuracy: 0.2458 - val_loss: 1.6462 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6389 - accuracy: 0.2839 - val_loss: 1.6456 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2839 - val_loss: 1.6451 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2797 - val_loss: 1.6444 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6351 - accuracy: 0.2669 - val_loss: 1.6438 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2585 - val_loss: 1.6432 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6366 - accuracy: 0.2161 - val_loss: 1.6427 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2373 - val_loss: 1.6422 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2246 - val_loss: 1.6417 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2373 - val_loss: 1.6411 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2373 - val_loss: 1.6407 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2754 - val_loss: 1.6402 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2458 - val_loss: 1.6399 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2585 - val_loss: 1.6395 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2458 - val_loss: 1.6390 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2373 - val_loss: 1.6385 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.3093 - val_loss: 1.6383 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2585 - val_loss: 1.6380 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2839 - val_loss: 1.6376 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2627 - val_loss: 1.6372 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2246 - val_loss: 1.6370 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2797 - val_loss: 1.6366 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.3093 - val_loss: 1.6362 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2712 - val_loss: 1.6361 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2797 - val_loss: 1.6357 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2458 - val_loss: 1.6354 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2712 - val_loss: 1.6347 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2246 - val_loss: 1.6343 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6126 - accuracy: 0.2669 - val_loss: 1.6341 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2542 - val_loss: 1.6337 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 86ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2712 - val_loss: 1.6335 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6072 - accuracy: 0.2797 - val_loss: 1.6335 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2712 - val_loss: 1.6331 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2542 - val_loss: 1.6329 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6122 - accuracy: 0.2669 - val_loss: 1.6326 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.3008 - val_loss: 1.6325 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6036 - accuracy: 0.2627 - val_loss: 1.6324 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.2415 - val_loss: 1.6321 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.5948 - accuracy: 0.2881 - val_loss: 1.6320 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6095 - accuracy: 0.2500 - val_loss: 1.6318 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6017 - accuracy: 0.2712 - val_loss: 1.6316 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.2797 - val_loss: 1.6316 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6007 - accuracy: 0.3008 - val_loss: 1.6313 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6003 - accuracy: 0.3178 - val_loss: 1.6310 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.5998 - accuracy: 0.3220 - val_loss: 1.6311 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.5971 - accuracy: 0.2754 - val_loss: 1.6310 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.5992 - accuracy: 0.3008 - val_loss: 1.6309 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.5994 - accuracy: 0.2669 - val_loss: 1.6308 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.5987 - accuracy: 0.3008 - val_loss: 1.6309 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.5958 - accuracy: 0.2669 - val_loss: 1.6305 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6041 - accuracy: 0.2500 - val_loss: 1.6303 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6021 - accuracy: 0.2288 - val_loss: 1.6302 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6019 - accuracy: 0.3051 - val_loss: 1.6298 - val_accuracy: 0.2203 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.5921 - accuracy: 0.2585 - val_loss: 1.6297 - val_accuracy: 0.2203 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6005 - accuracy: 0.2966 - val_loss: 1.6298 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.5966 - accuracy: 0.3051 - val_loss: 1.6296 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 71ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2415 - val_loss: 1.6294 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.5920 - accuracy: 0.2797 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.5924 - accuracy: 0.2585 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.5980 - accuracy: 0.2797 - val_loss: 1.6290 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.5966 - accuracy: 0.2839 - val_loss: 1.6290 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.5967 - accuracy: 0.2881 - val_loss: 1.6292 - val_accuracy: 0.2542 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.5976 - accuracy: 0.2839 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.5957 - accuracy: 0.2669 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.5923 - accuracy: 0.2585 - val_loss: 1.6291 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.5866 - accuracy: 0.2881 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.5901 - accuracy: 0.2754 - val_loss: 1.6292 - val_accuracy: 0.2373 - lr: 1.2500e-05 - 69ms/epoch - 5ms/step\n",
      "Node 23 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6603 - accuracy: 0.2034 - val_loss: 1.6592 - val_accuracy: 0.1525 - lr: 1.0000e-04 - 2s/epoch - 312ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6595 - accuracy: 0.1737 - val_loss: 1.6584 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.2331 - val_loss: 1.6575 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.2034 - val_loss: 1.6568 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2203 - val_loss: 1.6560 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.1780 - val_loss: 1.6551 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6546 - accuracy: 0.2500 - val_loss: 1.6545 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6523 - accuracy: 0.2288 - val_loss: 1.6537 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2161 - val_loss: 1.6531 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2119 - val_loss: 1.6524 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2542 - val_loss: 1.6518 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6504 - accuracy: 0.1949 - val_loss: 1.6512 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2161 - val_loss: 1.6507 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2203 - val_loss: 1.6501 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2161 - val_loss: 1.6497 - val_accuracy: 0.2034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2627 - val_loss: 1.6490 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2373 - val_loss: 1.6486 - val_accuracy: 0.2203 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6443 - accuracy: 0.1992 - val_loss: 1.6480 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2161 - val_loss: 1.6476 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2161 - val_loss: 1.6472 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.2161 - val_loss: 1.6468 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2203 - val_loss: 1.6463 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2585 - val_loss: 1.6457 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2627 - val_loss: 1.6454 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.2415 - val_loss: 1.6450 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2669 - val_loss: 1.6446 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2076 - val_loss: 1.6444 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2754 - val_loss: 1.6439 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2839 - val_loss: 1.6435 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2627 - val_loss: 1.6429 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2881 - val_loss: 1.6424 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6435 - accuracy: 0.2119 - val_loss: 1.6419 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2627 - val_loss: 1.6415 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2458 - val_loss: 1.6411 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2076 - val_loss: 1.6405 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2458 - val_loss: 1.6401 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 71ms/epoch - 9ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2542 - val_loss: 1.6396 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2246 - val_loss: 1.6393 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2161 - val_loss: 1.6391 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2373 - val_loss: 1.6389 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2415 - val_loss: 1.6385 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2627 - val_loss: 1.6381 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2458 - val_loss: 1.6377 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2288 - val_loss: 1.6374 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2373 - val_loss: 1.6373 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6375 - accuracy: 0.2669 - val_loss: 1.6371 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6389 - accuracy: 0.1992 - val_loss: 1.6370 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2500 - val_loss: 1.6369 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2288 - val_loss: 1.6366 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2754 - val_loss: 1.6364 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2542 - val_loss: 1.6361 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2415 - val_loss: 1.6357 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2754 - val_loss: 1.6355 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2585 - val_loss: 1.6352 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2585 - val_loss: 1.6348 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2331 - val_loss: 1.6346 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2458 - val_loss: 1.6343 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2542 - val_loss: 1.6341 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2373 - val_loss: 1.6338 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2627 - val_loss: 1.6336 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2415 - val_loss: 1.6334 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2331 - val_loss: 1.6332 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2458 - val_loss: 1.6330 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2585 - val_loss: 1.6329 - val_accuracy: 0.2373 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2669 - val_loss: 1.6325 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2627 - val_loss: 1.6322 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2585 - val_loss: 1.6318 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2415 - val_loss: 1.6312 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2331 - val_loss: 1.6307 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2627 - val_loss: 1.6303 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2712 - val_loss: 1.6300 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2585 - val_loss: 1.6297 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6124 - accuracy: 0.2331 - val_loss: 1.6296 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6124 - accuracy: 0.2712 - val_loss: 1.6293 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2458 - val_loss: 1.6291 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2161 - val_loss: 1.6291 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2585 - val_loss: 1.6291 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2712 - val_loss: 1.6290 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2415 - val_loss: 1.6288 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2331 - val_loss: 1.6287 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2712 - val_loss: 1.6283 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6074 - accuracy: 0.2839 - val_loss: 1.6280 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2542 - val_loss: 1.6276 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2881 - val_loss: 1.6272 - val_accuracy: 0.2542 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6099 - accuracy: 0.2458 - val_loss: 1.6269 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6024 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2542 - val_loss: 1.6266 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2458 - val_loss: 1.6265 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6043 - accuracy: 0.2712 - val_loss: 1.6265 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6032 - accuracy: 0.2627 - val_loss: 1.6260 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6016 - accuracy: 0.2966 - val_loss: 1.6257 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.5992 - accuracy: 0.2712 - val_loss: 1.6256 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6059 - accuracy: 0.2542 - val_loss: 1.6254 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6067 - accuracy: 0.2331 - val_loss: 1.6253 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6069 - accuracy: 0.2203 - val_loss: 1.6249 - val_accuracy: 0.2712 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.5999 - accuracy: 0.2585 - val_loss: 1.6246 - val_accuracy: 0.2881 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6044 - accuracy: 0.2712 - val_loss: 1.6242 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6045 - accuracy: 0.2797 - val_loss: 1.6237 - val_accuracy: 0.3051 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6113 - accuracy: 0.2373 - val_loss: 1.6236 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.5955 - accuracy: 0.3008 - val_loss: 1.6233 - val_accuracy: 0.3220 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Node 23 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 23 - Best Validation Accuracy: 0.3220\n",
      "Best model saved for Node 23 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_23.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_24_dataset.csv\n",
      "Node 24 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6351 - accuracy: 0.1514 - val_loss: 1.6340 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 3s/epoch - 198ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6360 - accuracy: 0.1606 - val_loss: 1.6337 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6340 - accuracy: 0.2064 - val_loss: 1.6335 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6348 - accuracy: 0.1972 - val_loss: 1.6334 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6340 - accuracy: 0.1789 - val_loss: 1.6332 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6324 - accuracy: 0.2156 - val_loss: 1.6330 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6326 - accuracy: 0.2110 - val_loss: 1.6328 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6326 - accuracy: 0.2248 - val_loss: 1.6326 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6321 - accuracy: 0.2294 - val_loss: 1.6324 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2294 - val_loss: 1.6322 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6313 - accuracy: 0.2202 - val_loss: 1.6321 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6311 - accuracy: 0.1972 - val_loss: 1.6319 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2202 - val_loss: 1.6317 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2018 - val_loss: 1.6315 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2385 - val_loss: 1.6313 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6299 - accuracy: 0.1972 - val_loss: 1.6311 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6310 - accuracy: 0.2064 - val_loss: 1.6309 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6293 - accuracy: 0.2294 - val_loss: 1.6307 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2431 - val_loss: 1.6304 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6275 - accuracy: 0.2615 - val_loss: 1.6303 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.2615 - val_loss: 1.6301 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2156 - val_loss: 1.6299 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.1881 - val_loss: 1.6297 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.1835 - val_loss: 1.6296 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2477 - val_loss: 1.6294 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2018 - val_loss: 1.6292 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2569 - val_loss: 1.6290 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2294 - val_loss: 1.6289 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2431 - val_loss: 1.6287 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2339 - val_loss: 1.6286 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2156 - val_loss: 1.6284 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6262 - accuracy: 0.2018 - val_loss: 1.6283 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2477 - val_loss: 1.6281 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2294 - val_loss: 1.6279 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6262 - accuracy: 0.1927 - val_loss: 1.6277 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2156 - val_loss: 1.6275 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6265 - accuracy: 0.2110 - val_loss: 1.6274 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2202 - val_loss: 1.6272 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2018 - val_loss: 1.6270 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.1972 - val_loss: 1.6269 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6250 - accuracy: 0.2294 - val_loss: 1.6267 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2523 - val_loss: 1.6266 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6251 - accuracy: 0.2248 - val_loss: 1.6265 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6235 - accuracy: 0.2339 - val_loss: 1.6263 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.1881 - val_loss: 1.6262 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6234 - accuracy: 0.2156 - val_loss: 1.6261 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6243 - accuracy: 0.2018 - val_loss: 1.6260 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.2294 - val_loss: 1.6259 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2339 - val_loss: 1.6257 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2339 - val_loss: 1.6256 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2294 - val_loss: 1.6254 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2431 - val_loss: 1.6253 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2523 - val_loss: 1.6252 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 49ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2339 - val_loss: 1.6250 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2431 - val_loss: 1.6249 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2477 - val_loss: 1.6248 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2431 - val_loss: 1.6246 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6203 - accuracy: 0.2431 - val_loss: 1.6245 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6196 - accuracy: 0.1972 - val_loss: 1.6246 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6232 - accuracy: 0.2156 - val_loss: 1.6245 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2202 - val_loss: 1.6244 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6185 - accuracy: 0.2431 - val_loss: 1.6242 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6159 - accuracy: 0.2569 - val_loss: 1.6242 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2294 - val_loss: 1.6241 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2110 - val_loss: 1.6240 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2523 - val_loss: 1.6239 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2202 - val_loss: 1.6238 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6146 - accuracy: 0.2385 - val_loss: 1.6237 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6152 - accuracy: 0.2248 - val_loss: 1.6237 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2477 - val_loss: 1.6235 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.2569 - val_loss: 1.6233 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6165 - accuracy: 0.2385 - val_loss: 1.6232 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2294 - val_loss: 1.6231 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2110 - val_loss: 1.6231 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6171 - accuracy: 0.2110 - val_loss: 1.6230 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6155 - accuracy: 0.2248 - val_loss: 1.6229 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6166 - accuracy: 0.2156 - val_loss: 1.6229 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2110 - val_loss: 1.6228 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6170 - accuracy: 0.1927 - val_loss: 1.6226 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2064 - val_loss: 1.6224 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2064 - val_loss: 1.6223 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6159 - accuracy: 0.2431 - val_loss: 1.6223 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2202 - val_loss: 1.6223 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6122 - accuracy: 0.2431 - val_loss: 1.6222 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.1881 - val_loss: 1.6221 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6144 - accuracy: 0.2706 - val_loss: 1.6220 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6133 - accuracy: 0.2294 - val_loss: 1.6220 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6151 - accuracy: 0.2202 - val_loss: 1.6220 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2156 - val_loss: 1.6219 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2018 - val_loss: 1.6218 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2569 - val_loss: 1.6218 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6117 - accuracy: 0.2294 - val_loss: 1.6217 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6128 - accuracy: 0.2385 - val_loss: 1.6217 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2064 - val_loss: 1.6217 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6152 - accuracy: 0.2156 - val_loss: 1.6216 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6094 - accuracy: 0.2569 - val_loss: 1.6215 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6140 - accuracy: 0.2294 - val_loss: 1.6215 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6109 - accuracy: 0.2339 - val_loss: 1.6216 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6118 - accuracy: 0.2569 - val_loss: 1.6216 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6133 - accuracy: 0.2202 - val_loss: 1.6216 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Node 24 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6351 - accuracy: 0.2018 - val_loss: 1.6347 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 2s/epoch - 353ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6348 - accuracy: 0.1927 - val_loss: 1.6345 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6344 - accuracy: 0.2294 - val_loss: 1.6343 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.1881 - val_loss: 1.6342 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6340 - accuracy: 0.2018 - val_loss: 1.6340 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.2294 - val_loss: 1.6339 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.2156 - val_loss: 1.6337 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2156 - val_loss: 1.6336 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.1881 - val_loss: 1.6334 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.1881 - val_loss: 1.6333 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.1972 - val_loss: 1.6331 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.2477 - val_loss: 1.6330 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6326 - accuracy: 0.2156 - val_loss: 1.6327 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2064 - val_loss: 1.6326 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2477 - val_loss: 1.6324 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2569 - val_loss: 1.6323 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2569 - val_loss: 1.6322 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2018 - val_loss: 1.6321 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.1606 - val_loss: 1.6320 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2110 - val_loss: 1.6319 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2202 - val_loss: 1.6318 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2248 - val_loss: 1.6317 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2248 - val_loss: 1.6315 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2156 - val_loss: 1.6314 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2477 - val_loss: 1.6313 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6308 - accuracy: 0.2294 - val_loss: 1.6312 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2477 - val_loss: 1.6310 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2294 - val_loss: 1.6309 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.1972 - val_loss: 1.6307 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2477 - val_loss: 1.6306 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.1972 - val_loss: 1.6305 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2385 - val_loss: 1.6303 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2523 - val_loss: 1.6302 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2064 - val_loss: 1.6301 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2248 - val_loss: 1.6299 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2569 - val_loss: 1.6298 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2156 - val_loss: 1.6297 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6293 - accuracy: 0.2523 - val_loss: 1.6296 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2523 - val_loss: 1.6296 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2248 - val_loss: 1.6295 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2064 - val_loss: 1.6294 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2248 - val_loss: 1.6293 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2202 - val_loss: 1.6292 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2294 - val_loss: 1.6291 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2248 - val_loss: 1.6290 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2202 - val_loss: 1.6288 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2110 - val_loss: 1.6286 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2339 - val_loss: 1.6285 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2431 - val_loss: 1.6283 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2248 - val_loss: 1.6283 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2477 - val_loss: 1.6282 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2018 - val_loss: 1.6281 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 48ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2385 - val_loss: 1.6281 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2477 - val_loss: 1.6280 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2569 - val_loss: 1.6279 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2248 - val_loss: 1.6278 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2477 - val_loss: 1.6277 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6242 - accuracy: 0.2202 - val_loss: 1.6276 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2615 - val_loss: 1.6275 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2202 - val_loss: 1.6273 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2431 - val_loss: 1.6272 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.1972 - val_loss: 1.6271 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2339 - val_loss: 1.6270 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2156 - val_loss: 1.6269 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2477 - val_loss: 1.6269 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6217 - accuracy: 0.2431 - val_loss: 1.6267 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2385 - val_loss: 1.6266 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2385 - val_loss: 1.6266 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.2156 - val_loss: 1.6265 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2202 - val_loss: 1.6263 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2018 - val_loss: 1.6263 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6217 - accuracy: 0.2385 - val_loss: 1.6262 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2248 - val_loss: 1.6261 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6193 - accuracy: 0.2477 - val_loss: 1.6260 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2339 - val_loss: 1.6259 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6227 - accuracy: 0.2615 - val_loss: 1.6258 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6203 - accuracy: 0.2569 - val_loss: 1.6258 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2615 - val_loss: 1.6257 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2294 - val_loss: 1.6256 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2523 - val_loss: 1.6256 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2523 - val_loss: 1.6255 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2018 - val_loss: 1.6254 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2569 - val_loss: 1.6253 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2569 - val_loss: 1.6253 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2294 - val_loss: 1.6252 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6244 - accuracy: 0.1927 - val_loss: 1.6252 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2339 - val_loss: 1.6252 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2294 - val_loss: 1.6251 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2064 - val_loss: 1.6251 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6163 - accuracy: 0.2339 - val_loss: 1.6250 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2248 - val_loss: 1.6250 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2156 - val_loss: 1.6250 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6189 - accuracy: 0.2706 - val_loss: 1.6249 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2064 - val_loss: 1.6249 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2110 - val_loss: 1.6248 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6226 - accuracy: 0.2110 - val_loss: 1.6248 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6173 - accuracy: 0.2523 - val_loss: 1.6248 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2018 - val_loss: 1.6247 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 46ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2385 - val_loss: 1.6247 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2615 - val_loss: 1.6246 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Node 24 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6602 - accuracy: 0.1835 - val_loss: 1.6591 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 3s/epoch - 198ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6596 - accuracy: 0.2064 - val_loss: 1.6584 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6574 - accuracy: 0.2248 - val_loss: 1.6577 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6580 - accuracy: 0.2248 - val_loss: 1.6571 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6573 - accuracy: 0.1789 - val_loss: 1.6563 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6541 - accuracy: 0.2752 - val_loss: 1.6557 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6544 - accuracy: 0.2064 - val_loss: 1.6551 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6539 - accuracy: 0.1835 - val_loss: 1.6543 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6524 - accuracy: 0.2385 - val_loss: 1.6537 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6515 - accuracy: 0.2018 - val_loss: 1.6532 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6506 - accuracy: 0.2431 - val_loss: 1.6528 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6510 - accuracy: 0.1927 - val_loss: 1.6524 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6507 - accuracy: 0.2110 - val_loss: 1.6518 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6487 - accuracy: 0.1927 - val_loss: 1.6513 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6470 - accuracy: 0.2615 - val_loss: 1.6507 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6449 - accuracy: 0.2294 - val_loss: 1.6503 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6438 - accuracy: 0.2294 - val_loss: 1.6499 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6461 - accuracy: 0.2110 - val_loss: 1.6495 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6431 - accuracy: 0.2523 - val_loss: 1.6491 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6425 - accuracy: 0.2523 - val_loss: 1.6487 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6447 - accuracy: 0.2064 - val_loss: 1.6482 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6428 - accuracy: 0.2431 - val_loss: 1.6479 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6411 - accuracy: 0.2294 - val_loss: 1.6474 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6414 - accuracy: 0.2385 - val_loss: 1.6471 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6405 - accuracy: 0.2156 - val_loss: 1.6466 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6412 - accuracy: 0.2294 - val_loss: 1.6462 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6381 - accuracy: 0.2202 - val_loss: 1.6458 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6363 - accuracy: 0.2569 - val_loss: 1.6455 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6359 - accuracy: 0.2752 - val_loss: 1.6452 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6352 - accuracy: 0.2661 - val_loss: 1.6450 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6383 - accuracy: 0.2431 - val_loss: 1.6446 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6369 - accuracy: 0.2339 - val_loss: 1.6443 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6376 - accuracy: 0.2110 - val_loss: 1.6442 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6353 - accuracy: 0.2477 - val_loss: 1.6439 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2615 - val_loss: 1.6435 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6379 - accuracy: 0.2248 - val_loss: 1.6432 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2385 - val_loss: 1.6430 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6356 - accuracy: 0.2385 - val_loss: 1.6427 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6317 - accuracy: 0.2431 - val_loss: 1.6424 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6297 - accuracy: 0.2569 - val_loss: 1.6421 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6302 - accuracy: 0.2385 - val_loss: 1.6418 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6288 - accuracy: 0.2798 - val_loss: 1.6416 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2431 - val_loss: 1.6416 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6305 - accuracy: 0.2431 - val_loss: 1.6413 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6265 - accuracy: 0.2523 - val_loss: 1.6413 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2339 - val_loss: 1.6411 - val_accuracy: 0.1273 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2752 - val_loss: 1.6411 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2431 - val_loss: 1.6406 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6252 - accuracy: 0.2615 - val_loss: 1.6405 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6283 - accuracy: 0.2064 - val_loss: 1.6404 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6252 - accuracy: 0.2752 - val_loss: 1.6402 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2706 - val_loss: 1.6400 - val_accuracy: 0.1273 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2890 - val_loss: 1.6400 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2431 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6228 - accuracy: 0.2431 - val_loss: 1.6398 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2798 - val_loss: 1.6398 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2752 - val_loss: 1.6397 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2661 - val_loss: 1.6397 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2706 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6184 - accuracy: 0.2477 - val_loss: 1.6398 - val_accuracy: 0.1455 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6185 - accuracy: 0.2431 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2844 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 2.5000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6146 - accuracy: 0.3165 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 2.5000e-05 - 63ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6135 - accuracy: 0.2569 - val_loss: 1.6399 - val_accuracy: 0.1455 - lr: 2.5000e-05 - 65ms/epoch - 5ms/step\n",
      "Node 24 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6593 - accuracy: 0.2110 - val_loss: 1.6600 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 3s/epoch - 401ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6606 - accuracy: 0.1789 - val_loss: 1.6596 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6589 - accuracy: 0.2339 - val_loss: 1.6591 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6590 - accuracy: 0.1881 - val_loss: 1.6587 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6578 - accuracy: 0.2018 - val_loss: 1.6583 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6563 - accuracy: 0.1835 - val_loss: 1.6580 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6558 - accuracy: 0.2431 - val_loss: 1.6577 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6570 - accuracy: 0.2110 - val_loss: 1.6573 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6552 - accuracy: 0.2294 - val_loss: 1.6569 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6552 - accuracy: 0.2110 - val_loss: 1.6565 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2569 - val_loss: 1.6562 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6540 - accuracy: 0.2431 - val_loss: 1.6559 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6522 - accuracy: 0.2936 - val_loss: 1.6557 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6537 - accuracy: 0.1972 - val_loss: 1.6554 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6521 - accuracy: 0.2615 - val_loss: 1.6551 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.1376 - val_loss: 1.6548 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6537 - accuracy: 0.2248 - val_loss: 1.6546 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6482 - accuracy: 0.2706 - val_loss: 1.6543 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6513 - accuracy: 0.2018 - val_loss: 1.6539 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6515 - accuracy: 0.2339 - val_loss: 1.6536 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6516 - accuracy: 0.1835 - val_loss: 1.6533 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6497 - accuracy: 0.1789 - val_loss: 1.6531 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6483 - accuracy: 0.2661 - val_loss: 1.6528 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6487 - accuracy: 0.2569 - val_loss: 1.6525 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6498 - accuracy: 0.2110 - val_loss: 1.6521 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6462 - accuracy: 0.2752 - val_loss: 1.6518 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6478 - accuracy: 0.2523 - val_loss: 1.6516 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6473 - accuracy: 0.2339 - val_loss: 1.6513 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6455 - accuracy: 0.2661 - val_loss: 1.6511 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6461 - accuracy: 0.2339 - val_loss: 1.6508 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6443 - accuracy: 0.2615 - val_loss: 1.6505 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6457 - accuracy: 0.2431 - val_loss: 1.6503 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6461 - accuracy: 0.2156 - val_loss: 1.6500 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6462 - accuracy: 0.2018 - val_loss: 1.6497 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6443 - accuracy: 0.2431 - val_loss: 1.6494 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6425 - accuracy: 0.2248 - val_loss: 1.6492 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6424 - accuracy: 0.2477 - val_loss: 1.6490 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6445 - accuracy: 0.2431 - val_loss: 1.6487 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6431 - accuracy: 0.2569 - val_loss: 1.6485 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2248 - val_loss: 1.6483 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6433 - accuracy: 0.2339 - val_loss: 1.6480 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6425 - accuracy: 0.2248 - val_loss: 1.6478 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6431 - accuracy: 0.2110 - val_loss: 1.6475 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6436 - accuracy: 0.2248 - val_loss: 1.6474 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6372 - accuracy: 0.2752 - val_loss: 1.6472 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.2569 - val_loss: 1.6470 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2615 - val_loss: 1.6467 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6403 - accuracy: 0.2156 - val_loss: 1.6465 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2615 - val_loss: 1.6464 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6365 - accuracy: 0.2706 - val_loss: 1.6462 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6376 - accuracy: 0.2248 - val_loss: 1.6461 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6370 - accuracy: 0.2156 - val_loss: 1.6460 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6365 - accuracy: 0.2982 - val_loss: 1.6458 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 64ms/epoch - 9ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6400 - accuracy: 0.2156 - val_loss: 1.6456 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6402 - accuracy: 0.2294 - val_loss: 1.6455 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6358 - accuracy: 0.2385 - val_loss: 1.6452 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6355 - accuracy: 0.2018 - val_loss: 1.6450 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6369 - accuracy: 0.2615 - val_loss: 1.6448 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2615 - val_loss: 1.6447 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2890 - val_loss: 1.6446 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2844 - val_loss: 1.6444 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2339 - val_loss: 1.6443 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.2890 - val_loss: 1.6443 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2569 - val_loss: 1.6442 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2431 - val_loss: 1.6442 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2615 - val_loss: 1.6439 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2798 - val_loss: 1.6438 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2569 - val_loss: 1.6436 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2706 - val_loss: 1.6434 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2661 - val_loss: 1.6433 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2661 - val_loss: 1.6432 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2202 - val_loss: 1.6431 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2064 - val_loss: 1.6431 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.3028 - val_loss: 1.6431 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6308 - accuracy: 0.2661 - val_loss: 1.6431 - val_accuracy: 0.3091 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2661 - val_loss: 1.6430 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2615 - val_loss: 1.6430 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2248 - val_loss: 1.6430 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2661 - val_loss: 1.6429 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 42ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6282 - accuracy: 0.2156 - val_loss: 1.6428 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2706 - val_loss: 1.6428 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2890 - val_loss: 1.6428 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 48ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2569 - val_loss: 1.6427 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2339 - val_loss: 1.6426 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2752 - val_loss: 1.6426 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2661 - val_loss: 1.6425 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2615 - val_loss: 1.6424 - val_accuracy: 0.2909 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2752 - val_loss: 1.6424 - val_accuracy: 0.2909 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2890 - val_loss: 1.6423 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2615 - val_loss: 1.6423 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 42ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2523 - val_loss: 1.6422 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2569 - val_loss: 1.6422 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2661 - val_loss: 1.6421 - val_accuracy: 0.3273 - lr: 5.0000e-05 - 42ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2156 - val_loss: 1.6421 - val_accuracy: 0.3091 - lr: 5.0000e-05 - 42ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2706 - val_loss: 1.6421 - val_accuracy: 0.3091 - lr: 2.5000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6219 - accuracy: 0.2661 - val_loss: 1.6421 - val_accuracy: 0.3091 - lr: 2.5000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2706 - val_loss: 1.6422 - val_accuracy: 0.3273 - lr: 2.5000e-05 - 43ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2752 - val_loss: 1.6421 - val_accuracy: 0.3455 - lr: 1.2500e-05 - 42ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2936 - val_loss: 1.6421 - val_accuracy: 0.3273 - lr: 1.2500e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2569 - val_loss: 1.6421 - val_accuracy: 0.3455 - lr: 1.2500e-05 - 65ms/epoch - 9ms/step\n",
      "Node 24 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 24 - Best Validation Accuracy: 0.3455\n",
      "Best model saved for Node 24 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_24.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_25_dataset.csv\n",
      "Node 25 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6346 - accuracy: 0.2237 - val_loss: 1.6351 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 2s/epoch - 163ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.2149 - val_loss: 1.6346 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.2193 - val_loss: 1.6339 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.2456 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2149 - val_loss: 1.6329 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.1974 - val_loss: 1.6325 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6319 - accuracy: 0.2588 - val_loss: 1.6320 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2281 - val_loss: 1.6315 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2544 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2061 - val_loss: 1.6308 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2544 - val_loss: 1.6304 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2500 - val_loss: 1.6300 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2719 - val_loss: 1.6292 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2368 - val_loss: 1.6288 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2456 - val_loss: 1.6285 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2237 - val_loss: 1.6284 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2412 - val_loss: 1.6281 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2237 - val_loss: 1.6279 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2281 - val_loss: 1.6275 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2368 - val_loss: 1.6272 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2325 - val_loss: 1.6269 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2281 - val_loss: 1.6265 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2456 - val_loss: 1.6263 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2368 - val_loss: 1.6261 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2281 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2237 - val_loss: 1.6256 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2456 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2588 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2368 - val_loss: 1.6249 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2368 - val_loss: 1.6247 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2368 - val_loss: 1.6245 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2281 - val_loss: 1.6243 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2456 - val_loss: 1.6241 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2281 - val_loss: 1.6239 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2237 - val_loss: 1.6237 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2325 - val_loss: 1.6236 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2368 - val_loss: 1.6234 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6238 - accuracy: 0.2237 - val_loss: 1.6234 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6152 - accuracy: 0.2281 - val_loss: 1.6233 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2281 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2368 - val_loss: 1.6230 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2237 - val_loss: 1.6228 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2368 - val_loss: 1.6227 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2412 - val_loss: 1.6226 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2325 - val_loss: 1.6224 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2281 - val_loss: 1.6221 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2412 - val_loss: 1.6219 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2281 - val_loss: 1.6216 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2281 - val_loss: 1.6215 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6099 - accuracy: 0.2325 - val_loss: 1.6213 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2193 - val_loss: 1.6212 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2368 - val_loss: 1.6210 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2544 - val_loss: 1.6208 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2281 - val_loss: 1.6206 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2325 - val_loss: 1.6205 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2456 - val_loss: 1.6205 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2412 - val_loss: 1.6204 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2456 - val_loss: 1.6203 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2456 - val_loss: 1.6200 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2412 - val_loss: 1.6200 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2412 - val_loss: 1.6197 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2061 - val_loss: 1.6196 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2325 - val_loss: 1.6195 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2368 - val_loss: 1.6194 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2500 - val_loss: 1.6194 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2456 - val_loss: 1.6193 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6158 - accuracy: 0.2412 - val_loss: 1.6192 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2632 - val_loss: 1.6190 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2456 - val_loss: 1.6188 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6110 - accuracy: 0.2281 - val_loss: 1.6187 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2456 - val_loss: 1.6186 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2588 - val_loss: 1.6184 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.2237 - val_loss: 1.6183 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2412 - val_loss: 1.6182 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2237 - val_loss: 1.6181 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2412 - val_loss: 1.6180 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6085 - accuracy: 0.2412 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6116 - accuracy: 0.2237 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2500 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6126 - accuracy: 0.2281 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6050 - accuracy: 0.2500 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2456 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2368 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6118 - accuracy: 0.2281 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2500 - val_loss: 1.6179 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2325 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6112 - accuracy: 0.2544 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2237 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2544 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2500 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6137 - accuracy: 0.2281 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2412 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2193 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.2368 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2368 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2149 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6053 - accuracy: 0.2456 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 3.1250e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2544 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 1.5625e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6098 - accuracy: 0.2412 - val_loss: 1.6178 - val_accuracy: 0.2281 - lr: 1.5625e-06 - 46ms/epoch - 3ms/step\n",
      "Node 25 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6355 - accuracy: 0.1930 - val_loss: 1.6361 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 3s/epoch - 361ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2281 - val_loss: 1.6358 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.1886 - val_loss: 1.6356 - val_accuracy: 0.2456 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.1886 - val_loss: 1.6353 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2237 - val_loss: 1.6351 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1930 - val_loss: 1.6348 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.1930 - val_loss: 1.6346 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2368 - val_loss: 1.6343 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2412 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2281 - val_loss: 1.6339 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2061 - val_loss: 1.6336 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2061 - val_loss: 1.6333 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2544 - val_loss: 1.6331 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2325 - val_loss: 1.6329 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2149 - val_loss: 1.6327 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2149 - val_loss: 1.6325 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2105 - val_loss: 1.6323 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2061 - val_loss: 1.6320 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.1886 - val_loss: 1.6318 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2632 - val_loss: 1.6316 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.1798 - val_loss: 1.6314 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2105 - val_loss: 1.6312 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.1974 - val_loss: 1.6311 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.1798 - val_loss: 1.6310 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.1930 - val_loss: 1.6309 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2149 - val_loss: 1.6308 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.1930 - val_loss: 1.6305 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2281 - val_loss: 1.6303 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2281 - val_loss: 1.6301 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2061 - val_loss: 1.6299 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2281 - val_loss: 1.6297 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2368 - val_loss: 1.6295 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.1974 - val_loss: 1.6294 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2368 - val_loss: 1.6292 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.1623 - val_loss: 1.6291 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2588 - val_loss: 1.6290 - val_accuracy: 0.1579 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2105 - val_loss: 1.6287 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2149 - val_loss: 1.6285 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2588 - val_loss: 1.6284 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.1842 - val_loss: 1.6283 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2281 - val_loss: 1.6281 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2237 - val_loss: 1.6279 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2368 - val_loss: 1.6277 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.1930 - val_loss: 1.6275 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2105 - val_loss: 1.6273 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2500 - val_loss: 1.6272 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2500 - val_loss: 1.6271 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2456 - val_loss: 1.6269 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2193 - val_loss: 1.6268 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.1930 - val_loss: 1.6267 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.1886 - val_loss: 1.6265 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6264 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2675 - val_loss: 1.6262 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2456 - val_loss: 1.6261 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2237 - val_loss: 1.6261 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2149 - val_loss: 1.6260 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2675 - val_loss: 1.6259 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.1974 - val_loss: 1.6258 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2719 - val_loss: 1.6256 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2061 - val_loss: 1.6254 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2632 - val_loss: 1.6253 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2018 - val_loss: 1.6252 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2237 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2544 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2281 - val_loss: 1.6251 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2061 - val_loss: 1.6250 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2500 - val_loss: 1.6248 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2193 - val_loss: 1.6247 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2281 - val_loss: 1.6246 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2193 - val_loss: 1.6245 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2193 - val_loss: 1.6244 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2412 - val_loss: 1.6244 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2544 - val_loss: 1.6243 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2632 - val_loss: 1.6242 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2325 - val_loss: 1.6241 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2456 - val_loss: 1.6241 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2456 - val_loss: 1.6239 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2719 - val_loss: 1.6238 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2544 - val_loss: 1.6236 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2325 - val_loss: 1.6235 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2061 - val_loss: 1.6234 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2149 - val_loss: 1.6232 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2368 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2588 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2018 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2193 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2412 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2368 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2412 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2193 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2368 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6121 - accuracy: 0.2325 - val_loss: 1.6231 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Node 25 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6574 - accuracy: 0.2018 - val_loss: 1.6598 - val_accuracy: 0.1228 - lr: 1.0000e-04 - 3s/epoch - 167ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6588 - accuracy: 0.2456 - val_loss: 1.6588 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6561 - accuracy: 0.2105 - val_loss: 1.6578 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6549 - accuracy: 0.2851 - val_loss: 1.6569 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6539 - accuracy: 0.2632 - val_loss: 1.6562 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6529 - accuracy: 0.2500 - val_loss: 1.6555 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6500 - accuracy: 0.2632 - val_loss: 1.6545 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6511 - accuracy: 0.2281 - val_loss: 1.6536 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6495 - accuracy: 0.2281 - val_loss: 1.6527 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6492 - accuracy: 0.1974 - val_loss: 1.6518 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6492 - accuracy: 0.2632 - val_loss: 1.6512 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6461 - accuracy: 0.2412 - val_loss: 1.6505 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6443 - accuracy: 0.2412 - val_loss: 1.6499 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2237 - val_loss: 1.6491 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2281 - val_loss: 1.6485 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6440 - accuracy: 0.2456 - val_loss: 1.6478 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6406 - accuracy: 0.2281 - val_loss: 1.6471 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6430 - accuracy: 0.2632 - val_loss: 1.6465 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6429 - accuracy: 0.2237 - val_loss: 1.6461 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6422 - accuracy: 0.2412 - val_loss: 1.6457 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6391 - accuracy: 0.2368 - val_loss: 1.6453 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6373 - accuracy: 0.2368 - val_loss: 1.6449 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6373 - accuracy: 0.2456 - val_loss: 1.6447 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6362 - accuracy: 0.2368 - val_loss: 1.6443 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6360 - accuracy: 0.2544 - val_loss: 1.6439 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6395 - accuracy: 0.2325 - val_loss: 1.6434 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6355 - accuracy: 0.2412 - val_loss: 1.6430 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6374 - accuracy: 0.2500 - val_loss: 1.6427 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2325 - val_loss: 1.6423 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2412 - val_loss: 1.6419 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2412 - val_loss: 1.6416 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2368 - val_loss: 1.6415 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2325 - val_loss: 1.6414 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2368 - val_loss: 1.6412 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2281 - val_loss: 1.6410 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2632 - val_loss: 1.6405 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2237 - val_loss: 1.6401 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2588 - val_loss: 1.6398 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2456 - val_loss: 1.6395 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2412 - val_loss: 1.6392 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2500 - val_loss: 1.6388 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2500 - val_loss: 1.6388 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2325 - val_loss: 1.6388 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2368 - val_loss: 1.6385 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2325 - val_loss: 1.6384 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.2149 - val_loss: 1.6383 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.2193 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2456 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2544 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6135 - accuracy: 0.2544 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 89ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2368 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2456 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2456 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2412 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2368 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2544 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2412 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2544 - val_loss: 1.6380 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2412 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2412 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 69ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2588 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6166 - accuracy: 0.2719 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 6.2500e-06 - 67ms/epoch - 4ms/step\n",
      "Node 25 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6597 - accuracy: 0.2281 - val_loss: 1.6587 - val_accuracy: 0.1930 - lr: 1.0000e-04 - 3s/epoch - 360ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6596 - accuracy: 0.2193 - val_loss: 1.6582 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6574 - accuracy: 0.2193 - val_loss: 1.6578 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.1754 - val_loss: 1.6574 - val_accuracy: 0.1754 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2588 - val_loss: 1.6567 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.1974 - val_loss: 1.6561 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.1974 - val_loss: 1.6555 - val_accuracy: 0.3158 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6539 - accuracy: 0.2018 - val_loss: 1.6549 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2149 - val_loss: 1.6544 - val_accuracy: 0.2632 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2325 - val_loss: 1.6539 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2368 - val_loss: 1.6533 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2061 - val_loss: 1.6527 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2368 - val_loss: 1.6521 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2325 - val_loss: 1.6516 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6521 - accuracy: 0.2368 - val_loss: 1.6512 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2325 - val_loss: 1.6507 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6499 - accuracy: 0.2193 - val_loss: 1.6504 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.2763 - val_loss: 1.6499 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2456 - val_loss: 1.6495 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2368 - val_loss: 1.6490 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2588 - val_loss: 1.6488 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2281 - val_loss: 1.6484 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2456 - val_loss: 1.6481 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2588 - val_loss: 1.6477 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2368 - val_loss: 1.6473 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2368 - val_loss: 1.6469 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2368 - val_loss: 1.6466 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2368 - val_loss: 1.6463 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2325 - val_loss: 1.6459 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2325 - val_loss: 1.6455 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2368 - val_loss: 1.6452 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2325 - val_loss: 1.6448 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2237 - val_loss: 1.6445 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2281 - val_loss: 1.6442 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2281 - val_loss: 1.6439 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.2368 - val_loss: 1.6438 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2149 - val_loss: 1.6434 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2281 - val_loss: 1.6431 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2281 - val_loss: 1.6427 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6370 - accuracy: 0.2325 - val_loss: 1.6425 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2544 - val_loss: 1.6424 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2544 - val_loss: 1.6423 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2325 - val_loss: 1.6421 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.2325 - val_loss: 1.6421 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2368 - val_loss: 1.6419 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2368 - val_loss: 1.6415 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2368 - val_loss: 1.6411 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2325 - val_loss: 1.6407 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2149 - val_loss: 1.6404 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2544 - val_loss: 1.6401 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 72ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2412 - val_loss: 1.6400 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2281 - val_loss: 1.6398 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2456 - val_loss: 1.6395 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2325 - val_loss: 1.6392 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2325 - val_loss: 1.6389 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2412 - val_loss: 1.6387 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2412 - val_loss: 1.6385 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2237 - val_loss: 1.6383 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2588 - val_loss: 1.6383 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2412 - val_loss: 1.6381 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2412 - val_loss: 1.6379 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2456 - val_loss: 1.6377 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2368 - val_loss: 1.6373 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2544 - val_loss: 1.6369 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2544 - val_loss: 1.6367 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2544 - val_loss: 1.6365 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2237 - val_loss: 1.6363 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2412 - val_loss: 1.6361 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2368 - val_loss: 1.6360 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2281 - val_loss: 1.6359 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2368 - val_loss: 1.6357 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2193 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2281 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2588 - val_loss: 1.6356 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2281 - val_loss: 1.6355 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2368 - val_loss: 1.6354 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2588 - val_loss: 1.6353 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2193 - val_loss: 1.6352 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2456 - val_loss: 1.6352 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2325 - val_loss: 1.6350 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2588 - val_loss: 1.6349 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2807 - val_loss: 1.6348 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2588 - val_loss: 1.6348 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2368 - val_loss: 1.6346 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2544 - val_loss: 1.6346 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2719 - val_loss: 1.6344 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2368 - val_loss: 1.6344 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2412 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2544 - val_loss: 1.6340 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2281 - val_loss: 1.6339 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2456 - val_loss: 1.6337 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2149 - val_loss: 1.6335 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2368 - val_loss: 1.6334 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2105 - val_loss: 1.6332 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2149 - val_loss: 1.6330 - val_accuracy: 0.2281 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2675 - val_loss: 1.6328 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2325 - val_loss: 1.6328 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 71ms/epoch - 9ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2105 - val_loss: 1.6328 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2456 - val_loss: 1.6328 - val_accuracy: 0.2105 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Node 25 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 25 - Best Validation Accuracy: 0.3158\n",
      "Best model saved for Node 25 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_25.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_26_dataset.csv\n",
      "Node 26 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6360 - accuracy: 0.1991 - val_loss: 1.6344 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 3s/epoch - 218ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6333 - accuracy: 0.2269 - val_loss: 1.6342 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6342 - accuracy: 0.2361 - val_loss: 1.6338 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6350 - accuracy: 0.2130 - val_loss: 1.6336 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6335 - accuracy: 0.2500 - val_loss: 1.6333 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6359 - accuracy: 0.1991 - val_loss: 1.6331 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6343 - accuracy: 0.2130 - val_loss: 1.6328 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6321 - accuracy: 0.2222 - val_loss: 1.6325 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6331 - accuracy: 0.2222 - val_loss: 1.6322 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6328 - accuracy: 0.2269 - val_loss: 1.6320 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2269 - val_loss: 1.6317 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6305 - accuracy: 0.2315 - val_loss: 1.6314 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2269 - val_loss: 1.6311 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2407 - val_loss: 1.6308 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6300 - accuracy: 0.2361 - val_loss: 1.6306 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2315 - val_loss: 1.6304 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6310 - accuracy: 0.2222 - val_loss: 1.6300 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6297 - accuracy: 0.2083 - val_loss: 1.6298 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6304 - accuracy: 0.2176 - val_loss: 1.6297 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6307 - accuracy: 0.2361 - val_loss: 1.6295 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6315 - accuracy: 0.2222 - val_loss: 1.6293 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6293 - accuracy: 0.2315 - val_loss: 1.6291 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2222 - val_loss: 1.6288 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6273 - accuracy: 0.2407 - val_loss: 1.6285 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6288 - accuracy: 0.2315 - val_loss: 1.6282 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2361 - val_loss: 1.6281 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2407 - val_loss: 1.6279 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6267 - accuracy: 0.2315 - val_loss: 1.6276 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2269 - val_loss: 1.6274 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2269 - val_loss: 1.6274 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6247 - accuracy: 0.2454 - val_loss: 1.6272 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6209 - accuracy: 0.2361 - val_loss: 1.6271 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2269 - val_loss: 1.6268 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6236 - accuracy: 0.2315 - val_loss: 1.6266 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2222 - val_loss: 1.6263 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2130 - val_loss: 1.6260 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6219 - accuracy: 0.2361 - val_loss: 1.6258 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2361 - val_loss: 1.6257 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6267 - accuracy: 0.2315 - val_loss: 1.6256 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.2176 - val_loss: 1.6254 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6276 - accuracy: 0.2315 - val_loss: 1.6251 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6232 - accuracy: 0.2315 - val_loss: 1.6250 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6234 - accuracy: 0.2315 - val_loss: 1.6249 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2315 - val_loss: 1.6247 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2546 - val_loss: 1.6246 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6235 - accuracy: 0.2361 - val_loss: 1.6245 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2269 - val_loss: 1.6244 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2315 - val_loss: 1.6241 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2222 - val_loss: 1.6240 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2269 - val_loss: 1.6238 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6221 - accuracy: 0.2269 - val_loss: 1.6236 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6233 - accuracy: 0.2269 - val_loss: 1.6235 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6226 - accuracy: 0.2269 - val_loss: 1.6234 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2454 - val_loss: 1.6233 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6228 - accuracy: 0.2315 - val_loss: 1.6231 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2315 - val_loss: 1.6229 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2361 - val_loss: 1.6226 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2222 - val_loss: 1.6225 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6195 - accuracy: 0.2315 - val_loss: 1.6225 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2454 - val_loss: 1.6225 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.2315 - val_loss: 1.6223 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2315 - val_loss: 1.6222 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2361 - val_loss: 1.6222 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6218 - accuracy: 0.2269 - val_loss: 1.6220 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2454 - val_loss: 1.6219 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2315 - val_loss: 1.6218 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2269 - val_loss: 1.6218 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2361 - val_loss: 1.6216 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6172 - accuracy: 0.2361 - val_loss: 1.6215 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6192 - accuracy: 0.2361 - val_loss: 1.6213 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2546 - val_loss: 1.6212 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6142 - accuracy: 0.2361 - val_loss: 1.6210 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2315 - val_loss: 1.6209 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2222 - val_loss: 1.6209 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.1991 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2176 - val_loss: 1.6208 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2407 - val_loss: 1.6206 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6139 - accuracy: 0.2685 - val_loss: 1.6204 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6144 - accuracy: 0.2222 - val_loss: 1.6204 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6180 - accuracy: 0.2407 - val_loss: 1.6205 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2037 - val_loss: 1.6204 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2315 - val_loss: 1.6203 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6142 - accuracy: 0.2407 - val_loss: 1.6203 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6149 - accuracy: 0.2269 - val_loss: 1.6202 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2315 - val_loss: 1.6201 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2222 - val_loss: 1.6201 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2546 - val_loss: 1.6200 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2222 - val_loss: 1.6200 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6122 - accuracy: 0.2546 - val_loss: 1.6199 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2315 - val_loss: 1.6200 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2500 - val_loss: 1.6199 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6173 - accuracy: 0.2083 - val_loss: 1.6199 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2130 - val_loss: 1.6198 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6177 - accuracy: 0.2546 - val_loss: 1.6198 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2176 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2222 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "14/14 - 0s - loss: 1.6114 - accuracy: 0.2176 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6140 - accuracy: 0.2361 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2546 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.2269 - val_loss: 1.6197 - val_accuracy: 0.2407 - lr: 1.2500e-05 - 49ms/epoch - 4ms/step\n",
      "Node 26 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6364 - accuracy: 0.1991 - val_loss: 1.6344 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 3s/epoch - 363ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2083 - val_loss: 1.6342 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.2083 - val_loss: 1.6341 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2130 - val_loss: 1.6339 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 22ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2315 - val_loss: 1.6337 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6339 - accuracy: 0.2037 - val_loss: 1.6336 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2176 - val_loss: 1.6334 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2222 - val_loss: 1.6332 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.1991 - val_loss: 1.6330 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2731 - val_loss: 1.6328 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.1898 - val_loss: 1.6327 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.2269 - val_loss: 1.6325 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2037 - val_loss: 1.6323 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2222 - val_loss: 1.6321 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6325 - accuracy: 0.2222 - val_loss: 1.6320 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.1898 - val_loss: 1.6319 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2269 - val_loss: 1.6317 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6304 - accuracy: 0.2269 - val_loss: 1.6317 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.1944 - val_loss: 1.6317 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2454 - val_loss: 1.6316 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2176 - val_loss: 1.6316 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.1944 - val_loss: 1.6315 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2176 - val_loss: 1.6314 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.1944 - val_loss: 1.6314 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6305 - accuracy: 0.2037 - val_loss: 1.6313 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2083 - val_loss: 1.6313 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2222 - val_loss: 1.6312 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.1852 - val_loss: 1.6311 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2269 - val_loss: 1.6310 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2222 - val_loss: 1.6309 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2454 - val_loss: 1.6308 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2130 - val_loss: 1.6308 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2639 - val_loss: 1.6307 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2269 - val_loss: 1.6306 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2176 - val_loss: 1.6306 - val_accuracy: 0.1667 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2083 - val_loss: 1.6305 - val_accuracy: 0.1667 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2083 - val_loss: 1.6305 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2315 - val_loss: 1.6304 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2361 - val_loss: 1.6304 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2361 - val_loss: 1.6303 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2315 - val_loss: 1.6302 - val_accuracy: 0.1296 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2454 - val_loss: 1.6302 - val_accuracy: 0.1296 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.1991 - val_loss: 1.6301 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2593 - val_loss: 1.6301 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.1806 - val_loss: 1.6300 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6293 - accuracy: 0.2222 - val_loss: 1.6299 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2454 - val_loss: 1.6299 - val_accuracy: 0.1296 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2454 - val_loss: 1.6298 - val_accuracy: 0.1111 - lr: 5.0000e-05 - 47ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2222 - val_loss: 1.6297 - val_accuracy: 0.1481 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2593 - val_loss: 1.6296 - val_accuracy: 0.1667 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2083 - val_loss: 1.6296 - val_accuracy: 0.1667 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2917 - val_loss: 1.6295 - val_accuracy: 0.1667 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2963 - val_loss: 1.6294 - val_accuracy: 0.1852 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2037 - val_loss: 1.6293 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2315 - val_loss: 1.6291 - val_accuracy: 0.2037 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2685 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2176 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2130 - val_loss: 1.6289 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.1806 - val_loss: 1.6289 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2500 - val_loss: 1.6289 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.1991 - val_loss: 1.6288 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2315 - val_loss: 1.6287 - val_accuracy: 0.2593 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6292 - accuracy: 0.2037 - val_loss: 1.6287 - val_accuracy: 0.2593 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2778 - val_loss: 1.6286 - val_accuracy: 0.2593 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2454 - val_loss: 1.6286 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6282 - accuracy: 0.2269 - val_loss: 1.6286 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2222 - val_loss: 1.6285 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6234 - accuracy: 0.2870 - val_loss: 1.6284 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2639 - val_loss: 1.6283 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2593 - val_loss: 1.6283 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2407 - val_loss: 1.6282 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2361 - val_loss: 1.6281 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2407 - val_loss: 1.6280 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 32ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6261 - accuracy: 0.2315 - val_loss: 1.6280 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2593 - val_loss: 1.6279 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2454 - val_loss: 1.6279 - val_accuracy: 0.2593 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2222 - val_loss: 1.6278 - val_accuracy: 0.2593 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2222 - val_loss: 1.6277 - val_accuracy: 0.2407 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2361 - val_loss: 1.6277 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2083 - val_loss: 1.6277 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2546 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 27ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2917 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2361 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2685 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6240 - accuracy: 0.2731 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6249 - accuracy: 0.2454 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2500 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2083 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 28ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2176 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2454 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 27ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.1759 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 28ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6243 - accuracy: 0.2315 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 28ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2407 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2361 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 6.2500e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2731 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 47ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6261 - accuracy: 0.1991 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 28ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "7/7 - 0s - loss: 1.6223 - accuracy: 0.2824 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 3.1250e-06 - 28ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2778 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 27ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.1759 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 27ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2407 - val_loss: 1.6275 - val_accuracy: 0.2222 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Node 26 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6607 - accuracy: 0.2037 - val_loss: 1.6599 - val_accuracy: 0.1852 - lr: 1.0000e-04 - 3s/epoch - 210ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6597 - accuracy: 0.2130 - val_loss: 1.6588 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6580 - accuracy: 0.2500 - val_loss: 1.6580 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6574 - accuracy: 0.2315 - val_loss: 1.6574 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6558 - accuracy: 0.2454 - val_loss: 1.6567 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6569 - accuracy: 0.1898 - val_loss: 1.6559 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6546 - accuracy: 0.2083 - val_loss: 1.6551 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6535 - accuracy: 0.2361 - val_loss: 1.6545 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6530 - accuracy: 0.1898 - val_loss: 1.6537 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6530 - accuracy: 0.2315 - val_loss: 1.6528 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6519 - accuracy: 0.2222 - val_loss: 1.6522 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6511 - accuracy: 0.2407 - val_loss: 1.6515 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6474 - accuracy: 0.2361 - val_loss: 1.6507 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6500 - accuracy: 0.1898 - val_loss: 1.6499 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6510 - accuracy: 0.2315 - val_loss: 1.6492 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6479 - accuracy: 0.2639 - val_loss: 1.6486 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6465 - accuracy: 0.2361 - val_loss: 1.6479 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6476 - accuracy: 0.2731 - val_loss: 1.6475 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6439 - accuracy: 0.2269 - val_loss: 1.6468 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6437 - accuracy: 0.2685 - val_loss: 1.6462 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6436 - accuracy: 0.2315 - val_loss: 1.6456 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6434 - accuracy: 0.2269 - val_loss: 1.6451 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6429 - accuracy: 0.2315 - val_loss: 1.6446 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6410 - accuracy: 0.2500 - val_loss: 1.6442 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6435 - accuracy: 0.2269 - val_loss: 1.6438 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6429 - accuracy: 0.2269 - val_loss: 1.6435 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6389 - accuracy: 0.2685 - val_loss: 1.6431 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6382 - accuracy: 0.2361 - val_loss: 1.6426 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6383 - accuracy: 0.2593 - val_loss: 1.6421 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6373 - accuracy: 0.2361 - val_loss: 1.6416 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6369 - accuracy: 0.2315 - val_loss: 1.6411 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6392 - accuracy: 0.2315 - val_loss: 1.6406 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6358 - accuracy: 0.2315 - val_loss: 1.6403 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6361 - accuracy: 0.2500 - val_loss: 1.6400 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6316 - accuracy: 0.2731 - val_loss: 1.6397 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6347 - accuracy: 0.2315 - val_loss: 1.6394 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6374 - accuracy: 0.2500 - val_loss: 1.6389 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6270 - accuracy: 0.2639 - val_loss: 1.6387 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6320 - accuracy: 0.2407 - val_loss: 1.6383 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6319 - accuracy: 0.2593 - val_loss: 1.6379 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6364 - accuracy: 0.2500 - val_loss: 1.6377 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6358 - accuracy: 0.2269 - val_loss: 1.6376 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6329 - accuracy: 0.2176 - val_loss: 1.6374 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6278 - accuracy: 0.2315 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6306 - accuracy: 0.2176 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2731 - val_loss: 1.6368 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6282 - accuracy: 0.2176 - val_loss: 1.6364 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6258 - accuracy: 0.2454 - val_loss: 1.6362 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6265 - accuracy: 0.2361 - val_loss: 1.6361 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 82ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2639 - val_loss: 1.6358 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2593 - val_loss: 1.6355 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2593 - val_loss: 1.6352 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6298 - accuracy: 0.2037 - val_loss: 1.6350 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2407 - val_loss: 1.6348 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6252 - accuracy: 0.2361 - val_loss: 1.6346 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6248 - accuracy: 0.2593 - val_loss: 1.6344 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6341 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2546 - val_loss: 1.6339 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2269 - val_loss: 1.6339 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2639 - val_loss: 1.6338 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2407 - val_loss: 1.6336 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6235 - accuracy: 0.2454 - val_loss: 1.6335 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2917 - val_loss: 1.6333 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2593 - val_loss: 1.6332 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6216 - accuracy: 0.2593 - val_loss: 1.6332 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2685 - val_loss: 1.6330 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2546 - val_loss: 1.6329 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2315 - val_loss: 1.6326 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.3056 - val_loss: 1.6325 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6137 - accuracy: 0.2870 - val_loss: 1.6323 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2685 - val_loss: 1.6322 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2685 - val_loss: 1.6321 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2778 - val_loss: 1.6322 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6127 - accuracy: 0.2500 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2824 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 57ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2593 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2778 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6142 - accuracy: 0.2500 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6166 - accuracy: 0.2500 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Node 26 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6620 - accuracy: 0.1574 - val_loss: 1.6612 - val_accuracy: 0.1481 - lr: 1.0000e-04 - 3s/epoch - 361ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6610 - accuracy: 0.1898 - val_loss: 1.6605 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6603 - accuracy: 0.1944 - val_loss: 1.6598 - val_accuracy: 0.2037 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6600 - accuracy: 0.2037 - val_loss: 1.6592 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6595 - accuracy: 0.1944 - val_loss: 1.6586 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6583 - accuracy: 0.1944 - val_loss: 1.6581 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6584 - accuracy: 0.2037 - val_loss: 1.6576 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6580 - accuracy: 0.1852 - val_loss: 1.6572 - val_accuracy: 0.2778 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6565 - accuracy: 0.2222 - val_loss: 1.6567 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6562 - accuracy: 0.2222 - val_loss: 1.6563 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6564 - accuracy: 0.1944 - val_loss: 1.6558 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6556 - accuracy: 0.2361 - val_loss: 1.6553 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6561 - accuracy: 0.2037 - val_loss: 1.6549 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6555 - accuracy: 0.2269 - val_loss: 1.6544 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6552 - accuracy: 0.2546 - val_loss: 1.6540 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6546 - accuracy: 0.2361 - val_loss: 1.6536 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6546 - accuracy: 0.2037 - val_loss: 1.6533 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6532 - accuracy: 0.2778 - val_loss: 1.6529 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6512 - accuracy: 0.2731 - val_loss: 1.6525 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6520 - accuracy: 0.2315 - val_loss: 1.6521 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6516 - accuracy: 0.2593 - val_loss: 1.6518 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6503 - accuracy: 0.2685 - val_loss: 1.6514 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6512 - accuracy: 0.2593 - val_loss: 1.6510 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6504 - accuracy: 0.2269 - val_loss: 1.6506 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6508 - accuracy: 0.2269 - val_loss: 1.6501 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6496 - accuracy: 0.2176 - val_loss: 1.6497 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6491 - accuracy: 0.2593 - val_loss: 1.6495 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6493 - accuracy: 0.2361 - val_loss: 1.6492 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2454 - val_loss: 1.6488 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6487 - accuracy: 0.2546 - val_loss: 1.6484 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6472 - accuracy: 0.1991 - val_loss: 1.6479 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6471 - accuracy: 0.2593 - val_loss: 1.6476 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6454 - accuracy: 0.2407 - val_loss: 1.6472 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6464 - accuracy: 0.2454 - val_loss: 1.6468 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6457 - accuracy: 0.2500 - val_loss: 1.6464 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6453 - accuracy: 0.2130 - val_loss: 1.6460 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6455 - accuracy: 0.2500 - val_loss: 1.6457 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6444 - accuracy: 0.2315 - val_loss: 1.6453 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6451 - accuracy: 0.2407 - val_loss: 1.6449 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6430 - accuracy: 0.2269 - val_loss: 1.6445 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6455 - accuracy: 0.2269 - val_loss: 1.6443 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6424 - accuracy: 0.2500 - val_loss: 1.6440 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6442 - accuracy: 0.2546 - val_loss: 1.6437 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6427 - accuracy: 0.2407 - val_loss: 1.6434 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6411 - accuracy: 0.2454 - val_loss: 1.6431 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6392 - accuracy: 0.2546 - val_loss: 1.6427 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2176 - val_loss: 1.6424 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6419 - accuracy: 0.2222 - val_loss: 1.6420 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2454 - val_loss: 1.6417 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6389 - accuracy: 0.2315 - val_loss: 1.6414 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6403 - accuracy: 0.2500 - val_loss: 1.6411 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 61ms/epoch - 9ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2176 - val_loss: 1.6408 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6368 - accuracy: 0.2593 - val_loss: 1.6404 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6377 - accuracy: 0.2130 - val_loss: 1.6401 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6371 - accuracy: 0.2269 - val_loss: 1.6398 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.2315 - val_loss: 1.6395 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6370 - accuracy: 0.2593 - val_loss: 1.6393 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6365 - accuracy: 0.2407 - val_loss: 1.6390 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6358 - accuracy: 0.2731 - val_loss: 1.6389 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.1991 - val_loss: 1.6387 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6367 - accuracy: 0.2269 - val_loss: 1.6385 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6369 - accuracy: 0.2454 - val_loss: 1.6382 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6349 - accuracy: 0.2361 - val_loss: 1.6380 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2824 - val_loss: 1.6378 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6377 - accuracy: 0.2407 - val_loss: 1.6376 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.2222 - val_loss: 1.6373 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6350 - accuracy: 0.2222 - val_loss: 1.6371 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2500 - val_loss: 1.6369 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6360 - accuracy: 0.2130 - val_loss: 1.6368 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2778 - val_loss: 1.6366 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6349 - accuracy: 0.2222 - val_loss: 1.6365 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2778 - val_loss: 1.6363 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2222 - val_loss: 1.6361 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2315 - val_loss: 1.6359 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6354 - accuracy: 0.2315 - val_loss: 1.6357 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2454 - val_loss: 1.6355 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.2731 - val_loss: 1.6355 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2269 - val_loss: 1.6355 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2639 - val_loss: 1.6354 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2685 - val_loss: 1.6352 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6305 - accuracy: 0.2222 - val_loss: 1.6350 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6305 - accuracy: 0.2037 - val_loss: 1.6348 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2778 - val_loss: 1.6346 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2407 - val_loss: 1.6344 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2315 - val_loss: 1.6342 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2176 - val_loss: 1.6341 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6339 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2639 - val_loss: 1.6337 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2222 - val_loss: 1.6336 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2731 - val_loss: 1.6334 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 39ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2407 - val_loss: 1.6333 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2639 - val_loss: 1.6330 - val_accuracy: 0.2407 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2917 - val_loss: 1.6329 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2593 - val_loss: 1.6328 - val_accuracy: 0.2593 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2361 - val_loss: 1.6329 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2824 - val_loss: 1.6328 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2361 - val_loss: 1.6326 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2361 - val_loss: 1.6324 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6200 - accuracy: 0.2731 - val_loss: 1.6322 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 62ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2546 - val_loss: 1.6321 - val_accuracy: 0.2963 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Node 26 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 26 - Best Validation Accuracy: 0.2963\n",
      "Best model saved for Node 26 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_26.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_27_dataset.csv\n",
      "Node 27 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6350 - accuracy: 0.1780 - val_loss: 1.6356 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 3s/epoch - 194ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.2076 - val_loss: 1.6354 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.1907 - val_loss: 1.6352 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.1949 - val_loss: 1.6349 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2076 - val_loss: 1.6349 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.1864 - val_loss: 1.6347 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.2203 - val_loss: 1.6345 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2415 - val_loss: 1.6343 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6333 - accuracy: 0.1907 - val_loss: 1.6340 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2246 - val_loss: 1.6337 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2500 - val_loss: 1.6336 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.1864 - val_loss: 1.6335 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2373 - val_loss: 1.6334 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.1822 - val_loss: 1.6332 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2246 - val_loss: 1.6330 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2585 - val_loss: 1.6329 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.1568 - val_loss: 1.6328 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2076 - val_loss: 1.6327 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.1949 - val_loss: 1.6325 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2542 - val_loss: 1.6323 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2500 - val_loss: 1.6321 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2203 - val_loss: 1.6319 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2203 - val_loss: 1.6317 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2246 - val_loss: 1.6315 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2288 - val_loss: 1.6313 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6310 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2797 - val_loss: 1.6309 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2161 - val_loss: 1.6308 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6251 - accuracy: 0.2373 - val_loss: 1.6307 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2119 - val_loss: 1.6306 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2458 - val_loss: 1.6305 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.1907 - val_loss: 1.6303 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2161 - val_loss: 1.6302 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.1992 - val_loss: 1.6300 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2458 - val_loss: 1.6298 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2373 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2627 - val_loss: 1.6294 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2585 - val_loss: 1.6292 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2331 - val_loss: 1.6291 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2542 - val_loss: 1.6289 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2542 - val_loss: 1.6287 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2331 - val_loss: 1.6285 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2203 - val_loss: 1.6284 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2373 - val_loss: 1.6283 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2119 - val_loss: 1.6282 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2203 - val_loss: 1.6280 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6212 - accuracy: 0.2246 - val_loss: 1.6279 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2246 - val_loss: 1.6277 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2500 - val_loss: 1.6276 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2712 - val_loss: 1.6276 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2627 - val_loss: 1.6276 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2373 - val_loss: 1.6273 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.3093 - val_loss: 1.6271 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2712 - val_loss: 1.6268 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2627 - val_loss: 1.6267 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2415 - val_loss: 1.6266 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2161 - val_loss: 1.6265 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.1907 - val_loss: 1.6262 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2373 - val_loss: 1.6261 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2034 - val_loss: 1.6260 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2881 - val_loss: 1.6260 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2627 - val_loss: 1.6259 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2331 - val_loss: 1.6259 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2627 - val_loss: 1.6258 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2585 - val_loss: 1.6257 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2754 - val_loss: 1.6256 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2669 - val_loss: 1.6257 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2331 - val_loss: 1.6255 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2458 - val_loss: 1.6252 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.3093 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2500 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6121 - accuracy: 0.2712 - val_loss: 1.6249 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2669 - val_loss: 1.6249 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2458 - val_loss: 1.6248 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2669 - val_loss: 1.6247 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2331 - val_loss: 1.6246 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6099 - accuracy: 0.2797 - val_loss: 1.6246 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6135 - accuracy: 0.2161 - val_loss: 1.6245 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6118 - accuracy: 0.2373 - val_loss: 1.6245 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2797 - val_loss: 1.6245 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6104 - accuracy: 0.2542 - val_loss: 1.6244 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2627 - val_loss: 1.6244 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6080 - accuracy: 0.2458 - val_loss: 1.6245 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2415 - val_loss: 1.6243 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2288 - val_loss: 1.6241 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.3008 - val_loss: 1.6239 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6007 - accuracy: 0.3305 - val_loss: 1.6239 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2542 - val_loss: 1.6238 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6107 - accuracy: 0.2669 - val_loss: 1.6236 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6085 - accuracy: 0.2585 - val_loss: 1.6234 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6082 - accuracy: 0.2881 - val_loss: 1.6234 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2331 - val_loss: 1.6235 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6114 - accuracy: 0.2076 - val_loss: 1.6235 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2542 - val_loss: 1.6235 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2458 - val_loss: 1.6234 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.2500 - val_loss: 1.6235 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2542 - val_loss: 1.6235 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Node 27 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6319 - accuracy: 0.2119 - val_loss: 1.6337 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.1695 - val_loss: 1.6336 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2119 - val_loss: 1.6334 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.1822 - val_loss: 1.6332 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2034 - val_loss: 1.6331 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2415 - val_loss: 1.6329 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2034 - val_loss: 1.6329 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2415 - val_loss: 1.6328 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2458 - val_loss: 1.6328 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1907 - val_loss: 1.6327 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2161 - val_loss: 1.6326 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.1949 - val_loss: 1.6325 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2415 - val_loss: 1.6324 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2288 - val_loss: 1.6324 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2161 - val_loss: 1.6322 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2500 - val_loss: 1.6321 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2246 - val_loss: 1.6320 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2119 - val_loss: 1.6320 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.1992 - val_loss: 1.6319 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.1822 - val_loss: 1.6318 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2500 - val_loss: 1.6317 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2161 - val_loss: 1.6316 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2669 - val_loss: 1.6316 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2585 - val_loss: 1.6315 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2754 - val_loss: 1.6314 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2331 - val_loss: 1.6312 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2669 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2542 - val_loss: 1.6310 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.1907 - val_loss: 1.6309 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2458 - val_loss: 1.6308 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2331 - val_loss: 1.6307 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2500 - val_loss: 1.6306 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2500 - val_loss: 1.6306 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2458 - val_loss: 1.6306 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2458 - val_loss: 1.6306 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2712 - val_loss: 1.6306 - val_accuracy: 0.1833 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2373 - val_loss: 1.6305 - val_accuracy: 0.1833 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2542 - val_loss: 1.6305 - val_accuracy: 0.1833 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2712 - val_loss: 1.6304 - val_accuracy: 0.1833 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2076 - val_loss: 1.6304 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2076 - val_loss: 1.6303 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2500 - val_loss: 1.6303 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2034 - val_loss: 1.6302 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2542 - val_loss: 1.6301 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2669 - val_loss: 1.6301 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2458 - val_loss: 1.6300 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2754 - val_loss: 1.6300 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2754 - val_loss: 1.6299 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2288 - val_loss: 1.6299 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2161 - val_loss: 1.6299 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 50ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2331 - val_loss: 1.6298 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2924 - val_loss: 1.6298 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2542 - val_loss: 1.6297 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2500 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2288 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2754 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.1992 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2754 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.1907 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2542 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2076 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2585 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2754 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2669 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 1.2500e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2669 - val_loss: 1.6296 - val_accuracy: 0.1833 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2161 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2415 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2542 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.1250e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2669 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.1250e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2331 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.1250e-06 - 33ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.1822 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2246 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.5625e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2288 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.5625e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2203 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2246 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2881 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2627 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.9062e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2542 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 3.9062e-07 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2585 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.9531e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2373 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.9531e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2076 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.9531e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 9.7656e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2203 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 9.7656e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2331 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 9.7656e-08 - 36ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2669 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2246 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2246 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2415 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 2.4414e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2754 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 2.4414e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2458 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 2.4414e-08 - 28ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2712 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.2207e-08 - 49ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2627 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2203 - val_loss: 1.6295 - val_accuracy: 0.1833 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Node 27 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6591 - accuracy: 0.2203 - val_loss: 1.6607 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 3s/epoch - 189ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6593 - accuracy: 0.2161 - val_loss: 1.6600 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6584 - accuracy: 0.1653 - val_loss: 1.6594 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6576 - accuracy: 0.1949 - val_loss: 1.6589 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6571 - accuracy: 0.2203 - val_loss: 1.6582 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6551 - accuracy: 0.2500 - val_loss: 1.6576 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6550 - accuracy: 0.2458 - val_loss: 1.6569 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6543 - accuracy: 0.2754 - val_loss: 1.6563 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6535 - accuracy: 0.1737 - val_loss: 1.6557 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6517 - accuracy: 0.2669 - val_loss: 1.6552 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.2203 - val_loss: 1.6545 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6508 - accuracy: 0.3008 - val_loss: 1.6539 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6502 - accuracy: 0.2542 - val_loss: 1.6533 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6491 - accuracy: 0.2500 - val_loss: 1.6527 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6494 - accuracy: 0.2119 - val_loss: 1.6521 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6484 - accuracy: 0.2076 - val_loss: 1.6516 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2669 - val_loss: 1.6511 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6475 - accuracy: 0.2542 - val_loss: 1.6507 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6466 - accuracy: 0.2627 - val_loss: 1.6502 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2246 - val_loss: 1.6497 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6433 - accuracy: 0.2797 - val_loss: 1.6492 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6440 - accuracy: 0.2458 - val_loss: 1.6488 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6440 - accuracy: 0.2500 - val_loss: 1.6484 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6428 - accuracy: 0.2797 - val_loss: 1.6480 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6417 - accuracy: 0.2203 - val_loss: 1.6476 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6401 - accuracy: 0.2712 - val_loss: 1.6468 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6406 - accuracy: 0.2585 - val_loss: 1.6464 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6398 - accuracy: 0.2500 - val_loss: 1.6460 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6390 - accuracy: 0.2627 - val_loss: 1.6455 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6404 - accuracy: 0.2585 - val_loss: 1.6450 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6356 - accuracy: 0.3093 - val_loss: 1.6445 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6389 - accuracy: 0.2500 - val_loss: 1.6440 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6396 - accuracy: 0.2246 - val_loss: 1.6435 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6358 - accuracy: 0.2712 - val_loss: 1.6430 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6363 - accuracy: 0.3008 - val_loss: 1.6426 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6355 - accuracy: 0.2627 - val_loss: 1.6421 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.3305 - val_loss: 1.6419 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2669 - val_loss: 1.6416 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2966 - val_loss: 1.6413 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6319 - accuracy: 0.2712 - val_loss: 1.6410 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.2542 - val_loss: 1.6407 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6331 - accuracy: 0.2754 - val_loss: 1.6403 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2754 - val_loss: 1.6399 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.3051 - val_loss: 1.6396 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2669 - val_loss: 1.6396 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2669 - val_loss: 1.6393 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2712 - val_loss: 1.6388 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2585 - val_loss: 1.6381 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2585 - val_loss: 1.6374 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2754 - val_loss: 1.6369 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2669 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2881 - val_loss: 1.6360 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 86ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.3008 - val_loss: 1.6359 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.3008 - val_loss: 1.6359 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.3051 - val_loss: 1.6357 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2712 - val_loss: 1.6355 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.3051 - val_loss: 1.6351 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.3390 - val_loss: 1.6347 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2585 - val_loss: 1.6343 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2797 - val_loss: 1.6338 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2585 - val_loss: 1.6340 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2966 - val_loss: 1.6339 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.3093 - val_loss: 1.6333 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2966 - val_loss: 1.6334 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6051 - accuracy: 0.3263 - val_loss: 1.6333 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6118 - accuracy: 0.2754 - val_loss: 1.6330 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6082 - accuracy: 0.3432 - val_loss: 1.6330 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.3008 - val_loss: 1.6336 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2542 - val_loss: 1.6331 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.3008 - val_loss: 1.6329 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.3263 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2415 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6088 - accuracy: 0.3263 - val_loss: 1.6327 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 71ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6058 - accuracy: 0.3263 - val_loss: 1.6325 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2924 - val_loss: 1.6324 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2966 - val_loss: 1.6323 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6126 - accuracy: 0.2754 - val_loss: 1.6324 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.3178 - val_loss: 1.6322 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2881 - val_loss: 1.6320 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.5990 - accuracy: 0.3220 - val_loss: 1.6321 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6037 - accuracy: 0.2966 - val_loss: 1.6320 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6032 - accuracy: 0.2881 - val_loss: 1.6317 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2881 - val_loss: 1.6315 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2331 - val_loss: 1.6313 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6086 - accuracy: 0.2627 - val_loss: 1.6310 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2924 - val_loss: 1.6309 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2627 - val_loss: 1.6306 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6017 - accuracy: 0.3136 - val_loss: 1.6306 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.3093 - val_loss: 1.6308 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6038 - accuracy: 0.2881 - val_loss: 1.6307 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6003 - accuracy: 0.3178 - val_loss: 1.6308 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2712 - val_loss: 1.6309 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.5995 - accuracy: 0.2669 - val_loss: 1.6309 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6113 - accuracy: 0.2585 - val_loss: 1.6310 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 69ms/epoch - 5ms/step\n",
      "Node 27 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6600 - accuracy: 0.1907 - val_loss: 1.6594 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 3s/epoch - 363ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6588 - accuracy: 0.1992 - val_loss: 1.6589 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6585 - accuracy: 0.1610 - val_loss: 1.6585 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.2076 - val_loss: 1.6580 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6589 - accuracy: 0.1907 - val_loss: 1.6575 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6571 - accuracy: 0.2161 - val_loss: 1.6571 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.1610 - val_loss: 1.6567 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2288 - val_loss: 1.6563 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2246 - val_loss: 1.6559 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6558 - accuracy: 0.1907 - val_loss: 1.6554 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6545 - accuracy: 0.1949 - val_loss: 1.6550 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2203 - val_loss: 1.6546 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2076 - val_loss: 1.6543 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6538 - accuracy: 0.2415 - val_loss: 1.6539 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2627 - val_loss: 1.6535 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6517 - accuracy: 0.2542 - val_loss: 1.6530 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6520 - accuracy: 0.2119 - val_loss: 1.6525 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.1992 - val_loss: 1.6522 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.1907 - val_loss: 1.6519 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2712 - val_loss: 1.6515 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2373 - val_loss: 1.6512 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2373 - val_loss: 1.6509 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2034 - val_loss: 1.6505 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6475 - accuracy: 0.2246 - val_loss: 1.6502 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2458 - val_loss: 1.6499 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2627 - val_loss: 1.6495 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6469 - accuracy: 0.2161 - val_loss: 1.6491 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2627 - val_loss: 1.6487 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2373 - val_loss: 1.6483 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2331 - val_loss: 1.6480 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2797 - val_loss: 1.6477 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6449 - accuracy: 0.2839 - val_loss: 1.6473 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6457 - accuracy: 0.2288 - val_loss: 1.6469 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2373 - val_loss: 1.6466 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2500 - val_loss: 1.6464 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6460 - accuracy: 0.1992 - val_loss: 1.6461 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2627 - val_loss: 1.6458 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6428 - accuracy: 0.2415 - val_loss: 1.6456 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2627 - val_loss: 1.6453 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2288 - val_loss: 1.6450 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2203 - val_loss: 1.6447 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2415 - val_loss: 1.6444 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2458 - val_loss: 1.6441 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2585 - val_loss: 1.6439 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2458 - val_loss: 1.6436 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2754 - val_loss: 1.6434 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2627 - val_loss: 1.6432 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2585 - val_loss: 1.6429 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2373 - val_loss: 1.6427 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.3347 - val_loss: 1.6424 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2712 - val_loss: 1.6422 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2500 - val_loss: 1.6419 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6366 - accuracy: 0.2203 - val_loss: 1.6416 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2966 - val_loss: 1.6413 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2500 - val_loss: 1.6411 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2246 - val_loss: 1.6408 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2542 - val_loss: 1.6405 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2924 - val_loss: 1.6402 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2542 - val_loss: 1.6400 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2797 - val_loss: 1.6399 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2754 - val_loss: 1.6397 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2585 - val_loss: 1.6394 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2331 - val_loss: 1.6391 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2331 - val_loss: 1.6388 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2924 - val_loss: 1.6386 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2542 - val_loss: 1.6385 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2458 - val_loss: 1.6383 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2627 - val_loss: 1.6381 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2415 - val_loss: 1.6379 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2542 - val_loss: 1.6379 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2458 - val_loss: 1.6377 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2585 - val_loss: 1.6375 - val_accuracy: 0.3167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.3051 - val_loss: 1.6372 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.3220 - val_loss: 1.6370 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2627 - val_loss: 1.6367 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2585 - val_loss: 1.6366 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2839 - val_loss: 1.6364 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2373 - val_loss: 1.6362 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2797 - val_loss: 1.6361 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2458 - val_loss: 1.6361 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2669 - val_loss: 1.6361 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2881 - val_loss: 1.6358 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2458 - val_loss: 1.6356 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2712 - val_loss: 1.6356 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2458 - val_loss: 1.6354 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2669 - val_loss: 1.6352 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2966 - val_loss: 1.6352 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2712 - val_loss: 1.6350 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 56ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2458 - val_loss: 1.6348 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.1907 - val_loss: 1.6347 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6346 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2839 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.3263 - val_loss: 1.6345 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2669 - val_loss: 1.6343 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2966 - val_loss: 1.6342 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2458 - val_loss: 1.6341 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.3136 - val_loss: 1.6343 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2712 - val_loss: 1.6340 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2839 - val_loss: 1.6341 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 68ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2373 - val_loss: 1.6339 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Node 27 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 27 - Best Validation Accuracy: 0.3167\n",
      "Best model saved for Node 27 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_27.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_28_dataset.csv\n",
      "Node 28 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6357 - accuracy: 0.1970 - val_loss: 1.6355 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 3s/epoch - 148ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6338 - accuracy: 0.2007 - val_loss: 1.6350 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6357 - accuracy: 0.1933 - val_loss: 1.6346 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6333 - accuracy: 0.2119 - val_loss: 1.6341 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6346 - accuracy: 0.1970 - val_loss: 1.6339 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6327 - accuracy: 0.2342 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6323 - accuracy: 0.2454 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6330 - accuracy: 0.1896 - val_loss: 1.6326 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6325 - accuracy: 0.1933 - val_loss: 1.6323 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6328 - accuracy: 0.2082 - val_loss: 1.6320 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6313 - accuracy: 0.2268 - val_loss: 1.6317 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6309 - accuracy: 0.2639 - val_loss: 1.6314 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6299 - accuracy: 0.2230 - val_loss: 1.6311 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6291 - accuracy: 0.2379 - val_loss: 1.6308 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2491 - val_loss: 1.6305 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 57ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6293 - accuracy: 0.2565 - val_loss: 1.6302 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6298 - accuracy: 0.2119 - val_loss: 1.6299 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2602 - val_loss: 1.6297 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6294 - accuracy: 0.2082 - val_loss: 1.6295 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6298 - accuracy: 0.2193 - val_loss: 1.6292 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6278 - accuracy: 0.2305 - val_loss: 1.6291 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2305 - val_loss: 1.6288 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6289 - accuracy: 0.2454 - val_loss: 1.6286 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6271 - accuracy: 0.2342 - val_loss: 1.6285 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6278 - accuracy: 0.2342 - val_loss: 1.6284 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6258 - accuracy: 0.2454 - val_loss: 1.6282 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6243 - accuracy: 0.2491 - val_loss: 1.6278 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6255 - accuracy: 0.2342 - val_loss: 1.6277 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6248 - accuracy: 0.2416 - val_loss: 1.6274 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.2268 - val_loss: 1.6272 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6234 - accuracy: 0.2454 - val_loss: 1.6270 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6213 - accuracy: 0.2528 - val_loss: 1.6268 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6244 - accuracy: 0.2230 - val_loss: 1.6267 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.2416 - val_loss: 1.6265 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6226 - accuracy: 0.2491 - val_loss: 1.6263 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6236 - accuracy: 0.2268 - val_loss: 1.6260 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2602 - val_loss: 1.6259 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2602 - val_loss: 1.6257 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6210 - accuracy: 0.2416 - val_loss: 1.6255 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6175 - accuracy: 0.2565 - val_loss: 1.6254 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2602 - val_loss: 1.6252 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2788 - val_loss: 1.6250 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6219 - accuracy: 0.2193 - val_loss: 1.6249 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6202 - accuracy: 0.2528 - val_loss: 1.6247 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6215 - accuracy: 0.2416 - val_loss: 1.6244 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6192 - accuracy: 0.2491 - val_loss: 1.6242 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6209 - accuracy: 0.2379 - val_loss: 1.6241 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6205 - accuracy: 0.2416 - val_loss: 1.6240 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6205 - accuracy: 0.2528 - val_loss: 1.6238 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2788 - val_loss: 1.6237 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6183 - accuracy: 0.2491 - val_loss: 1.6236 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6176 - accuracy: 0.2751 - val_loss: 1.6235 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6169 - accuracy: 0.2528 - val_loss: 1.6234 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2342 - val_loss: 1.6233 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6160 - accuracy: 0.2751 - val_loss: 1.6231 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6183 - accuracy: 0.2305 - val_loss: 1.6231 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6134 - accuracy: 0.2751 - val_loss: 1.6231 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6185 - accuracy: 0.2379 - val_loss: 1.6230 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6190 - accuracy: 0.2751 - val_loss: 1.6229 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6158 - accuracy: 0.2788 - val_loss: 1.6226 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6165 - accuracy: 0.2639 - val_loss: 1.6226 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6143 - accuracy: 0.2862 - val_loss: 1.6224 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6162 - accuracy: 0.2305 - val_loss: 1.6223 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6164 - accuracy: 0.2491 - val_loss: 1.6222 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2454 - val_loss: 1.6222 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6170 - accuracy: 0.2268 - val_loss: 1.6220 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6111 - accuracy: 0.2714 - val_loss: 1.6220 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2565 - val_loss: 1.6218 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6149 - accuracy: 0.2565 - val_loss: 1.6216 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6201 - accuracy: 0.2379 - val_loss: 1.6215 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6158 - accuracy: 0.2677 - val_loss: 1.6213 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6148 - accuracy: 0.2230 - val_loss: 1.6211 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2119 - val_loss: 1.6211 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2342 - val_loss: 1.6210 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6137 - accuracy: 0.2639 - val_loss: 1.6210 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6089 - accuracy: 0.2788 - val_loss: 1.6209 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6125 - accuracy: 0.2788 - val_loss: 1.6208 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6111 - accuracy: 0.2714 - val_loss: 1.6209 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6127 - accuracy: 0.2528 - val_loss: 1.6208 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6099 - accuracy: 0.2677 - val_loss: 1.6208 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6072 - accuracy: 0.2677 - val_loss: 1.6208 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6129 - accuracy: 0.2305 - val_loss: 1.6207 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6174 - accuracy: 0.2119 - val_loss: 1.6206 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6147 - accuracy: 0.2342 - val_loss: 1.6206 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6154 - accuracy: 0.2268 - val_loss: 1.6205 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6157 - accuracy: 0.2491 - val_loss: 1.6205 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6107 - accuracy: 0.2602 - val_loss: 1.6205 - val_accuracy: 0.2059 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6116 - accuracy: 0.2788 - val_loss: 1.6205 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6117 - accuracy: 0.2825 - val_loss: 1.6205 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6098 - accuracy: 0.2677 - val_loss: 1.6204 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 53ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6150 - accuracy: 0.2639 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6104 - accuracy: 0.2193 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6129 - accuracy: 0.3011 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.6121 - accuracy: 0.2342 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 2.5000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6095 - accuracy: 0.2639 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 1.2500e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6125 - accuracy: 0.2268 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 1.2500e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "17/17 - 0s - loss: 1.6099 - accuracy: 0.2714 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 1.2500e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.6073 - accuracy: 0.2639 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.6106 - accuracy: 0.2454 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 6.2500e-06 - 52ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "17/17 - 0s - loss: 1.6100 - accuracy: 0.2862 - val_loss: 1.6203 - val_accuracy: 0.2059 - lr: 6.2500e-06 - 52ms/epoch - 3ms/step\n",
      "Node 28 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6363 - accuracy: 0.1933 - val_loss: 1.6372 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 3s/epoch - 322ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6365 - accuracy: 0.2230 - val_loss: 1.6368 - val_accuracy: 0.1176 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6366 - accuracy: 0.1747 - val_loss: 1.6364 - val_accuracy: 0.1471 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6353 - accuracy: 0.1896 - val_loss: 1.6360 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6358 - accuracy: 0.2007 - val_loss: 1.6357 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6356 - accuracy: 0.1710 - val_loss: 1.6353 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.1450 - val_loss: 1.6349 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6358 - accuracy: 0.1710 - val_loss: 1.6345 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6348 - accuracy: 0.2268 - val_loss: 1.6344 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6347 - accuracy: 0.1822 - val_loss: 1.6341 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6325 - accuracy: 0.2677 - val_loss: 1.6338 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6320 - accuracy: 0.2602 - val_loss: 1.6335 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6322 - accuracy: 0.2193 - val_loss: 1.6331 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6326 - accuracy: 0.2156 - val_loss: 1.6327 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2454 - val_loss: 1.6324 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6314 - accuracy: 0.2379 - val_loss: 1.6322 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 39ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2454 - val_loss: 1.6319 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6308 - accuracy: 0.2565 - val_loss: 1.6316 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6306 - accuracy: 0.2045 - val_loss: 1.6314 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2305 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2379 - val_loss: 1.6309 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2193 - val_loss: 1.6307 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6297 - accuracy: 0.2342 - val_loss: 1.6305 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6297 - accuracy: 0.2454 - val_loss: 1.6302 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2528 - val_loss: 1.6300 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2379 - val_loss: 1.6298 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2156 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2491 - val_loss: 1.6293 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6280 - accuracy: 0.2565 - val_loss: 1.6291 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2454 - val_loss: 1.6288 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 39ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2602 - val_loss: 1.6285 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2677 - val_loss: 1.6283 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2007 - val_loss: 1.6280 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2454 - val_loss: 1.6278 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6297 - accuracy: 0.2230 - val_loss: 1.6276 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2491 - val_loss: 1.6275 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2379 - val_loss: 1.6273 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2230 - val_loss: 1.6271 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2119 - val_loss: 1.6268 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2416 - val_loss: 1.6266 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2342 - val_loss: 1.6264 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2119 - val_loss: 1.6262 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2305 - val_loss: 1.6260 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.1933 - val_loss: 1.6258 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6236 - accuracy: 0.2454 - val_loss: 1.6256 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 37ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6224 - accuracy: 0.2305 - val_loss: 1.6254 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6226 - accuracy: 0.2156 - val_loss: 1.6252 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6240 - accuracy: 0.2454 - val_loss: 1.6250 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6217 - accuracy: 0.2379 - val_loss: 1.6248 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 37ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2565 - val_loss: 1.6246 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2082 - val_loss: 1.6243 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2491 - val_loss: 1.6241 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2305 - val_loss: 1.6240 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2379 - val_loss: 1.6238 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6180 - accuracy: 0.2714 - val_loss: 1.6236 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6180 - accuracy: 0.1822 - val_loss: 1.6233 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2379 - val_loss: 1.6231 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2379 - val_loss: 1.6230 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6195 - accuracy: 0.2602 - val_loss: 1.6228 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6230 - accuracy: 0.2677 - val_loss: 1.6227 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6216 - accuracy: 0.2751 - val_loss: 1.6225 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6209 - accuracy: 0.2528 - val_loss: 1.6224 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6155 - accuracy: 0.2230 - val_loss: 1.6222 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6195 - accuracy: 0.2491 - val_loss: 1.6220 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2305 - val_loss: 1.6218 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6165 - accuracy: 0.2454 - val_loss: 1.6217 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2751 - val_loss: 1.6216 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2268 - val_loss: 1.6215 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6157 - accuracy: 0.2379 - val_loss: 1.6214 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6232 - accuracy: 0.2342 - val_loss: 1.6212 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6199 - accuracy: 0.2491 - val_loss: 1.6211 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2193 - val_loss: 1.6210 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2454 - val_loss: 1.6209 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6183 - accuracy: 0.2305 - val_loss: 1.6207 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2193 - val_loss: 1.6205 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6180 - accuracy: 0.2379 - val_loss: 1.6204 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2454 - val_loss: 1.6203 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2528 - val_loss: 1.6201 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6145 - accuracy: 0.2305 - val_loss: 1.6200 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6169 - accuracy: 0.2305 - val_loss: 1.6198 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6208 - accuracy: 0.2007 - val_loss: 1.6197 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.1933 - val_loss: 1.6196 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6159 - accuracy: 0.2119 - val_loss: 1.6195 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6153 - accuracy: 0.2268 - val_loss: 1.6193 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2305 - val_loss: 1.6192 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2379 - val_loss: 1.6191 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6178 - accuracy: 0.2602 - val_loss: 1.6191 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6204 - accuracy: 0.2193 - val_loss: 1.6191 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6098 - accuracy: 0.2342 - val_loss: 1.6191 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2156 - val_loss: 1.6190 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6168 - accuracy: 0.2193 - val_loss: 1.6190 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 35ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6133 - accuracy: 0.2454 - val_loss: 1.6189 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6199 - accuracy: 0.1970 - val_loss: 1.6189 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6096 - accuracy: 0.2454 - val_loss: 1.6188 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2268 - val_loss: 1.6187 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 35ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6128 - accuracy: 0.2268 - val_loss: 1.6186 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 35ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6160 - accuracy: 0.2268 - val_loss: 1.6186 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 52ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.2082 - val_loss: 1.6186 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 36ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "9/9 - 0s - loss: 1.6125 - accuracy: 0.2268 - val_loss: 1.6186 - val_accuracy: 0.2353 - lr: 5.0000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6161 - accuracy: 0.2565 - val_loss: 1.6185 - val_accuracy: 0.2353 - lr: 2.5000e-05 - 33ms/epoch - 4ms/step\n",
      "Node 28 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6574 - accuracy: 0.2342 - val_loss: 1.6576 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 3s/epoch - 148ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6563 - accuracy: 0.2082 - val_loss: 1.6566 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6555 - accuracy: 0.1970 - val_loss: 1.6554 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6541 - accuracy: 0.2268 - val_loss: 1.6544 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6530 - accuracy: 0.2156 - val_loss: 1.6536 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6523 - accuracy: 0.2119 - val_loss: 1.6527 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6509 - accuracy: 0.2491 - val_loss: 1.6518 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6507 - accuracy: 0.2082 - val_loss: 1.6510 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6498 - accuracy: 0.2602 - val_loss: 1.6500 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6493 - accuracy: 0.2602 - val_loss: 1.6493 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6462 - accuracy: 0.2602 - val_loss: 1.6486 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6458 - accuracy: 0.2379 - val_loss: 1.6476 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6460 - accuracy: 0.2230 - val_loss: 1.6467 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6449 - accuracy: 0.2491 - val_loss: 1.6461 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 82ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6450 - accuracy: 0.2677 - val_loss: 1.6453 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6429 - accuracy: 0.2379 - val_loss: 1.6445 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6453 - accuracy: 0.2454 - val_loss: 1.6439 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6412 - accuracy: 0.2714 - val_loss: 1.6433 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6427 - accuracy: 0.2454 - val_loss: 1.6424 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6408 - accuracy: 0.2528 - val_loss: 1.6418 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6362 - accuracy: 0.2714 - val_loss: 1.6414 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6377 - accuracy: 0.2379 - val_loss: 1.6409 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6397 - accuracy: 0.2379 - val_loss: 1.6403 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6393 - accuracy: 0.2528 - val_loss: 1.6396 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6406 - accuracy: 0.2045 - val_loss: 1.6390 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6361 - accuracy: 0.2602 - val_loss: 1.6385 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6346 - accuracy: 0.2639 - val_loss: 1.6379 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6358 - accuracy: 0.2751 - val_loss: 1.6374 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6343 - accuracy: 0.2602 - val_loss: 1.6368 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6339 - accuracy: 0.2491 - val_loss: 1.6364 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6309 - accuracy: 0.2602 - val_loss: 1.6360 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2379 - val_loss: 1.6358 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6304 - accuracy: 0.2379 - val_loss: 1.6354 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6335 - accuracy: 0.2305 - val_loss: 1.6347 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2416 - val_loss: 1.6344 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6286 - accuracy: 0.2379 - val_loss: 1.6337 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2416 - val_loss: 1.6334 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6295 - accuracy: 0.2379 - val_loss: 1.6331 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6286 - accuracy: 0.2305 - val_loss: 1.6329 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6282 - accuracy: 0.2602 - val_loss: 1.6327 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6271 - accuracy: 0.2379 - val_loss: 1.6323 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2342 - val_loss: 1.6320 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6290 - accuracy: 0.2565 - val_loss: 1.6315 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2528 - val_loss: 1.6310 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6247 - accuracy: 0.2007 - val_loss: 1.6308 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6253 - accuracy: 0.2491 - val_loss: 1.6304 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2379 - val_loss: 1.6301 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6227 - accuracy: 0.2491 - val_loss: 1.6297 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2565 - val_loss: 1.6294 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6207 - accuracy: 0.2230 - val_loss: 1.6290 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2528 - val_loss: 1.6289 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2491 - val_loss: 1.6286 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2268 - val_loss: 1.6286 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6152 - accuracy: 0.2342 - val_loss: 1.6283 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2416 - val_loss: 1.6281 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6172 - accuracy: 0.2528 - val_loss: 1.6279 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6176 - accuracy: 0.2454 - val_loss: 1.6278 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2528 - val_loss: 1.6277 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6139 - accuracy: 0.2416 - val_loss: 1.6276 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6155 - accuracy: 0.2491 - val_loss: 1.6273 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6104 - accuracy: 0.2677 - val_loss: 1.6271 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6105 - accuracy: 0.2491 - val_loss: 1.6271 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6178 - accuracy: 0.2491 - val_loss: 1.6268 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6143 - accuracy: 0.2305 - val_loss: 1.6265 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6089 - accuracy: 0.2268 - val_loss: 1.6264 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6188 - accuracy: 0.2677 - val_loss: 1.6261 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6045 - accuracy: 0.2565 - val_loss: 1.6259 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6067 - accuracy: 0.2751 - val_loss: 1.6256 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6051 - accuracy: 0.2342 - val_loss: 1.6256 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6054 - accuracy: 0.2565 - val_loss: 1.6258 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "17/17 - 0s - loss: 1.6080 - accuracy: 0.2342 - val_loss: 1.6257 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6134 - accuracy: 0.2230 - val_loss: 1.6257 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6035 - accuracy: 0.2565 - val_loss: 1.6256 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6150 - accuracy: 0.2677 - val_loss: 1.6254 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 76ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6080 - accuracy: 0.2528 - val_loss: 1.6254 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 76ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6039 - accuracy: 0.2900 - val_loss: 1.6252 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 76ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6136 - accuracy: 0.2454 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6062 - accuracy: 0.2491 - val_loss: 1.6252 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 75ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6057 - accuracy: 0.2677 - val_loss: 1.6250 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 76ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6081 - accuracy: 0.2379 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 82ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6046 - accuracy: 0.2677 - val_loss: 1.6250 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "17/17 - 0s - loss: 1.6058 - accuracy: 0.2454 - val_loss: 1.6250 - val_accuracy: 0.2206 - lr: 5.0000e-05 - 75ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.5986 - accuracy: 0.2862 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 2.5000e-05 - 75ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6026 - accuracy: 0.2714 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 2.5000e-05 - 76ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "17/17 - 0s - loss: 1.5990 - accuracy: 0.2751 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 2.5000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6069 - accuracy: 0.2230 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 1.2500e-05 - 74ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6028 - accuracy: 0.2565 - val_loss: 1.6250 - val_accuracy: 0.2206 - lr: 1.2500e-05 - 75ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "17/17 - 0s - loss: 1.6056 - accuracy: 0.2565 - val_loss: 1.6250 - val_accuracy: 0.2206 - lr: 1.2500e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6102 - accuracy: 0.2491 - val_loss: 1.6251 - val_accuracy: 0.2206 - lr: 6.2500e-06 - 74ms/epoch - 4ms/step\n",
      "Node 28 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6633 - accuracy: 0.1970 - val_loss: 1.6605 - val_accuracy: 0.1324 - lr: 1.0000e-04 - 3s/epoch - 321ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6615 - accuracy: 0.1896 - val_loss: 1.6596 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6609 - accuracy: 0.2156 - val_loss: 1.6588 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6603 - accuracy: 0.1859 - val_loss: 1.6582 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 37ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6598 - accuracy: 0.1896 - val_loss: 1.6578 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6589 - accuracy: 0.1933 - val_loss: 1.6573 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6588 - accuracy: 0.1784 - val_loss: 1.6567 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6573 - accuracy: 0.2156 - val_loss: 1.6563 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6574 - accuracy: 0.1933 - val_loss: 1.6560 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6561 - accuracy: 0.2156 - val_loss: 1.6556 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6549 - accuracy: 0.2305 - val_loss: 1.6551 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6555 - accuracy: 0.2305 - val_loss: 1.6547 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6548 - accuracy: 0.1896 - val_loss: 1.6542 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6527 - accuracy: 0.2379 - val_loss: 1.6538 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6529 - accuracy: 0.2602 - val_loss: 1.6533 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6517 - accuracy: 0.2751 - val_loss: 1.6527 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 59ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6518 - accuracy: 0.2565 - val_loss: 1.6523 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6515 - accuracy: 0.2119 - val_loss: 1.6518 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6515 - accuracy: 0.2454 - val_loss: 1.6513 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6501 - accuracy: 0.2602 - val_loss: 1.6508 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6504 - accuracy: 0.2119 - val_loss: 1.6503 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6487 - accuracy: 0.2639 - val_loss: 1.6498 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6487 - accuracy: 0.2045 - val_loss: 1.6493 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6477 - accuracy: 0.2714 - val_loss: 1.6490 - val_accuracy: 0.1176 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6482 - accuracy: 0.2528 - val_loss: 1.6486 - val_accuracy: 0.1176 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6480 - accuracy: 0.2342 - val_loss: 1.6482 - val_accuracy: 0.1471 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6459 - accuracy: 0.2677 - val_loss: 1.6477 - val_accuracy: 0.1324 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6465 - accuracy: 0.2528 - val_loss: 1.6474 - val_accuracy: 0.1471 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6463 - accuracy: 0.2565 - val_loss: 1.6469 - val_accuracy: 0.1471 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6450 - accuracy: 0.2268 - val_loss: 1.6464 - val_accuracy: 0.1176 - lr: 1.0000e-04 - 57ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6430 - accuracy: 0.2677 - val_loss: 1.6459 - val_accuracy: 0.1324 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6440 - accuracy: 0.2230 - val_loss: 1.6454 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6425 - accuracy: 0.2602 - val_loss: 1.6448 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6425 - accuracy: 0.2528 - val_loss: 1.6443 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6415 - accuracy: 0.2565 - val_loss: 1.6438 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6425 - accuracy: 0.2268 - val_loss: 1.6435 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6408 - accuracy: 0.2788 - val_loss: 1.6431 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6390 - accuracy: 0.2825 - val_loss: 1.6427 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6412 - accuracy: 0.2602 - val_loss: 1.6423 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6403 - accuracy: 0.2119 - val_loss: 1.6420 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6369 - accuracy: 0.2639 - val_loss: 1.6417 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6370 - accuracy: 0.2751 - val_loss: 1.6413 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6374 - accuracy: 0.2565 - val_loss: 1.6408 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6375 - accuracy: 0.2342 - val_loss: 1.6405 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6374 - accuracy: 0.2528 - val_loss: 1.6400 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2602 - val_loss: 1.6397 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6362 - accuracy: 0.2491 - val_loss: 1.6393 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.2268 - val_loss: 1.6387 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 56ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6331 - accuracy: 0.2565 - val_loss: 1.6383 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6357 - accuracy: 0.2045 - val_loss: 1.6379 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2565 - val_loss: 1.6375 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 71ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6319 - accuracy: 0.2342 - val_loss: 1.6372 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2751 - val_loss: 1.6370 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2528 - val_loss: 1.6367 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2230 - val_loss: 1.6363 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6350 - accuracy: 0.2230 - val_loss: 1.6359 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6366 - accuracy: 0.2268 - val_loss: 1.6356 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6251 - accuracy: 0.2900 - val_loss: 1.6353 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6272 - accuracy: 0.2677 - val_loss: 1.6350 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6277 - accuracy: 0.2602 - val_loss: 1.6347 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2379 - val_loss: 1.6344 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2268 - val_loss: 1.6341 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2602 - val_loss: 1.6338 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2677 - val_loss: 1.6337 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.2342 - val_loss: 1.6334 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6257 - accuracy: 0.2379 - val_loss: 1.6332 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2974 - val_loss: 1.6329 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2379 - val_loss: 1.6326 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6262 - accuracy: 0.2602 - val_loss: 1.6322 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2454 - val_loss: 1.6319 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6232 - accuracy: 0.2342 - val_loss: 1.6315 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6251 - accuracy: 0.2602 - val_loss: 1.6313 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6320 - accuracy: 0.2416 - val_loss: 1.6310 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 56ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2677 - val_loss: 1.6308 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6229 - accuracy: 0.2825 - val_loss: 1.6306 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 56ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.1859 - val_loss: 1.6302 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2602 - val_loss: 1.6300 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2305 - val_loss: 1.6299 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2007 - val_loss: 1.6299 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6258 - accuracy: 0.2082 - val_loss: 1.6298 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2454 - val_loss: 1.6295 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6168 - accuracy: 0.2602 - val_loss: 1.6290 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2565 - val_loss: 1.6288 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6156 - accuracy: 0.2639 - val_loss: 1.6287 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6195 - accuracy: 0.2788 - val_loss: 1.6286 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6216 - accuracy: 0.2156 - val_loss: 1.6284 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6126 - accuracy: 0.2639 - val_loss: 1.6282 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 57ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2565 - val_loss: 1.6279 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6157 - accuracy: 0.2342 - val_loss: 1.6275 - val_accuracy: 0.1912 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6183 - accuracy: 0.2639 - val_loss: 1.6275 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2565 - val_loss: 1.6273 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6184 - accuracy: 0.2751 - val_loss: 1.6273 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6141 - accuracy: 0.2602 - val_loss: 1.6271 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6141 - accuracy: 0.2565 - val_loss: 1.6268 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 57ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6117 - accuracy: 0.2379 - val_loss: 1.6266 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6121 - accuracy: 0.2528 - val_loss: 1.6263 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6130 - accuracy: 0.2788 - val_loss: 1.6261 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 72ms/epoch - 8ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6142 - accuracy: 0.2454 - val_loss: 1.6262 - val_accuracy: 0.1765 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2602 - val_loss: 1.6263 - val_accuracy: 0.1471 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "9/9 - 0s - loss: 1.6121 - accuracy: 0.2714 - val_loss: 1.6260 - val_accuracy: 0.1618 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Node 28 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 28 - Best Validation Accuracy: 0.2941\n",
      "Best model saved for Node 28 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_28.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_29_dataset.csv\n",
      "Node 29 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6340 - accuracy: 0.2035 - val_loss: 1.6336 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 3s/epoch - 192ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6350 - accuracy: 0.2165 - val_loss: 1.6334 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.2511 - val_loss: 1.6332 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2078 - val_loss: 1.6330 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2511 - val_loss: 1.6328 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.1991 - val_loss: 1.6325 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6355 - accuracy: 0.1905 - val_loss: 1.6324 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2121 - val_loss: 1.6321 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2424 - val_loss: 1.6319 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.1732 - val_loss: 1.6316 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.2078 - val_loss: 1.6312 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6309 - accuracy: 0.2251 - val_loss: 1.6310 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2338 - val_loss: 1.6307 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2165 - val_loss: 1.6306 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2424 - val_loss: 1.6304 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2251 - val_loss: 1.6302 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2381 - val_loss: 1.6299 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2294 - val_loss: 1.6296 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2338 - val_loss: 1.6294 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6285 - accuracy: 0.2208 - val_loss: 1.6292 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2381 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6283 - accuracy: 0.2208 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2381 - val_loss: 1.6285 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2035 - val_loss: 1.6283 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2121 - val_loss: 1.6281 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2208 - val_loss: 1.6280 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.1991 - val_loss: 1.6279 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2424 - val_loss: 1.6277 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2208 - val_loss: 1.6276 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2208 - val_loss: 1.6273 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2208 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2251 - val_loss: 1.6270 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2078 - val_loss: 1.6268 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2338 - val_loss: 1.6266 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2121 - val_loss: 1.6265 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2208 - val_loss: 1.6264 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2424 - val_loss: 1.6262 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2208 - val_loss: 1.6262 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2165 - val_loss: 1.6260 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2035 - val_loss: 1.6258 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2251 - val_loss: 1.6258 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2078 - val_loss: 1.6256 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2251 - val_loss: 1.6254 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2165 - val_loss: 1.6253 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2208 - val_loss: 1.6251 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2251 - val_loss: 1.6250 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2208 - val_loss: 1.6249 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2294 - val_loss: 1.6248 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2121 - val_loss: 1.6246 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2294 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2035 - val_loss: 1.6243 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2468 - val_loss: 1.6241 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2208 - val_loss: 1.6240 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2165 - val_loss: 1.6239 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2294 - val_loss: 1.6238 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2165 - val_loss: 1.6236 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.1991 - val_loss: 1.6236 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2208 - val_loss: 1.6235 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2338 - val_loss: 1.6233 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2511 - val_loss: 1.6232 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2251 - val_loss: 1.6230 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2468 - val_loss: 1.6229 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2035 - val_loss: 1.6228 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2338 - val_loss: 1.6227 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2165 - val_loss: 1.6225 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2294 - val_loss: 1.6224 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2294 - val_loss: 1.6223 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2424 - val_loss: 1.6222 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2165 - val_loss: 1.6222 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2251 - val_loss: 1.6220 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2381 - val_loss: 1.6220 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2251 - val_loss: 1.6218 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2597 - val_loss: 1.6217 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2338 - val_loss: 1.6217 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2554 - val_loss: 1.6216 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2381 - val_loss: 1.6214 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6157 - accuracy: 0.2381 - val_loss: 1.6213 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2165 - val_loss: 1.6212 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2165 - val_loss: 1.6211 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2468 - val_loss: 1.6211 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2424 - val_loss: 1.6211 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2294 - val_loss: 1.6211 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2338 - val_loss: 1.6210 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2165 - val_loss: 1.6210 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6117 - accuracy: 0.2381 - val_loss: 1.6209 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2208 - val_loss: 1.6208 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2251 - val_loss: 1.6208 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2294 - val_loss: 1.6208 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2424 - val_loss: 1.6207 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2251 - val_loss: 1.6206 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2251 - val_loss: 1.6206 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2511 - val_loss: 1.6205 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2251 - val_loss: 1.6205 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2121 - val_loss: 1.6204 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2424 - val_loss: 1.6204 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2424 - val_loss: 1.6203 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2208 - val_loss: 1.6203 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2338 - val_loss: 1.6203 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2294 - val_loss: 1.6202 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6134 - accuracy: 0.2597 - val_loss: 1.6202 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Node 29 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6343 - accuracy: 0.2294 - val_loss: 1.6369 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 3s/epoch - 318ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.1905 - val_loss: 1.6365 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.1861 - val_loss: 1.6362 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6371 - accuracy: 0.1991 - val_loss: 1.6359 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2294 - val_loss: 1.6357 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.1602 - val_loss: 1.6354 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2294 - val_loss: 1.6351 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.1861 - val_loss: 1.6347 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.1732 - val_loss: 1.6344 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2165 - val_loss: 1.6342 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.1775 - val_loss: 1.6339 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.1905 - val_loss: 1.6336 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2078 - val_loss: 1.6334 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.1645 - val_loss: 1.6332 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2078 - val_loss: 1.6331 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2035 - val_loss: 1.6329 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.1775 - val_loss: 1.6326 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2294 - val_loss: 1.6324 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.1429 - val_loss: 1.6323 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.1515 - val_loss: 1.6321 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.1775 - val_loss: 1.6320 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.1385 - val_loss: 1.6319 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1905 - val_loss: 1.6317 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2078 - val_loss: 1.6315 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.1558 - val_loss: 1.6314 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2597 - val_loss: 1.6313 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2424 - val_loss: 1.6311 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2035 - val_loss: 1.6310 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2035 - val_loss: 1.6309 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.1905 - val_loss: 1.6307 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2078 - val_loss: 1.6306 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2121 - val_loss: 1.6304 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1558 - val_loss: 1.6302 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2381 - val_loss: 1.6301 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2424 - val_loss: 1.6300 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.1991 - val_loss: 1.6299 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2338 - val_loss: 1.6298 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2078 - val_loss: 1.6297 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.1991 - val_loss: 1.6296 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.1991 - val_loss: 1.6295 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2294 - val_loss: 1.6293 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2078 - val_loss: 1.6292 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2294 - val_loss: 1.6291 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.1732 - val_loss: 1.6290 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.1948 - val_loss: 1.6288 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2424 - val_loss: 1.6287 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2468 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2078 - val_loss: 1.6285 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2208 - val_loss: 1.6284 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2078 - val_loss: 1.6283 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.1991 - val_loss: 1.6282 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.1991 - val_loss: 1.6281 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2035 - val_loss: 1.6279 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.1688 - val_loss: 1.6278 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2208 - val_loss: 1.6277 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.1775 - val_loss: 1.6276 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2165 - val_loss: 1.6275 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.1472 - val_loss: 1.6274 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.1991 - val_loss: 1.6273 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.1991 - val_loss: 1.6271 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2468 - val_loss: 1.6270 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2121 - val_loss: 1.6269 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.1861 - val_loss: 1.6268 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2035 - val_loss: 1.6267 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2208 - val_loss: 1.6266 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2597 - val_loss: 1.6265 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.1991 - val_loss: 1.6264 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.1775 - val_loss: 1.6263 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2208 - val_loss: 1.6263 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2294 - val_loss: 1.6262 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.1645 - val_loss: 1.6260 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2165 - val_loss: 1.6259 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2208 - val_loss: 1.6257 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.1991 - val_loss: 1.6257 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.1861 - val_loss: 1.6256 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2208 - val_loss: 1.6255 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2511 - val_loss: 1.6254 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.1991 - val_loss: 1.6252 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.1905 - val_loss: 1.6251 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2597 - val_loss: 1.6250 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2424 - val_loss: 1.6249 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2251 - val_loss: 1.6248 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2727 - val_loss: 1.6246 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2251 - val_loss: 1.6246 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2078 - val_loss: 1.6245 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2381 - val_loss: 1.6244 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2165 - val_loss: 1.6242 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2121 - val_loss: 1.6241 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2165 - val_loss: 1.6240 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2078 - val_loss: 1.6238 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2727 - val_loss: 1.6237 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2121 - val_loss: 1.6236 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2035 - val_loss: 1.6235 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2294 - val_loss: 1.6234 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2208 - val_loss: 1.6233 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2381 - val_loss: 1.6233 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2078 - val_loss: 1.6232 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2597 - val_loss: 1.6231 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2078 - val_loss: 1.6230 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2597 - val_loss: 1.6228 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 29 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6604 - accuracy: 0.1991 - val_loss: 1.6605 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 3s/epoch - 195ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6586 - accuracy: 0.1861 - val_loss: 1.6596 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6581 - accuracy: 0.2381 - val_loss: 1.6588 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6569 - accuracy: 0.2208 - val_loss: 1.6581 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6573 - accuracy: 0.2208 - val_loss: 1.6574 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6554 - accuracy: 0.2035 - val_loss: 1.6567 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6535 - accuracy: 0.2121 - val_loss: 1.6560 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6545 - accuracy: 0.2078 - val_loss: 1.6552 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6528 - accuracy: 0.2338 - val_loss: 1.6544 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6528 - accuracy: 0.2251 - val_loss: 1.6536 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6527 - accuracy: 0.2165 - val_loss: 1.6529 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6509 - accuracy: 0.2338 - val_loss: 1.6522 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6513 - accuracy: 0.2208 - val_loss: 1.6514 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2251 - val_loss: 1.6507 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6484 - accuracy: 0.2381 - val_loss: 1.6501 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6482 - accuracy: 0.2078 - val_loss: 1.6496 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6478 - accuracy: 0.2338 - val_loss: 1.6491 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6449 - accuracy: 0.2424 - val_loss: 1.6486 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6476 - accuracy: 0.2165 - val_loss: 1.6481 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2165 - val_loss: 1.6475 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6472 - accuracy: 0.1948 - val_loss: 1.6468 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6434 - accuracy: 0.2424 - val_loss: 1.6463 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6440 - accuracy: 0.2424 - val_loss: 1.6457 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6417 - accuracy: 0.2424 - val_loss: 1.6452 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6429 - accuracy: 0.2165 - val_loss: 1.6447 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6412 - accuracy: 0.2468 - val_loss: 1.6440 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6403 - accuracy: 0.2424 - val_loss: 1.6435 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6445 - accuracy: 0.1991 - val_loss: 1.6433 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6369 - accuracy: 0.2468 - val_loss: 1.6428 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6402 - accuracy: 0.2424 - val_loss: 1.6424 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6413 - accuracy: 0.2165 - val_loss: 1.6418 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6372 - accuracy: 0.2597 - val_loss: 1.6413 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6387 - accuracy: 0.2424 - val_loss: 1.6409 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6371 - accuracy: 0.2338 - val_loss: 1.6404 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6394 - accuracy: 0.2381 - val_loss: 1.6401 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6361 - accuracy: 0.2121 - val_loss: 1.6396 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2294 - val_loss: 1.6393 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2251 - val_loss: 1.6390 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2511 - val_loss: 1.6387 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6350 - accuracy: 0.2294 - val_loss: 1.6383 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2468 - val_loss: 1.6380 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2338 - val_loss: 1.6375 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.2078 - val_loss: 1.6371 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2165 - val_loss: 1.6368 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.2338 - val_loss: 1.6364 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2208 - val_loss: 1.6361 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2381 - val_loss: 1.6357 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2294 - val_loss: 1.6354 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2468 - val_loss: 1.6349 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2381 - val_loss: 1.6346 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2381 - val_loss: 1.6342 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2035 - val_loss: 1.6339 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.2078 - val_loss: 1.6335 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2381 - val_loss: 1.6332 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2424 - val_loss: 1.6328 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2208 - val_loss: 1.6326 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.1905 - val_loss: 1.6322 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.1905 - val_loss: 1.6319 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2424 - val_loss: 1.6317 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2078 - val_loss: 1.6315 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2035 - val_loss: 1.6314 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6285 - accuracy: 0.1905 - val_loss: 1.6311 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2468 - val_loss: 1.6309 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2294 - val_loss: 1.6306 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2641 - val_loss: 1.6302 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2597 - val_loss: 1.6299 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2424 - val_loss: 1.6296 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2251 - val_loss: 1.6294 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2381 - val_loss: 1.6292 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2381 - val_loss: 1.6291 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2078 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2424 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2294 - val_loss: 1.6288 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2424 - val_loss: 1.6287 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2208 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2294 - val_loss: 1.6283 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2208 - val_loss: 1.6281 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2814 - val_loss: 1.6279 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6239 - accuracy: 0.2381 - val_loss: 1.6278 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2814 - val_loss: 1.6274 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2468 - val_loss: 1.6272 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2165 - val_loss: 1.6267 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2424 - val_loss: 1.6263 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2381 - val_loss: 1.6260 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2208 - val_loss: 1.6257 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2121 - val_loss: 1.6255 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2597 - val_loss: 1.6256 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2511 - val_loss: 1.6256 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2078 - val_loss: 1.6256 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2511 - val_loss: 1.6255 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2338 - val_loss: 1.6254 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 71ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2424 - val_loss: 1.6254 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2294 - val_loss: 1.6253 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2468 - val_loss: 1.6253 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2468 - val_loss: 1.6253 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.1948 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2338 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 90ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2511 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 70ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2424 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2468 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 1.2500e-05 - 69ms/epoch - 5ms/step\n",
      "Node 29 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6618 - accuracy: 0.1515 - val_loss: 1.6598 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 3s/epoch - 352ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6587 - accuracy: 0.2338 - val_loss: 1.6592 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2165 - val_loss: 1.6587 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.1991 - val_loss: 1.6582 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6583 - accuracy: 0.2035 - val_loss: 1.6579 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.1905 - val_loss: 1.6573 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2078 - val_loss: 1.6569 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.1861 - val_loss: 1.6564 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.1991 - val_loss: 1.6561 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2035 - val_loss: 1.6557 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6546 - accuracy: 0.1688 - val_loss: 1.6552 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6538 - accuracy: 0.1818 - val_loss: 1.6547 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2121 - val_loss: 1.6542 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2078 - val_loss: 1.6538 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6552 - accuracy: 0.1818 - val_loss: 1.6534 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6537 - accuracy: 0.2078 - val_loss: 1.6530 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2424 - val_loss: 1.6526 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.1905 - val_loss: 1.6522 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.1991 - val_loss: 1.6518 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2251 - val_loss: 1.6514 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6516 - accuracy: 0.2424 - val_loss: 1.6510 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2684 - val_loss: 1.6505 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6484 - accuracy: 0.1905 - val_loss: 1.6502 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2078 - val_loss: 1.6498 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2294 - val_loss: 1.6494 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6504 - accuracy: 0.2078 - val_loss: 1.6491 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2294 - val_loss: 1.6488 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2294 - val_loss: 1.6485 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2251 - val_loss: 1.6481 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2511 - val_loss: 1.6479 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2338 - val_loss: 1.6477 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2511 - val_loss: 1.6474 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6457 - accuracy: 0.2468 - val_loss: 1.6470 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6467 - accuracy: 0.2208 - val_loss: 1.6467 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2554 - val_loss: 1.6464 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2727 - val_loss: 1.6461 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2511 - val_loss: 1.6457 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2338 - val_loss: 1.6453 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2554 - val_loss: 1.6451 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2078 - val_loss: 1.6448 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6439 - accuracy: 0.2338 - val_loss: 1.6446 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6457 - accuracy: 0.1775 - val_loss: 1.6443 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6397 - accuracy: 0.2987 - val_loss: 1.6440 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2381 - val_loss: 1.6437 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.1948 - val_loss: 1.6435 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6444 - accuracy: 0.2208 - val_loss: 1.6432 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2597 - val_loss: 1.6430 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2251 - val_loss: 1.6427 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2900 - val_loss: 1.6425 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2597 - val_loss: 1.6423 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6367 - accuracy: 0.2554 - val_loss: 1.6421 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6398 - accuracy: 0.2597 - val_loss: 1.6418 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 71ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.1991 - val_loss: 1.6416 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2251 - val_loss: 1.6413 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6381 - accuracy: 0.2338 - val_loss: 1.6410 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.2554 - val_loss: 1.6409 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2597 - val_loss: 1.6408 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2424 - val_loss: 1.6405 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2814 - val_loss: 1.6403 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2381 - val_loss: 1.6401 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2641 - val_loss: 1.6398 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2381 - val_loss: 1.6394 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2078 - val_loss: 1.6391 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2900 - val_loss: 1.6389 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2381 - val_loss: 1.6386 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2814 - val_loss: 1.6384 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2511 - val_loss: 1.6382 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2381 - val_loss: 1.6380 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2684 - val_loss: 1.6379 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2554 - val_loss: 1.6378 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2554 - val_loss: 1.6376 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2857 - val_loss: 1.6374 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2900 - val_loss: 1.6372 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2684 - val_loss: 1.6370 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2165 - val_loss: 1.6370 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.1991 - val_loss: 1.6368 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2511 - val_loss: 1.6367 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2597 - val_loss: 1.6365 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2684 - val_loss: 1.6363 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2424 - val_loss: 1.6360 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2338 - val_loss: 1.6358 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2424 - val_loss: 1.6355 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2208 - val_loss: 1.6352 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2424 - val_loss: 1.6350 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2727 - val_loss: 1.6348 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2294 - val_loss: 1.6345 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2684 - val_loss: 1.6343 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2554 - val_loss: 1.6339 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2251 - val_loss: 1.6338 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2381 - val_loss: 1.6336 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2165 - val_loss: 1.6335 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2857 - val_loss: 1.6335 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2597 - val_loss: 1.6335 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2597 - val_loss: 1.6334 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2641 - val_loss: 1.6334 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2554 - val_loss: 1.6334 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 51ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2511 - val_loss: 1.6333 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 49ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2121 - val_loss: 1.6332 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2511 - val_loss: 1.6331 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 67ms/epoch - 8ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2251 - val_loss: 1.6331 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 49ms/epoch - 6ms/step\n",
      "Node 29 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 29 - Best Validation Accuracy: 0.2931\n",
      "Best model saved for Node 29 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_29.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_30_dataset.csv\n",
      "Node 30 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6357 - accuracy: 0.1577 - val_loss: 1.6348 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 3s/epoch - 148ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6344 - accuracy: 0.2385 - val_loss: 1.6343 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6349 - accuracy: 0.1923 - val_loss: 1.6338 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 42ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6344 - accuracy: 0.2231 - val_loss: 1.6335 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6356 - accuracy: 0.1692 - val_loss: 1.6331 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6332 - accuracy: 0.2077 - val_loss: 1.6328 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6330 - accuracy: 0.2192 - val_loss: 1.6325 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6336 - accuracy: 0.2154 - val_loss: 1.6324 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6331 - accuracy: 0.2000 - val_loss: 1.6321 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6318 - accuracy: 0.2038 - val_loss: 1.6318 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6322 - accuracy: 0.1962 - val_loss: 1.6315 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6320 - accuracy: 0.2231 - val_loss: 1.6313 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6315 - accuracy: 0.1923 - val_loss: 1.6312 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2000 - val_loss: 1.6309 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6315 - accuracy: 0.2115 - val_loss: 1.6306 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2154 - val_loss: 1.6303 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6306 - accuracy: 0.2192 - val_loss: 1.6300 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2115 - val_loss: 1.6297 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6294 - accuracy: 0.2308 - val_loss: 1.6294 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2269 - val_loss: 1.6291 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6287 - accuracy: 0.2308 - val_loss: 1.6288 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6287 - accuracy: 0.2115 - val_loss: 1.6285 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6284 - accuracy: 0.2346 - val_loss: 1.6282 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6290 - accuracy: 0.2269 - val_loss: 1.6280 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6277 - accuracy: 0.2462 - val_loss: 1.6277 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2269 - val_loss: 1.6275 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6274 - accuracy: 0.2500 - val_loss: 1.6273 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6282 - accuracy: 0.2269 - val_loss: 1.6270 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6273 - accuracy: 0.2192 - val_loss: 1.6268 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6260 - accuracy: 0.2462 - val_loss: 1.6265 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6264 - accuracy: 0.2269 - val_loss: 1.6262 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6257 - accuracy: 0.2577 - val_loss: 1.6260 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6252 - accuracy: 0.2192 - val_loss: 1.6257 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.2192 - val_loss: 1.6254 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6239 - accuracy: 0.2462 - val_loss: 1.6251 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6233 - accuracy: 0.2538 - val_loss: 1.6248 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6237 - accuracy: 0.2346 - val_loss: 1.6246 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6258 - accuracy: 0.2308 - val_loss: 1.6243 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6243 - accuracy: 0.2654 - val_loss: 1.6239 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2500 - val_loss: 1.6238 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6244 - accuracy: 0.2269 - val_loss: 1.6236 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6238 - accuracy: 0.2385 - val_loss: 1.6233 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2500 - val_loss: 1.6229 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2231 - val_loss: 1.6226 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2192 - val_loss: 1.6225 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6210 - accuracy: 0.2462 - val_loss: 1.6223 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6210 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2462 - val_loss: 1.6217 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6220 - accuracy: 0.2308 - val_loss: 1.6215 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2462 - val_loss: 1.6212 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6216 - accuracy: 0.2385 - val_loss: 1.6210 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6192 - accuracy: 0.2577 - val_loss: 1.6208 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6186 - accuracy: 0.2423 - val_loss: 1.6206 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2500 - val_loss: 1.6203 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6197 - accuracy: 0.2615 - val_loss: 1.6200 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2115 - val_loss: 1.6199 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6212 - accuracy: 0.2346 - val_loss: 1.6197 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2500 - val_loss: 1.6195 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6184 - accuracy: 0.2615 - val_loss: 1.6192 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6173 - accuracy: 0.2462 - val_loss: 1.6189 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6172 - accuracy: 0.2769 - val_loss: 1.6187 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2192 - val_loss: 1.6185 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6175 - accuracy: 0.2423 - val_loss: 1.6183 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6179 - accuracy: 0.2385 - val_loss: 1.6180 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6151 - accuracy: 0.2654 - val_loss: 1.6178 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6178 - accuracy: 0.2731 - val_loss: 1.6176 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6159 - accuracy: 0.2692 - val_loss: 1.6174 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6146 - accuracy: 0.2692 - val_loss: 1.6173 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 57ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6155 - accuracy: 0.2346 - val_loss: 1.6171 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6164 - accuracy: 0.2769 - val_loss: 1.6169 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6144 - accuracy: 0.2885 - val_loss: 1.6167 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6140 - accuracy: 0.2692 - val_loss: 1.6164 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 58ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6163 - accuracy: 0.2385 - val_loss: 1.6162 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6161 - accuracy: 0.2308 - val_loss: 1.6159 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6118 - accuracy: 0.2577 - val_loss: 1.6156 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6133 - accuracy: 0.2423 - val_loss: 1.6154 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6140 - accuracy: 0.2346 - val_loss: 1.6151 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6102 - accuracy: 0.2846 - val_loss: 1.6148 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6167 - accuracy: 0.2500 - val_loss: 1.6146 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6131 - accuracy: 0.2423 - val_loss: 1.6144 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6094 - accuracy: 0.2769 - val_loss: 1.6141 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6184 - accuracy: 0.2577 - val_loss: 1.6139 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6118 - accuracy: 0.2615 - val_loss: 1.6138 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6143 - accuracy: 0.2500 - val_loss: 1.6136 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6089 - accuracy: 0.2885 - val_loss: 1.6133 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6086 - accuracy: 0.2923 - val_loss: 1.6131 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6114 - accuracy: 0.2654 - val_loss: 1.6129 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6165 - accuracy: 0.2154 - val_loss: 1.6127 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6118 - accuracy: 0.2577 - val_loss: 1.6126 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6085 - accuracy: 0.2615 - val_loss: 1.6124 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6134 - accuracy: 0.2423 - val_loss: 1.6122 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6155 - accuracy: 0.2615 - val_loss: 1.6121 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6119 - accuracy: 0.2346 - val_loss: 1.6120 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.6140 - accuracy: 0.2423 - val_loss: 1.6118 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6117 - accuracy: 0.2615 - val_loss: 1.6116 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6111 - accuracy: 0.2423 - val_loss: 1.6114 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 1.6113 - accuracy: 0.2808 - val_loss: 1.6110 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.6099 - accuracy: 0.2462 - val_loss: 1.6108 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.6106 - accuracy: 0.2308 - val_loss: 1.6106 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 1.6072 - accuracy: 0.2654 - val_loss: 1.6103 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Node 30 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6350 - accuracy: 0.2000 - val_loss: 1.6356 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 3s/epoch - 323ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6355 - accuracy: 0.1923 - val_loss: 1.6353 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6362 - accuracy: 0.1769 - val_loss: 1.6351 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6338 - accuracy: 0.1962 - val_loss: 1.6348 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6341 - accuracy: 0.1923 - val_loss: 1.6346 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6340 - accuracy: 0.1885 - val_loss: 1.6343 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6334 - accuracy: 0.2154 - val_loss: 1.6342 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6357 - accuracy: 0.1308 - val_loss: 1.6339 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6351 - accuracy: 0.2038 - val_loss: 1.6337 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6335 - accuracy: 0.2462 - val_loss: 1.6334 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6332 - accuracy: 0.2423 - val_loss: 1.6332 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6333 - accuracy: 0.2077 - val_loss: 1.6330 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2308 - val_loss: 1.6327 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2538 - val_loss: 1.6324 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6330 - accuracy: 0.2038 - val_loss: 1.6322 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6335 - accuracy: 0.2115 - val_loss: 1.6321 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6300 - accuracy: 0.2462 - val_loss: 1.6319 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.2192 - val_loss: 1.6318 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2308 - val_loss: 1.6316 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6311 - accuracy: 0.1962 - val_loss: 1.6314 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6334 - accuracy: 0.2000 - val_loss: 1.6312 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2231 - val_loss: 1.6310 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2192 - val_loss: 1.6309 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6287 - accuracy: 0.2346 - val_loss: 1.6307 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2423 - val_loss: 1.6305 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6285 - accuracy: 0.2269 - val_loss: 1.6304 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2269 - val_loss: 1.6302 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6300 - accuracy: 0.2000 - val_loss: 1.6300 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6300 - accuracy: 0.2269 - val_loss: 1.6298 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6319 - accuracy: 0.1923 - val_loss: 1.6296 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2077 - val_loss: 1.6295 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.1885 - val_loss: 1.6293 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6304 - accuracy: 0.1962 - val_loss: 1.6291 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.2538 - val_loss: 1.6290 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2038 - val_loss: 1.6287 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2077 - val_loss: 1.6286 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2462 - val_loss: 1.6284 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2077 - val_loss: 1.6283 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2077 - val_loss: 1.6281 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6292 - accuracy: 0.1962 - val_loss: 1.6280 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6277 - accuracy: 0.1692 - val_loss: 1.6278 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6298 - accuracy: 0.1923 - val_loss: 1.6276 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.1885 - val_loss: 1.6275 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6262 - accuracy: 0.2038 - val_loss: 1.6273 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2192 - val_loss: 1.6271 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2154 - val_loss: 1.6270 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6271 - accuracy: 0.2308 - val_loss: 1.6268 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6234 - accuracy: 0.2615 - val_loss: 1.6266 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6250 - accuracy: 0.2731 - val_loss: 1.6265 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2077 - val_loss: 1.6264 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2154 - val_loss: 1.6262 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6268 - accuracy: 0.2269 - val_loss: 1.6260 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6254 - accuracy: 0.2231 - val_loss: 1.6259 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6250 - accuracy: 0.2231 - val_loss: 1.6258 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2538 - val_loss: 1.6257 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2308 - val_loss: 1.6256 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2423 - val_loss: 1.6254 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6272 - accuracy: 0.2423 - val_loss: 1.6253 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6251 - accuracy: 0.2077 - val_loss: 1.6253 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2077 - val_loss: 1.6252 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2346 - val_loss: 1.6250 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6269 - accuracy: 0.2231 - val_loss: 1.6249 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2462 - val_loss: 1.6248 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2308 - val_loss: 1.6246 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2115 - val_loss: 1.6244 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6273 - accuracy: 0.2154 - val_loss: 1.6243 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2231 - val_loss: 1.6242 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6230 - accuracy: 0.2231 - val_loss: 1.6241 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2346 - val_loss: 1.6240 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6221 - accuracy: 0.2538 - val_loss: 1.6239 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.1962 - val_loss: 1.6237 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6188 - accuracy: 0.2269 - val_loss: 1.6236 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6226 - accuracy: 0.2423 - val_loss: 1.6235 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6251 - accuracy: 0.1808 - val_loss: 1.6233 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6214 - accuracy: 0.2308 - val_loss: 1.6232 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.2346 - val_loss: 1.6230 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2538 - val_loss: 1.6228 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2692 - val_loss: 1.6227 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6235 - accuracy: 0.2269 - val_loss: 1.6225 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2269 - val_loss: 1.6224 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6231 - accuracy: 0.2231 - val_loss: 1.6222 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6212 - accuracy: 0.2154 - val_loss: 1.6221 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.1923 - val_loss: 1.6220 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2115 - val_loss: 1.6218 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6198 - accuracy: 0.2577 - val_loss: 1.6217 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2423 - val_loss: 1.6216 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6194 - accuracy: 0.2192 - val_loss: 1.6215 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6218 - accuracy: 0.2423 - val_loss: 1.6213 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6209 - accuracy: 0.2385 - val_loss: 1.6212 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2115 - val_loss: 1.6211 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2308 - val_loss: 1.6210 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6233 - accuracy: 0.1962 - val_loss: 1.6209 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6202 - accuracy: 0.2308 - val_loss: 1.6208 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6172 - accuracy: 0.2692 - val_loss: 1.6207 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2423 - val_loss: 1.6205 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6213 - accuracy: 0.2231 - val_loss: 1.6204 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6204 - accuracy: 0.2423 - val_loss: 1.6203 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6167 - accuracy: 0.2115 - val_loss: 1.6202 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6190 - accuracy: 0.2577 - val_loss: 1.6200 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2308 - val_loss: 1.6200 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Node 30 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6591 - accuracy: 0.2038 - val_loss: 1.6593 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 3s/epoch - 151ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6594 - accuracy: 0.1769 - val_loss: 1.6583 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6569 - accuracy: 0.2346 - val_loss: 1.6572 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6574 - accuracy: 0.2308 - val_loss: 1.6560 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6552 - accuracy: 0.2192 - val_loss: 1.6550 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6538 - accuracy: 0.2269 - val_loss: 1.6541 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6536 - accuracy: 0.2192 - val_loss: 1.6533 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6530 - accuracy: 0.2346 - val_loss: 1.6524 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6520 - accuracy: 0.2231 - val_loss: 1.6516 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6505 - accuracy: 0.2615 - val_loss: 1.6506 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6512 - accuracy: 0.2000 - val_loss: 1.6498 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6502 - accuracy: 0.2192 - val_loss: 1.6489 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6502 - accuracy: 0.2308 - val_loss: 1.6482 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6474 - accuracy: 0.2500 - val_loss: 1.6473 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6464 - accuracy: 0.2192 - val_loss: 1.6465 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6466 - accuracy: 0.2269 - val_loss: 1.6457 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6479 - accuracy: 0.2577 - val_loss: 1.6450 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6460 - accuracy: 0.2731 - val_loss: 1.6443 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6444 - accuracy: 0.2500 - val_loss: 1.6435 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6406 - accuracy: 0.2308 - val_loss: 1.6429 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6399 - accuracy: 0.2692 - val_loss: 1.6421 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6459 - accuracy: 0.2308 - val_loss: 1.6415 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6403 - accuracy: 0.2462 - val_loss: 1.6408 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6394 - accuracy: 0.2269 - val_loss: 1.6401 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6402 - accuracy: 0.2346 - val_loss: 1.6396 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6369 - accuracy: 0.2615 - val_loss: 1.6388 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6425 - accuracy: 0.2500 - val_loss: 1.6382 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6362 - accuracy: 0.2538 - val_loss: 1.6376 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6365 - accuracy: 0.2462 - val_loss: 1.6369 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6372 - accuracy: 0.2385 - val_loss: 1.6363 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6403 - accuracy: 0.2692 - val_loss: 1.6358 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6356 - accuracy: 0.2308 - val_loss: 1.6352 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6359 - accuracy: 0.2885 - val_loss: 1.6347 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6350 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6333 - accuracy: 0.2500 - val_loss: 1.6336 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6318 - accuracy: 0.2962 - val_loss: 1.6330 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6324 - accuracy: 0.2462 - val_loss: 1.6323 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6305 - accuracy: 0.2346 - val_loss: 1.6317 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6323 - accuracy: 0.2769 - val_loss: 1.6311 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6299 - accuracy: 0.2154 - val_loss: 1.6307 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2577 - val_loss: 1.6301 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6273 - accuracy: 0.2462 - val_loss: 1.6296 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6280 - accuracy: 0.2615 - val_loss: 1.6291 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6266 - accuracy: 0.2615 - val_loss: 1.6285 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6286 - accuracy: 0.2615 - val_loss: 1.6281 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6280 - accuracy: 0.2615 - val_loss: 1.6276 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2731 - val_loss: 1.6272 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6297 - accuracy: 0.2615 - val_loss: 1.6267 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6248 - accuracy: 0.2500 - val_loss: 1.6262 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6318 - accuracy: 0.2654 - val_loss: 1.6258 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6263 - accuracy: 0.2115 - val_loss: 1.6253 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6229 - accuracy: 0.2615 - val_loss: 1.6248 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6293 - accuracy: 0.2500 - val_loss: 1.6244 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6175 - accuracy: 0.2615 - val_loss: 1.6238 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6217 - accuracy: 0.2538 - val_loss: 1.6233 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6250 - accuracy: 0.2385 - val_loss: 1.6230 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2346 - val_loss: 1.6227 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6234 - accuracy: 0.2692 - val_loss: 1.6222 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6211 - accuracy: 0.2154 - val_loss: 1.6216 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2769 - val_loss: 1.6211 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6222 - accuracy: 0.2577 - val_loss: 1.6206 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6251 - accuracy: 0.2769 - val_loss: 1.6202 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6189 - accuracy: 0.2962 - val_loss: 1.6199 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6196 - accuracy: 0.2731 - val_loss: 1.6194 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6157 - accuracy: 0.2538 - val_loss: 1.6187 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6177 - accuracy: 0.2769 - val_loss: 1.6182 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6230 - accuracy: 0.2346 - val_loss: 1.6179 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6141 - accuracy: 0.2731 - val_loss: 1.6176 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6147 - accuracy: 0.2423 - val_loss: 1.6168 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6141 - accuracy: 0.2731 - val_loss: 1.6160 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6215 - accuracy: 0.2577 - val_loss: 1.6154 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6133 - accuracy: 0.3000 - val_loss: 1.6149 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6147 - accuracy: 0.2808 - val_loss: 1.6143 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6102 - accuracy: 0.2846 - val_loss: 1.6138 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6127 - accuracy: 0.2846 - val_loss: 1.6133 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6118 - accuracy: 0.2577 - val_loss: 1.6128 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6135 - accuracy: 0.2692 - val_loss: 1.6123 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6097 - accuracy: 0.2538 - val_loss: 1.6117 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6143 - accuracy: 0.2462 - val_loss: 1.6114 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6141 - accuracy: 0.2692 - val_loss: 1.6111 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6107 - accuracy: 0.2462 - val_loss: 1.6105 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6101 - accuracy: 0.2885 - val_loss: 1.6099 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6149 - accuracy: 0.2500 - val_loss: 1.6096 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6153 - accuracy: 0.2577 - val_loss: 1.6093 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6090 - accuracy: 0.3038 - val_loss: 1.6089 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6068 - accuracy: 0.2692 - val_loss: 1.6085 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6087 - accuracy: 0.2654 - val_loss: 1.6081 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6075 - accuracy: 0.2846 - val_loss: 1.6072 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6099 - accuracy: 0.2654 - val_loss: 1.6065 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6016 - accuracy: 0.3154 - val_loss: 1.6059 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6045 - accuracy: 0.2923 - val_loss: 1.6052 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6009 - accuracy: 0.2885 - val_loss: 1.6044 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6084 - accuracy: 0.2885 - val_loss: 1.6040 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.6024 - accuracy: 0.2962 - val_loss: 1.6038 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.5981 - accuracy: 0.3038 - val_loss: 1.6033 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6037 - accuracy: 0.2654 - val_loss: 1.6025 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 1.6101 - accuracy: 0.2615 - val_loss: 1.6019 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.5965 - accuracy: 0.2385 - val_loss: 1.6013 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 100ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.6032 - accuracy: 0.3038 - val_loss: 1.6008 - val_accuracy: 0.3182 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 1.6082 - accuracy: 0.3154 - val_loss: 1.6003 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Node 30 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6612 - accuracy: 0.1808 - val_loss: 1.6605 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 3s/epoch - 333ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6602 - accuracy: 0.1885 - val_loss: 1.6598 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6595 - accuracy: 0.2462 - val_loss: 1.6592 - val_accuracy: 0.2121 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6589 - accuracy: 0.2154 - val_loss: 1.6586 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6589 - accuracy: 0.2038 - val_loss: 1.6581 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6581 - accuracy: 0.2500 - val_loss: 1.6575 - val_accuracy: 0.1970 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6583 - accuracy: 0.1846 - val_loss: 1.6570 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6558 - accuracy: 0.2423 - val_loss: 1.6565 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6559 - accuracy: 0.2154 - val_loss: 1.6560 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6558 - accuracy: 0.1923 - val_loss: 1.6555 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6543 - accuracy: 0.2192 - val_loss: 1.6550 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6531 - accuracy: 0.2692 - val_loss: 1.6545 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6518 - accuracy: 0.2808 - val_loss: 1.6540 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6538 - accuracy: 0.2385 - val_loss: 1.6535 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6511 - accuracy: 0.2577 - val_loss: 1.6530 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6533 - accuracy: 0.2115 - val_loss: 1.6526 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6520 - accuracy: 0.2115 - val_loss: 1.6520 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6519 - accuracy: 0.2308 - val_loss: 1.6515 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6498 - accuracy: 0.2269 - val_loss: 1.6510 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6517 - accuracy: 0.2462 - val_loss: 1.6506 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6480 - accuracy: 0.2385 - val_loss: 1.6501 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6495 - accuracy: 0.2500 - val_loss: 1.6497 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6477 - accuracy: 0.2308 - val_loss: 1.6492 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6498 - accuracy: 0.2308 - val_loss: 1.6488 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6478 - accuracy: 0.2308 - val_loss: 1.6484 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6470 - accuracy: 0.2346 - val_loss: 1.6480 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6465 - accuracy: 0.2385 - val_loss: 1.6476 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6467 - accuracy: 0.2269 - val_loss: 1.6472 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6444 - accuracy: 0.2192 - val_loss: 1.6467 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6455 - accuracy: 0.2577 - val_loss: 1.6463 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6449 - accuracy: 0.2615 - val_loss: 1.6460 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6421 - accuracy: 0.2731 - val_loss: 1.6456 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6422 - accuracy: 0.2462 - val_loss: 1.6452 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6435 - accuracy: 0.2385 - val_loss: 1.6448 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6419 - accuracy: 0.2615 - val_loss: 1.6443 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6434 - accuracy: 0.2308 - val_loss: 1.6439 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6429 - accuracy: 0.2500 - val_loss: 1.6436 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6395 - accuracy: 0.2462 - val_loss: 1.6432 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6400 - accuracy: 0.2731 - val_loss: 1.6427 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6446 - accuracy: 0.2231 - val_loss: 1.6424 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6380 - accuracy: 0.2731 - val_loss: 1.6421 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6419 - accuracy: 0.2423 - val_loss: 1.6418 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6363 - accuracy: 0.2885 - val_loss: 1.6414 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6397 - accuracy: 0.2423 - val_loss: 1.6410 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6403 - accuracy: 0.2538 - val_loss: 1.6407 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6340 - accuracy: 0.2423 - val_loss: 1.6403 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6404 - accuracy: 0.2654 - val_loss: 1.6400 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6382 - accuracy: 0.2538 - val_loss: 1.6396 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6379 - accuracy: 0.2462 - val_loss: 1.6392 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2500 - val_loss: 1.6389 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6378 - accuracy: 0.2308 - val_loss: 1.6386 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 71ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6379 - accuracy: 0.2308 - val_loss: 1.6382 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6347 - accuracy: 0.2500 - val_loss: 1.6380 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6364 - accuracy: 0.2731 - val_loss: 1.6377 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6331 - accuracy: 0.2654 - val_loss: 1.6373 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6335 - accuracy: 0.2231 - val_loss: 1.6370 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6344 - accuracy: 0.2885 - val_loss: 1.6366 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6353 - accuracy: 0.2615 - val_loss: 1.6362 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6386 - accuracy: 0.2346 - val_loss: 1.6358 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6360 - accuracy: 0.2308 - val_loss: 1.6355 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6334 - accuracy: 0.2808 - val_loss: 1.6353 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6359 - accuracy: 0.2269 - val_loss: 1.6349 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6305 - accuracy: 0.2423 - val_loss: 1.6346 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6334 - accuracy: 0.2462 - val_loss: 1.6342 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.2654 - val_loss: 1.6339 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2577 - val_loss: 1.6336 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6332 - accuracy: 0.2308 - val_loss: 1.6334 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6310 - accuracy: 0.2500 - val_loss: 1.6332 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6302 - accuracy: 0.2385 - val_loss: 1.6330 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6272 - accuracy: 0.2923 - val_loss: 1.6327 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2577 - val_loss: 1.6325 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6279 - accuracy: 0.2692 - val_loss: 1.6322 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6318 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6301 - accuracy: 0.2577 - val_loss: 1.6315 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6282 - accuracy: 0.2500 - val_loss: 1.6313 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6278 - accuracy: 0.2692 - val_loss: 1.6310 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6330 - accuracy: 0.2577 - val_loss: 1.6308 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2423 - val_loss: 1.6305 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6290 - accuracy: 0.2346 - val_loss: 1.6302 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6250 - accuracy: 0.2692 - val_loss: 1.6299 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6291 - accuracy: 0.2731 - val_loss: 1.6296 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6333 - accuracy: 0.2346 - val_loss: 1.6294 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2462 - val_loss: 1.6291 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2500 - val_loss: 1.6287 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6245 - accuracy: 0.2577 - val_loss: 1.6284 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6264 - accuracy: 0.2692 - val_loss: 1.6281 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.3115 - val_loss: 1.6278 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2654 - val_loss: 1.6273 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6222 - accuracy: 0.2731 - val_loss: 1.6269 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6207 - accuracy: 0.2577 - val_loss: 1.6265 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2846 - val_loss: 1.6263 - val_accuracy: 0.3030 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6261 - accuracy: 0.2500 - val_loss: 1.6261 - val_accuracy: 0.2879 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2846 - val_loss: 1.6259 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6246 - accuracy: 0.2731 - val_loss: 1.6257 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2538 - val_loss: 1.6255 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6203 - accuracy: 0.2500 - val_loss: 1.6252 - val_accuracy: 0.2273 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6208 - accuracy: 0.2654 - val_loss: 1.6249 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2692 - val_loss: 1.6246 - val_accuracy: 0.2424 - lr: 1.0000e-04 - 70ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6128 - accuracy: 0.3000 - val_loss: 1.6244 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6191 - accuracy: 0.2615 - val_loss: 1.6241 - val_accuracy: 0.2576 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Node 30 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 30 - Best Validation Accuracy: 0.3182\n",
      "Best model saved for Node 30 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_30.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_31_dataset.csv\n",
      "Node 31 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6385 - accuracy: 0.1613 - val_loss: 1.6357 - val_accuracy: 0.1290 - lr: 1.0000e-04 - 3s/epoch - 158ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6383 - accuracy: 0.1573 - val_loss: 1.6351 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6346 - accuracy: 0.2218 - val_loss: 1.6345 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 38ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2298 - val_loss: 1.6340 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6336 - accuracy: 0.2016 - val_loss: 1.6337 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.1734 - val_loss: 1.6331 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2540 - val_loss: 1.6327 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2218 - val_loss: 1.6323 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2419 - val_loss: 1.6319 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.1855 - val_loss: 1.6316 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2218 - val_loss: 1.6314 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.1935 - val_loss: 1.6311 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.1855 - val_loss: 1.6308 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.1976 - val_loss: 1.6304 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2460 - val_loss: 1.6302 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.2298 - val_loss: 1.6299 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2177 - val_loss: 1.6294 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2016 - val_loss: 1.6292 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2379 - val_loss: 1.6290 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6276 - accuracy: 0.2500 - val_loss: 1.6287 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2056 - val_loss: 1.6285 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2500 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2056 - val_loss: 1.6281 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2298 - val_loss: 1.6279 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6286 - accuracy: 0.2298 - val_loss: 1.6277 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2540 - val_loss: 1.6274 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2460 - val_loss: 1.6272 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2016 - val_loss: 1.6269 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2177 - val_loss: 1.6267 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2621 - val_loss: 1.6265 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2379 - val_loss: 1.6262 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2298 - val_loss: 1.6260 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6250 - accuracy: 0.2258 - val_loss: 1.6257 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2137 - val_loss: 1.6254 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2540 - val_loss: 1.6252 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2419 - val_loss: 1.6250 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2540 - val_loss: 1.6247 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2258 - val_loss: 1.6245 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.1935 - val_loss: 1.6242 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2298 - val_loss: 1.6241 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2419 - val_loss: 1.6239 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2097 - val_loss: 1.6237 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2500 - val_loss: 1.6235 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2339 - val_loss: 1.6232 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2097 - val_loss: 1.6230 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6189 - accuracy: 0.2379 - val_loss: 1.6228 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2621 - val_loss: 1.6226 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2339 - val_loss: 1.6224 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2460 - val_loss: 1.6222 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2339 - val_loss: 1.6220 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2661 - val_loss: 1.6218 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2177 - val_loss: 1.6216 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2056 - val_loss: 1.6215 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6194 - accuracy: 0.2702 - val_loss: 1.6212 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2298 - val_loss: 1.6211 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2379 - val_loss: 1.6208 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2177 - val_loss: 1.6206 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.1815 - val_loss: 1.6204 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2460 - val_loss: 1.6203 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2056 - val_loss: 1.6200 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2339 - val_loss: 1.6197 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2419 - val_loss: 1.6195 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2581 - val_loss: 1.6194 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2177 - val_loss: 1.6191 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2419 - val_loss: 1.6189 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2540 - val_loss: 1.6187 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2137 - val_loss: 1.6186 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2379 - val_loss: 1.6185 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2339 - val_loss: 1.6185 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2702 - val_loss: 1.6183 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2339 - val_loss: 1.6182 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6163 - accuracy: 0.2379 - val_loss: 1.6181 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2460 - val_loss: 1.6180 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2177 - val_loss: 1.6179 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2339 - val_loss: 1.6177 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6163 - accuracy: 0.2500 - val_loss: 1.6176 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6148 - accuracy: 0.2661 - val_loss: 1.6174 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.1935 - val_loss: 1.6173 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2137 - val_loss: 1.6170 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2379 - val_loss: 1.6169 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2581 - val_loss: 1.6167 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6080 - accuracy: 0.2379 - val_loss: 1.6165 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6045 - accuracy: 0.2823 - val_loss: 1.6162 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2500 - val_loss: 1.6161 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6167 - accuracy: 0.2056 - val_loss: 1.6160 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6100 - accuracy: 0.2419 - val_loss: 1.6158 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6140 - accuracy: 0.2137 - val_loss: 1.6156 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2419 - val_loss: 1.6154 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2379 - val_loss: 1.6153 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6078 - accuracy: 0.2460 - val_loss: 1.6152 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.1895 - val_loss: 1.6151 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6116 - accuracy: 0.2379 - val_loss: 1.6150 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2379 - val_loss: 1.6149 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6054 - accuracy: 0.2298 - val_loss: 1.6147 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2258 - val_loss: 1.6146 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6094 - accuracy: 0.2419 - val_loss: 1.6145 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6102 - accuracy: 0.2540 - val_loss: 1.6144 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6072 - accuracy: 0.2540 - val_loss: 1.6142 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6100 - accuracy: 0.2742 - val_loss: 1.6142 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Node 31 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6338 - accuracy: 0.2218 - val_loss: 1.6331 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2419 - val_loss: 1.6327 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2177 - val_loss: 1.6323 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2177 - val_loss: 1.6319 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2258 - val_loss: 1.6315 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2097 - val_loss: 1.6312 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2419 - val_loss: 1.6308 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2137 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2339 - val_loss: 1.6301 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2500 - val_loss: 1.6298 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2621 - val_loss: 1.6295 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2298 - val_loss: 1.6292 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2298 - val_loss: 1.6289 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2298 - val_loss: 1.6286 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2298 - val_loss: 1.6283 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2298 - val_loss: 1.6282 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2339 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2621 - val_loss: 1.6278 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2339 - val_loss: 1.6276 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2339 - val_loss: 1.6273 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2258 - val_loss: 1.6270 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2379 - val_loss: 1.6269 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2298 - val_loss: 1.6267 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2339 - val_loss: 1.6265 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2500 - val_loss: 1.6264 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2258 - val_loss: 1.6263 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2500 - val_loss: 1.6261 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2460 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2218 - val_loss: 1.6257 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2419 - val_loss: 1.6255 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2460 - val_loss: 1.6254 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2339 - val_loss: 1.6252 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2298 - val_loss: 1.6250 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2339 - val_loss: 1.6248 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2339 - val_loss: 1.6246 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2339 - val_loss: 1.6244 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2540 - val_loss: 1.6243 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6156 - accuracy: 0.2298 - val_loss: 1.6241 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2540 - val_loss: 1.6239 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2298 - val_loss: 1.6237 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2621 - val_loss: 1.6235 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2419 - val_loss: 1.6234 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2298 - val_loss: 1.6233 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2137 - val_loss: 1.6232 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2339 - val_loss: 1.6231 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2379 - val_loss: 1.6230 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2379 - val_loss: 1.6228 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2258 - val_loss: 1.6228 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2339 - val_loss: 1.6227 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2379 - val_loss: 1.6226 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2460 - val_loss: 1.6224 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2218 - val_loss: 1.6223 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2379 - val_loss: 1.6222 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6145 - accuracy: 0.2419 - val_loss: 1.6221 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2339 - val_loss: 1.6220 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2258 - val_loss: 1.6219 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2500 - val_loss: 1.6219 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2298 - val_loss: 1.6218 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6149 - accuracy: 0.2258 - val_loss: 1.6217 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2298 - val_loss: 1.6217 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2056 - val_loss: 1.6217 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2540 - val_loss: 1.6216 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6103 - accuracy: 0.2379 - val_loss: 1.6216 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6096 - accuracy: 0.2339 - val_loss: 1.6215 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2379 - val_loss: 1.6214 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2540 - val_loss: 1.6213 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6107 - accuracy: 0.2500 - val_loss: 1.6213 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2460 - val_loss: 1.6212 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2379 - val_loss: 1.6212 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2379 - val_loss: 1.6211 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2137 - val_loss: 1.6210 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6092 - accuracy: 0.2702 - val_loss: 1.6209 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2339 - val_loss: 1.6208 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2621 - val_loss: 1.6208 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2500 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2581 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2540 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2419 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2419 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2500 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6129 - accuracy: 0.2500 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2339 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2540 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6057 - accuracy: 0.2339 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2540 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6130 - accuracy: 0.2460 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2460 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6154 - accuracy: 0.2339 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.2298 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2258 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2702 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6108 - accuracy: 0.2581 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2379 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6130 - accuracy: 0.2460 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6088 - accuracy: 0.2298 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6104 - accuracy: 0.2500 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 29ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6098 - accuracy: 0.2621 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 51ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6117 - accuracy: 0.2419 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2540 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2298 - val_loss: 1.6206 - val_accuracy: 0.2258 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Node 31 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6609 - accuracy: 0.2056 - val_loss: 1.6601 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 3s/epoch - 172ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6605 - accuracy: 0.1815 - val_loss: 1.6590 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6574 - accuracy: 0.2581 - val_loss: 1.6579 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6560 - accuracy: 0.2339 - val_loss: 1.6568 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6550 - accuracy: 0.2016 - val_loss: 1.6557 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6562 - accuracy: 0.1976 - val_loss: 1.6549 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6536 - accuracy: 0.2339 - val_loss: 1.6540 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6523 - accuracy: 0.2177 - val_loss: 1.6529 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6509 - accuracy: 0.2339 - val_loss: 1.6519 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6514 - accuracy: 0.2177 - val_loss: 1.6509 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6501 - accuracy: 0.2218 - val_loss: 1.6500 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6472 - accuracy: 0.2218 - val_loss: 1.6493 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6466 - accuracy: 0.2258 - val_loss: 1.6485 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2218 - val_loss: 1.6478 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6447 - accuracy: 0.2218 - val_loss: 1.6470 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6447 - accuracy: 0.2258 - val_loss: 1.6461 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6446 - accuracy: 0.2218 - val_loss: 1.6454 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6429 - accuracy: 0.2218 - val_loss: 1.6447 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6350 - accuracy: 0.2177 - val_loss: 1.6440 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6392 - accuracy: 0.2218 - val_loss: 1.6433 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6397 - accuracy: 0.2258 - val_loss: 1.6427 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6367 - accuracy: 0.2218 - val_loss: 1.6422 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6395 - accuracy: 0.2218 - val_loss: 1.6415 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6371 - accuracy: 0.2298 - val_loss: 1.6410 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6376 - accuracy: 0.2137 - val_loss: 1.6404 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6371 - accuracy: 0.2097 - val_loss: 1.6399 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6345 - accuracy: 0.2218 - val_loss: 1.6393 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6369 - accuracy: 0.2339 - val_loss: 1.6386 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6322 - accuracy: 0.2218 - val_loss: 1.6381 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.2137 - val_loss: 1.6375 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6331 - accuracy: 0.2298 - val_loss: 1.6369 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2339 - val_loss: 1.6365 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2339 - val_loss: 1.6360 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.2177 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2218 - val_loss: 1.6352 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2218 - val_loss: 1.6348 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2258 - val_loss: 1.6344 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2298 - val_loss: 1.6341 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2339 - val_loss: 1.6336 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2177 - val_loss: 1.6332 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2218 - val_loss: 1.6328 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2419 - val_loss: 1.6326 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2379 - val_loss: 1.6323 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.2177 - val_loss: 1.6324 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2339 - val_loss: 1.6321 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2339 - val_loss: 1.6318 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2581 - val_loss: 1.6314 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2298 - val_loss: 1.6309 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2379 - val_loss: 1.6305 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2661 - val_loss: 1.6303 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2258 - val_loss: 1.6301 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2298 - val_loss: 1.6298 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2258 - val_loss: 1.6295 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6189 - accuracy: 0.2177 - val_loss: 1.6292 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2500 - val_loss: 1.6289 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2097 - val_loss: 1.6287 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2581 - val_loss: 1.6283 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2984 - val_loss: 1.6280 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2702 - val_loss: 1.6279 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2258 - val_loss: 1.6280 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6167 - accuracy: 0.2379 - val_loss: 1.6279 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2339 - val_loss: 1.6276 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6076 - accuracy: 0.2661 - val_loss: 1.6276 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2258 - val_loss: 1.6275 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2621 - val_loss: 1.6271 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2258 - val_loss: 1.6270 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6094 - accuracy: 0.2742 - val_loss: 1.6271 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6068 - accuracy: 0.2661 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2298 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2298 - val_loss: 1.6271 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2339 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6122 - accuracy: 0.2661 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6094 - accuracy: 0.2742 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 74ms/epoch - 5ms/step\n",
      "Node 31 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 2s - loss: 1.6594 - accuracy: 0.2540 - val_loss: 1.6583 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 2s/epoch - 307ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.2500 - val_loss: 1.6576 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6573 - accuracy: 0.2379 - val_loss: 1.6569 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6554 - accuracy: 0.2379 - val_loss: 1.6564 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.2339 - val_loss: 1.6558 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2540 - val_loss: 1.6551 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2419 - val_loss: 1.6544 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2419 - val_loss: 1.6538 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6532 - accuracy: 0.2016 - val_loss: 1.6532 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2218 - val_loss: 1.6526 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6499 - accuracy: 0.2500 - val_loss: 1.6520 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6488 - accuracy: 0.2339 - val_loss: 1.6515 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.2581 - val_loss: 1.6510 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6492 - accuracy: 0.2177 - val_loss: 1.6505 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2500 - val_loss: 1.6500 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2339 - val_loss: 1.6496 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6503 - accuracy: 0.2177 - val_loss: 1.6492 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2419 - val_loss: 1.6487 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2218 - val_loss: 1.6483 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6427 - accuracy: 0.2419 - val_loss: 1.6478 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2419 - val_loss: 1.6474 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2500 - val_loss: 1.6469 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2460 - val_loss: 1.6465 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6435 - accuracy: 0.2298 - val_loss: 1.6460 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2137 - val_loss: 1.6456 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6460 - accuracy: 0.2339 - val_loss: 1.6453 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2298 - val_loss: 1.6449 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2460 - val_loss: 1.6445 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2379 - val_loss: 1.6442 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2460 - val_loss: 1.6439 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2540 - val_loss: 1.6435 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2258 - val_loss: 1.6431 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2379 - val_loss: 1.6428 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2460 - val_loss: 1.6424 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2137 - val_loss: 1.6420 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2419 - val_loss: 1.6416 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2218 - val_loss: 1.6413 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2137 - val_loss: 1.6410 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2540 - val_loss: 1.6407 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2339 - val_loss: 1.6404 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2298 - val_loss: 1.6401 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2258 - val_loss: 1.6398 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2500 - val_loss: 1.6395 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2460 - val_loss: 1.6392 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2339 - val_loss: 1.6389 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2581 - val_loss: 1.6386 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2460 - val_loss: 1.6383 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2298 - val_loss: 1.6381 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2419 - val_loss: 1.6378 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2661 - val_loss: 1.6375 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2661 - val_loss: 1.6372 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2419 - val_loss: 1.6369 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2258 - val_loss: 1.6367 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2621 - val_loss: 1.6366 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2379 - val_loss: 1.6363 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2379 - val_loss: 1.6360 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2218 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2339 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2540 - val_loss: 1.6353 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2339 - val_loss: 1.6351 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2379 - val_loss: 1.6350 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2379 - val_loss: 1.6348 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2460 - val_loss: 1.6345 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2540 - val_loss: 1.6343 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2339 - val_loss: 1.6340 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2581 - val_loss: 1.6338 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2661 - val_loss: 1.6335 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2339 - val_loss: 1.6333 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2339 - val_loss: 1.6331 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2460 - val_loss: 1.6329 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2177 - val_loss: 1.6327 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2419 - val_loss: 1.6325 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2339 - val_loss: 1.6323 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2540 - val_loss: 1.6321 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2621 - val_loss: 1.6319 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2258 - val_loss: 1.6317 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2621 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2339 - val_loss: 1.6313 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2661 - val_loss: 1.6311 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2581 - val_loss: 1.6308 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2661 - val_loss: 1.6306 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2581 - val_loss: 1.6304 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2742 - val_loss: 1.6302 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2782 - val_loss: 1.6301 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2379 - val_loss: 1.6299 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2218 - val_loss: 1.6299 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6136 - accuracy: 0.2702 - val_loss: 1.6297 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2218 - val_loss: 1.6294 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2258 - val_loss: 1.6294 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6110 - accuracy: 0.2500 - val_loss: 1.6291 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2661 - val_loss: 1.6289 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6070 - accuracy: 0.2863 - val_loss: 1.6289 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2581 - val_loss: 1.6287 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6127 - accuracy: 0.2742 - val_loss: 1.6285 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2540 - val_loss: 1.6283 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2823 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6120 - accuracy: 0.2702 - val_loss: 1.6281 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6103 - accuracy: 0.2621 - val_loss: 1.6280 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6089 - accuracy: 0.2742 - val_loss: 1.6278 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2742 - val_loss: 1.6276 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Node 31 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 31 - Best Validation Accuracy: 0.3226\n",
      "Best model saved for Node 31 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_31.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_32_dataset.csv\n",
      "Node 32 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6336 - accuracy: 0.2333 - val_loss: 1.6346 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 2s/epoch - 145ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.2083 - val_loss: 1.6341 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.1958 - val_loss: 1.6337 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.2042 - val_loss: 1.6335 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.1792 - val_loss: 1.6332 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.1667 - val_loss: 1.6332 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6341 - accuracy: 0.2250 - val_loss: 1.6330 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.2167 - val_loss: 1.6328 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2583 - val_loss: 1.6326 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2208 - val_loss: 1.6324 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2333 - val_loss: 1.6321 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2542 - val_loss: 1.6318 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2417 - val_loss: 1.6316 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.1875 - val_loss: 1.6315 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.2125 - val_loss: 1.6313 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2458 - val_loss: 1.6311 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2958 - val_loss: 1.6309 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2042 - val_loss: 1.6307 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2083 - val_loss: 1.6305 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.1958 - val_loss: 1.6303 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2292 - val_loss: 1.6301 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2333 - val_loss: 1.6300 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.2208 - val_loss: 1.6299 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2125 - val_loss: 1.6298 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2292 - val_loss: 1.6295 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2458 - val_loss: 1.6293 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2458 - val_loss: 1.6290 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2417 - val_loss: 1.6289 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.1875 - val_loss: 1.6287 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2167 - val_loss: 1.6287 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2083 - val_loss: 1.6284 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2375 - val_loss: 1.6281 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2292 - val_loss: 1.6280 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2292 - val_loss: 1.6278 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2792 - val_loss: 1.6277 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2542 - val_loss: 1.6275 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2750 - val_loss: 1.6273 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2750 - val_loss: 1.6272 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2500 - val_loss: 1.6271 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2708 - val_loss: 1.6270 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2458 - val_loss: 1.6269 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2208 - val_loss: 1.6268 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2542 - val_loss: 1.6266 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2625 - val_loss: 1.6264 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2458 - val_loss: 1.6262 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.1917 - val_loss: 1.6260 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.1833 - val_loss: 1.6259 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2875 - val_loss: 1.6258 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2417 - val_loss: 1.6256 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2917 - val_loss: 1.6255 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2458 - val_loss: 1.6253 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2750 - val_loss: 1.6252 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2167 - val_loss: 1.6251 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2333 - val_loss: 1.6249 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2292 - val_loss: 1.6248 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2417 - val_loss: 1.6247 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2833 - val_loss: 1.6246 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2292 - val_loss: 1.6245 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2417 - val_loss: 1.6244 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.1750 - val_loss: 1.6242 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2542 - val_loss: 1.6240 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.3417 - val_loss: 1.6239 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2208 - val_loss: 1.6237 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2750 - val_loss: 1.6236 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2833 - val_loss: 1.6235 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2667 - val_loss: 1.6235 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2708 - val_loss: 1.6234 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.3042 - val_loss: 1.6233 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.3000 - val_loss: 1.6232 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2708 - val_loss: 1.6231 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6171 - accuracy: 0.2708 - val_loss: 1.6229 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.3167 - val_loss: 1.6228 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.3000 - val_loss: 1.6226 - val_accuracy: 0.3607 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2375 - val_loss: 1.6225 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2458 - val_loss: 1.6224 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2708 - val_loss: 1.6222 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2000 - val_loss: 1.6221 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6107 - accuracy: 0.3208 - val_loss: 1.6221 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2333 - val_loss: 1.6219 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6154 - accuracy: 0.2542 - val_loss: 1.6218 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2167 - val_loss: 1.6216 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2708 - val_loss: 1.6215 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2625 - val_loss: 1.6214 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2667 - val_loss: 1.6212 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2958 - val_loss: 1.6212 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2625 - val_loss: 1.6210 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6133 - accuracy: 0.2708 - val_loss: 1.6209 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2708 - val_loss: 1.6207 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2625 - val_loss: 1.6206 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2875 - val_loss: 1.6205 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2750 - val_loss: 1.6205 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6056 - accuracy: 0.2958 - val_loss: 1.6204 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2750 - val_loss: 1.6202 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2542 - val_loss: 1.6200 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6136 - accuracy: 0.2625 - val_loss: 1.6199 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6099 - accuracy: 0.2542 - val_loss: 1.6199 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2667 - val_loss: 1.6197 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2583 - val_loss: 1.6197 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2583 - val_loss: 1.6196 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6095 - accuracy: 0.3042 - val_loss: 1.6195 - val_accuracy: 0.3279 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Node 32 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6365 - accuracy: 0.1917 - val_loss: 1.6356 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 3s/epoch - 316ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.1917 - val_loss: 1.6354 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2125 - val_loss: 1.6353 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.1375 - val_loss: 1.6352 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.1833 - val_loss: 1.6351 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2042 - val_loss: 1.6349 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2083 - val_loss: 1.6348 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.1917 - val_loss: 1.6347 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.1833 - val_loss: 1.6346 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.1583 - val_loss: 1.6345 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2292 - val_loss: 1.6344 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.1917 - val_loss: 1.6343 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2208 - val_loss: 1.6342 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2208 - val_loss: 1.6341 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2167 - val_loss: 1.6339 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2000 - val_loss: 1.6338 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2083 - val_loss: 1.6337 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2375 - val_loss: 1.6336 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2375 - val_loss: 1.6334 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2042 - val_loss: 1.6333 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2167 - val_loss: 1.6331 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2000 - val_loss: 1.6330 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2667 - val_loss: 1.6329 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2375 - val_loss: 1.6327 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2292 - val_loss: 1.6326 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2125 - val_loss: 1.6325 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2500 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1875 - val_loss: 1.6323 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2417 - val_loss: 1.6322 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2042 - val_loss: 1.6321 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2167 - val_loss: 1.6319 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2042 - val_loss: 1.6318 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2500 - val_loss: 1.6316 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.1917 - val_loss: 1.6314 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2125 - val_loss: 1.6313 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2250 - val_loss: 1.6311 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2042 - val_loss: 1.6310 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2250 - val_loss: 1.6309 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2458 - val_loss: 1.6308 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2208 - val_loss: 1.6306 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2292 - val_loss: 1.6306 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2250 - val_loss: 1.6305 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2208 - val_loss: 1.6304 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2333 - val_loss: 1.6303 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2292 - val_loss: 1.6302 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2458 - val_loss: 1.6300 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2333 - val_loss: 1.6299 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2542 - val_loss: 1.6299 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2250 - val_loss: 1.6297 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2208 - val_loss: 1.6297 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2208 - val_loss: 1.6295 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2042 - val_loss: 1.6294 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2542 - val_loss: 1.6293 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2500 - val_loss: 1.6292 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2417 - val_loss: 1.6291 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2250 - val_loss: 1.6290 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2333 - val_loss: 1.6289 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2083 - val_loss: 1.6287 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2417 - val_loss: 1.6286 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2625 - val_loss: 1.6285 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2333 - val_loss: 1.6284 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2333 - val_loss: 1.6284 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2500 - val_loss: 1.6283 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2375 - val_loss: 1.6283 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2250 - val_loss: 1.6282 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.1917 - val_loss: 1.6281 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2292 - val_loss: 1.6281 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2708 - val_loss: 1.6279 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2750 - val_loss: 1.6278 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2458 - val_loss: 1.6276 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2167 - val_loss: 1.6275 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2500 - val_loss: 1.6274 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2292 - val_loss: 1.6273 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2250 - val_loss: 1.6271 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.3000 - val_loss: 1.6270 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2500 - val_loss: 1.6268 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2958 - val_loss: 1.6268 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2458 - val_loss: 1.6267 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2292 - val_loss: 1.6266 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2667 - val_loss: 1.6265 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2500 - val_loss: 1.6264 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2208 - val_loss: 1.6263 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2542 - val_loss: 1.6262 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2583 - val_loss: 1.6261 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2542 - val_loss: 1.6260 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2208 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2250 - val_loss: 1.6259 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2375 - val_loss: 1.6258 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2750 - val_loss: 1.6257 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2250 - val_loss: 1.6256 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2000 - val_loss: 1.6255 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2583 - val_loss: 1.6254 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2333 - val_loss: 1.6254 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2292 - val_loss: 1.6253 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2500 - val_loss: 1.6252 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2458 - val_loss: 1.6251 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2250 - val_loss: 1.6250 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2583 - val_loss: 1.6248 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2375 - val_loss: 1.6248 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2458 - val_loss: 1.6247 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Node 32 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6585 - accuracy: 0.2042 - val_loss: 1.6589 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 2s/epoch - 147ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6595 - accuracy: 0.1667 - val_loss: 1.6581 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6591 - accuracy: 0.2125 - val_loss: 1.6575 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6570 - accuracy: 0.2125 - val_loss: 1.6566 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6568 - accuracy: 0.2208 - val_loss: 1.6561 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6555 - accuracy: 0.2375 - val_loss: 1.6554 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6546 - accuracy: 0.2375 - val_loss: 1.6548 - val_accuracy: 0.1803 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6532 - accuracy: 0.2500 - val_loss: 1.6543 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6530 - accuracy: 0.2042 - val_loss: 1.6538 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6538 - accuracy: 0.1958 - val_loss: 1.6532 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6525 - accuracy: 0.2333 - val_loss: 1.6526 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6522 - accuracy: 0.2208 - val_loss: 1.6520 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6501 - accuracy: 0.2500 - val_loss: 1.6514 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6489 - accuracy: 0.2958 - val_loss: 1.6507 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6497 - accuracy: 0.2208 - val_loss: 1.6502 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2542 - val_loss: 1.6496 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2458 - val_loss: 1.6491 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2125 - val_loss: 1.6485 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2708 - val_loss: 1.6479 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6461 - accuracy: 0.2250 - val_loss: 1.6474 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6445 - accuracy: 0.2625 - val_loss: 1.6469 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6447 - accuracy: 0.2458 - val_loss: 1.6463 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6450 - accuracy: 0.2167 - val_loss: 1.6457 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.2375 - val_loss: 1.6453 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6416 - accuracy: 0.2458 - val_loss: 1.6448 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6434 - accuracy: 0.2333 - val_loss: 1.6443 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6413 - accuracy: 0.2583 - val_loss: 1.6438 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6388 - accuracy: 0.2583 - val_loss: 1.6434 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6402 - accuracy: 0.2583 - val_loss: 1.6429 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6386 - accuracy: 0.2375 - val_loss: 1.6426 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6380 - accuracy: 0.2500 - val_loss: 1.6421 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6378 - accuracy: 0.2417 - val_loss: 1.6416 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6375 - accuracy: 0.2458 - val_loss: 1.6412 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6363 - accuracy: 0.2792 - val_loss: 1.6408 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6373 - accuracy: 0.2292 - val_loss: 1.6404 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6369 - accuracy: 0.2917 - val_loss: 1.6400 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6368 - accuracy: 0.2542 - val_loss: 1.6396 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6370 - accuracy: 0.2792 - val_loss: 1.6391 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2792 - val_loss: 1.6387 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2708 - val_loss: 1.6382 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.2333 - val_loss: 1.6377 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2958 - val_loss: 1.6371 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2875 - val_loss: 1.6367 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2833 - val_loss: 1.6363 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.2375 - val_loss: 1.6360 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2917 - val_loss: 1.6358 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2792 - val_loss: 1.6355 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2792 - val_loss: 1.6351 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2833 - val_loss: 1.6347 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2542 - val_loss: 1.6344 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2750 - val_loss: 1.6341 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2250 - val_loss: 1.6337 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2917 - val_loss: 1.6333 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2750 - val_loss: 1.6327 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2833 - val_loss: 1.6324 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2417 - val_loss: 1.6322 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2667 - val_loss: 1.6320 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2417 - val_loss: 1.6318 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.3208 - val_loss: 1.6316 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2583 - val_loss: 1.6315 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6131 - accuracy: 0.3292 - val_loss: 1.6311 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2792 - val_loss: 1.6308 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2625 - val_loss: 1.6305 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.3000 - val_loss: 1.6304 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2958 - val_loss: 1.6302 - val_accuracy: 0.1967 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.3167 - val_loss: 1.6298 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2833 - val_loss: 1.6294 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2917 - val_loss: 1.6291 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6166 - accuracy: 0.2583 - val_loss: 1.6289 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6083 - accuracy: 0.2917 - val_loss: 1.6286 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.3167 - val_loss: 1.6282 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.3375 - val_loss: 1.6277 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6113 - accuracy: 0.2833 - val_loss: 1.6274 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6136 - accuracy: 0.3208 - val_loss: 1.6270 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2667 - val_loss: 1.6264 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6081 - accuracy: 0.3375 - val_loss: 1.6261 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6060 - accuracy: 0.3167 - val_loss: 1.6258 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6073 - accuracy: 0.2750 - val_loss: 1.6253 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6041 - accuracy: 0.2875 - val_loss: 1.6252 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2917 - val_loss: 1.6249 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6039 - accuracy: 0.2958 - val_loss: 1.6244 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.5992 - accuracy: 0.3167 - val_loss: 1.6242 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.5983 - accuracy: 0.3292 - val_loss: 1.6238 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6016 - accuracy: 0.3167 - val_loss: 1.6235 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6042 - accuracy: 0.3042 - val_loss: 1.6235 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.5972 - accuracy: 0.2667 - val_loss: 1.6234 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6055 - accuracy: 0.2917 - val_loss: 1.6232 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6015 - accuracy: 0.3125 - val_loss: 1.6232 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6057 - accuracy: 0.3000 - val_loss: 1.6232 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.5949 - accuracy: 0.3125 - val_loss: 1.6233 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.5985 - accuracy: 0.3000 - val_loss: 1.6231 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.5971 - accuracy: 0.2833 - val_loss: 1.6233 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.5876 - accuracy: 0.3250 - val_loss: 1.6233 - val_accuracy: 0.2787 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.5916 - accuracy: 0.3250 - val_loss: 1.6234 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5968 - accuracy: 0.3458 - val_loss: 1.6232 - val_accuracy: 0.2787 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.5960 - accuracy: 0.2917 - val_loss: 1.6231 - val_accuracy: 0.2623 - lr: 2.5000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6005 - accuracy: 0.3083 - val_loss: 1.6231 - val_accuracy: 0.2623 - lr: 1.2500e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6037 - accuracy: 0.2833 - val_loss: 1.6230 - val_accuracy: 0.2787 - lr: 1.2500e-05 - 79ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6003 - accuracy: 0.3083 - val_loss: 1.6229 - val_accuracy: 0.2459 - lr: 1.2500e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5965 - accuracy: 0.3167 - val_loss: 1.6228 - val_accuracy: 0.2787 - lr: 1.2500e-05 - 62ms/epoch - 4ms/step\n",
      "Node 32 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6609 - accuracy: 0.2167 - val_loss: 1.6600 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 3s/epoch - 348ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6596 - accuracy: 0.2083 - val_loss: 1.6595 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6611 - accuracy: 0.1708 - val_loss: 1.6590 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6595 - accuracy: 0.1875 - val_loss: 1.6586 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6597 - accuracy: 0.2000 - val_loss: 1.6582 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6588 - accuracy: 0.1958 - val_loss: 1.6578 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6574 - accuracy: 0.2292 - val_loss: 1.6573 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6568 - accuracy: 0.2208 - val_loss: 1.6568 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6567 - accuracy: 0.2125 - val_loss: 1.6564 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2333 - val_loss: 1.6560 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6554 - accuracy: 0.2333 - val_loss: 1.6556 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2208 - val_loss: 1.6552 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6542 - accuracy: 0.2333 - val_loss: 1.6547 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6543 - accuracy: 0.2292 - val_loss: 1.6543 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6532 - accuracy: 0.2292 - val_loss: 1.6539 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6529 - accuracy: 0.2583 - val_loss: 1.6534 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2292 - val_loss: 1.6529 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2458 - val_loss: 1.6524 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6524 - accuracy: 0.2333 - val_loss: 1.6519 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6514 - accuracy: 0.2333 - val_loss: 1.6515 - val_accuracy: 0.2295 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2583 - val_loss: 1.6511 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6500 - accuracy: 0.2250 - val_loss: 1.6506 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2333 - val_loss: 1.6502 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6514 - accuracy: 0.2250 - val_loss: 1.6498 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6473 - accuracy: 0.2667 - val_loss: 1.6494 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2042 - val_loss: 1.6490 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2208 - val_loss: 1.6486 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6473 - accuracy: 0.2208 - val_loss: 1.6481 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2292 - val_loss: 1.6477 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2500 - val_loss: 1.6474 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2250 - val_loss: 1.6470 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6457 - accuracy: 0.2417 - val_loss: 1.6467 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2667 - val_loss: 1.6463 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6456 - accuracy: 0.2250 - val_loss: 1.6459 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2375 - val_loss: 1.6455 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2333 - val_loss: 1.6452 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2583 - val_loss: 1.6449 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2583 - val_loss: 1.6446 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2750 - val_loss: 1.6444 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2458 - val_loss: 1.6441 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2458 - val_loss: 1.6437 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2625 - val_loss: 1.6434 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2458 - val_loss: 1.6429 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2667 - val_loss: 1.6425 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2417 - val_loss: 1.6420 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2250 - val_loss: 1.6417 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2583 - val_loss: 1.6414 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2875 - val_loss: 1.6411 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6394 - accuracy: 0.2292 - val_loss: 1.6407 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2625 - val_loss: 1.6404 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2458 - val_loss: 1.6401 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6375 - accuracy: 0.2708 - val_loss: 1.6398 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2292 - val_loss: 1.6395 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2917 - val_loss: 1.6392 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2458 - val_loss: 1.6389 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2542 - val_loss: 1.6386 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2500 - val_loss: 1.6383 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2417 - val_loss: 1.6379 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2208 - val_loss: 1.6375 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2667 - val_loss: 1.6372 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2458 - val_loss: 1.6370 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2542 - val_loss: 1.6368 - val_accuracy: 0.2623 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2583 - val_loss: 1.6365 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2792 - val_loss: 1.6362 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2458 - val_loss: 1.6359 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2625 - val_loss: 1.6356 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2667 - val_loss: 1.6353 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2583 - val_loss: 1.6350 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2958 - val_loss: 1.6346 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2458 - val_loss: 1.6341 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2458 - val_loss: 1.6338 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2375 - val_loss: 1.6335 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.3042 - val_loss: 1.6332 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2417 - val_loss: 1.6328 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2542 - val_loss: 1.6325 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2542 - val_loss: 1.6322 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2917 - val_loss: 1.6320 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2667 - val_loss: 1.6318 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2458 - val_loss: 1.6317 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2708 - val_loss: 1.6314 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2708 - val_loss: 1.6311 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2625 - val_loss: 1.6308 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2583 - val_loss: 1.6304 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2708 - val_loss: 1.6300 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2667 - val_loss: 1.6297 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2250 - val_loss: 1.6295 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2500 - val_loss: 1.6291 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2833 - val_loss: 1.6288 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2667 - val_loss: 1.6285 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2292 - val_loss: 1.6283 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2542 - val_loss: 1.6279 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2583 - val_loss: 1.6277 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2708 - val_loss: 1.6273 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2542 - val_loss: 1.6269 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.2750 - val_loss: 1.6265 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2625 - val_loss: 1.6262 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6076 - accuracy: 0.2792 - val_loss: 1.6259 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2750 - val_loss: 1.6256 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.3042 - val_loss: 1.6255 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2667 - val_loss: 1.6253 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 66ms/epoch - 8ms/step\n",
      "Node 32 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 32 - Best Validation Accuracy: 0.3607\n",
      "Best model saved for Node 32 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_32.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_33_dataset.csv\n",
      "Node 33 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6344 - accuracy: 0.2082 - val_loss: 1.6344 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 3s/epoch - 158ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6347 - accuracy: 0.2041 - val_loss: 1.6341 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2612 - val_loss: 1.6337 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2571 - val_loss: 1.6331 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6344 - accuracy: 0.2000 - val_loss: 1.6329 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2163 - val_loss: 1.6327 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.2490 - val_loss: 1.6324 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2367 - val_loss: 1.6321 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2204 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2327 - val_loss: 1.6319 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2490 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2122 - val_loss: 1.6321 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2245 - val_loss: 1.6318 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2408 - val_loss: 1.6317 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6302 - accuracy: 0.1837 - val_loss: 1.6316 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2122 - val_loss: 1.6315 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2286 - val_loss: 1.6315 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2245 - val_loss: 1.6313 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2122 - val_loss: 1.6312 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6287 - accuracy: 0.2898 - val_loss: 1.6310 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2122 - val_loss: 1.6309 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2735 - val_loss: 1.6309 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2612 - val_loss: 1.6307 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2245 - val_loss: 1.6305 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2082 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2653 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2245 - val_loss: 1.6303 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2367 - val_loss: 1.6302 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2041 - val_loss: 1.6301 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2245 - val_loss: 1.6300 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2653 - val_loss: 1.6299 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6294 - accuracy: 0.2122 - val_loss: 1.6298 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2490 - val_loss: 1.6297 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2082 - val_loss: 1.6296 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2245 - val_loss: 1.6294 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2367 - val_loss: 1.6294 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2612 - val_loss: 1.6293 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2735 - val_loss: 1.6293 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2612 - val_loss: 1.6292 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2408 - val_loss: 1.6291 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2163 - val_loss: 1.6290 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2449 - val_loss: 1.6289 - val_accuracy: 0.2581 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2612 - val_loss: 1.6288 - val_accuracy: 0.2581 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6241 - accuracy: 0.2653 - val_loss: 1.6287 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2449 - val_loss: 1.6286 - val_accuracy: 0.2581 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2367 - val_loss: 1.6286 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2449 - val_loss: 1.6286 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2286 - val_loss: 1.6285 - val_accuracy: 0.1935 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6261 - accuracy: 0.2327 - val_loss: 1.6285 - val_accuracy: 0.1935 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2694 - val_loss: 1.6284 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2816 - val_loss: 1.6283 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6260 - accuracy: 0.2286 - val_loss: 1.6283 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2286 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2367 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6258 - accuracy: 0.2245 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2122 - val_loss: 1.6281 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2204 - val_loss: 1.6281 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2571 - val_loss: 1.6281 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2367 - val_loss: 1.6281 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2449 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2408 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2245 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2327 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 6.2500e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2531 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2612 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2000 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.1250e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2653 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2612 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2367 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.5625e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2408 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2367 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2286 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 7.8125e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2408 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2490 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.9062e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2327 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 3.9062e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2694 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2082 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2612 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.9531e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2449 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2327 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 9.7656e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2490 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 9.7656e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2327 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 4.8828e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2367 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 4.8828e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2612 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2735 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 2.4414e-08 - 48ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2245 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 2.4414e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2776 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 2.4414e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2571 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.2207e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2571 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.2207e-08 - 54ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2408 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 1.2207e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2490 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2163 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 6.1035e-09 - 48ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2571 - val_loss: 1.6280 - val_accuracy: 0.2258 - lr: 6.1035e-09 - 49ms/epoch - 3ms/step\n",
      "Node 33 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6354 - accuracy: 0.2367 - val_loss: 1.6358 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 3s/epoch - 364ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2327 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2000 - val_loss: 1.6355 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2204 - val_loss: 1.6353 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.1959 - val_loss: 1.6351 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.1918 - val_loss: 1.6349 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2000 - val_loss: 1.6348 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2041 - val_loss: 1.6346 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2041 - val_loss: 1.6345 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2204 - val_loss: 1.6344 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2571 - val_loss: 1.6342 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2163 - val_loss: 1.6341 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2449 - val_loss: 1.6340 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2245 - val_loss: 1.6338 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.1714 - val_loss: 1.6337 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2163 - val_loss: 1.6335 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2490 - val_loss: 1.6333 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2286 - val_loss: 1.6331 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2122 - val_loss: 1.6329 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2286 - val_loss: 1.6328 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2163 - val_loss: 1.6327 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2449 - val_loss: 1.6326 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2367 - val_loss: 1.6326 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2367 - val_loss: 1.6326 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2490 - val_loss: 1.6325 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.1755 - val_loss: 1.6324 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.1673 - val_loss: 1.6323 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2531 - val_loss: 1.6321 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2408 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2898 - val_loss: 1.6319 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2245 - val_loss: 1.6319 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2816 - val_loss: 1.6317 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2531 - val_loss: 1.6316 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2204 - val_loss: 1.6314 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2735 - val_loss: 1.6313 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2939 - val_loss: 1.6312 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2612 - val_loss: 1.6311 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2204 - val_loss: 1.6310 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2735 - val_loss: 1.6309 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2408 - val_loss: 1.6307 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2204 - val_loss: 1.6306 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2163 - val_loss: 1.6305 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2408 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2041 - val_loss: 1.6303 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2449 - val_loss: 1.6302 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2449 - val_loss: 1.6301 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2571 - val_loss: 1.6300 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2612 - val_loss: 1.6299 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2286 - val_loss: 1.6298 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2082 - val_loss: 1.6296 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2204 - val_loss: 1.6295 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2449 - val_loss: 1.6293 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2367 - val_loss: 1.6292 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2490 - val_loss: 1.6291 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2612 - val_loss: 1.6290 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2857 - val_loss: 1.6289 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2286 - val_loss: 1.6288 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2490 - val_loss: 1.6287 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2082 - val_loss: 1.6286 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2449 - val_loss: 1.6285 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2612 - val_loss: 1.6285 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2776 - val_loss: 1.6285 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2286 - val_loss: 1.6284 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2776 - val_loss: 1.6283 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2612 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2612 - val_loss: 1.6282 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.3020 - val_loss: 1.6281 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.3061 - val_loss: 1.6280 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2367 - val_loss: 1.6279 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2816 - val_loss: 1.6279 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2898 - val_loss: 1.6278 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2327 - val_loss: 1.6277 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2980 - val_loss: 1.6277 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2490 - val_loss: 1.6276 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2286 - val_loss: 1.6275 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2571 - val_loss: 1.6274 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2367 - val_loss: 1.6274 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2327 - val_loss: 1.6273 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2531 - val_loss: 1.6273 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2653 - val_loss: 1.6272 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2612 - val_loss: 1.6270 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2327 - val_loss: 1.6269 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2776 - val_loss: 1.6268 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2653 - val_loss: 1.6268 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2204 - val_loss: 1.6267 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2449 - val_loss: 1.6267 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.2449 - val_loss: 1.6266 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2612 - val_loss: 1.6266 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2408 - val_loss: 1.6265 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2694 - val_loss: 1.6264 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2612 - val_loss: 1.6264 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2735 - val_loss: 1.6263 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2694 - val_loss: 1.6263 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2449 - val_loss: 1.6262 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2408 - val_loss: 1.6262 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2612 - val_loss: 1.6261 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2571 - val_loss: 1.6260 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6140 - accuracy: 0.2939 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2694 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2490 - val_loss: 1.6258 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 33 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6614 - accuracy: 0.2122 - val_loss: 1.6618 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 159ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6605 - accuracy: 0.1878 - val_loss: 1.6608 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6598 - accuracy: 0.2041 - val_loss: 1.6600 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6588 - accuracy: 0.2204 - val_loss: 1.6592 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6577 - accuracy: 0.2571 - val_loss: 1.6585 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6569 - accuracy: 0.2245 - val_loss: 1.6578 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6560 - accuracy: 0.2367 - val_loss: 1.6570 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6562 - accuracy: 0.2041 - val_loss: 1.6564 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6535 - accuracy: 0.2980 - val_loss: 1.6558 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6530 - accuracy: 0.2041 - val_loss: 1.6550 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6523 - accuracy: 0.2408 - val_loss: 1.6543 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6518 - accuracy: 0.2367 - val_loss: 1.6537 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6506 - accuracy: 0.2694 - val_loss: 1.6531 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6510 - accuracy: 0.2082 - val_loss: 1.6525 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6505 - accuracy: 0.2122 - val_loss: 1.6519 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6484 - accuracy: 0.2735 - val_loss: 1.6513 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6471 - accuracy: 0.2816 - val_loss: 1.6509 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6473 - accuracy: 0.2204 - val_loss: 1.6504 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6484 - accuracy: 0.2327 - val_loss: 1.6497 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6485 - accuracy: 0.2204 - val_loss: 1.6491 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6469 - accuracy: 0.2449 - val_loss: 1.6486 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6458 - accuracy: 0.2327 - val_loss: 1.6481 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6442 - accuracy: 0.2449 - val_loss: 1.6476 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6415 - accuracy: 0.2816 - val_loss: 1.6472 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6429 - accuracy: 0.2327 - val_loss: 1.6466 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6436 - accuracy: 0.2612 - val_loss: 1.6461 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6426 - accuracy: 0.2408 - val_loss: 1.6456 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6409 - accuracy: 0.2286 - val_loss: 1.6450 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6398 - accuracy: 0.2857 - val_loss: 1.6444 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6377 - accuracy: 0.2939 - val_loss: 1.6440 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6397 - accuracy: 0.2327 - val_loss: 1.6435 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6379 - accuracy: 0.2816 - val_loss: 1.6431 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6378 - accuracy: 0.2531 - val_loss: 1.6425 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6376 - accuracy: 0.2449 - val_loss: 1.6421 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6355 - accuracy: 0.2653 - val_loss: 1.6416 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6351 - accuracy: 0.2490 - val_loss: 1.6412 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6340 - accuracy: 0.2449 - val_loss: 1.6408 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6352 - accuracy: 0.2531 - val_loss: 1.6403 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6350 - accuracy: 0.2531 - val_loss: 1.6397 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6295 - accuracy: 0.2571 - val_loss: 1.6393 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.2408 - val_loss: 1.6388 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2531 - val_loss: 1.6384 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6324 - accuracy: 0.2245 - val_loss: 1.6382 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2816 - val_loss: 1.6379 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2816 - val_loss: 1.6375 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2939 - val_loss: 1.6374 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6267 - accuracy: 0.2694 - val_loss: 1.6371 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2653 - val_loss: 1.6369 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2776 - val_loss: 1.6364 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6252 - accuracy: 0.2816 - val_loss: 1.6361 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6257 - accuracy: 0.2816 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2735 - val_loss: 1.6353 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2939 - val_loss: 1.6351 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 90ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2776 - val_loss: 1.6348 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2571 - val_loss: 1.6345 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2571 - val_loss: 1.6342 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2939 - val_loss: 1.6338 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2776 - val_loss: 1.6336 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2653 - val_loss: 1.6335 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2816 - val_loss: 1.6333 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2939 - val_loss: 1.6332 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2327 - val_loss: 1.6330 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2735 - val_loss: 1.6330 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2367 - val_loss: 1.6328 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2735 - val_loss: 1.6327 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6086 - accuracy: 0.2816 - val_loss: 1.6324 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2612 - val_loss: 1.6322 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2612 - val_loss: 1.6320 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6047 - accuracy: 0.2898 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2531 - val_loss: 1.6320 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6142 - accuracy: 0.2694 - val_loss: 1.6316 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2490 - val_loss: 1.6316 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2857 - val_loss: 1.6317 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2694 - val_loss: 1.6315 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6015 - accuracy: 0.2816 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6070 - accuracy: 0.2735 - val_loss: 1.6315 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6023 - accuracy: 0.2653 - val_loss: 1.6316 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2735 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6195 - accuracy: 0.2204 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6006 - accuracy: 0.2898 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6120 - accuracy: 0.2490 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6014 - accuracy: 0.2939 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6080 - accuracy: 0.2857 - val_loss: 1.6315 - val_accuracy: 0.2097 - lr: 1.2500e-05 - 72ms/epoch - 4ms/step\n",
      "Node 33 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6611 - accuracy: 0.2082 - val_loss: 1.6605 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 362ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6613 - accuracy: 0.1959 - val_loss: 1.6600 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6594 - accuracy: 0.1837 - val_loss: 1.6595 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6600 - accuracy: 0.1755 - val_loss: 1.6591 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6590 - accuracy: 0.1959 - val_loss: 1.6587 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6587 - accuracy: 0.1633 - val_loss: 1.6583 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6588 - accuracy: 0.2000 - val_loss: 1.6579 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6575 - accuracy: 0.2286 - val_loss: 1.6574 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.2122 - val_loss: 1.6570 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6573 - accuracy: 0.2163 - val_loss: 1.6566 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.2490 - val_loss: 1.6561 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2286 - val_loss: 1.6555 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6554 - accuracy: 0.2367 - val_loss: 1.6551 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6545 - accuracy: 0.2082 - val_loss: 1.6547 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2000 - val_loss: 1.6544 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6532 - accuracy: 0.2163 - val_loss: 1.6540 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2163 - val_loss: 1.6536 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2245 - val_loss: 1.6532 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2735 - val_loss: 1.6528 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6504 - accuracy: 0.2327 - val_loss: 1.6525 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2612 - val_loss: 1.6521 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2204 - val_loss: 1.6517 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2122 - val_loss: 1.6513 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2286 - val_loss: 1.6509 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.2408 - val_loss: 1.6505 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2122 - val_loss: 1.6502 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2327 - val_loss: 1.6498 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6488 - accuracy: 0.2327 - val_loss: 1.6496 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2286 - val_loss: 1.6492 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2408 - val_loss: 1.6489 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2571 - val_loss: 1.6485 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2245 - val_loss: 1.6481 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2449 - val_loss: 1.6477 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2408 - val_loss: 1.6474 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2449 - val_loss: 1.6470 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2653 - val_loss: 1.6467 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2490 - val_loss: 1.6464 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2367 - val_loss: 1.6460 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2531 - val_loss: 1.6457 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2204 - val_loss: 1.6455 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2653 - val_loss: 1.6452 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2531 - val_loss: 1.6449 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2490 - val_loss: 1.6446 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2122 - val_loss: 1.6444 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2408 - val_loss: 1.6441 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2245 - val_loss: 1.6438 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2449 - val_loss: 1.6436 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6386 - accuracy: 0.2776 - val_loss: 1.6432 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6419 - accuracy: 0.2408 - val_loss: 1.6430 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.2694 - val_loss: 1.6427 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 68ms/epoch - 9ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2612 - val_loss: 1.6424 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2245 - val_loss: 1.6421 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2612 - val_loss: 1.6418 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2449 - val_loss: 1.6416 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2163 - val_loss: 1.6413 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2694 - val_loss: 1.6410 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2245 - val_loss: 1.6408 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2367 - val_loss: 1.6406 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2653 - val_loss: 1.6404 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2612 - val_loss: 1.6403 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2531 - val_loss: 1.6401 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2245 - val_loss: 1.6399 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2531 - val_loss: 1.6397 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2204 - val_loss: 1.6394 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2449 - val_loss: 1.6392 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2694 - val_loss: 1.6389 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2571 - val_loss: 1.6388 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2531 - val_loss: 1.6385 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2653 - val_loss: 1.6383 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2327 - val_loss: 1.6380 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2490 - val_loss: 1.6378 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2816 - val_loss: 1.6376 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2490 - val_loss: 1.6374 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2653 - val_loss: 1.6372 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2898 - val_loss: 1.6371 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2082 - val_loss: 1.6370 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2531 - val_loss: 1.6369 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2776 - val_loss: 1.6367 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2531 - val_loss: 1.6365 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2367 - val_loss: 1.6364 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2490 - val_loss: 1.6362 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2531 - val_loss: 1.6360 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2490 - val_loss: 1.6359 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2571 - val_loss: 1.6358 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2980 - val_loss: 1.6357 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2490 - val_loss: 1.6356 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2571 - val_loss: 1.6355 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2286 - val_loss: 1.6354 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2327 - val_loss: 1.6352 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2490 - val_loss: 1.6351 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2612 - val_loss: 1.6350 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2490 - val_loss: 1.6349 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2449 - val_loss: 1.6348 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2327 - val_loss: 1.6348 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2776 - val_loss: 1.6347 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2735 - val_loss: 1.6346 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2776 - val_loss: 1.6345 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2571 - val_loss: 1.6343 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2776 - val_loss: 1.6342 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2776 - val_loss: 1.6340 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Node 33 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 33 - Best Validation Accuracy: 0.3065\n",
      "Best model saved for Node 33 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_33.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_34_dataset.csv\n",
      "Node 34 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 1.6336 - accuracy: 0.1971 - val_loss: 1.6350 - val_accuracy: 0.1346 - lr: 1.0000e-04 - 2s/epoch - 138ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 1.6350 - accuracy: 0.2115 - val_loss: 1.6345 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 1.6345 - accuracy: 0.1779 - val_loss: 1.6341 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 27ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 1.6335 - accuracy: 0.2596 - val_loss: 1.6340 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 1.6337 - accuracy: 0.2067 - val_loss: 1.6335 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 1.6327 - accuracy: 0.2404 - val_loss: 1.6331 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.6302 - accuracy: 0.2548 - val_loss: 1.6327 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6311 - accuracy: 0.2308 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.6316 - accuracy: 0.2356 - val_loss: 1.6322 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.6310 - accuracy: 0.2067 - val_loss: 1.6318 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.6317 - accuracy: 0.2452 - val_loss: 1.6314 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.6285 - accuracy: 0.2692 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.6308 - accuracy: 0.2163 - val_loss: 1.6311 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 1.6284 - accuracy: 0.2404 - val_loss: 1.6309 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 1.6276 - accuracy: 0.2356 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 1.6273 - accuracy: 0.2692 - val_loss: 1.6302 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 1.6296 - accuracy: 0.1875 - val_loss: 1.6300 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 1.6267 - accuracy: 0.2404 - val_loss: 1.6298 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 1.6255 - accuracy: 0.2212 - val_loss: 1.6294 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 1.6249 - accuracy: 0.2452 - val_loss: 1.6290 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 1.6260 - accuracy: 0.2356 - val_loss: 1.6285 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 1.6242 - accuracy: 0.2788 - val_loss: 1.6283 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 1.6256 - accuracy: 0.2452 - val_loss: 1.6279 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 1.6266 - accuracy: 0.2308 - val_loss: 1.6278 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 1.6255 - accuracy: 0.2356 - val_loss: 1.6275 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 1.6237 - accuracy: 0.2356 - val_loss: 1.6271 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 1.6234 - accuracy: 0.2740 - val_loss: 1.6267 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 1.6222 - accuracy: 0.2452 - val_loss: 1.6264 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 1.6246 - accuracy: 0.2260 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 1.6195 - accuracy: 0.2740 - val_loss: 1.6258 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 1.6215 - accuracy: 0.2644 - val_loss: 1.6256 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 1.6227 - accuracy: 0.2500 - val_loss: 1.6254 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 1.6204 - accuracy: 0.2308 - val_loss: 1.6252 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 1.6208 - accuracy: 0.2356 - val_loss: 1.6249 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 1.6151 - accuracy: 0.2740 - val_loss: 1.6246 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 1.6236 - accuracy: 0.2596 - val_loss: 1.6245 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 1.6178 - accuracy: 0.2692 - val_loss: 1.6242 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 1.6211 - accuracy: 0.2548 - val_loss: 1.6240 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 1.6176 - accuracy: 0.2644 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 1.6175 - accuracy: 0.2788 - val_loss: 1.6235 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 1.6196 - accuracy: 0.2452 - val_loss: 1.6233 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 1.6180 - accuracy: 0.2692 - val_loss: 1.6232 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 1.6245 - accuracy: 0.2212 - val_loss: 1.6231 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 1.6173 - accuracy: 0.2404 - val_loss: 1.6230 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 1.6179 - accuracy: 0.2260 - val_loss: 1.6229 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 1.6232 - accuracy: 0.2404 - val_loss: 1.6228 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 1.6147 - accuracy: 0.2837 - val_loss: 1.6227 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 1.6190 - accuracy: 0.2404 - val_loss: 1.6226 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 1.6199 - accuracy: 0.2596 - val_loss: 1.6225 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 1.6142 - accuracy: 0.2452 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 1.6158 - accuracy: 0.2644 - val_loss: 1.6223 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 1.6128 - accuracy: 0.2644 - val_loss: 1.6220 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 1.6213 - accuracy: 0.2452 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 1.6164 - accuracy: 0.2788 - val_loss: 1.6217 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 1.6156 - accuracy: 0.2596 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 1.6124 - accuracy: 0.2740 - val_loss: 1.6213 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 1.6191 - accuracy: 0.2548 - val_loss: 1.6211 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 1.6103 - accuracy: 0.2548 - val_loss: 1.6210 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 1.6157 - accuracy: 0.2500 - val_loss: 1.6209 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 1.6109 - accuracy: 0.2692 - val_loss: 1.6208 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 1.6149 - accuracy: 0.2404 - val_loss: 1.6208 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 1.6149 - accuracy: 0.2308 - val_loss: 1.6208 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 1.6142 - accuracy: 0.2500 - val_loss: 1.6205 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 1.6112 - accuracy: 0.2452 - val_loss: 1.6203 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 1.6130 - accuracy: 0.2740 - val_loss: 1.6202 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 1.6109 - accuracy: 0.2500 - val_loss: 1.6202 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 1.6151 - accuracy: 0.2692 - val_loss: 1.6201 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 1.6019 - accuracy: 0.2452 - val_loss: 1.6199 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 1.6119 - accuracy: 0.2644 - val_loss: 1.6198 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 1.6152 - accuracy: 0.2308 - val_loss: 1.6198 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 1.6067 - accuracy: 0.2740 - val_loss: 1.6197 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 1.6113 - accuracy: 0.2452 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 1.6045 - accuracy: 0.2740 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 1.6172 - accuracy: 0.2356 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "13/13 - 0s - loss: 1.6063 - accuracy: 0.2644 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 1.6178 - accuracy: 0.2500 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 1.6143 - accuracy: 0.2548 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 34ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "13/13 - 0s - loss: 1.6044 - accuracy: 0.2500 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 36ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 1.6128 - accuracy: 0.2452 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 1.6112 - accuracy: 0.2500 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 1.6069 - accuracy: 0.2500 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 34ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 1.6115 - accuracy: 0.2452 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 35ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 1.6037 - accuracy: 0.2788 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "13/13 - 0s - loss: 1.6102 - accuracy: 0.2981 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 1.6052 - accuracy: 0.2644 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 36ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 1.6081 - accuracy: 0.2596 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 37ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "13/13 - 0s - loss: 1.6123 - accuracy: 0.2500 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 34ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 1.6133 - accuracy: 0.2308 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 6.2500e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 1.6027 - accuracy: 0.2692 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 6.2500e-06 - 37ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "13/13 - 0s - loss: 1.6104 - accuracy: 0.2692 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 6.2500e-06 - 37ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 1.6094 - accuracy: 0.2356 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 3.1250e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 1.6175 - accuracy: 0.2308 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 3.1250e-06 - 35ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "13/13 - 0s - loss: 1.6163 - accuracy: 0.2212 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 3.1250e-06 - 36ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 1.6158 - accuracy: 0.2260 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.5625e-06 - 34ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 1.6043 - accuracy: 0.2596 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.5625e-06 - 37ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "13/13 - 0s - loss: 1.6078 - accuracy: 0.2692 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.5625e-06 - 56ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 1.6099 - accuracy: 0.2596 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 7.8125e-07 - 36ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 1.5987 - accuracy: 0.2644 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 7.8125e-07 - 37ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "13/13 - 0s - loss: 1.6109 - accuracy: 0.2452 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 7.8125e-07 - 36ms/epoch - 3ms/step\n",
      "Node 34 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6369 - accuracy: 0.1394 - val_loss: 1.6361 - val_accuracy: 0.1346 - lr: 1.0000e-04 - 3s/epoch - 423ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6356 - accuracy: 0.1827 - val_loss: 1.6359 - val_accuracy: 0.1346 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6349 - accuracy: 0.1875 - val_loss: 1.6356 - val_accuracy: 0.1538 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.2356 - val_loss: 1.6353 - val_accuracy: 0.1346 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6353 - accuracy: 0.2019 - val_loss: 1.6350 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.2308 - val_loss: 1.6347 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6358 - accuracy: 0.2019 - val_loss: 1.6344 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2212 - val_loss: 1.6341 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6358 - accuracy: 0.2067 - val_loss: 1.6338 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.2163 - val_loss: 1.6335 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2548 - val_loss: 1.6333 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2115 - val_loss: 1.6331 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.2356 - val_loss: 1.6329 - val_accuracy: 0.1731 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2548 - val_loss: 1.6328 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.2644 - val_loss: 1.6326 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2404 - val_loss: 1.6324 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.1923 - val_loss: 1.6322 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.1971 - val_loss: 1.6321 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2981 - val_loss: 1.6318 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2356 - val_loss: 1.6315 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2212 - val_loss: 1.6312 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2163 - val_loss: 1.6309 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6284 - accuracy: 0.2260 - val_loss: 1.6307 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2212 - val_loss: 1.6305 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2500 - val_loss: 1.6303 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2644 - val_loss: 1.6300 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2067 - val_loss: 1.6297 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6308 - accuracy: 0.2740 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2404 - val_loss: 1.6292 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2356 - val_loss: 1.6291 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2500 - val_loss: 1.6289 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2740 - val_loss: 1.6286 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2260 - val_loss: 1.6285 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.1923 - val_loss: 1.6284 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2548 - val_loss: 1.6283 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6249 - accuracy: 0.2692 - val_loss: 1.6282 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2404 - val_loss: 1.6281 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2500 - val_loss: 1.6279 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2356 - val_loss: 1.6277 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2404 - val_loss: 1.6275 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2644 - val_loss: 1.6274 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2596 - val_loss: 1.6272 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2404 - val_loss: 1.6271 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2548 - val_loss: 1.6269 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2452 - val_loss: 1.6268 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2500 - val_loss: 1.6266 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6229 - accuracy: 0.2404 - val_loss: 1.6266 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6212 - accuracy: 0.2356 - val_loss: 1.6265 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2404 - val_loss: 1.6263 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2404 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2452 - val_loss: 1.6260 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6245 - accuracy: 0.2404 - val_loss: 1.6259 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2548 - val_loss: 1.6257 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2500 - val_loss: 1.6255 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2548 - val_loss: 1.6253 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2404 - val_loss: 1.6252 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2548 - val_loss: 1.6251 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2644 - val_loss: 1.6250 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2452 - val_loss: 1.6249 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2548 - val_loss: 1.6248 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2404 - val_loss: 1.6247 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6204 - accuracy: 0.2308 - val_loss: 1.6246 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2452 - val_loss: 1.6244 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2452 - val_loss: 1.6243 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6152 - accuracy: 0.2740 - val_loss: 1.6242 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2356 - val_loss: 1.6241 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2212 - val_loss: 1.6240 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2404 - val_loss: 1.6239 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2548 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2452 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2596 - val_loss: 1.6237 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2404 - val_loss: 1.6235 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2452 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6173 - accuracy: 0.2596 - val_loss: 1.6233 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6159 - accuracy: 0.2788 - val_loss: 1.6232 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6154 - accuracy: 0.2596 - val_loss: 1.6231 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2404 - val_loss: 1.6229 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6204 - accuracy: 0.2452 - val_loss: 1.6228 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6146 - accuracy: 0.2596 - val_loss: 1.6227 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6181 - accuracy: 0.2452 - val_loss: 1.6226 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2308 - val_loss: 1.6225 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6178 - accuracy: 0.2596 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6184 - accuracy: 0.2548 - val_loss: 1.6223 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6166 - accuracy: 0.2356 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2548 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6164 - accuracy: 0.2356 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2548 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2308 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6149 - accuracy: 0.2452 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6151 - accuracy: 0.2452 - val_loss: 1.6220 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6163 - accuracy: 0.2452 - val_loss: 1.6220 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6158 - accuracy: 0.2452 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6179 - accuracy: 0.2212 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6184 - accuracy: 0.2596 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2548 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "7/7 - 0s - loss: 1.6176 - accuracy: 0.2596 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6144 - accuracy: 0.2644 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 47ms/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6132 - accuracy: 0.2596 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "7/7 - 0s - loss: 1.6154 - accuracy: 0.2500 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2500 - val_loss: 1.6218 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 28ms/epoch - 4ms/step\n",
      "Node 34 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 2s - loss: 1.6572 - accuracy: 0.2308 - val_loss: 1.6581 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 2s/epoch - 140ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 1.6557 - accuracy: 0.2404 - val_loss: 1.6570 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 1.6557 - accuracy: 0.1875 - val_loss: 1.6560 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 1.6560 - accuracy: 0.2163 - val_loss: 1.6553 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 1.6542 - accuracy: 0.2692 - val_loss: 1.6544 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 1.6530 - accuracy: 0.2404 - val_loss: 1.6537 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 1.6510 - accuracy: 0.2548 - val_loss: 1.6529 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 1.6498 - accuracy: 0.2356 - val_loss: 1.6520 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 1.6500 - accuracy: 0.2115 - val_loss: 1.6514 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 1.6501 - accuracy: 0.2163 - val_loss: 1.6506 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 1.6489 - accuracy: 0.2404 - val_loss: 1.6498 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 1.6469 - accuracy: 0.2212 - val_loss: 1.6493 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 1.6480 - accuracy: 0.2212 - val_loss: 1.6487 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 1.6429 - accuracy: 0.2644 - val_loss: 1.6482 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 1.6443 - accuracy: 0.2596 - val_loss: 1.6474 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 1.6448 - accuracy: 0.2404 - val_loss: 1.6470 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 1.6463 - accuracy: 0.2692 - val_loss: 1.6464 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 162ms/epoch - 12ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 1.6391 - accuracy: 0.2500 - val_loss: 1.6455 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 1.6424 - accuracy: 0.2596 - val_loss: 1.6448 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 1.6383 - accuracy: 0.2308 - val_loss: 1.6443 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 1.6390 - accuracy: 0.2596 - val_loss: 1.6437 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 1.6388 - accuracy: 0.2548 - val_loss: 1.6432 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 1.6387 - accuracy: 0.2596 - val_loss: 1.6428 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 1.6425 - accuracy: 0.2548 - val_loss: 1.6424 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 1.6359 - accuracy: 0.2644 - val_loss: 1.6419 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 1.6344 - accuracy: 0.2548 - val_loss: 1.6413 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 1.6369 - accuracy: 0.2788 - val_loss: 1.6409 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 1.6348 - accuracy: 0.2500 - val_loss: 1.6404 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 1.6308 - accuracy: 0.2548 - val_loss: 1.6399 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 1.6346 - accuracy: 0.2644 - val_loss: 1.6395 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 1.6360 - accuracy: 0.2548 - val_loss: 1.6393 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 1.6325 - accuracy: 0.2404 - val_loss: 1.6389 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 1.6356 - accuracy: 0.2596 - val_loss: 1.6385 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 1.6326 - accuracy: 0.2404 - val_loss: 1.6382 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 1.6359 - accuracy: 0.2308 - val_loss: 1.6380 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 1.6288 - accuracy: 0.2644 - val_loss: 1.6377 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 59ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 1.6294 - accuracy: 0.2452 - val_loss: 1.6375 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 1.6251 - accuracy: 0.2692 - val_loss: 1.6371 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 1.6281 - accuracy: 0.2500 - val_loss: 1.6367 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 1.6318 - accuracy: 0.2404 - val_loss: 1.6363 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 1.6294 - accuracy: 0.2692 - val_loss: 1.6360 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 1.6286 - accuracy: 0.2452 - val_loss: 1.6359 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 1.6183 - accuracy: 0.2548 - val_loss: 1.6354 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 1.6250 - accuracy: 0.2356 - val_loss: 1.6351 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 1.6243 - accuracy: 0.2452 - val_loss: 1.6349 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 1.6286 - accuracy: 0.2548 - val_loss: 1.6347 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 1.6253 - accuracy: 0.2548 - val_loss: 1.6346 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 1.6234 - accuracy: 0.2740 - val_loss: 1.6343 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 1.6211 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6339 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 72ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 1.6258 - accuracy: 0.2404 - val_loss: 1.6338 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 1.6279 - accuracy: 0.2548 - val_loss: 1.6336 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 1.6176 - accuracy: 0.2596 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 1.6183 - accuracy: 0.2596 - val_loss: 1.6332 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 1.6179 - accuracy: 0.2644 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 1.6190 - accuracy: 0.2500 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 1.6205 - accuracy: 0.2596 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 1.6182 - accuracy: 0.2596 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 1.6130 - accuracy: 0.2740 - val_loss: 1.6322 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 1.6164 - accuracy: 0.2356 - val_loss: 1.6322 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 1.6199 - accuracy: 0.2548 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 1.6088 - accuracy: 0.2644 - val_loss: 1.6319 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 1.6094 - accuracy: 0.2788 - val_loss: 1.6318 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 1.6218 - accuracy: 0.2500 - val_loss: 1.6317 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 1.6156 - accuracy: 0.2596 - val_loss: 1.6315 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 1.6114 - accuracy: 0.2404 - val_loss: 1.6314 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 1.6179 - accuracy: 0.2548 - val_loss: 1.6313 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 1.6117 - accuracy: 0.2740 - val_loss: 1.6313 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "13/13 - 0s - loss: 1.6187 - accuracy: 0.2548 - val_loss: 1.6313 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 1.6102 - accuracy: 0.2740 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 1.6096 - accuracy: 0.2933 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 1.6128 - accuracy: 0.2452 - val_loss: 1.6311 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 1.6136 - accuracy: 0.3077 - val_loss: 1.6310 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 1.6149 - accuracy: 0.2692 - val_loss: 1.6309 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 1.6139 - accuracy: 0.2644 - val_loss: 1.6308 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 1.6133 - accuracy: 0.2596 - val_loss: 1.6307 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 1.6079 - accuracy: 0.2740 - val_loss: 1.6307 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 51ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 1.6098 - accuracy: 0.2740 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 1.6143 - accuracy: 0.2740 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 1.6052 - accuracy: 0.2885 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 1.6042 - accuracy: 0.2740 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 57ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "13/13 - 0s - loss: 1.6127 - accuracy: 0.2933 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 56ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 1.6126 - accuracy: 0.2740 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 1.6073 - accuracy: 0.2644 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "13/13 - 0s - loss: 1.6083 - accuracy: 0.2548 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 52ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 1.6091 - accuracy: 0.2740 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 53ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 1.6152 - accuracy: 0.2740 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 55ms/epoch - 4ms/step\n",
      "Node 34 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6602 - accuracy: 0.2212 - val_loss: 1.6606 - val_accuracy: 0.1731 - lr: 1.0000e-04 - 3s/epoch - 411ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6605 - accuracy: 0.2067 - val_loss: 1.6600 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6605 - accuracy: 0.2115 - val_loss: 1.6595 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6590 - accuracy: 0.1875 - val_loss: 1.6590 - val_accuracy: 0.1538 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6587 - accuracy: 0.2260 - val_loss: 1.6584 - val_accuracy: 0.1923 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6574 - accuracy: 0.2260 - val_loss: 1.6578 - val_accuracy: 0.2115 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6573 - accuracy: 0.2067 - val_loss: 1.6572 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6555 - accuracy: 0.2308 - val_loss: 1.6566 - val_accuracy: 0.2692 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6547 - accuracy: 0.2452 - val_loss: 1.6560 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2115 - val_loss: 1.6554 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6535 - accuracy: 0.2837 - val_loss: 1.6550 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6541 - accuracy: 0.2260 - val_loss: 1.6545 - val_accuracy: 0.2308 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6542 - accuracy: 0.2404 - val_loss: 1.6538 - val_accuracy: 0.2885 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6517 - accuracy: 0.2548 - val_loss: 1.6533 - val_accuracy: 0.2885 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6519 - accuracy: 0.2548 - val_loss: 1.6529 - val_accuracy: 0.2692 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6519 - accuracy: 0.2548 - val_loss: 1.6525 - val_accuracy: 0.2692 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6500 - accuracy: 0.2452 - val_loss: 1.6519 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6505 - accuracy: 0.2356 - val_loss: 1.6514 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6505 - accuracy: 0.2163 - val_loss: 1.6509 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6483 - accuracy: 0.2404 - val_loss: 1.6505 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2500 - val_loss: 1.6501 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6495 - accuracy: 0.2212 - val_loss: 1.6497 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6475 - accuracy: 0.2356 - val_loss: 1.6493 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6496 - accuracy: 0.2500 - val_loss: 1.6489 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6481 - accuracy: 0.2452 - val_loss: 1.6484 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6476 - accuracy: 0.2500 - val_loss: 1.6480 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6491 - accuracy: 0.2356 - val_loss: 1.6476 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6460 - accuracy: 0.2260 - val_loss: 1.6473 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6433 - accuracy: 0.2404 - val_loss: 1.6469 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6443 - accuracy: 0.2596 - val_loss: 1.6464 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6460 - accuracy: 0.2500 - val_loss: 1.6460 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6427 - accuracy: 0.2500 - val_loss: 1.6456 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6402 - accuracy: 0.2308 - val_loss: 1.6452 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2404 - val_loss: 1.6448 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6398 - accuracy: 0.2548 - val_loss: 1.6444 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6435 - accuracy: 0.2260 - val_loss: 1.6440 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6410 - accuracy: 0.2404 - val_loss: 1.6437 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6384 - accuracy: 0.2404 - val_loss: 1.6433 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2548 - val_loss: 1.6430 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6419 - accuracy: 0.2356 - val_loss: 1.6429 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6362 - accuracy: 0.2548 - val_loss: 1.6426 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6375 - accuracy: 0.2548 - val_loss: 1.6424 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6362 - accuracy: 0.2788 - val_loss: 1.6421 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6362 - accuracy: 0.2548 - val_loss: 1.6417 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6381 - accuracy: 0.2452 - val_loss: 1.6414 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6339 - accuracy: 0.2404 - val_loss: 1.6411 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2452 - val_loss: 1.6407 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6370 - accuracy: 0.2548 - val_loss: 1.6403 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6372 - accuracy: 0.2115 - val_loss: 1.6400 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6334 - accuracy: 0.2596 - val_loss: 1.6397 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2452 - val_loss: 1.6394 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6348 - accuracy: 0.2548 - val_loss: 1.6391 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 59ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2452 - val_loss: 1.6389 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6306 - accuracy: 0.2596 - val_loss: 1.6386 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2933 - val_loss: 1.6383 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6332 - accuracy: 0.2500 - val_loss: 1.6380 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2644 - val_loss: 1.6377 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.2644 - val_loss: 1.6374 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2500 - val_loss: 1.6372 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.2404 - val_loss: 1.6370 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.2308 - val_loss: 1.6368 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6298 - accuracy: 0.2548 - val_loss: 1.6366 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2548 - val_loss: 1.6364 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6287 - accuracy: 0.2596 - val_loss: 1.6362 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6252 - accuracy: 0.2644 - val_loss: 1.6360 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2788 - val_loss: 1.6359 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2692 - val_loss: 1.6356 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6240 - accuracy: 0.2452 - val_loss: 1.6354 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2548 - val_loss: 1.6353 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2452 - val_loss: 1.6351 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2500 - val_loss: 1.6349 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.2548 - val_loss: 1.6347 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2500 - val_loss: 1.6344 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2452 - val_loss: 1.6341 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6325 - accuracy: 0.2404 - val_loss: 1.6339 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2644 - val_loss: 1.6337 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6223 - accuracy: 0.2644 - val_loss: 1.6333 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6329 - accuracy: 0.2644 - val_loss: 1.6331 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6292 - accuracy: 0.2452 - val_loss: 1.6330 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6248 - accuracy: 0.2644 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6196 - accuracy: 0.2788 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2452 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2596 - val_loss: 1.6323 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6229 - accuracy: 0.2452 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2596 - val_loss: 1.6320 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2500 - val_loss: 1.6319 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2596 - val_loss: 1.6318 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2596 - val_loss: 1.6316 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2740 - val_loss: 1.6315 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2548 - val_loss: 1.6314 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6203 - accuracy: 0.2740 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2596 - val_loss: 1.6311 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6155 - accuracy: 0.2885 - val_loss: 1.6310 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6159 - accuracy: 0.2212 - val_loss: 1.6308 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6174 - accuracy: 0.2644 - val_loss: 1.6306 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6304 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6175 - accuracy: 0.2788 - val_loss: 1.6302 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2788 - val_loss: 1.6301 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6174 - accuracy: 0.2740 - val_loss: 1.6301 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6176 - accuracy: 0.2500 - val_loss: 1.6299 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 9ms/step\n",
      "Node 34 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 34 - Best Validation Accuracy: 0.2885\n",
      "Best model saved for Node 34 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_34.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_35_dataset.csv\n",
      "Node 35 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6350 - accuracy: 0.2091 - val_loss: 1.6350 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 3s/epoch - 202ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6341 - accuracy: 0.1864 - val_loss: 1.6345 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6350 - accuracy: 0.1545 - val_loss: 1.6340 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6341 - accuracy: 0.1864 - val_loss: 1.6335 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6342 - accuracy: 0.2000 - val_loss: 1.6328 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6313 - accuracy: 0.2273 - val_loss: 1.6324 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6334 - accuracy: 0.2091 - val_loss: 1.6322 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6322 - accuracy: 0.2273 - val_loss: 1.6320 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6324 - accuracy: 0.2045 - val_loss: 1.6317 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2136 - val_loss: 1.6312 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2273 - val_loss: 1.6307 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2045 - val_loss: 1.6303 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6296 - accuracy: 0.2000 - val_loss: 1.6299 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2136 - val_loss: 1.6295 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 49ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2591 - val_loss: 1.6293 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 51ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2136 - val_loss: 1.6289 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6296 - accuracy: 0.2273 - val_loss: 1.6287 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2000 - val_loss: 1.6283 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2045 - val_loss: 1.6278 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2318 - val_loss: 1.6275 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6264 - accuracy: 0.2318 - val_loss: 1.6272 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2227 - val_loss: 1.6269 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6239 - accuracy: 0.2318 - val_loss: 1.6265 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6244 - accuracy: 0.2500 - val_loss: 1.6262 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2136 - val_loss: 1.6259 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2409 - val_loss: 1.6257 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2364 - val_loss: 1.6255 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2545 - val_loss: 1.6251 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2318 - val_loss: 1.6247 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6224 - accuracy: 0.2045 - val_loss: 1.6243 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2591 - val_loss: 1.6240 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6224 - accuracy: 0.2091 - val_loss: 1.6236 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2591 - val_loss: 1.6235 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2455 - val_loss: 1.6233 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2136 - val_loss: 1.6231 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6226 - accuracy: 0.2227 - val_loss: 1.6228 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2455 - val_loss: 1.6227 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2182 - val_loss: 1.6224 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2409 - val_loss: 1.6221 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2182 - val_loss: 1.6219 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.2364 - val_loss: 1.6218 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6196 - accuracy: 0.2591 - val_loss: 1.6216 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2273 - val_loss: 1.6214 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6149 - accuracy: 0.2318 - val_loss: 1.6210 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2364 - val_loss: 1.6208 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6170 - accuracy: 0.2318 - val_loss: 1.6206 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6213 - accuracy: 0.2227 - val_loss: 1.6203 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2455 - val_loss: 1.6202 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2455 - val_loss: 1.6199 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2364 - val_loss: 1.6197 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2455 - val_loss: 1.6195 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.1909 - val_loss: 1.6193 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.1818 - val_loss: 1.6190 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2364 - val_loss: 1.6187 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2227 - val_loss: 1.6184 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6151 - accuracy: 0.2182 - val_loss: 1.6183 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2409 - val_loss: 1.6182 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.1955 - val_loss: 1.6180 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2500 - val_loss: 1.6177 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2182 - val_loss: 1.6175 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2364 - val_loss: 1.6173 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6129 - accuracy: 0.2273 - val_loss: 1.6171 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2273 - val_loss: 1.6171 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2545 - val_loss: 1.6169 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6115 - accuracy: 0.2273 - val_loss: 1.6167 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6130 - accuracy: 0.2273 - val_loss: 1.6164 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2182 - val_loss: 1.6163 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6060 - accuracy: 0.2318 - val_loss: 1.6160 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6110 - accuracy: 0.2318 - val_loss: 1.6159 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6109 - accuracy: 0.2591 - val_loss: 1.6156 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6088 - accuracy: 0.2318 - val_loss: 1.6154 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6063 - accuracy: 0.2273 - val_loss: 1.6152 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6031 - accuracy: 0.2500 - val_loss: 1.6151 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2273 - val_loss: 1.6150 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6106 - accuracy: 0.2727 - val_loss: 1.6149 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6087 - accuracy: 0.2500 - val_loss: 1.6148 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6032 - accuracy: 0.2500 - val_loss: 1.6146 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6112 - accuracy: 0.2318 - val_loss: 1.6145 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6090 - accuracy: 0.2364 - val_loss: 1.6144 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6073 - accuracy: 0.2409 - val_loss: 1.6142 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2227 - val_loss: 1.6141 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 49ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6076 - accuracy: 0.2409 - val_loss: 1.6141 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6086 - accuracy: 0.2591 - val_loss: 1.6141 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.5924 - accuracy: 0.2455 - val_loss: 1.6140 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6056 - accuracy: 0.2455 - val_loss: 1.6139 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6105 - accuracy: 0.2227 - val_loss: 1.6139 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6044 - accuracy: 0.2318 - val_loss: 1.6138 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6061 - accuracy: 0.2364 - val_loss: 1.6137 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 48ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6029 - accuracy: 0.2682 - val_loss: 1.6137 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6037 - accuracy: 0.2364 - val_loss: 1.6136 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6009 - accuracy: 0.2818 - val_loss: 1.6135 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6049 - accuracy: 0.2545 - val_loss: 1.6135 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6065 - accuracy: 0.2318 - val_loss: 1.6135 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6060 - accuracy: 0.2364 - val_loss: 1.6135 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6018 - accuracy: 0.2727 - val_loss: 1.6134 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2318 - val_loss: 1.6133 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6068 - accuracy: 0.2455 - val_loss: 1.6134 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6114 - accuracy: 0.2364 - val_loss: 1.6133 - val_accuracy: 0.2364 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "14/14 - 0s - loss: 1.6124 - accuracy: 0.2000 - val_loss: 1.6133 - val_accuracy: 0.2182 - lr: 5.0000e-05 - 69ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6005 - accuracy: 0.2909 - val_loss: 1.6133 - val_accuracy: 0.2182 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Node 35 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6349 - accuracy: 0.2091 - val_loss: 1.6346 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 2s/epoch - 354ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.2273 - val_loss: 1.6344 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6364 - accuracy: 0.1591 - val_loss: 1.6342 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.1818 - val_loss: 1.6340 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.1727 - val_loss: 1.6338 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6341 - accuracy: 0.1909 - val_loss: 1.6336 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.1864 - val_loss: 1.6335 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6351 - accuracy: 0.2045 - val_loss: 1.6333 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2273 - val_loss: 1.6331 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2227 - val_loss: 1.6329 - val_accuracy: 0.1455 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2136 - val_loss: 1.6327 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2182 - val_loss: 1.6325 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2136 - val_loss: 1.6323 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6319 - accuracy: 0.2409 - val_loss: 1.6321 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2455 - val_loss: 1.6319 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.1955 - val_loss: 1.6318 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6292 - accuracy: 0.2455 - val_loss: 1.6316 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2273 - val_loss: 1.6314 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2364 - val_loss: 1.6312 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2727 - val_loss: 1.6310 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2273 - val_loss: 1.6308 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2227 - val_loss: 1.6305 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2364 - val_loss: 1.6304 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2273 - val_loss: 1.6302 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6309 - accuracy: 0.2500 - val_loss: 1.6301 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2682 - val_loss: 1.6299 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6280 - accuracy: 0.2591 - val_loss: 1.6297 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6290 - accuracy: 0.2682 - val_loss: 1.6295 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2045 - val_loss: 1.6294 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2000 - val_loss: 1.6292 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2682 - val_loss: 1.6289 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2409 - val_loss: 1.6286 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2136 - val_loss: 1.6284 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2409 - val_loss: 1.6282 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2182 - val_loss: 1.6281 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.1909 - val_loss: 1.6279 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2273 - val_loss: 1.6277 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2545 - val_loss: 1.6275 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2364 - val_loss: 1.6272 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.2000 - val_loss: 1.6271 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2273 - val_loss: 1.6269 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2136 - val_loss: 1.6268 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2409 - val_loss: 1.6267 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2364 - val_loss: 1.6266 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2318 - val_loss: 1.6264 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6227 - accuracy: 0.2000 - val_loss: 1.6262 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.2273 - val_loss: 1.6260 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2409 - val_loss: 1.6258 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2545 - val_loss: 1.6257 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2682 - val_loss: 1.6255 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6229 - accuracy: 0.2636 - val_loss: 1.6253 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2364 - val_loss: 1.6252 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6204 - accuracy: 0.2545 - val_loss: 1.6250 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 50ms/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2455 - val_loss: 1.6248 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6238 - accuracy: 0.2364 - val_loss: 1.6246 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2318 - val_loss: 1.6244 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2636 - val_loss: 1.6243 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6165 - accuracy: 0.2909 - val_loss: 1.6242 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.1864 - val_loss: 1.6240 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2682 - val_loss: 1.6239 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2909 - val_loss: 1.6237 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6178 - accuracy: 0.2545 - val_loss: 1.6236 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2500 - val_loss: 1.6234 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.2318 - val_loss: 1.6233 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6247 - accuracy: 0.2227 - val_loss: 1.6232 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2318 - val_loss: 1.6231 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6184 - accuracy: 0.2773 - val_loss: 1.6230 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6178 - accuracy: 0.2864 - val_loss: 1.6229 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2318 - val_loss: 1.6228 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2455 - val_loss: 1.6226 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2636 - val_loss: 1.6225 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6186 - accuracy: 0.2545 - val_loss: 1.6223 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6169 - accuracy: 0.2318 - val_loss: 1.6222 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6192 - accuracy: 0.2773 - val_loss: 1.6221 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6172 - accuracy: 0.2727 - val_loss: 1.6219 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6203 - accuracy: 0.2455 - val_loss: 1.6218 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2864 - val_loss: 1.6216 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6155 - accuracy: 0.3091 - val_loss: 1.6214 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6162 - accuracy: 0.2409 - val_loss: 1.6213 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2409 - val_loss: 1.6212 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2364 - val_loss: 1.6211 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6164 - accuracy: 0.2591 - val_loss: 1.6210 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6178 - accuracy: 0.2364 - val_loss: 1.6209 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6129 - accuracy: 0.2455 - val_loss: 1.6207 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6153 - accuracy: 0.2636 - val_loss: 1.6206 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6135 - accuracy: 0.2545 - val_loss: 1.6204 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6172 - accuracy: 0.2545 - val_loss: 1.6203 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6150 - accuracy: 0.2455 - val_loss: 1.6201 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6114 - accuracy: 0.2864 - val_loss: 1.6200 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6129 - accuracy: 0.2455 - val_loss: 1.6199 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6144 - accuracy: 0.2273 - val_loss: 1.6197 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6181 - accuracy: 0.2727 - val_loss: 1.6196 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6098 - accuracy: 0.2727 - val_loss: 1.6194 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6122 - accuracy: 0.2545 - val_loss: 1.6192 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6109 - accuracy: 0.2682 - val_loss: 1.6191 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6099 - accuracy: 0.2682 - val_loss: 1.6189 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6100 - accuracy: 0.2545 - val_loss: 1.6188 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6105 - accuracy: 0.2591 - val_loss: 1.6186 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6108 - accuracy: 0.2455 - val_loss: 1.6185 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6120 - accuracy: 0.2591 - val_loss: 1.6184 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Node 35 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6609 - accuracy: 0.2091 - val_loss: 1.6594 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 3s/epoch - 202ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6586 - accuracy: 0.2000 - val_loss: 1.6585 - val_accuracy: 0.1636 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6580 - accuracy: 0.2091 - val_loss: 1.6576 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6569 - accuracy: 0.2364 - val_loss: 1.6568 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6559 - accuracy: 0.2273 - val_loss: 1.6557 - val_accuracy: 0.1818 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6533 - accuracy: 0.2636 - val_loss: 1.6544 - val_accuracy: 0.2727 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6543 - accuracy: 0.2636 - val_loss: 1.6535 - val_accuracy: 0.2909 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6514 - accuracy: 0.2182 - val_loss: 1.6523 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6524 - accuracy: 0.2182 - val_loss: 1.6513 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6516 - accuracy: 0.2227 - val_loss: 1.6502 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6483 - accuracy: 0.2136 - val_loss: 1.6492 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6485 - accuracy: 0.2500 - val_loss: 1.6485 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6478 - accuracy: 0.2455 - val_loss: 1.6478 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6460 - accuracy: 0.2182 - val_loss: 1.6467 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6458 - accuracy: 0.2136 - val_loss: 1.6459 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6478 - accuracy: 0.2409 - val_loss: 1.6452 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6426 - accuracy: 0.2364 - val_loss: 1.6444 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6422 - accuracy: 0.2273 - val_loss: 1.6436 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6417 - accuracy: 0.2500 - val_loss: 1.6427 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6409 - accuracy: 0.2545 - val_loss: 1.6416 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6403 - accuracy: 0.2273 - val_loss: 1.6407 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6391 - accuracy: 0.2818 - val_loss: 1.6399 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6354 - accuracy: 0.2409 - val_loss: 1.6390 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6374 - accuracy: 0.2364 - val_loss: 1.6383 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6407 - accuracy: 0.2727 - val_loss: 1.6376 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6314 - accuracy: 0.2682 - val_loss: 1.6368 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6376 - accuracy: 0.2409 - val_loss: 1.6360 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2591 - val_loss: 1.6353 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6344 - accuracy: 0.2455 - val_loss: 1.6344 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6351 - accuracy: 0.2273 - val_loss: 1.6341 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2409 - val_loss: 1.6337 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2636 - val_loss: 1.6328 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2636 - val_loss: 1.6321 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2500 - val_loss: 1.6316 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2455 - val_loss: 1.6310 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2545 - val_loss: 1.6304 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6233 - accuracy: 0.2545 - val_loss: 1.6297 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6259 - accuracy: 0.2773 - val_loss: 1.6293 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2318 - val_loss: 1.6288 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2545 - val_loss: 1.6284 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2818 - val_loss: 1.6280 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2364 - val_loss: 1.6277 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2864 - val_loss: 1.6273 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2773 - val_loss: 1.6267 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6203 - accuracy: 0.2591 - val_loss: 1.6261 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2727 - val_loss: 1.6257 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6149 - accuracy: 0.2864 - val_loss: 1.6252 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2364 - val_loss: 1.6248 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2591 - val_loss: 1.6243 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2773 - val_loss: 1.6238 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2773 - val_loss: 1.6234 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 88ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6172 - accuracy: 0.2455 - val_loss: 1.6228 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6236 - accuracy: 0.2591 - val_loss: 1.6226 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6239 - accuracy: 0.2500 - val_loss: 1.6225 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6061 - accuracy: 0.2636 - val_loss: 1.6220 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6134 - accuracy: 0.2773 - val_loss: 1.6214 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6085 - accuracy: 0.2545 - val_loss: 1.6209 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.2545 - val_loss: 1.6204 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6100 - accuracy: 0.2409 - val_loss: 1.6200 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6144 - accuracy: 0.2591 - val_loss: 1.6195 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6085 - accuracy: 0.2591 - val_loss: 1.6192 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6097 - accuracy: 0.2909 - val_loss: 1.6189 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6180 - accuracy: 0.2591 - val_loss: 1.6189 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6143 - accuracy: 0.2636 - val_loss: 1.6185 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6131 - accuracy: 0.2636 - val_loss: 1.6182 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2500 - val_loss: 1.6177 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2409 - val_loss: 1.6175 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6055 - accuracy: 0.3136 - val_loss: 1.6170 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6079 - accuracy: 0.2773 - val_loss: 1.6164 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6165 - accuracy: 0.2636 - val_loss: 1.6162 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6042 - accuracy: 0.2227 - val_loss: 1.6158 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6003 - accuracy: 0.2909 - val_loss: 1.6153 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.5996 - accuracy: 0.2773 - val_loss: 1.6148 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6113 - accuracy: 0.2409 - val_loss: 1.6145 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6017 - accuracy: 0.2727 - val_loss: 1.6142 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6022 - accuracy: 0.2773 - val_loss: 1.6140 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6143 - accuracy: 0.2727 - val_loss: 1.6138 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6008 - accuracy: 0.2591 - val_loss: 1.6134 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6032 - accuracy: 0.2773 - val_loss: 1.6128 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.5940 - accuracy: 0.3227 - val_loss: 1.6126 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.5872 - accuracy: 0.2864 - val_loss: 1.6119 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.5964 - accuracy: 0.2500 - val_loss: 1.6116 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.5903 - accuracy: 0.2773 - val_loss: 1.6110 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.5925 - accuracy: 0.2455 - val_loss: 1.6105 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.5846 - accuracy: 0.2636 - val_loss: 1.6100 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.5917 - accuracy: 0.2909 - val_loss: 1.6094 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.5895 - accuracy: 0.2727 - val_loss: 1.6092 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.5905 - accuracy: 0.3000 - val_loss: 1.6090 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.5988 - accuracy: 0.3000 - val_loss: 1.6088 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.5905 - accuracy: 0.3000 - val_loss: 1.6087 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.5916 - accuracy: 0.3091 - val_loss: 1.6082 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.5883 - accuracy: 0.2409 - val_loss: 1.6082 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.5772 - accuracy: 0.3273 - val_loss: 1.6073 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.5919 - accuracy: 0.2773 - val_loss: 1.6073 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.5853 - accuracy: 0.2818 - val_loss: 1.6070 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.5892 - accuracy: 0.2773 - val_loss: 1.6070 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.5752 - accuracy: 0.3091 - val_loss: 1.6061 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.5934 - accuracy: 0.2818 - val_loss: 1.6053 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.5811 - accuracy: 0.2864 - val_loss: 1.6046 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.5936 - accuracy: 0.2818 - val_loss: 1.6043 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Node 35 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6601 - accuracy: 0.2182 - val_loss: 1.6591 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 2s/epoch - 351ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6595 - accuracy: 0.2136 - val_loss: 1.6582 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6574 - accuracy: 0.2227 - val_loss: 1.6576 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6594 - accuracy: 0.2045 - val_loss: 1.6569 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6570 - accuracy: 0.2409 - val_loss: 1.6564 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6576 - accuracy: 0.2364 - val_loss: 1.6558 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2591 - val_loss: 1.6552 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6557 - accuracy: 0.2318 - val_loss: 1.6546 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6551 - accuracy: 0.1864 - val_loss: 1.6540 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6538 - accuracy: 0.2591 - val_loss: 1.6534 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6539 - accuracy: 0.2136 - val_loss: 1.6529 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6535 - accuracy: 0.2182 - val_loss: 1.6524 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6538 - accuracy: 0.2364 - val_loss: 1.6519 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6508 - accuracy: 0.2091 - val_loss: 1.6513 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6485 - accuracy: 0.2455 - val_loss: 1.6507 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6490 - accuracy: 0.2545 - val_loss: 1.6502 - val_accuracy: 0.2545 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6527 - accuracy: 0.2500 - val_loss: 1.6496 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6473 - accuracy: 0.2273 - val_loss: 1.6492 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6476 - accuracy: 0.2545 - val_loss: 1.6486 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6450 - accuracy: 0.2545 - val_loss: 1.6481 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6444 - accuracy: 0.2182 - val_loss: 1.6476 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6467 - accuracy: 0.1955 - val_loss: 1.6471 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6459 - accuracy: 0.2364 - val_loss: 1.6466 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6413 - accuracy: 0.2636 - val_loss: 1.6461 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6442 - accuracy: 0.2227 - val_loss: 1.6457 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6418 - accuracy: 0.2591 - val_loss: 1.6453 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6424 - accuracy: 0.2409 - val_loss: 1.6448 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6412 - accuracy: 0.2409 - val_loss: 1.6444 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6448 - accuracy: 0.2227 - val_loss: 1.6440 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6423 - accuracy: 0.2818 - val_loss: 1.6437 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6390 - accuracy: 0.2636 - val_loss: 1.6433 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6401 - accuracy: 0.2500 - val_loss: 1.6429 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6384 - accuracy: 0.3000 - val_loss: 1.6425 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6398 - accuracy: 0.2818 - val_loss: 1.6421 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6382 - accuracy: 0.2318 - val_loss: 1.6418 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6383 - accuracy: 0.1955 - val_loss: 1.6415 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.2500 - val_loss: 1.6413 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2136 - val_loss: 1.6410 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6393 - accuracy: 0.2545 - val_loss: 1.6407 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2682 - val_loss: 1.6403 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6360 - accuracy: 0.2682 - val_loss: 1.6401 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6384 - accuracy: 0.2773 - val_loss: 1.6397 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.1864 - val_loss: 1.6394 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6333 - accuracy: 0.2864 - val_loss: 1.6391 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2545 - val_loss: 1.6387 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6328 - accuracy: 0.2364 - val_loss: 1.6383 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.2045 - val_loss: 1.6380 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6308 - accuracy: 0.3136 - val_loss: 1.6377 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6336 - accuracy: 0.3045 - val_loss: 1.6373 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6275 - accuracy: 0.2955 - val_loss: 1.6371 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2409 - val_loss: 1.6370 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2545 - val_loss: 1.6368 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 63ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.2500 - val_loss: 1.6366 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.2682 - val_loss: 1.6363 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.2364 - val_loss: 1.6360 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6355 - accuracy: 0.2545 - val_loss: 1.6359 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2682 - val_loss: 1.6357 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2864 - val_loss: 1.6356 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2227 - val_loss: 1.6354 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6281 - accuracy: 0.2227 - val_loss: 1.6352 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6233 - accuracy: 0.2818 - val_loss: 1.6350 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6321 - accuracy: 0.2682 - val_loss: 1.6348 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2500 - val_loss: 1.6346 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.2727 - val_loss: 1.6345 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6214 - accuracy: 0.2636 - val_loss: 1.6344 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6251 - accuracy: 0.2682 - val_loss: 1.6342 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6340 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6227 - accuracy: 0.2682 - val_loss: 1.6339 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6279 - accuracy: 0.2727 - val_loss: 1.6336 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6221 - accuracy: 0.2545 - val_loss: 1.6334 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2955 - val_loss: 1.6331 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6135 - accuracy: 0.2500 - val_loss: 1.6329 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2727 - val_loss: 1.6328 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2955 - val_loss: 1.6326 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2545 - val_loss: 1.6324 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6171 - accuracy: 0.2636 - val_loss: 1.6322 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2682 - val_loss: 1.6322 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2682 - val_loss: 1.6319 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6121 - accuracy: 0.2864 - val_loss: 1.6317 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2727 - val_loss: 1.6315 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6168 - accuracy: 0.2227 - val_loss: 1.6314 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6156 - accuracy: 0.2773 - val_loss: 1.6313 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2318 - val_loss: 1.6311 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2682 - val_loss: 1.6311 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6153 - accuracy: 0.2818 - val_loss: 1.6310 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.3045 - val_loss: 1.6309 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2636 - val_loss: 1.6308 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6134 - accuracy: 0.2773 - val_loss: 1.6307 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6161 - accuracy: 0.2182 - val_loss: 1.6306 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6118 - accuracy: 0.2773 - val_loss: 1.6304 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6110 - accuracy: 0.3045 - val_loss: 1.6303 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6135 - accuracy: 0.2636 - val_loss: 1.6302 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6065 - accuracy: 0.2818 - val_loss: 1.6302 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6076 - accuracy: 0.2591 - val_loss: 1.6301 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6153 - accuracy: 0.2364 - val_loss: 1.6299 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6103 - accuracy: 0.2773 - val_loss: 1.6297 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6074 - accuracy: 0.2864 - val_loss: 1.6297 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6069 - accuracy: 0.2636 - val_loss: 1.6296 - val_accuracy: 0.2182 - lr: 1.0000e-04 - 49ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6141 - accuracy: 0.2727 - val_loss: 1.6294 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 62ms/epoch - 9ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6144 - accuracy: 0.2909 - val_loss: 1.6294 - val_accuracy: 0.2364 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Node 35 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 35 - Best Validation Accuracy: 0.2909\n",
      "Best model saved for Node 35 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_35.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_36_dataset.csv\n",
      "Node 36 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6342 - accuracy: 0.2245 - val_loss: 1.6346 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 3s/epoch - 159ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.2204 - val_loss: 1.6341 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.2041 - val_loss: 1.6337 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.2163 - val_loss: 1.6335 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2041 - val_loss: 1.6330 - val_accuracy: 0.1129 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6324 - accuracy: 0.2245 - val_loss: 1.6327 - val_accuracy: 0.1452 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6335 - accuracy: 0.1837 - val_loss: 1.6323 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6321 - accuracy: 0.1918 - val_loss: 1.6320 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2163 - val_loss: 1.6316 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2000 - val_loss: 1.6311 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2163 - val_loss: 1.6308 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2367 - val_loss: 1.6305 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.1837 - val_loss: 1.6301 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6287 - accuracy: 0.2286 - val_loss: 1.6296 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2082 - val_loss: 1.6292 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6287 - accuracy: 0.2041 - val_loss: 1.6288 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2367 - val_loss: 1.6282 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2898 - val_loss: 1.6279 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2327 - val_loss: 1.6272 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.1837 - val_loss: 1.6269 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2449 - val_loss: 1.6265 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2612 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2449 - val_loss: 1.6255 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2490 - val_loss: 1.6250 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2367 - val_loss: 1.6249 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2327 - val_loss: 1.6244 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2286 - val_loss: 1.6242 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2082 - val_loss: 1.6239 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2163 - val_loss: 1.6235 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.1796 - val_loss: 1.6233 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2612 - val_loss: 1.6229 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2286 - val_loss: 1.6223 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.1959 - val_loss: 1.6220 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2286 - val_loss: 1.6217 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2245 - val_loss: 1.6215 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2245 - val_loss: 1.6213 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2000 - val_loss: 1.6210 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2204 - val_loss: 1.6207 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2082 - val_loss: 1.6204 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2653 - val_loss: 1.6200 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2367 - val_loss: 1.6197 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2245 - val_loss: 1.6194 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2898 - val_loss: 1.6191 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6242 - accuracy: 0.2163 - val_loss: 1.6189 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2327 - val_loss: 1.6187 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2490 - val_loss: 1.6184 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6226 - accuracy: 0.2286 - val_loss: 1.6183 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2082 - val_loss: 1.6183 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2082 - val_loss: 1.6183 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2490 - val_loss: 1.6183 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2327 - val_loss: 1.6180 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2490 - val_loss: 1.6178 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2367 - val_loss: 1.6174 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2327 - val_loss: 1.6170 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2327 - val_loss: 1.6167 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2653 - val_loss: 1.6166 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2571 - val_loss: 1.6164 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2490 - val_loss: 1.6162 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2490 - val_loss: 1.6160 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2694 - val_loss: 1.6157 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6136 - accuracy: 0.2408 - val_loss: 1.6155 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2490 - val_loss: 1.6153 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2327 - val_loss: 1.6150 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2531 - val_loss: 1.6146 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2204 - val_loss: 1.6145 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2163 - val_loss: 1.6142 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2286 - val_loss: 1.6139 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6113 - accuracy: 0.2735 - val_loss: 1.6137 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6136 - accuracy: 0.2163 - val_loss: 1.6134 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2571 - val_loss: 1.6132 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2408 - val_loss: 1.6130 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2204 - val_loss: 1.6129 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6103 - accuracy: 0.2367 - val_loss: 1.6129 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2449 - val_loss: 1.6126 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6171 - accuracy: 0.2082 - val_loss: 1.6125 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6093 - accuracy: 0.2449 - val_loss: 1.6123 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6123 - accuracy: 0.2163 - val_loss: 1.6121 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2531 - val_loss: 1.6120 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2245 - val_loss: 1.6118 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6091 - accuracy: 0.2694 - val_loss: 1.6116 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.1755 - val_loss: 1.6116 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6090 - accuracy: 0.2612 - val_loss: 1.6115 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2408 - val_loss: 1.6112 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2408 - val_loss: 1.6111 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6128 - accuracy: 0.2449 - val_loss: 1.6109 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6076 - accuracy: 0.2490 - val_loss: 1.6105 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2286 - val_loss: 1.6104 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6072 - accuracy: 0.2531 - val_loss: 1.6102 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6098 - accuracy: 0.2449 - val_loss: 1.6099 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6063 - accuracy: 0.2653 - val_loss: 1.6096 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6070 - accuracy: 0.2571 - val_loss: 1.6094 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2367 - val_loss: 1.6093 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6076 - accuracy: 0.2367 - val_loss: 1.6091 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2163 - val_loss: 1.6089 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2367 - val_loss: 1.6087 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6093 - accuracy: 0.2776 - val_loss: 1.6085 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6061 - accuracy: 0.2653 - val_loss: 1.6084 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.1918 - val_loss: 1.6085 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2571 - val_loss: 1.6084 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6079 - accuracy: 0.2449 - val_loss: 1.6082 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Node 36 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6353 - accuracy: 0.2408 - val_loss: 1.6320 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 3s/epoch - 361ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2286 - val_loss: 1.6319 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.1796 - val_loss: 1.6317 - val_accuracy: 0.3548 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2000 - val_loss: 1.6314 - val_accuracy: 0.3387 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1878 - val_loss: 1.6312 - val_accuracy: 0.3710 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.1551 - val_loss: 1.6309 - val_accuracy: 0.3871 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.1878 - val_loss: 1.6307 - val_accuracy: 0.3548 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2490 - val_loss: 1.6304 - val_accuracy: 0.3548 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.1837 - val_loss: 1.6302 - val_accuracy: 0.3710 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2286 - val_loss: 1.6300 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2327 - val_loss: 1.6298 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2449 - val_loss: 1.6295 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2245 - val_loss: 1.6292 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2041 - val_loss: 1.6289 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2449 - val_loss: 1.6287 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2408 - val_loss: 1.6284 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2776 - val_loss: 1.6281 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2245 - val_loss: 1.6278 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2490 - val_loss: 1.6276 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2531 - val_loss: 1.6273 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2531 - val_loss: 1.6270 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2980 - val_loss: 1.6265 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2898 - val_loss: 1.6262 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2245 - val_loss: 1.6260 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2735 - val_loss: 1.6258 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2571 - val_loss: 1.6254 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2367 - val_loss: 1.6253 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2653 - val_loss: 1.6251 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2327 - val_loss: 1.6250 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2449 - val_loss: 1.6248 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2122 - val_loss: 1.6245 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2122 - val_loss: 1.6243 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2000 - val_loss: 1.6239 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2939 - val_loss: 1.6235 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2490 - val_loss: 1.6232 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2490 - val_loss: 1.6228 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2408 - val_loss: 1.6225 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2327 - val_loss: 1.6223 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2327 - val_loss: 1.6221 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2857 - val_loss: 1.6218 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2531 - val_loss: 1.6215 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2531 - val_loss: 1.6212 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2857 - val_loss: 1.6210 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2204 - val_loss: 1.6208 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2286 - val_loss: 1.6207 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2286 - val_loss: 1.6205 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2408 - val_loss: 1.6203 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2653 - val_loss: 1.6201 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2653 - val_loss: 1.6200 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2653 - val_loss: 1.6198 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2327 - val_loss: 1.6196 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2612 - val_loss: 1.6195 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2327 - val_loss: 1.6193 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2653 - val_loss: 1.6191 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2653 - val_loss: 1.6188 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2245 - val_loss: 1.6186 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2163 - val_loss: 1.6184 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.2735 - val_loss: 1.6182 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2286 - val_loss: 1.6180 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2735 - val_loss: 1.6178 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2367 - val_loss: 1.6176 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2449 - val_loss: 1.6175 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2367 - val_loss: 1.6173 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2082 - val_loss: 1.6171 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2490 - val_loss: 1.6169 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2286 - val_loss: 1.6168 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2286 - val_loss: 1.6167 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2449 - val_loss: 1.6166 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.3020 - val_loss: 1.6164 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2286 - val_loss: 1.6162 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2735 - val_loss: 1.6160 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2694 - val_loss: 1.6158 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2204 - val_loss: 1.6157 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.3020 - val_loss: 1.6155 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2449 - val_loss: 1.6154 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2122 - val_loss: 1.6153 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6138 - accuracy: 0.2857 - val_loss: 1.6153 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2612 - val_loss: 1.6151 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2245 - val_loss: 1.6150 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2245 - val_loss: 1.6151 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2694 - val_loss: 1.6149 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.3184 - val_loss: 1.6148 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2490 - val_loss: 1.6146 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2163 - val_loss: 1.6144 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2612 - val_loss: 1.6143 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2898 - val_loss: 1.6140 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2449 - val_loss: 1.6139 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2245 - val_loss: 1.6138 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2327 - val_loss: 1.6137 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6132 - accuracy: 0.2735 - val_loss: 1.6136 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2163 - val_loss: 1.6134 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2531 - val_loss: 1.6133 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2571 - val_loss: 1.6132 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6113 - accuracy: 0.2857 - val_loss: 1.6130 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2612 - val_loss: 1.6129 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6129 - accuracy: 0.2735 - val_loss: 1.6128 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2041 - val_loss: 1.6127 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2531 - val_loss: 1.6126 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6107 - accuracy: 0.2408 - val_loss: 1.6124 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2490 - val_loss: 1.6123 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Node 36 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6606 - accuracy: 0.1959 - val_loss: 1.6598 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 159ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6594 - accuracy: 0.2163 - val_loss: 1.6584 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6580 - accuracy: 0.2204 - val_loss: 1.6573 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6566 - accuracy: 0.2245 - val_loss: 1.6563 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6567 - accuracy: 0.2204 - val_loss: 1.6556 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6556 - accuracy: 0.2245 - val_loss: 1.6547 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6533 - accuracy: 0.2204 - val_loss: 1.6539 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 83ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6528 - accuracy: 0.2163 - val_loss: 1.6529 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6508 - accuracy: 0.1918 - val_loss: 1.6520 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6502 - accuracy: 0.2327 - val_loss: 1.6511 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6501 - accuracy: 0.2449 - val_loss: 1.6502 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6508 - accuracy: 0.1959 - val_loss: 1.6491 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6485 - accuracy: 0.2367 - val_loss: 1.6481 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6499 - accuracy: 0.2204 - val_loss: 1.6472 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6497 - accuracy: 0.2245 - val_loss: 1.6465 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6452 - accuracy: 0.2163 - val_loss: 1.6457 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6446 - accuracy: 0.2367 - val_loss: 1.6449 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6436 - accuracy: 0.2449 - val_loss: 1.6441 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6438 - accuracy: 0.2163 - val_loss: 1.6433 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6426 - accuracy: 0.2367 - val_loss: 1.6424 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6445 - accuracy: 0.2041 - val_loss: 1.6417 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6404 - accuracy: 0.2327 - val_loss: 1.6409 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6404 - accuracy: 0.2204 - val_loss: 1.6401 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6404 - accuracy: 0.2490 - val_loss: 1.6393 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6402 - accuracy: 0.1959 - val_loss: 1.6388 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6358 - accuracy: 0.2327 - val_loss: 1.6380 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6359 - accuracy: 0.2245 - val_loss: 1.6374 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6377 - accuracy: 0.2245 - val_loss: 1.6369 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6356 - accuracy: 0.2571 - val_loss: 1.6363 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6353 - accuracy: 0.2122 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6363 - accuracy: 0.2531 - val_loss: 1.6349 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6358 - accuracy: 0.2367 - val_loss: 1.6343 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6361 - accuracy: 0.2449 - val_loss: 1.6337 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6326 - accuracy: 0.2408 - val_loss: 1.6330 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2163 - val_loss: 1.6325 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2367 - val_loss: 1.6319 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6327 - accuracy: 0.2163 - val_loss: 1.6315 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6313 - accuracy: 0.2122 - val_loss: 1.6309 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6347 - accuracy: 0.2041 - val_loss: 1.6304 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2204 - val_loss: 1.6300 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6291 - accuracy: 0.2204 - val_loss: 1.6295 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2163 - val_loss: 1.6290 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2245 - val_loss: 1.6283 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2653 - val_loss: 1.6278 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2367 - val_loss: 1.6273 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2286 - val_loss: 1.6265 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6270 - accuracy: 0.2531 - val_loss: 1.6262 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2163 - val_loss: 1.6259 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2612 - val_loss: 1.6255 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6225 - accuracy: 0.2653 - val_loss: 1.6252 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2204 - val_loss: 1.6248 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 95ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2694 - val_loss: 1.6244 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6212 - accuracy: 0.2408 - val_loss: 1.6239 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2408 - val_loss: 1.6234 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2571 - val_loss: 1.6228 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2531 - val_loss: 1.6224 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2245 - val_loss: 1.6219 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2449 - val_loss: 1.6214 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2490 - val_loss: 1.6211 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2857 - val_loss: 1.6208 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2571 - val_loss: 1.6201 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2408 - val_loss: 1.6198 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2408 - val_loss: 1.6193 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2531 - val_loss: 1.6191 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2367 - val_loss: 1.6185 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2327 - val_loss: 1.6180 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6123 - accuracy: 0.2367 - val_loss: 1.6176 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2408 - val_loss: 1.6171 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6178 - accuracy: 0.2490 - val_loss: 1.6167 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2735 - val_loss: 1.6165 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2571 - val_loss: 1.6163 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2653 - val_loss: 1.6159 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6137 - accuracy: 0.2694 - val_loss: 1.6154 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2612 - val_loss: 1.6152 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2408 - val_loss: 1.6148 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2816 - val_loss: 1.6147 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6142 - accuracy: 0.2245 - val_loss: 1.6145 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6117 - accuracy: 0.2449 - val_loss: 1.6139 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2408 - val_loss: 1.6136 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6116 - accuracy: 0.2694 - val_loss: 1.6132 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6057 - accuracy: 0.2367 - val_loss: 1.6129 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6085 - accuracy: 0.2571 - val_loss: 1.6127 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2816 - val_loss: 1.6123 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2163 - val_loss: 1.6119 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6093 - accuracy: 0.2531 - val_loss: 1.6116 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6063 - accuracy: 0.2694 - val_loss: 1.6113 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6029 - accuracy: 0.2939 - val_loss: 1.6109 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6112 - accuracy: 0.2857 - val_loss: 1.6107 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6045 - accuracy: 0.2816 - val_loss: 1.6104 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.5931 - accuracy: 0.2939 - val_loss: 1.6100 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6096 - accuracy: 0.2531 - val_loss: 1.6100 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6025 - accuracy: 0.2449 - val_loss: 1.6093 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6036 - accuracy: 0.2531 - val_loss: 1.6086 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6091 - accuracy: 0.2653 - val_loss: 1.6085 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6019 - accuracy: 0.2612 - val_loss: 1.6081 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6049 - accuracy: 0.2735 - val_loss: 1.6077 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6040 - accuracy: 0.2490 - val_loss: 1.6076 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.5953 - accuracy: 0.2939 - val_loss: 1.6071 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6064 - accuracy: 0.2531 - val_loss: 1.6069 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 96ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.5993 - accuracy: 0.2653 - val_loss: 1.6064 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Node 36 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6588 - accuracy: 0.2163 - val_loss: 1.6585 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 352ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6576 - accuracy: 0.2449 - val_loss: 1.6579 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6573 - accuracy: 0.2408 - val_loss: 1.6572 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2245 - val_loss: 1.6565 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6557 - accuracy: 0.2286 - val_loss: 1.6559 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6567 - accuracy: 0.1959 - val_loss: 1.6554 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2612 - val_loss: 1.6549 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2571 - val_loss: 1.6544 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2204 - val_loss: 1.6538 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2367 - val_loss: 1.6534 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2327 - val_loss: 1.6527 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2531 - val_loss: 1.6521 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2327 - val_loss: 1.6515 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2245 - val_loss: 1.6508 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2245 - val_loss: 1.6503 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2204 - val_loss: 1.6499 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6516 - accuracy: 0.2082 - val_loss: 1.6494 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2204 - val_loss: 1.6489 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6488 - accuracy: 0.2286 - val_loss: 1.6484 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2653 - val_loss: 1.6480 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2449 - val_loss: 1.6476 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.2367 - val_loss: 1.6471 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6444 - accuracy: 0.2735 - val_loss: 1.6466 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2490 - val_loss: 1.6460 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2816 - val_loss: 1.6455 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2612 - val_loss: 1.6450 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2367 - val_loss: 1.6445 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6456 - accuracy: 0.2163 - val_loss: 1.6441 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2776 - val_loss: 1.6437 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2245 - val_loss: 1.6433 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2000 - val_loss: 1.6429 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2082 - val_loss: 1.6425 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2286 - val_loss: 1.6420 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2367 - val_loss: 1.6415 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2531 - val_loss: 1.6411 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6416 - accuracy: 0.2163 - val_loss: 1.6406 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2000 - val_loss: 1.6402 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2367 - val_loss: 1.6397 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2571 - val_loss: 1.6392 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2694 - val_loss: 1.6388 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2286 - val_loss: 1.6385 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2531 - val_loss: 1.6381 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2531 - val_loss: 1.6377 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2490 - val_loss: 1.6372 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 57ms/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2367 - val_loss: 1.6368 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2735 - val_loss: 1.6364 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2408 - val_loss: 1.6361 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2612 - val_loss: 1.6358 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2939 - val_loss: 1.6354 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2082 - val_loss: 1.6351 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.1959 - val_loss: 1.6349 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2204 - val_loss: 1.6346 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2449 - val_loss: 1.6342 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2653 - val_loss: 1.6340 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2408 - val_loss: 1.6337 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2204 - val_loss: 1.6334 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2571 - val_loss: 1.6332 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2204 - val_loss: 1.6330 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2531 - val_loss: 1.6326 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2531 - val_loss: 1.6323 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2694 - val_loss: 1.6320 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2245 - val_loss: 1.6317 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2449 - val_loss: 1.6313 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2571 - val_loss: 1.6310 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2082 - val_loss: 1.6306 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2735 - val_loss: 1.6303 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2571 - val_loss: 1.6300 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2857 - val_loss: 1.6298 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.3020 - val_loss: 1.6294 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2612 - val_loss: 1.6292 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2857 - val_loss: 1.6290 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2163 - val_loss: 1.6288 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2694 - val_loss: 1.6287 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2776 - val_loss: 1.6286 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2286 - val_loss: 1.6284 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2327 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2612 - val_loss: 1.6280 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2367 - val_loss: 1.6278 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2735 - val_loss: 1.6275 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2571 - val_loss: 1.6272 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2653 - val_loss: 1.6270 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2327 - val_loss: 1.6267 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2367 - val_loss: 1.6266 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2122 - val_loss: 1.6264 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2612 - val_loss: 1.6262 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2449 - val_loss: 1.6258 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2816 - val_loss: 1.6255 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2490 - val_loss: 1.6254 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2571 - val_loss: 1.6252 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6181 - accuracy: 0.2857 - val_loss: 1.6249 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2449 - val_loss: 1.6246 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6084 - accuracy: 0.3020 - val_loss: 1.6244 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6127 - accuracy: 0.2653 - val_loss: 1.6242 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2612 - val_loss: 1.6239 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6072 - accuracy: 0.2980 - val_loss: 1.6236 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2571 - val_loss: 1.6234 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6113 - accuracy: 0.2531 - val_loss: 1.6233 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.3061 - val_loss: 1.6232 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2490 - val_loss: 1.6230 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2571 - val_loss: 1.6227 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 66ms/epoch - 8ms/step\n",
      "Node 36 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 36 - Best Validation Accuracy: 0.3871\n",
      "Best model saved for Node 36 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_36.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_37_dataset.csv\n",
      "Node 37 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 2s - loss: 1.6331 - accuracy: 0.2362 - val_loss: 1.6333 - val_accuracy: 0.3235 - lr: 1.0000e-04 - 2s/epoch - 144ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6344 - accuracy: 0.1734 - val_loss: 1.6328 - val_accuracy: 0.3382 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6345 - accuracy: 0.1882 - val_loss: 1.6324 - val_accuracy: 0.3235 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6318 - accuracy: 0.2362 - val_loss: 1.6319 - val_accuracy: 0.3382 - lr: 1.0000e-04 - 41ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6323 - accuracy: 0.2399 - val_loss: 1.6315 - val_accuracy: 0.3235 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6321 - accuracy: 0.2288 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6310 - accuracy: 0.2583 - val_loss: 1.6306 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6299 - accuracy: 0.2288 - val_loss: 1.6302 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6305 - accuracy: 0.2694 - val_loss: 1.6299 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6291 - accuracy: 0.2177 - val_loss: 1.6294 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6300 - accuracy: 0.2030 - val_loss: 1.6290 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6291 - accuracy: 0.2214 - val_loss: 1.6288 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6285 - accuracy: 0.1993 - val_loss: 1.6282 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6311 - accuracy: 0.2251 - val_loss: 1.6279 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6274 - accuracy: 0.2288 - val_loss: 1.6275 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6267 - accuracy: 0.2288 - val_loss: 1.6271 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6274 - accuracy: 0.2362 - val_loss: 1.6267 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6270 - accuracy: 0.1919 - val_loss: 1.6263 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6232 - accuracy: 0.2435 - val_loss: 1.6258 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6264 - accuracy: 0.2214 - val_loss: 1.6253 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6256 - accuracy: 0.2288 - val_loss: 1.6248 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6228 - accuracy: 0.2620 - val_loss: 1.6243 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6225 - accuracy: 0.2546 - val_loss: 1.6241 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6208 - accuracy: 0.2214 - val_loss: 1.6236 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6253 - accuracy: 0.2066 - val_loss: 1.6233 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6241 - accuracy: 0.2362 - val_loss: 1.6231 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6224 - accuracy: 0.2251 - val_loss: 1.6228 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6258 - accuracy: 0.2214 - val_loss: 1.6226 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6234 - accuracy: 0.2435 - val_loss: 1.6224 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6215 - accuracy: 0.2325 - val_loss: 1.6220 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6199 - accuracy: 0.2546 - val_loss: 1.6217 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6218 - accuracy: 0.2325 - val_loss: 1.6213 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6214 - accuracy: 0.2066 - val_loss: 1.6210 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6195 - accuracy: 0.1993 - val_loss: 1.6206 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6195 - accuracy: 0.1956 - val_loss: 1.6201 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6197 - accuracy: 0.2214 - val_loss: 1.6196 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6184 - accuracy: 0.2620 - val_loss: 1.6193 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6182 - accuracy: 0.2214 - val_loss: 1.6188 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6161 - accuracy: 0.2583 - val_loss: 1.6185 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2177 - val_loss: 1.6182 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6202 - accuracy: 0.2103 - val_loss: 1.6181 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6203 - accuracy: 0.2325 - val_loss: 1.6179 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6189 - accuracy: 0.2768 - val_loss: 1.6176 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6138 - accuracy: 0.2435 - val_loss: 1.6173 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6207 - accuracy: 0.2066 - val_loss: 1.6170 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6160 - accuracy: 0.2288 - val_loss: 1.6168 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6193 - accuracy: 0.2325 - val_loss: 1.6165 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6165 - accuracy: 0.2288 - val_loss: 1.6162 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6153 - accuracy: 0.2325 - val_loss: 1.6160 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6154 - accuracy: 0.2325 - val_loss: 1.6157 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6177 - accuracy: 0.2030 - val_loss: 1.6154 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6139 - accuracy: 0.2399 - val_loss: 1.6150 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6167 - accuracy: 0.2288 - val_loss: 1.6149 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6140 - accuracy: 0.2288 - val_loss: 1.6146 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6144 - accuracy: 0.2657 - val_loss: 1.6144 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6155 - accuracy: 0.2657 - val_loss: 1.6143 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6107 - accuracy: 0.2620 - val_loss: 1.6141 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6122 - accuracy: 0.2472 - val_loss: 1.6137 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6125 - accuracy: 0.2399 - val_loss: 1.6136 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6139 - accuracy: 0.2362 - val_loss: 1.6135 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6150 - accuracy: 0.2251 - val_loss: 1.6133 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6118 - accuracy: 0.2325 - val_loss: 1.6131 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6113 - accuracy: 0.2583 - val_loss: 1.6129 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6075 - accuracy: 0.2620 - val_loss: 1.6126 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6048 - accuracy: 0.2509 - val_loss: 1.6123 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6093 - accuracy: 0.2472 - val_loss: 1.6120 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6112 - accuracy: 0.2399 - val_loss: 1.6117 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6078 - accuracy: 0.2288 - val_loss: 1.6116 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6093 - accuracy: 0.2325 - val_loss: 1.6113 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6084 - accuracy: 0.2399 - val_loss: 1.6111 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6102 - accuracy: 0.2509 - val_loss: 1.6110 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6049 - accuracy: 0.2620 - val_loss: 1.6108 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6166 - accuracy: 0.2509 - val_loss: 1.6107 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6125 - accuracy: 0.2509 - val_loss: 1.6105 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6095 - accuracy: 0.2546 - val_loss: 1.6105 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6142 - accuracy: 0.2251 - val_loss: 1.6104 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6024 - accuracy: 0.2841 - val_loss: 1.6102 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6102 - accuracy: 0.2546 - val_loss: 1.6098 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6126 - accuracy: 0.2435 - val_loss: 1.6096 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.6023 - accuracy: 0.3026 - val_loss: 1.6094 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6107 - accuracy: 0.2694 - val_loss: 1.6094 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6041 - accuracy: 0.2583 - val_loss: 1.6090 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.6020 - accuracy: 0.2509 - val_loss: 1.6089 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6060 - accuracy: 0.2399 - val_loss: 1.6086 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.6043 - accuracy: 0.2657 - val_loss: 1.6084 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.6120 - accuracy: 0.2472 - val_loss: 1.6083 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6045 - accuracy: 0.2362 - val_loss: 1.6082 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.5976 - accuracy: 0.2878 - val_loss: 1.6082 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.6077 - accuracy: 0.2103 - val_loss: 1.6080 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6014 - accuracy: 0.2435 - val_loss: 1.6077 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.6076 - accuracy: 0.2472 - val_loss: 1.6076 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.6074 - accuracy: 0.2620 - val_loss: 1.6073 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.6063 - accuracy: 0.2804 - val_loss: 1.6073 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.6081 - accuracy: 0.2509 - val_loss: 1.6073 - val_accuracy: 0.2059 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6073 - accuracy: 0.2435 - val_loss: 1.6072 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6049 - accuracy: 0.2472 - val_loss: 1.6070 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 1.6011 - accuracy: 0.2435 - val_loss: 1.6068 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.5965 - accuracy: 0.2878 - val_loss: 1.6065 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.6052 - accuracy: 0.2509 - val_loss: 1.6064 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 1.5995 - accuracy: 0.2399 - val_loss: 1.6062 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Node 37 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6340 - accuracy: 0.2583 - val_loss: 1.6342 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 3s/epoch - 328ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6341 - accuracy: 0.2140 - val_loss: 1.6340 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6363 - accuracy: 0.1734 - val_loss: 1.6337 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6343 - accuracy: 0.2140 - val_loss: 1.6334 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6356 - accuracy: 0.1845 - val_loss: 1.6331 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6345 - accuracy: 0.1882 - val_loss: 1.6328 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6320 - accuracy: 0.2177 - val_loss: 1.6325 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6335 - accuracy: 0.1808 - val_loss: 1.6322 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6328 - accuracy: 0.2435 - val_loss: 1.6320 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6324 - accuracy: 0.2546 - val_loss: 1.6316 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6322 - accuracy: 0.2362 - val_loss: 1.6313 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6332 - accuracy: 0.2177 - val_loss: 1.6310 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6315 - accuracy: 0.2325 - val_loss: 1.6308 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6317 - accuracy: 0.1956 - val_loss: 1.6305 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6312 - accuracy: 0.2066 - val_loss: 1.6301 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6282 - accuracy: 0.2399 - val_loss: 1.6298 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.2620 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6303 - accuracy: 0.2177 - val_loss: 1.6292 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6321 - accuracy: 0.2140 - val_loss: 1.6289 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.2325 - val_loss: 1.6287 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6283 - accuracy: 0.2251 - val_loss: 1.6284 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2066 - val_loss: 1.6281 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6299 - accuracy: 0.1845 - val_loss: 1.6277 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6276 - accuracy: 0.2472 - val_loss: 1.6275 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6265 - accuracy: 0.2362 - val_loss: 1.6272 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6268 - accuracy: 0.2030 - val_loss: 1.6269 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6281 - accuracy: 0.2103 - val_loss: 1.6266 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6292 - accuracy: 0.2066 - val_loss: 1.6263 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6240 - accuracy: 0.2399 - val_loss: 1.6260 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6293 - accuracy: 0.1882 - val_loss: 1.6258 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2066 - val_loss: 1.6256 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2657 - val_loss: 1.6254 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6198 - accuracy: 0.2583 - val_loss: 1.6250 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.1993 - val_loss: 1.6247 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6266 - accuracy: 0.2214 - val_loss: 1.6245 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2140 - val_loss: 1.6243 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6255 - accuracy: 0.1771 - val_loss: 1.6241 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2103 - val_loss: 1.6239 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6247 - accuracy: 0.2030 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6230 - accuracy: 0.2177 - val_loss: 1.6236 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6229 - accuracy: 0.2251 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6256 - accuracy: 0.2509 - val_loss: 1.6232 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6227 - accuracy: 0.2288 - val_loss: 1.6229 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6260 - accuracy: 0.2030 - val_loss: 1.6228 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6237 - accuracy: 0.2103 - val_loss: 1.6228 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6219 - accuracy: 0.2251 - val_loss: 1.6226 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6245 - accuracy: 0.2177 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6239 - accuracy: 0.2251 - val_loss: 1.6223 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2435 - val_loss: 1.6222 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6185 - accuracy: 0.2768 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2472 - val_loss: 1.6219 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6173 - accuracy: 0.2509 - val_loss: 1.6217 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6196 - accuracy: 0.2472 - val_loss: 1.6214 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2362 - val_loss: 1.6211 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2214 - val_loss: 1.6208 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6182 - accuracy: 0.2546 - val_loss: 1.6206 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6187 - accuracy: 0.2657 - val_loss: 1.6204 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6202 - accuracy: 0.2435 - val_loss: 1.6203 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6162 - accuracy: 0.2546 - val_loss: 1.6201 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6177 - accuracy: 0.2399 - val_loss: 1.6199 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6197 - accuracy: 0.2583 - val_loss: 1.6198 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6145 - accuracy: 0.2362 - val_loss: 1.6196 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.2435 - val_loss: 1.6193 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6204 - accuracy: 0.2399 - val_loss: 1.6191 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6169 - accuracy: 0.2546 - val_loss: 1.6190 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6179 - accuracy: 0.2620 - val_loss: 1.6188 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6166 - accuracy: 0.2620 - val_loss: 1.6186 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6186 - accuracy: 0.2472 - val_loss: 1.6185 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2472 - val_loss: 1.6183 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6122 - accuracy: 0.2804 - val_loss: 1.6182 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6183 - accuracy: 0.2030 - val_loss: 1.6180 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6157 - accuracy: 0.2620 - val_loss: 1.6178 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2140 - val_loss: 1.6177 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6159 - accuracy: 0.2288 - val_loss: 1.6175 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6200 - accuracy: 0.2177 - val_loss: 1.6174 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6172 - accuracy: 0.2435 - val_loss: 1.6173 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6191 - accuracy: 0.1993 - val_loss: 1.6172 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6133 - accuracy: 0.2657 - val_loss: 1.6171 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6121 - accuracy: 0.3026 - val_loss: 1.6170 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6181 - accuracy: 0.1993 - val_loss: 1.6168 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6132 - accuracy: 0.2472 - val_loss: 1.6167 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2620 - val_loss: 1.6165 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6155 - accuracy: 0.2325 - val_loss: 1.6162 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6125 - accuracy: 0.2362 - val_loss: 1.6160 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2472 - val_loss: 1.6158 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6148 - accuracy: 0.2251 - val_loss: 1.6158 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6144 - accuracy: 0.2325 - val_loss: 1.6156 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6143 - accuracy: 0.2030 - val_loss: 1.6155 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 38ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6075 - accuracy: 0.2841 - val_loss: 1.6153 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6209 - accuracy: 0.2583 - val_loss: 1.6152 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6126 - accuracy: 0.2768 - val_loss: 1.6151 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6112 - accuracy: 0.2952 - val_loss: 1.6149 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6167 - accuracy: 0.2140 - val_loss: 1.6148 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6175 - accuracy: 0.2251 - val_loss: 1.6147 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6136 - accuracy: 0.2066 - val_loss: 1.6146 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6108 - accuracy: 0.2657 - val_loss: 1.6144 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6072 - accuracy: 0.2546 - val_loss: 1.6142 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6053 - accuracy: 0.2768 - val_loss: 1.6140 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6062 - accuracy: 0.2620 - val_loss: 1.6138 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6114 - accuracy: 0.2472 - val_loss: 1.6136 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Node 37 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 3s - loss: 1.6601 - accuracy: 0.2288 - val_loss: 1.6596 - val_accuracy: 0.2206 - lr: 1.0000e-04 - 3s/epoch - 168ms/step\n",
      "Epoch 2/100\n",
      "17/17 - 0s - loss: 1.6587 - accuracy: 0.2030 - val_loss: 1.6586 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "17/17 - 0s - loss: 1.6580 - accuracy: 0.2583 - val_loss: 1.6573 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "17/17 - 0s - loss: 1.6566 - accuracy: 0.2214 - val_loss: 1.6562 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "17/17 - 0s - loss: 1.6569 - accuracy: 0.2140 - val_loss: 1.6551 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "17/17 - 0s - loss: 1.6544 - accuracy: 0.2030 - val_loss: 1.6540 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "17/17 - 0s - loss: 1.6526 - accuracy: 0.2214 - val_loss: 1.6528 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "17/17 - 0s - loss: 1.6539 - accuracy: 0.1993 - val_loss: 1.6519 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "17/17 - 0s - loss: 1.6511 - accuracy: 0.2251 - val_loss: 1.6507 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "17/17 - 0s - loss: 1.6519 - accuracy: 0.2325 - val_loss: 1.6497 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "17/17 - 0s - loss: 1.6487 - accuracy: 0.2214 - val_loss: 1.6485 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "17/17 - 0s - loss: 1.6472 - accuracy: 0.2325 - val_loss: 1.6475 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "17/17 - 0s - loss: 1.6475 - accuracy: 0.2103 - val_loss: 1.6465 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "17/17 - 0s - loss: 1.6437 - accuracy: 0.2435 - val_loss: 1.6453 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "17/17 - 0s - loss: 1.6465 - accuracy: 0.2472 - val_loss: 1.6444 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "17/17 - 0s - loss: 1.6437 - accuracy: 0.2103 - val_loss: 1.6434 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "17/17 - 0s - loss: 1.6421 - accuracy: 0.2325 - val_loss: 1.6423 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "17/17 - 0s - loss: 1.6409 - accuracy: 0.2435 - val_loss: 1.6414 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "17/17 - 0s - loss: 1.6392 - accuracy: 0.2325 - val_loss: 1.6405 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "17/17 - 0s - loss: 1.6406 - accuracy: 0.2546 - val_loss: 1.6397 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "17/17 - 0s - loss: 1.6421 - accuracy: 0.2066 - val_loss: 1.6389 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "17/17 - 0s - loss: 1.6389 - accuracy: 0.2251 - val_loss: 1.6379 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "17/17 - 0s - loss: 1.6366 - accuracy: 0.2435 - val_loss: 1.6371 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "17/17 - 0s - loss: 1.6366 - accuracy: 0.2288 - val_loss: 1.6360 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "17/17 - 0s - loss: 1.6376 - accuracy: 0.2435 - val_loss: 1.6354 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "17/17 - 0s - loss: 1.6334 - accuracy: 0.2694 - val_loss: 1.6346 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "17/17 - 0s - loss: 1.6382 - accuracy: 0.2251 - val_loss: 1.6340 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "17/17 - 0s - loss: 1.6342 - accuracy: 0.2251 - val_loss: 1.6334 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "17/17 - 0s - loss: 1.6276 - accuracy: 0.2731 - val_loss: 1.6327 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "17/17 - 0s - loss: 1.6337 - accuracy: 0.2620 - val_loss: 1.6320 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "17/17 - 0s - loss: 1.6329 - accuracy: 0.2177 - val_loss: 1.6311 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "17/17 - 0s - loss: 1.6302 - accuracy: 0.2362 - val_loss: 1.6304 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "17/17 - 0s - loss: 1.6267 - accuracy: 0.2731 - val_loss: 1.6296 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2620 - val_loss: 1.6288 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "17/17 - 0s - loss: 1.6293 - accuracy: 0.2583 - val_loss: 1.6281 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "17/17 - 0s - loss: 1.6251 - accuracy: 0.2399 - val_loss: 1.6274 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "17/17 - 0s - loss: 1.6283 - accuracy: 0.2288 - val_loss: 1.6269 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.2435 - val_loss: 1.6264 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "17/17 - 0s - loss: 1.6284 - accuracy: 0.2620 - val_loss: 1.6258 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "17/17 - 0s - loss: 1.6308 - accuracy: 0.1993 - val_loss: 1.6256 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "17/17 - 0s - loss: 1.6259 - accuracy: 0.2214 - val_loss: 1.6249 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "17/17 - 0s - loss: 1.6252 - accuracy: 0.2435 - val_loss: 1.6243 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "17/17 - 0s - loss: 1.6261 - accuracy: 0.2251 - val_loss: 1.6237 - val_accuracy: 0.2353 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "17/17 - 0s - loss: 1.6200 - accuracy: 0.2546 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "17/17 - 0s - loss: 1.6206 - accuracy: 0.2657 - val_loss: 1.6230 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2472 - val_loss: 1.6226 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "17/17 - 0s - loss: 1.6261 - accuracy: 0.2435 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "17/17 - 0s - loss: 1.6170 - accuracy: 0.2952 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "17/17 - 0s - loss: 1.6221 - accuracy: 0.2399 - val_loss: 1.6209 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "17/17 - 0s - loss: 1.6249 - accuracy: 0.2804 - val_loss: 1.6203 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "17/17 - 0s - loss: 1.6131 - accuracy: 0.2768 - val_loss: 1.6197 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "17/17 - 0s - loss: 1.6149 - accuracy: 0.2768 - val_loss: 1.6193 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 99ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "17/17 - 0s - loss: 1.6174 - accuracy: 0.2915 - val_loss: 1.6189 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "17/17 - 0s - loss: 1.6190 - accuracy: 0.2546 - val_loss: 1.6184 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "17/17 - 0s - loss: 1.6167 - accuracy: 0.2583 - val_loss: 1.6178 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "17/17 - 0s - loss: 1.6136 - accuracy: 0.2841 - val_loss: 1.6175 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "17/17 - 0s - loss: 1.6177 - accuracy: 0.2620 - val_loss: 1.6169 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "17/17 - 0s - loss: 1.6223 - accuracy: 0.2694 - val_loss: 1.6165 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "17/17 - 0s - loss: 1.6172 - accuracy: 0.2768 - val_loss: 1.6161 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "17/17 - 0s - loss: 1.6184 - accuracy: 0.2768 - val_loss: 1.6158 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "17/17 - 0s - loss: 1.6172 - accuracy: 0.2620 - val_loss: 1.6153 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "17/17 - 0s - loss: 1.6140 - accuracy: 0.2509 - val_loss: 1.6151 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "17/17 - 0s - loss: 1.6156 - accuracy: 0.2583 - val_loss: 1.6147 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "17/17 - 0s - loss: 1.6163 - accuracy: 0.2694 - val_loss: 1.6144 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "17/17 - 0s - loss: 1.6093 - accuracy: 0.2694 - val_loss: 1.6140 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "17/17 - 0s - loss: 1.6133 - accuracy: 0.2952 - val_loss: 1.6134 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "17/17 - 0s - loss: 1.6187 - accuracy: 0.2509 - val_loss: 1.6131 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "17/17 - 0s - loss: 1.6175 - accuracy: 0.2694 - val_loss: 1.6130 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "17/17 - 0s - loss: 1.6080 - accuracy: 0.2694 - val_loss: 1.6124 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "17/17 - 0s - loss: 1.6142 - accuracy: 0.2399 - val_loss: 1.6121 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "17/17 - 0s - loss: 1.6149 - accuracy: 0.2657 - val_loss: 1.6118 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "17/17 - 0s - loss: 1.6087 - accuracy: 0.2657 - val_loss: 1.6115 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "17/17 - 0s - loss: 1.6112 - accuracy: 0.2731 - val_loss: 1.6112 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "17/17 - 0s - loss: 1.6144 - accuracy: 0.3100 - val_loss: 1.6108 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "17/17 - 0s - loss: 1.6134 - accuracy: 0.2657 - val_loss: 1.6105 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "17/17 - 0s - loss: 1.6090 - accuracy: 0.2657 - val_loss: 1.6102 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "17/17 - 0s - loss: 1.6059 - accuracy: 0.2915 - val_loss: 1.6096 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "17/17 - 0s - loss: 1.6019 - accuracy: 0.3063 - val_loss: 1.6090 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "17/17 - 0s - loss: 1.6043 - accuracy: 0.2841 - val_loss: 1.6085 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "17/17 - 0s - loss: 1.5962 - accuracy: 0.2915 - val_loss: 1.6079 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "17/17 - 0s - loss: 1.6046 - accuracy: 0.2768 - val_loss: 1.6077 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "17/17 - 0s - loss: 1.6104 - accuracy: 0.2694 - val_loss: 1.6076 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "17/17 - 0s - loss: 1.5989 - accuracy: 0.2657 - val_loss: 1.6069 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 73ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "17/17 - 0s - loss: 1.6011 - accuracy: 0.2952 - val_loss: 1.6066 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "17/17 - 0s - loss: 1.5971 - accuracy: 0.2878 - val_loss: 1.6064 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 74ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "17/17 - 0s - loss: 1.5988 - accuracy: 0.3137 - val_loss: 1.6058 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "17/17 - 0s - loss: 1.6047 - accuracy: 0.2878 - val_loss: 1.6054 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 75ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "17/17 - 0s - loss: 1.6075 - accuracy: 0.2583 - val_loss: 1.6051 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "17/17 - 0s - loss: 1.5965 - accuracy: 0.2694 - val_loss: 1.6048 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "17/17 - 0s - loss: 1.6012 - accuracy: 0.2841 - val_loss: 1.6043 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 84ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "17/17 - 0s - loss: 1.5978 - accuracy: 0.2694 - val_loss: 1.6037 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "17/17 - 0s - loss: 1.5997 - accuracy: 0.2768 - val_loss: 1.6035 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "17/17 - 0s - loss: 1.5918 - accuracy: 0.3026 - val_loss: 1.6028 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "17/17 - 0s - loss: 1.5846 - accuracy: 0.2952 - val_loss: 1.6020 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "17/17 - 0s - loss: 1.6100 - accuracy: 0.2915 - val_loss: 1.6017 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "17/17 - 0s - loss: 1.6070 - accuracy: 0.2768 - val_loss: 1.6017 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "17/17 - 0s - loss: 1.5950 - accuracy: 0.2989 - val_loss: 1.6015 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "17/17 - 0s - loss: 1.5923 - accuracy: 0.2841 - val_loss: 1.6007 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 76ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "17/17 - 0s - loss: 1.5991 - accuracy: 0.3063 - val_loss: 1.6002 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "17/17 - 0s - loss: 1.5973 - accuracy: 0.3100 - val_loss: 1.6004 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 97ms/epoch - 6ms/step\n",
      "Node 37 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 - 3s - loss: 1.6594 - accuracy: 0.2140 - val_loss: 1.6586 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 3s/epoch - 279ms/step\n",
      "Epoch 2/100\n",
      "9/9 - 0s - loss: 1.6588 - accuracy: 0.2288 - val_loss: 1.6577 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "9/9 - 0s - loss: 1.6580 - accuracy: 0.1919 - val_loss: 1.6570 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "9/9 - 0s - loss: 1.6563 - accuracy: 0.2362 - val_loss: 1.6564 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "9/9 - 0s - loss: 1.6562 - accuracy: 0.2251 - val_loss: 1.6558 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 29ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "9/9 - 0s - loss: 1.6555 - accuracy: 0.2472 - val_loss: 1.6551 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "9/9 - 0s - loss: 1.6555 - accuracy: 0.2399 - val_loss: 1.6544 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "9/9 - 0s - loss: 1.6547 - accuracy: 0.2399 - val_loss: 1.6536 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 30ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "9/9 - 0s - loss: 1.6545 - accuracy: 0.2288 - val_loss: 1.6529 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "9/9 - 0s - loss: 1.6528 - accuracy: 0.2214 - val_loss: 1.6523 - val_accuracy: 0.3235 - lr: 1.0000e-04 - 31ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "9/9 - 0s - loss: 1.6540 - accuracy: 0.2066 - val_loss: 1.6516 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 47ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "9/9 - 0s - loss: 1.6505 - accuracy: 0.2694 - val_loss: 1.6508 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "9/9 - 0s - loss: 1.6511 - accuracy: 0.2177 - val_loss: 1.6502 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "9/9 - 0s - loss: 1.6513 - accuracy: 0.2177 - val_loss: 1.6495 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "9/9 - 0s - loss: 1.6505 - accuracy: 0.1956 - val_loss: 1.6489 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "9/9 - 0s - loss: 1.6485 - accuracy: 0.2362 - val_loss: 1.6482 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "9/9 - 0s - loss: 1.6468 - accuracy: 0.2399 - val_loss: 1.6475 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "9/9 - 0s - loss: 1.6498 - accuracy: 0.2399 - val_loss: 1.6470 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "9/9 - 0s - loss: 1.6464 - accuracy: 0.2472 - val_loss: 1.6465 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "9/9 - 0s - loss: 1.6467 - accuracy: 0.2435 - val_loss: 1.6459 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "9/9 - 0s - loss: 1.6459 - accuracy: 0.2214 - val_loss: 1.6453 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "9/9 - 0s - loss: 1.6451 - accuracy: 0.2140 - val_loss: 1.6447 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "9/9 - 0s - loss: 1.6431 - accuracy: 0.2546 - val_loss: 1.6443 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "9/9 - 0s - loss: 1.6424 - accuracy: 0.2435 - val_loss: 1.6437 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "9/9 - 0s - loss: 1.6446 - accuracy: 0.2288 - val_loss: 1.6433 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "9/9 - 0s - loss: 1.6455 - accuracy: 0.2325 - val_loss: 1.6428 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "9/9 - 0s - loss: 1.6438 - accuracy: 0.2435 - val_loss: 1.6423 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "9/9 - 0s - loss: 1.6422 - accuracy: 0.2435 - val_loss: 1.6418 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "9/9 - 0s - loss: 1.6421 - accuracy: 0.2399 - val_loss: 1.6413 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "9/9 - 0s - loss: 1.6393 - accuracy: 0.2546 - val_loss: 1.6407 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "9/9 - 0s - loss: 1.6382 - accuracy: 0.2509 - val_loss: 1.6402 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 55ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "9/9 - 0s - loss: 1.6385 - accuracy: 0.2657 - val_loss: 1.6397 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "9/9 - 0s - loss: 1.6384 - accuracy: 0.2509 - val_loss: 1.6392 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "9/9 - 0s - loss: 1.6410 - accuracy: 0.2362 - val_loss: 1.6388 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "9/9 - 0s - loss: 1.6361 - accuracy: 0.2509 - val_loss: 1.6382 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "9/9 - 0s - loss: 1.6394 - accuracy: 0.2362 - val_loss: 1.6378 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "9/9 - 0s - loss: 1.6399 - accuracy: 0.2362 - val_loss: 1.6374 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "9/9 - 0s - loss: 1.6348 - accuracy: 0.2841 - val_loss: 1.6369 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "9/9 - 0s - loss: 1.6366 - accuracy: 0.2583 - val_loss: 1.6365 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "9/9 - 0s - loss: 1.6327 - accuracy: 0.2620 - val_loss: 1.6361 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "9/9 - 0s - loss: 1.6355 - accuracy: 0.2546 - val_loss: 1.6358 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "9/9 - 0s - loss: 1.6369 - accuracy: 0.2399 - val_loss: 1.6355 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "9/9 - 0s - loss: 1.6311 - accuracy: 0.2620 - val_loss: 1.6351 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "9/9 - 0s - loss: 1.6322 - accuracy: 0.2731 - val_loss: 1.6346 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 56ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "9/9 - 0s - loss: 1.6275 - accuracy: 0.2878 - val_loss: 1.6341 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "9/9 - 0s - loss: 1.6342 - accuracy: 0.2435 - val_loss: 1.6337 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "9/9 - 0s - loss: 1.6319 - accuracy: 0.2435 - val_loss: 1.6333 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "9/9 - 0s - loss: 1.6318 - accuracy: 0.2878 - val_loss: 1.6328 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2472 - val_loss: 1.6324 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "9/9 - 0s - loss: 1.6288 - accuracy: 0.2509 - val_loss: 1.6320 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "9/9 - 0s - loss: 1.6300 - accuracy: 0.2694 - val_loss: 1.6315 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 73ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "9/9 - 0s - loss: 1.6267 - accuracy: 0.2657 - val_loss: 1.6311 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "9/9 - 0s - loss: 1.6295 - accuracy: 0.2583 - val_loss: 1.6307 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2546 - val_loss: 1.6302 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2657 - val_loss: 1.6299 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "9/9 - 0s - loss: 1.6253 - accuracy: 0.2325 - val_loss: 1.6295 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "9/9 - 0s - loss: 1.6269 - accuracy: 0.2583 - val_loss: 1.6291 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "9/9 - 0s - loss: 1.6248 - accuracy: 0.2657 - val_loss: 1.6289 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2509 - val_loss: 1.6286 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2657 - val_loss: 1.6283 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "9/9 - 0s - loss: 1.6249 - accuracy: 0.2140 - val_loss: 1.6281 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "9/9 - 0s - loss: 1.6270 - accuracy: 0.2472 - val_loss: 1.6279 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "9/9 - 0s - loss: 1.6213 - accuracy: 0.2657 - val_loss: 1.6276 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "9/9 - 0s - loss: 1.6242 - accuracy: 0.2472 - val_loss: 1.6274 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "9/9 - 0s - loss: 1.6215 - accuracy: 0.2804 - val_loss: 1.6271 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "9/9 - 0s - loss: 1.6241 - accuracy: 0.2288 - val_loss: 1.6268 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "9/9 - 0s - loss: 1.6274 - accuracy: 0.2435 - val_loss: 1.6263 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "9/9 - 0s - loss: 1.6269 - accuracy: 0.2583 - val_loss: 1.6261 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "9/9 - 0s - loss: 1.6259 - accuracy: 0.2472 - val_loss: 1.6258 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "9/9 - 0s - loss: 1.6228 - accuracy: 0.2583 - val_loss: 1.6255 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "9/9 - 0s - loss: 1.6210 - accuracy: 0.2768 - val_loss: 1.6254 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "9/9 - 0s - loss: 1.6238 - accuracy: 0.2435 - val_loss: 1.6251 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "9/9 - 0s - loss: 1.6196 - accuracy: 0.2620 - val_loss: 1.6248 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "9/9 - 0s - loss: 1.6216 - accuracy: 0.2620 - val_loss: 1.6244 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "9/9 - 0s - loss: 1.6170 - accuracy: 0.2620 - val_loss: 1.6241 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "9/9 - 0s - loss: 1.6157 - accuracy: 0.2509 - val_loss: 1.6238 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "9/9 - 0s - loss: 1.6220 - accuracy: 0.2657 - val_loss: 1.6237 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "9/9 - 0s - loss: 1.6166 - accuracy: 0.2878 - val_loss: 1.6235 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "9/9 - 0s - loss: 1.6205 - accuracy: 0.2841 - val_loss: 1.6231 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "9/9 - 0s - loss: 1.6195 - accuracy: 0.2325 - val_loss: 1.6227 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "9/9 - 0s - loss: 1.6142 - accuracy: 0.2472 - val_loss: 1.6224 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2177 - val_loss: 1.6221 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "9/9 - 0s - loss: 1.6160 - accuracy: 0.2952 - val_loss: 1.6218 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "9/9 - 0s - loss: 1.6083 - accuracy: 0.2731 - val_loss: 1.6213 - val_accuracy: 0.3088 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "9/9 - 0s - loss: 1.6176 - accuracy: 0.2694 - val_loss: 1.6210 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "9/9 - 0s - loss: 1.6147 - accuracy: 0.2583 - val_loss: 1.6207 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "9/9 - 0s - loss: 1.6156 - accuracy: 0.2288 - val_loss: 1.6205 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "9/9 - 0s - loss: 1.6090 - accuracy: 0.2804 - val_loss: 1.6201 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "9/9 - 0s - loss: 1.6129 - accuracy: 0.2657 - val_loss: 1.6198 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "9/9 - 0s - loss: 1.6096 - accuracy: 0.2694 - val_loss: 1.6195 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "9/9 - 0s - loss: 1.6127 - accuracy: 0.2657 - val_loss: 1.6194 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 49ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "9/9 - 0s - loss: 1.6110 - accuracy: 0.2694 - val_loss: 1.6192 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "9/9 - 0s - loss: 1.6077 - accuracy: 0.2804 - val_loss: 1.6190 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "9/9 - 0s - loss: 1.6124 - accuracy: 0.2583 - val_loss: 1.6188 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "9/9 - 0s - loss: 1.6072 - accuracy: 0.2546 - val_loss: 1.6186 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 54ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "9/9 - 0s - loss: 1.6097 - accuracy: 0.2841 - val_loss: 1.6186 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "9/9 - 0s - loss: 1.6076 - accuracy: 0.2694 - val_loss: 1.6184 - val_accuracy: 0.2647 - lr: 1.0000e-04 - 48ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "9/9 - 0s - loss: 1.6061 - accuracy: 0.2768 - val_loss: 1.6181 - val_accuracy: 0.2794 - lr: 1.0000e-04 - 69ms/epoch - 8ms/step\n",
      "Epoch 99/100\n",
      "9/9 - 0s - loss: 1.6054 - accuracy: 0.2952 - val_loss: 1.6179 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 53ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "9/9 - 0s - loss: 1.6048 - accuracy: 0.2731 - val_loss: 1.6176 - val_accuracy: 0.2941 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Node 37 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 37 - Best Validation Accuracy: 0.3382\n",
      "Best model saved for Node 37 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_37.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_38_dataset.csv\n",
      "Node 38 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6350 - accuracy: 0.1667 - val_loss: 1.6349 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 2s/epoch - 147ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2042 - val_loss: 1.6345 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6335 - accuracy: 0.1750 - val_loss: 1.6339 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2250 - val_loss: 1.6334 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2417 - val_loss: 1.6330 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.2292 - val_loss: 1.6325 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2083 - val_loss: 1.6321 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6318 - accuracy: 0.2417 - val_loss: 1.6317 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2750 - val_loss: 1.6314 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2333 - val_loss: 1.6311 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6298 - accuracy: 0.2042 - val_loss: 1.6308 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2208 - val_loss: 1.6304 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.1917 - val_loss: 1.6301 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2250 - val_loss: 1.6298 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2833 - val_loss: 1.6293 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2417 - val_loss: 1.6289 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2583 - val_loss: 1.6285 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2250 - val_loss: 1.6281 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2292 - val_loss: 1.6278 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2375 - val_loss: 1.6275 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2208 - val_loss: 1.6272 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2583 - val_loss: 1.6268 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2417 - val_loss: 1.6266 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2125 - val_loss: 1.6264 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2458 - val_loss: 1.6261 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2000 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2333 - val_loss: 1.6256 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2208 - val_loss: 1.6254 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2458 - val_loss: 1.6252 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2167 - val_loss: 1.6249 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2417 - val_loss: 1.6247 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6245 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2417 - val_loss: 1.6243 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2333 - val_loss: 1.6240 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2500 - val_loss: 1.6237 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2125 - val_loss: 1.6233 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2208 - val_loss: 1.6230 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2333 - val_loss: 1.6227 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2333 - val_loss: 1.6225 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2417 - val_loss: 1.6222 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6131 - accuracy: 0.2458 - val_loss: 1.6220 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6188 - accuracy: 0.2250 - val_loss: 1.6218 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2375 - val_loss: 1.6216 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2417 - val_loss: 1.6213 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2417 - val_loss: 1.6210 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2708 - val_loss: 1.6208 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2167 - val_loss: 1.6206 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2667 - val_loss: 1.6204 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2917 - val_loss: 1.6202 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2500 - val_loss: 1.6200 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6112 - accuracy: 0.2583 - val_loss: 1.6198 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2375 - val_loss: 1.6197 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2542 - val_loss: 1.6195 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2458 - val_loss: 1.6194 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2542 - val_loss: 1.6193 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2250 - val_loss: 1.6191 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2292 - val_loss: 1.6190 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2083 - val_loss: 1.6189 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6086 - accuracy: 0.2542 - val_loss: 1.6187 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6110 - accuracy: 0.2583 - val_loss: 1.6186 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2750 - val_loss: 1.6185 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2750 - val_loss: 1.6184 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6158 - accuracy: 0.2125 - val_loss: 1.6183 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2458 - val_loss: 1.6182 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2542 - val_loss: 1.6181 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6090 - accuracy: 0.2583 - val_loss: 1.6180 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2542 - val_loss: 1.6179 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6113 - accuracy: 0.2375 - val_loss: 1.6178 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6153 - accuracy: 0.2583 - val_loss: 1.6177 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6104 - accuracy: 0.2667 - val_loss: 1.6176 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2417 - val_loss: 1.6175 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2542 - val_loss: 1.6174 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2625 - val_loss: 1.6173 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2167 - val_loss: 1.6172 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.3000 - val_loss: 1.6171 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6019 - accuracy: 0.2458 - val_loss: 1.6170 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2333 - val_loss: 1.6170 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6087 - accuracy: 0.2583 - val_loss: 1.6169 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2083 - val_loss: 1.6169 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6122 - accuracy: 0.2417 - val_loss: 1.6168 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6089 - accuracy: 0.2583 - val_loss: 1.6167 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.2792 - val_loss: 1.6167 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2458 - val_loss: 1.6166 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.2500 - val_loss: 1.6165 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6055 - accuracy: 0.2542 - val_loss: 1.6163 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6107 - accuracy: 0.2250 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6047 - accuracy: 0.2208 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6052 - accuracy: 0.2250 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6087 - accuracy: 0.2083 - val_loss: 1.6162 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6051 - accuracy: 0.2667 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.2375 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6002 - accuracy: 0.2917 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6087 - accuracy: 0.2292 - val_loss: 1.6161 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2250 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.5981 - accuracy: 0.2542 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.5966 - accuracy: 0.2667 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6077 - accuracy: 0.2500 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2792 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 58ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6013 - accuracy: 0.2750 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6045 - accuracy: 0.2458 - val_loss: 1.6160 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 38ms/epoch - 3ms/step\n",
      "Node 38 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6348 - accuracy: 0.2542 - val_loss: 1.6339 - val_accuracy: 0.3333 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.1958 - val_loss: 1.6336 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6360 - accuracy: 0.1833 - val_loss: 1.6333 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2208 - val_loss: 1.6331 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2292 - val_loss: 1.6328 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2208 - val_loss: 1.6326 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2125 - val_loss: 1.6323 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.1917 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2208 - val_loss: 1.6319 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2667 - val_loss: 1.6317 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2125 - val_loss: 1.6315 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2542 - val_loss: 1.6313 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2417 - val_loss: 1.6311 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2458 - val_loss: 1.6308 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2333 - val_loss: 1.6306 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2333 - val_loss: 1.6304 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2417 - val_loss: 1.6303 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2375 - val_loss: 1.6302 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2375 - val_loss: 1.6300 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2292 - val_loss: 1.6298 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2500 - val_loss: 1.6296 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2583 - val_loss: 1.6294 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2083 - val_loss: 1.6291 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2125 - val_loss: 1.6289 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2333 - val_loss: 1.6286 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2667 - val_loss: 1.6283 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2667 - val_loss: 1.6280 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2583 - val_loss: 1.6277 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2292 - val_loss: 1.6274 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2458 - val_loss: 1.6271 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2250 - val_loss: 1.6269 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2333 - val_loss: 1.6266 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2458 - val_loss: 1.6263 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2250 - val_loss: 1.6260 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2500 - val_loss: 1.6257 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2375 - val_loss: 1.6256 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2208 - val_loss: 1.6253 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2208 - val_loss: 1.6251 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2583 - val_loss: 1.6248 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2583 - val_loss: 1.6246 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2292 - val_loss: 1.6244 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2125 - val_loss: 1.6242 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2333 - val_loss: 1.6240 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2250 - val_loss: 1.6238 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2417 - val_loss: 1.6236 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2208 - val_loss: 1.6234 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2458 - val_loss: 1.6233 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2583 - val_loss: 1.6232 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2333 - val_loss: 1.6230 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2292 - val_loss: 1.6229 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2458 - val_loss: 1.6227 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2208 - val_loss: 1.6225 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2583 - val_loss: 1.6224 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2167 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2208 - val_loss: 1.6221 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2458 - val_loss: 1.6219 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2417 - val_loss: 1.6217 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2625 - val_loss: 1.6216 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2375 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2583 - val_loss: 1.6212 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2250 - val_loss: 1.6211 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2625 - val_loss: 1.6209 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2625 - val_loss: 1.6208 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2167 - val_loss: 1.6207 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2708 - val_loss: 1.6206 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2417 - val_loss: 1.6205 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2875 - val_loss: 1.6204 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2583 - val_loss: 1.6203 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2542 - val_loss: 1.6203 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2292 - val_loss: 1.6201 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2333 - val_loss: 1.6200 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6138 - accuracy: 0.2417 - val_loss: 1.6199 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2625 - val_loss: 1.6198 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2292 - val_loss: 1.6196 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2667 - val_loss: 1.6195 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2542 - val_loss: 1.6194 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2458 - val_loss: 1.6193 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2542 - val_loss: 1.6193 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2667 - val_loss: 1.6192 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6059 - accuracy: 0.2583 - val_loss: 1.6192 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2208 - val_loss: 1.6191 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2792 - val_loss: 1.6190 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2458 - val_loss: 1.6190 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6113 - accuracy: 0.2583 - val_loss: 1.6188 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2250 - val_loss: 1.6187 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2542 - val_loss: 1.6187 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2250 - val_loss: 1.6186 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6099 - accuracy: 0.2500 - val_loss: 1.6185 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2333 - val_loss: 1.6185 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2167 - val_loss: 1.6184 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2333 - val_loss: 1.6184 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2292 - val_loss: 1.6183 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2667 - val_loss: 1.6182 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2375 - val_loss: 1.6182 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6134 - accuracy: 0.2542 - val_loss: 1.6181 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2500 - val_loss: 1.6180 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2208 - val_loss: 1.6179 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2417 - val_loss: 1.6178 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6075 - accuracy: 0.2750 - val_loss: 1.6177 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6074 - accuracy: 0.2708 - val_loss: 1.6176 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Node 38 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6607 - accuracy: 0.1958 - val_loss: 1.6597 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 2s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6590 - accuracy: 0.2292 - val_loss: 1.6588 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6583 - accuracy: 0.2292 - val_loss: 1.6580 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6578 - accuracy: 0.2167 - val_loss: 1.6570 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6548 - accuracy: 0.2292 - val_loss: 1.6561 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6540 - accuracy: 0.2167 - val_loss: 1.6551 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6559 - accuracy: 0.2208 - val_loss: 1.6544 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6516 - accuracy: 0.2583 - val_loss: 1.6535 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6524 - accuracy: 0.2125 - val_loss: 1.6527 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6508 - accuracy: 0.2375 - val_loss: 1.6518 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6502 - accuracy: 0.2542 - val_loss: 1.6508 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6469 - accuracy: 0.2417 - val_loss: 1.6499 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2375 - val_loss: 1.6490 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6471 - accuracy: 0.2292 - val_loss: 1.6483 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6429 - accuracy: 0.2375 - val_loss: 1.6475 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6454 - accuracy: 0.2250 - val_loss: 1.6468 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6425 - accuracy: 0.2083 - val_loss: 1.6461 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6428 - accuracy: 0.2625 - val_loss: 1.6455 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6432 - accuracy: 0.2250 - val_loss: 1.6449 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6435 - accuracy: 0.2333 - val_loss: 1.6445 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6404 - accuracy: 0.2583 - val_loss: 1.6440 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6414 - accuracy: 0.2250 - val_loss: 1.6434 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6354 - accuracy: 0.2458 - val_loss: 1.6426 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6377 - accuracy: 0.2333 - val_loss: 1.6420 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2417 - val_loss: 1.6415 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6387 - accuracy: 0.2667 - val_loss: 1.6410 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6359 - accuracy: 0.2583 - val_loss: 1.6406 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6349 - accuracy: 0.2458 - val_loss: 1.6401 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.2458 - val_loss: 1.6395 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2167 - val_loss: 1.6390 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2375 - val_loss: 1.6387 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.2792 - val_loss: 1.6383 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2667 - val_loss: 1.6379 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2625 - val_loss: 1.6375 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2167 - val_loss: 1.6373 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2542 - val_loss: 1.6369 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2708 - val_loss: 1.6367 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2542 - val_loss: 1.6364 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.2333 - val_loss: 1.6362 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2542 - val_loss: 1.6359 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2792 - val_loss: 1.6357 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2375 - val_loss: 1.6354 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2667 - val_loss: 1.6352 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2583 - val_loss: 1.6348 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6236 - accuracy: 0.2667 - val_loss: 1.6346 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2667 - val_loss: 1.6342 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2583 - val_loss: 1.6341 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6260 - accuracy: 0.2875 - val_loss: 1.6337 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6264 - accuracy: 0.2500 - val_loss: 1.6336 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2750 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2167 - val_loss: 1.6333 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2708 - val_loss: 1.6331 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2792 - val_loss: 1.6331 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2792 - val_loss: 1.6329 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2542 - val_loss: 1.6328 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2500 - val_loss: 1.6327 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2333 - val_loss: 1.6327 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2750 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6160 - accuracy: 0.2667 - val_loss: 1.6325 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2833 - val_loss: 1.6324 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2917 - val_loss: 1.6323 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2792 - val_loss: 1.6320 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2792 - val_loss: 1.6320 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2625 - val_loss: 1.6320 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2292 - val_loss: 1.6318 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6106 - accuracy: 0.3000 - val_loss: 1.6319 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2833 - val_loss: 1.6318 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2708 - val_loss: 1.6320 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2875 - val_loss: 1.6321 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2708 - val_loss: 1.6321 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2583 - val_loss: 1.6322 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 59ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6071 - accuracy: 0.2833 - val_loss: 1.6321 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 59ms/epoch - 4ms/step\n",
      "Node 38 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6608 - accuracy: 0.1792 - val_loss: 1.6595 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6600 - accuracy: 0.2000 - val_loss: 1.6587 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6594 - accuracy: 0.2333 - val_loss: 1.6579 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2333 - val_loss: 1.6573 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6560 - accuracy: 0.2458 - val_loss: 1.6568 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.2500 - val_loss: 1.6560 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2542 - val_loss: 1.6555 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2458 - val_loss: 1.6550 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6552 - accuracy: 0.2417 - val_loss: 1.6545 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6530 - accuracy: 0.2583 - val_loss: 1.6540 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6534 - accuracy: 0.2125 - val_loss: 1.6534 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6517 - accuracy: 0.2458 - val_loss: 1.6528 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 40ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2917 - val_loss: 1.6521 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2333 - val_loss: 1.6515 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6485 - accuracy: 0.2667 - val_loss: 1.6510 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2417 - val_loss: 1.6505 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2458 - val_loss: 1.6501 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2333 - val_loss: 1.6497 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2833 - val_loss: 1.6492 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6468 - accuracy: 0.2458 - val_loss: 1.6489 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2792 - val_loss: 1.6484 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2583 - val_loss: 1.6480 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6423 - accuracy: 0.2625 - val_loss: 1.6475 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2708 - val_loss: 1.6472 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2500 - val_loss: 1.6467 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2792 - val_loss: 1.6462 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2417 - val_loss: 1.6458 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2625 - val_loss: 1.6454 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6386 - accuracy: 0.2542 - val_loss: 1.6450 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6375 - accuracy: 0.2625 - val_loss: 1.6445 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2583 - val_loss: 1.6441 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2375 - val_loss: 1.6437 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2667 - val_loss: 1.6433 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2792 - val_loss: 1.6430 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6409 - accuracy: 0.2750 - val_loss: 1.6428 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2667 - val_loss: 1.6424 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2750 - val_loss: 1.6422 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2500 - val_loss: 1.6419 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2500 - val_loss: 1.6416 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2542 - val_loss: 1.6413 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2417 - val_loss: 1.6411 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2625 - val_loss: 1.6409 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2583 - val_loss: 1.6407 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2750 - val_loss: 1.6405 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2458 - val_loss: 1.6403 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2458 - val_loss: 1.6401 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2292 - val_loss: 1.6399 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2667 - val_loss: 1.6396 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2667 - val_loss: 1.6394 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2625 - val_loss: 1.6391 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2500 - val_loss: 1.6388 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2708 - val_loss: 1.6385 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2458 - val_loss: 1.6383 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2625 - val_loss: 1.6381 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2625 - val_loss: 1.6378 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2708 - val_loss: 1.6377 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2583 - val_loss: 1.6375 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2542 - val_loss: 1.6373 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2833 - val_loss: 1.6371 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2958 - val_loss: 1.6370 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2500 - val_loss: 1.6368 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2708 - val_loss: 1.6366 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2750 - val_loss: 1.6365 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2625 - val_loss: 1.6364 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2625 - val_loss: 1.6363 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2458 - val_loss: 1.6363 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2542 - val_loss: 1.6361 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2708 - val_loss: 1.6359 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2417 - val_loss: 1.6358 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.3125 - val_loss: 1.6357 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2750 - val_loss: 1.6357 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6168 - accuracy: 0.2667 - val_loss: 1.6356 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2750 - val_loss: 1.6356 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2708 - val_loss: 1.6355 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2542 - val_loss: 1.6354 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2958 - val_loss: 1.6353 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2208 - val_loss: 1.6352 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2500 - val_loss: 1.6351 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2583 - val_loss: 1.6349 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6190 - accuracy: 0.2250 - val_loss: 1.6349 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2667 - val_loss: 1.6347 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2542 - val_loss: 1.6345 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2667 - val_loss: 1.6344 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2458 - val_loss: 1.6344 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.3042 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2375 - val_loss: 1.6346 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2625 - val_loss: 1.6346 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6180 - accuracy: 0.2542 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6146 - accuracy: 0.2208 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2792 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2625 - val_loss: 1.6345 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 45ms/epoch - 6ms/step\n",
      "Node 38 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 38 - Best Validation Accuracy: 0.3333\n",
      "Best model saved for Node 38 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_38.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_39_dataset.csv\n",
      "Node 39 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6349 - accuracy: 0.1870 - val_loss: 1.6327 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 3s/epoch - 183ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6331 - accuracy: 0.1463 - val_loss: 1.6312 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.1951 - val_loss: 1.6295 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6307 - accuracy: 0.1829 - val_loss: 1.6283 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2276 - val_loss: 1.6268 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2602 - val_loss: 1.6254 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2276 - val_loss: 1.6241 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2276 - val_loss: 1.6228 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2967 - val_loss: 1.6217 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2195 - val_loss: 1.6204 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2561 - val_loss: 1.6192 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2561 - val_loss: 1.6180 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6180 - accuracy: 0.2967 - val_loss: 1.6168 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2073 - val_loss: 1.6156 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2683 - val_loss: 1.6142 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2276 - val_loss: 1.6129 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2236 - val_loss: 1.6120 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2602 - val_loss: 1.6111 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6124 - accuracy: 0.2561 - val_loss: 1.6098 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2398 - val_loss: 1.6088 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6062 - accuracy: 0.2276 - val_loss: 1.6073 - val_accuracy: 0.3226 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6027 - accuracy: 0.2886 - val_loss: 1.6057 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6070 - accuracy: 0.2683 - val_loss: 1.6041 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2398 - val_loss: 1.6028 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6079 - accuracy: 0.2195 - val_loss: 1.6017 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6102 - accuracy: 0.2561 - val_loss: 1.6009 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6071 - accuracy: 0.2642 - val_loss: 1.6003 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6054 - accuracy: 0.2561 - val_loss: 1.5999 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2358 - val_loss: 1.5992 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6081 - accuracy: 0.2602 - val_loss: 1.5986 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6019 - accuracy: 0.3089 - val_loss: 1.5980 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.5952 - accuracy: 0.2764 - val_loss: 1.5967 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6049 - accuracy: 0.2764 - val_loss: 1.5956 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.5976 - accuracy: 0.2358 - val_loss: 1.5952 - val_accuracy: 0.3065 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.5989 - accuracy: 0.2805 - val_loss: 1.5945 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.5998 - accuracy: 0.2439 - val_loss: 1.5939 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6046 - accuracy: 0.2846 - val_loss: 1.5937 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6023 - accuracy: 0.2602 - val_loss: 1.5931 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.5966 - accuracy: 0.2236 - val_loss: 1.5927 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.5994 - accuracy: 0.2561 - val_loss: 1.5922 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.5918 - accuracy: 0.3049 - val_loss: 1.5920 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.5948 - accuracy: 0.2805 - val_loss: 1.5915 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.5980 - accuracy: 0.2236 - val_loss: 1.5913 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.5963 - accuracy: 0.2683 - val_loss: 1.5910 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.5887 - accuracy: 0.2561 - val_loss: 1.5904 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.5985 - accuracy: 0.3252 - val_loss: 1.5899 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.5871 - accuracy: 0.2846 - val_loss: 1.5894 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.5935 - accuracy: 0.2764 - val_loss: 1.5893 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.5949 - accuracy: 0.2846 - val_loss: 1.5889 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.5918 - accuracy: 0.3089 - val_loss: 1.5887 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.5828 - accuracy: 0.2480 - val_loss: 1.5885 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.5914 - accuracy: 0.2520 - val_loss: 1.5883 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.5942 - accuracy: 0.2683 - val_loss: 1.5882 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.5954 - accuracy: 0.2317 - val_loss: 1.5882 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.5998 - accuracy: 0.2886 - val_loss: 1.5880 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6005 - accuracy: 0.2561 - val_loss: 1.5882 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.5920 - accuracy: 0.2764 - val_loss: 1.5880 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.5909 - accuracy: 0.2642 - val_loss: 1.5878 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.5872 - accuracy: 0.3049 - val_loss: 1.5875 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6020 - accuracy: 0.2642 - val_loss: 1.5875 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.5962 - accuracy: 0.2724 - val_loss: 1.5879 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.5910 - accuracy: 0.2520 - val_loss: 1.5878 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.5819 - accuracy: 0.2642 - val_loss: 1.5876 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.5907 - accuracy: 0.2276 - val_loss: 1.5875 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.5940 - accuracy: 0.3171 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 50ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.5960 - accuracy: 0.2805 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6001 - accuracy: 0.2846 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.5910 - accuracy: 0.2846 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.5874 - accuracy: 0.2642 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.5867 - accuracy: 0.2927 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.5832 - accuracy: 0.2764 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.5919 - accuracy: 0.2724 - val_loss: 1.5874 - val_accuracy: 0.2742 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.5950 - accuracy: 0.2561 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.5925 - accuracy: 0.2561 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 6.2500e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.5931 - accuracy: 0.2927 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 6.2500e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.5834 - accuracy: 0.3171 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.1250e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.5876 - accuracy: 0.3171 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.1250e-06 - 52ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.5899 - accuracy: 0.2358 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.1250e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.5995 - accuracy: 0.2967 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.5625e-06 - 49ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.5918 - accuracy: 0.2602 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.5625e-06 - 50ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.5968 - accuracy: 0.2602 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.5625e-06 - 48ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.5937 - accuracy: 0.2642 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.5841 - accuracy: 0.2927 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 7.8125e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "16/16 - 0s - loss: 1.5835 - accuracy: 0.2764 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 7.8125e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.5928 - accuracy: 0.2480 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.9062e-07 - 47ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.5944 - accuracy: 0.2724 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.9062e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "16/16 - 0s - loss: 1.5949 - accuracy: 0.2520 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 3.9062e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.5799 - accuracy: 0.2927 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.9531e-07 - 48ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.5921 - accuracy: 0.2846 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.9531e-07 - 50ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "16/16 - 0s - loss: 1.5885 - accuracy: 0.2805 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.9531e-07 - 49ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.5943 - accuracy: 0.3049 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 9.7656e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.5915 - accuracy: 0.2642 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "16/16 - 0s - loss: 1.5934 - accuracy: 0.2683 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 9.7656e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.5939 - accuracy: 0.2764 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 4.8828e-08 - 70ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.5858 - accuracy: 0.2236 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 4.8828e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "16/16 - 0s - loss: 1.5957 - accuracy: 0.2724 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.5829 - accuracy: 0.2683 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 2.4414e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.5852 - accuracy: 0.2602 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 2.4414e-08 - 49ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "16/16 - 0s - loss: 1.5863 - accuracy: 0.2846 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 2.4414e-08 - 47ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.5838 - accuracy: 0.2846 - val_loss: 1.5873 - val_accuracy: 0.2742 - lr: 1.2207e-08 - 48ms/epoch - 3ms/step\n",
      "Node 39 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6337 - accuracy: 0.2317 - val_loss: 1.6336 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 356ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2602 - val_loss: 1.6324 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2439 - val_loss: 1.6311 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2317 - val_loss: 1.6299 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.1829 - val_loss: 1.6287 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2642 - val_loss: 1.6276 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2195 - val_loss: 1.6262 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.1911 - val_loss: 1.6250 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2886 - val_loss: 1.6240 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2683 - val_loss: 1.6230 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2358 - val_loss: 1.6221 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2520 - val_loss: 1.6211 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2764 - val_loss: 1.6200 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2073 - val_loss: 1.6191 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2683 - val_loss: 1.6182 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2358 - val_loss: 1.6173 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2967 - val_loss: 1.6164 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.1911 - val_loss: 1.6155 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2561 - val_loss: 1.6145 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2236 - val_loss: 1.6137 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2276 - val_loss: 1.6129 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2033 - val_loss: 1.6121 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6125 - accuracy: 0.2195 - val_loss: 1.6114 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6131 - accuracy: 0.2317 - val_loss: 1.6106 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6090 - accuracy: 0.2927 - val_loss: 1.6098 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6053 - accuracy: 0.2602 - val_loss: 1.6088 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6136 - accuracy: 0.1911 - val_loss: 1.6079 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2602 - val_loss: 1.6072 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6078 - accuracy: 0.2642 - val_loss: 1.6065 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6063 - accuracy: 0.2520 - val_loss: 1.6058 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2398 - val_loss: 1.6053 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6053 - accuracy: 0.2236 - val_loss: 1.6049 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6124 - accuracy: 0.2480 - val_loss: 1.6045 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6137 - accuracy: 0.2317 - val_loss: 1.6040 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6118 - accuracy: 0.2439 - val_loss: 1.6036 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6039 - accuracy: 0.2805 - val_loss: 1.6031 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6095 - accuracy: 0.2114 - val_loss: 1.6026 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6006 - accuracy: 0.2927 - val_loss: 1.6021 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 94ms/epoch - 12ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6031 - accuracy: 0.2764 - val_loss: 1.6017 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6024 - accuracy: 0.2439 - val_loss: 1.6013 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6061 - accuracy: 0.2846 - val_loss: 1.6008 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.5950 - accuracy: 0.2967 - val_loss: 1.6002 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6015 - accuracy: 0.2561 - val_loss: 1.5996 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6056 - accuracy: 0.3008 - val_loss: 1.5992 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6126 - accuracy: 0.2236 - val_loss: 1.5989 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6009 - accuracy: 0.2764 - val_loss: 1.5986 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.5970 - accuracy: 0.2683 - val_loss: 1.5983 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2764 - val_loss: 1.5979 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.5980 - accuracy: 0.2602 - val_loss: 1.5976 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6051 - accuracy: 0.2520 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 57ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2480 - val_loss: 1.5971 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.5957 - accuracy: 0.2846 - val_loss: 1.5968 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6076 - accuracy: 0.2561 - val_loss: 1.5965 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.5979 - accuracy: 0.2846 - val_loss: 1.5964 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6020 - accuracy: 0.2805 - val_loss: 1.5962 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6029 - accuracy: 0.2236 - val_loss: 1.5959 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6066 - accuracy: 0.2439 - val_loss: 1.5957 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6020 - accuracy: 0.2886 - val_loss: 1.5956 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.5954 - accuracy: 0.2642 - val_loss: 1.5954 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.5941 - accuracy: 0.2846 - val_loss: 1.5951 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.5923 - accuracy: 0.2602 - val_loss: 1.5948 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.5963 - accuracy: 0.2764 - val_loss: 1.5945 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.5998 - accuracy: 0.2602 - val_loss: 1.5943 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.5947 - accuracy: 0.3008 - val_loss: 1.5940 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.5967 - accuracy: 0.2642 - val_loss: 1.5937 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.5968 - accuracy: 0.2846 - val_loss: 1.5935 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.5942 - accuracy: 0.2846 - val_loss: 1.5934 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6001 - accuracy: 0.2846 - val_loss: 1.5933 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.5997 - accuracy: 0.2846 - val_loss: 1.5931 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.5985 - accuracy: 0.2561 - val_loss: 1.5930 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.5879 - accuracy: 0.2886 - val_loss: 1.5929 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6054 - accuracy: 0.2805 - val_loss: 1.5928 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.5880 - accuracy: 0.2846 - val_loss: 1.5926 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.5932 - accuracy: 0.2846 - val_loss: 1.5924 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6026 - accuracy: 0.2642 - val_loss: 1.5923 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.5977 - accuracy: 0.2764 - val_loss: 1.5922 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6013 - accuracy: 0.2683 - val_loss: 1.5921 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.5862 - accuracy: 0.2927 - val_loss: 1.5922 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6013 - accuracy: 0.2439 - val_loss: 1.5921 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.5889 - accuracy: 0.2886 - val_loss: 1.5919 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6026 - accuracy: 0.2195 - val_loss: 1.5918 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6020 - accuracy: 0.2846 - val_loss: 1.5918 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.5861 - accuracy: 0.2561 - val_loss: 1.5916 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.5858 - accuracy: 0.2561 - val_loss: 1.5915 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.5949 - accuracy: 0.2602 - val_loss: 1.5913 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6015 - accuracy: 0.2561 - val_loss: 1.5913 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.5896 - accuracy: 0.2602 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.5974 - accuracy: 0.2846 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.5993 - accuracy: 0.2805 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6012 - accuracy: 0.2602 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6030 - accuracy: 0.2805 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.5957 - accuracy: 0.2642 - val_loss: 1.5912 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.5902 - accuracy: 0.2520 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 34ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.5803 - accuracy: 0.3089 - val_loss: 1.5911 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6025 - accuracy: 0.2724 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.5860 - accuracy: 0.2724 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.5890 - accuracy: 0.2561 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.5864 - accuracy: 0.2764 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 53ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.5936 - accuracy: 0.2683 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 33ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.5940 - accuracy: 0.3008 - val_loss: 1.5910 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 33ms/epoch - 4ms/step\n",
      "Node 39 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6601 - accuracy: 0.1951 - val_loss: 1.6577 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 3s/epoch - 166ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6568 - accuracy: 0.2602 - val_loss: 1.6551 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6545 - accuracy: 0.2724 - val_loss: 1.6530 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6520 - accuracy: 0.2439 - val_loss: 1.6507 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6492 - accuracy: 0.2764 - val_loss: 1.6487 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6492 - accuracy: 0.2480 - val_loss: 1.6466 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2561 - val_loss: 1.6437 - val_accuracy: 0.2903 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6411 - accuracy: 0.2602 - val_loss: 1.6405 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 82ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6422 - accuracy: 0.2683 - val_loss: 1.6373 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6366 - accuracy: 0.2724 - val_loss: 1.6352 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6368 - accuracy: 0.2520 - val_loss: 1.6327 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2439 - val_loss: 1.6303 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6364 - accuracy: 0.2358 - val_loss: 1.6279 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6350 - accuracy: 0.2439 - val_loss: 1.6256 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2805 - val_loss: 1.6242 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6313 - accuracy: 0.1992 - val_loss: 1.6226 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 83ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2602 - val_loss: 1.6205 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6144 - accuracy: 0.2846 - val_loss: 1.6184 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2398 - val_loss: 1.6161 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2683 - val_loss: 1.6149 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2439 - val_loss: 1.6134 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2480 - val_loss: 1.6118 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6152 - accuracy: 0.3049 - val_loss: 1.6105 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2520 - val_loss: 1.6100 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2317 - val_loss: 1.6097 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6038 - accuracy: 0.2967 - val_loss: 1.6088 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2764 - val_loss: 1.6080 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2927 - val_loss: 1.6075 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6032 - accuracy: 0.2724 - val_loss: 1.6066 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2480 - val_loss: 1.6062 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2642 - val_loss: 1.6059 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.3171 - val_loss: 1.6059 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6068 - accuracy: 0.2602 - val_loss: 1.6054 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2561 - val_loss: 1.6050 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6110 - accuracy: 0.2561 - val_loss: 1.6048 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6071 - accuracy: 0.2846 - val_loss: 1.6044 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6057 - accuracy: 0.2642 - val_loss: 1.6040 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6179 - accuracy: 0.2764 - val_loss: 1.6039 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.5999 - accuracy: 0.2642 - val_loss: 1.6031 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6133 - accuracy: 0.2520 - val_loss: 1.6029 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2764 - val_loss: 1.6029 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.5868 - accuracy: 0.2846 - val_loss: 1.6023 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.5988 - accuracy: 0.2805 - val_loss: 1.6013 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6028 - accuracy: 0.2642 - val_loss: 1.6008 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.5976 - accuracy: 0.2520 - val_loss: 1.6003 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.5921 - accuracy: 0.3089 - val_loss: 1.5997 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6088 - accuracy: 0.2846 - val_loss: 1.5994 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6056 - accuracy: 0.2561 - val_loss: 1.5991 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.5946 - accuracy: 0.2846 - val_loss: 1.5988 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6079 - accuracy: 0.2805 - val_loss: 1.5993 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6017 - accuracy: 0.2724 - val_loss: 1.5994 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.5852 - accuracy: 0.3008 - val_loss: 1.5989 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 87ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6012 - accuracy: 0.2520 - val_loss: 1.5987 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 75ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.5991 - accuracy: 0.3008 - val_loss: 1.5986 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 74ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.5963 - accuracy: 0.2683 - val_loss: 1.5986 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 80ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.5966 - accuracy: 0.3049 - val_loss: 1.5985 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.5964 - accuracy: 0.2886 - val_loss: 1.5983 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.5949 - accuracy: 0.2846 - val_loss: 1.5982 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.5983 - accuracy: 0.3049 - val_loss: 1.5981 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.5929 - accuracy: 0.3130 - val_loss: 1.5981 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.5914 - accuracy: 0.2967 - val_loss: 1.5981 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.5881 - accuracy: 0.2602 - val_loss: 1.5979 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 74ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.5959 - accuracy: 0.2927 - val_loss: 1.5977 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.5998 - accuracy: 0.2724 - val_loss: 1.5976 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.5967 - accuracy: 0.2967 - val_loss: 1.5976 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6007 - accuracy: 0.2602 - val_loss: 1.5975 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.5867 - accuracy: 0.3049 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.5831 - accuracy: 0.2724 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 79ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.5943 - accuracy: 0.2805 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 75ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.5967 - accuracy: 0.3049 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6025 - accuracy: 0.2642 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6032 - accuracy: 0.2317 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 77ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.5920 - accuracy: 0.2805 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 74ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6003 - accuracy: 0.3008 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 81ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.5902 - accuracy: 0.2764 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.5911 - accuracy: 0.2846 - val_loss: 1.5974 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 78ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.5868 - accuracy: 0.2886 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 80ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.5956 - accuracy: 0.2642 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 1.2500e-05 - 81ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.5915 - accuracy: 0.2805 - val_loss: 1.5973 - val_accuracy: 0.2742 - lr: 6.2500e-06 - 82ms/epoch - 5ms/step\n",
      "Node 39 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6608 - accuracy: 0.2195 - val_loss: 1.6605 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 362ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.2398 - val_loss: 1.6586 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.2480 - val_loss: 1.6568 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.2398 - val_loss: 1.6550 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6554 - accuracy: 0.2398 - val_loss: 1.6534 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6539 - accuracy: 0.2439 - val_loss: 1.6516 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6501 - accuracy: 0.2642 - val_loss: 1.6498 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.3049 - val_loss: 1.6480 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2886 - val_loss: 1.6462 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6489 - accuracy: 0.2805 - val_loss: 1.6445 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2846 - val_loss: 1.6427 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.2764 - val_loss: 1.6408 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2967 - val_loss: 1.6391 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 56ms/epoch - 7ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.3008 - val_loss: 1.6376 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2805 - val_loss: 1.6359 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2764 - val_loss: 1.6339 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2805 - val_loss: 1.6322 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2764 - val_loss: 1.6306 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2764 - val_loss: 1.6291 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2846 - val_loss: 1.6277 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2764 - val_loss: 1.6263 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2805 - val_loss: 1.6247 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2805 - val_loss: 1.6234 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2805 - val_loss: 1.6220 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2886 - val_loss: 1.6206 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2886 - val_loss: 1.6195 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2764 - val_loss: 1.6186 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6144 - accuracy: 0.2764 - val_loss: 1.6178 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2846 - val_loss: 1.6166 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2805 - val_loss: 1.6156 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2724 - val_loss: 1.6149 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2886 - val_loss: 1.6143 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2886 - val_loss: 1.6137 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2683 - val_loss: 1.6131 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6149 - accuracy: 0.2683 - val_loss: 1.6125 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.2927 - val_loss: 1.6119 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6091 - accuracy: 0.2805 - val_loss: 1.6112 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6071 - accuracy: 0.2764 - val_loss: 1.6108 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6123 - accuracy: 0.2886 - val_loss: 1.6104 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6013 - accuracy: 0.2846 - val_loss: 1.6099 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2764 - val_loss: 1.6096 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6159 - accuracy: 0.2846 - val_loss: 1.6091 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2724 - val_loss: 1.6088 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2724 - val_loss: 1.6085 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2805 - val_loss: 1.6082 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2886 - val_loss: 1.6081 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6134 - accuracy: 0.2805 - val_loss: 1.6080 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6078 - accuracy: 0.2886 - val_loss: 1.6076 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2764 - val_loss: 1.6074 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6043 - accuracy: 0.2805 - val_loss: 1.6073 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6077 - accuracy: 0.2886 - val_loss: 1.6071 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 87ms/epoch - 11ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6074 - accuracy: 0.2805 - val_loss: 1.6071 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6133 - accuracy: 0.2764 - val_loss: 1.6069 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.5987 - accuracy: 0.2846 - val_loss: 1.6066 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6051 - accuracy: 0.2886 - val_loss: 1.6064 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2683 - val_loss: 1.6063 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6111 - accuracy: 0.2846 - val_loss: 1.6062 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6109 - accuracy: 0.2683 - val_loss: 1.6061 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6031 - accuracy: 0.2846 - val_loss: 1.6057 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 57ms/epoch - 7ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6028 - accuracy: 0.2724 - val_loss: 1.6055 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6105 - accuracy: 0.2886 - val_loss: 1.6053 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.5996 - accuracy: 0.2846 - val_loss: 1.6052 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6054 - accuracy: 0.2805 - val_loss: 1.6051 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6012 - accuracy: 0.2683 - val_loss: 1.6049 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 58ms/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6084 - accuracy: 0.2724 - val_loss: 1.6048 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 57ms/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.5995 - accuracy: 0.2886 - val_loss: 1.6047 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.5991 - accuracy: 0.2846 - val_loss: 1.6046 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.5981 - accuracy: 0.2846 - val_loss: 1.6043 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6027 - accuracy: 0.2764 - val_loss: 1.6042 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.5961 - accuracy: 0.3008 - val_loss: 1.6040 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.5969 - accuracy: 0.2724 - val_loss: 1.6039 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6033 - accuracy: 0.2846 - val_loss: 1.6038 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.5942 - accuracy: 0.2967 - val_loss: 1.6038 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.5980 - accuracy: 0.2805 - val_loss: 1.6038 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6008 - accuracy: 0.2683 - val_loss: 1.6035 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.5923 - accuracy: 0.2764 - val_loss: 1.6034 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6037 - accuracy: 0.2764 - val_loss: 1.6032 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6128 - accuracy: 0.2846 - val_loss: 1.6032 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 60ms/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6049 - accuracy: 0.2846 - val_loss: 1.6033 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.5971 - accuracy: 0.2764 - val_loss: 1.6033 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.5995 - accuracy: 0.3008 - val_loss: 1.6033 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 49ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6049 - accuracy: 0.2846 - val_loss: 1.6032 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 53ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.5944 - accuracy: 0.2805 - val_loss: 1.6032 - val_accuracy: 0.2742 - lr: 5.0000e-05 - 50ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.5953 - accuracy: 0.2805 - val_loss: 1.6032 - val_accuracy: 0.2742 - lr: 2.5000e-05 - 53ms/epoch - 7ms/step\n",
      "Node 39 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 39 - Best Validation Accuracy: 0.3226\n",
      "Best model saved for Node 39 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_39.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_40_dataset.csv\n",
      "Node 40 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6332 - accuracy: 0.2105 - val_loss: 1.6352 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 3s/epoch - 174ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6350 - accuracy: 0.2018 - val_loss: 1.6350 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.1930 - val_loss: 1.6345 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.2193 - val_loss: 1.6342 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.2237 - val_loss: 1.6337 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.2412 - val_loss: 1.6334 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2237 - val_loss: 1.6330 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.1754 - val_loss: 1.6324 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2105 - val_loss: 1.6320 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.1930 - val_loss: 1.6316 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2895 - val_loss: 1.6313 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.1886 - val_loss: 1.6310 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.1974 - val_loss: 1.6306 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2544 - val_loss: 1.6302 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2193 - val_loss: 1.6300 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2500 - val_loss: 1.6294 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2368 - val_loss: 1.6290 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2105 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2237 - val_loss: 1.6280 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2281 - val_loss: 1.6277 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2456 - val_loss: 1.6274 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6318 - accuracy: 0.1754 - val_loss: 1.6273 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2061 - val_loss: 1.6270 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6256 - accuracy: 0.2149 - val_loss: 1.6267 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.1974 - val_loss: 1.6264 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.1886 - val_loss: 1.6262 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2018 - val_loss: 1.6258 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.1930 - val_loss: 1.6255 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2149 - val_loss: 1.6252 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2105 - val_loss: 1.6250 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2368 - val_loss: 1.6247 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2895 - val_loss: 1.6244 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2456 - val_loss: 1.6239 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2325 - val_loss: 1.6235 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2193 - val_loss: 1.6233 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2018 - val_loss: 1.6231 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2368 - val_loss: 1.6228 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2412 - val_loss: 1.6224 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2149 - val_loss: 1.6222 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2281 - val_loss: 1.6217 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2061 - val_loss: 1.6215 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2325 - val_loss: 1.6213 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2939 - val_loss: 1.6211 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.1930 - val_loss: 1.6209 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2412 - val_loss: 1.6205 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2281 - val_loss: 1.6202 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2193 - val_loss: 1.6199 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2851 - val_loss: 1.6195 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2675 - val_loss: 1.6191 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2237 - val_loss: 1.6187 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2412 - val_loss: 1.6184 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2368 - val_loss: 1.6180 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2018 - val_loss: 1.6177 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6174 - accuracy: 0.2281 - val_loss: 1.6175 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2368 - val_loss: 1.6171 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6176 - accuracy: 0.2763 - val_loss: 1.6168 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2018 - val_loss: 1.6165 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.1886 - val_loss: 1.6164 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2456 - val_loss: 1.6160 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2719 - val_loss: 1.6157 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2412 - val_loss: 1.6155 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2105 - val_loss: 1.6153 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.2368 - val_loss: 1.6149 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2675 - val_loss: 1.6146 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2412 - val_loss: 1.6141 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2281 - val_loss: 1.6137 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2675 - val_loss: 1.6133 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2456 - val_loss: 1.6130 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2719 - val_loss: 1.6127 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2018 - val_loss: 1.6123 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6106 - accuracy: 0.2281 - val_loss: 1.6120 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2105 - val_loss: 1.6116 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6131 - accuracy: 0.2632 - val_loss: 1.6112 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6123 - accuracy: 0.2632 - val_loss: 1.6109 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.2500 - val_loss: 1.6104 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6102 - accuracy: 0.2763 - val_loss: 1.6101 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2412 - val_loss: 1.6098 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2544 - val_loss: 1.6096 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6087 - accuracy: 0.2412 - val_loss: 1.6094 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6054 - accuracy: 0.2632 - val_loss: 1.6088 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2500 - val_loss: 1.6084 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2325 - val_loss: 1.6080 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6078 - accuracy: 0.2412 - val_loss: 1.6079 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2368 - val_loss: 1.6075 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2105 - val_loss: 1.6073 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2368 - val_loss: 1.6072 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6032 - accuracy: 0.2500 - val_loss: 1.6068 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6036 - accuracy: 0.2939 - val_loss: 1.6066 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6066 - accuracy: 0.2281 - val_loss: 1.6062 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2368 - val_loss: 1.6059 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2763 - val_loss: 1.6056 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2588 - val_loss: 1.6051 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6030 - accuracy: 0.2895 - val_loss: 1.6046 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6036 - accuracy: 0.3070 - val_loss: 1.6041 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6056 - accuracy: 0.2632 - val_loss: 1.6035 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.5975 - accuracy: 0.2412 - val_loss: 1.6033 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6037 - accuracy: 0.2281 - val_loss: 1.6028 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6093 - accuracy: 0.2412 - val_loss: 1.6025 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6024 - accuracy: 0.3026 - val_loss: 1.6022 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 53ms/epoch - 4ms/step\n",
      "Node 40 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6341 - accuracy: 0.1974 - val_loss: 1.6329 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 3s/epoch - 402ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2061 - val_loss: 1.6326 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2368 - val_loss: 1.6322 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2193 - val_loss: 1.6319 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1798 - val_loss: 1.6318 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2412 - val_loss: 1.6317 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2281 - val_loss: 1.6315 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2456 - val_loss: 1.6312 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.1974 - val_loss: 1.6310 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.1842 - val_loss: 1.6307 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2368 - val_loss: 1.6305 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2149 - val_loss: 1.6302 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2237 - val_loss: 1.6300 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.1974 - val_loss: 1.6298 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2193 - val_loss: 1.6296 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2281 - val_loss: 1.6294 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2061 - val_loss: 1.6292 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2105 - val_loss: 1.6290 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2325 - val_loss: 1.6288 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2061 - val_loss: 1.6287 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2193 - val_loss: 1.6285 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2149 - val_loss: 1.6283 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2544 - val_loss: 1.6281 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2456 - val_loss: 1.6280 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2105 - val_loss: 1.6278 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2018 - val_loss: 1.6276 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2149 - val_loss: 1.6274 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.1930 - val_loss: 1.6272 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2149 - val_loss: 1.6270 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2368 - val_loss: 1.6268 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2193 - val_loss: 1.6266 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2061 - val_loss: 1.6264 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2149 - val_loss: 1.6262 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2193 - val_loss: 1.6260 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2237 - val_loss: 1.6257 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2061 - val_loss: 1.6255 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2368 - val_loss: 1.6253 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2105 - val_loss: 1.6251 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2281 - val_loss: 1.6249 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2018 - val_loss: 1.6247 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2105 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2149 - val_loss: 1.6243 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2500 - val_loss: 1.6241 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2412 - val_loss: 1.6239 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2237 - val_loss: 1.6237 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2237 - val_loss: 1.6235 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.1798 - val_loss: 1.6233 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2193 - val_loss: 1.6231 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2018 - val_loss: 1.6230 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2149 - val_loss: 1.6228 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2061 - val_loss: 1.6227 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2325 - val_loss: 1.6226 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2281 - val_loss: 1.6225 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2237 - val_loss: 1.6224 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2193 - val_loss: 1.6224 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2018 - val_loss: 1.6222 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2281 - val_loss: 1.6220 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2412 - val_loss: 1.6219 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2105 - val_loss: 1.6218 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2325 - val_loss: 1.6217 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2281 - val_loss: 1.6215 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2237 - val_loss: 1.6213 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2193 - val_loss: 1.6211 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2105 - val_loss: 1.6209 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2149 - val_loss: 1.6207 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2412 - val_loss: 1.6205 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2500 - val_loss: 1.6203 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2544 - val_loss: 1.6201 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2105 - val_loss: 1.6200 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2281 - val_loss: 1.6198 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2368 - val_loss: 1.6196 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.1886 - val_loss: 1.6194 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2281 - val_loss: 1.6194 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2325 - val_loss: 1.6193 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2368 - val_loss: 1.6191 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2193 - val_loss: 1.6190 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2149 - val_loss: 1.6188 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2237 - val_loss: 1.6186 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2544 - val_loss: 1.6183 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2237 - val_loss: 1.6181 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2193 - val_loss: 1.6179 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2412 - val_loss: 1.6178 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2061 - val_loss: 1.6176 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2281 - val_loss: 1.6175 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2325 - val_loss: 1.6173 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.1974 - val_loss: 1.6171 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2456 - val_loss: 1.6169 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2325 - val_loss: 1.6167 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2149 - val_loss: 1.6165 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2149 - val_loss: 1.6164 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2807 - val_loss: 1.6163 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6160 - accuracy: 0.2325 - val_loss: 1.6162 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6173 - accuracy: 0.2368 - val_loss: 1.6161 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2456 - val_loss: 1.6159 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2456 - val_loss: 1.6157 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2544 - val_loss: 1.6155 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2105 - val_loss: 1.6154 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6143 - accuracy: 0.2193 - val_loss: 1.6153 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2193 - val_loss: 1.6152 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2412 - val_loss: 1.6151 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Node 40 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6606 - accuracy: 0.2412 - val_loss: 1.6602 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 3s/epoch - 182ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6599 - accuracy: 0.2018 - val_loss: 1.6593 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6581 - accuracy: 0.1930 - val_loss: 1.6583 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6590 - accuracy: 0.1930 - val_loss: 1.6574 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6577 - accuracy: 0.2061 - val_loss: 1.6565 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6558 - accuracy: 0.1930 - val_loss: 1.6558 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6560 - accuracy: 0.1886 - val_loss: 1.6550 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6546 - accuracy: 0.1798 - val_loss: 1.6539 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.2149 - val_loss: 1.6528 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6534 - accuracy: 0.2325 - val_loss: 1.6520 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6508 - accuracy: 0.2588 - val_loss: 1.6512 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6498 - accuracy: 0.2237 - val_loss: 1.6504 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6513 - accuracy: 0.2061 - val_loss: 1.6499 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6521 - accuracy: 0.2193 - val_loss: 1.6493 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6507 - accuracy: 0.2149 - val_loss: 1.6486 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6489 - accuracy: 0.2325 - val_loss: 1.6479 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6502 - accuracy: 0.2325 - val_loss: 1.6473 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6466 - accuracy: 0.2632 - val_loss: 1.6465 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6474 - accuracy: 0.2456 - val_loss: 1.6457 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6464 - accuracy: 0.2544 - val_loss: 1.6450 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6443 - accuracy: 0.2412 - val_loss: 1.6443 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6450 - accuracy: 0.2325 - val_loss: 1.6437 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6434 - accuracy: 0.2412 - val_loss: 1.6432 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6452 - accuracy: 0.2325 - val_loss: 1.6426 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6428 - accuracy: 0.2456 - val_loss: 1.6420 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6427 - accuracy: 0.2412 - val_loss: 1.6414 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6419 - accuracy: 0.2368 - val_loss: 1.6408 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6388 - accuracy: 0.2456 - val_loss: 1.6403 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6408 - accuracy: 0.2018 - val_loss: 1.6397 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2588 - val_loss: 1.6390 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6355 - accuracy: 0.2763 - val_loss: 1.6383 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6404 - accuracy: 0.2412 - val_loss: 1.6377 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6369 - accuracy: 0.2325 - val_loss: 1.6372 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6377 - accuracy: 0.2237 - val_loss: 1.6367 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6388 - accuracy: 0.2325 - val_loss: 1.6362 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2325 - val_loss: 1.6357 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6352 - accuracy: 0.2325 - val_loss: 1.6352 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6359 - accuracy: 0.2149 - val_loss: 1.6347 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2500 - val_loss: 1.6342 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.2544 - val_loss: 1.6336 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2061 - val_loss: 1.6330 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2325 - val_loss: 1.6325 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2588 - val_loss: 1.6320 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2588 - val_loss: 1.6315 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2412 - val_loss: 1.6310 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6339 - accuracy: 0.1974 - val_loss: 1.6304 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6304 - accuracy: 0.2368 - val_loss: 1.6297 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2193 - val_loss: 1.6293 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2412 - val_loss: 1.6285 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6288 - accuracy: 0.2588 - val_loss: 1.6278 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 92ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2807 - val_loss: 1.6272 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2412 - val_loss: 1.6266 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2632 - val_loss: 1.6262 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2588 - val_loss: 1.6256 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2588 - val_loss: 1.6251 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2325 - val_loss: 1.6245 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2500 - val_loss: 1.6239 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2456 - val_loss: 1.6234 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2675 - val_loss: 1.6228 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2412 - val_loss: 1.6224 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6233 - accuracy: 0.2807 - val_loss: 1.6216 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2632 - val_loss: 1.6209 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2368 - val_loss: 1.6203 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2544 - val_loss: 1.6197 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2675 - val_loss: 1.6191 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2807 - val_loss: 1.6186 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2675 - val_loss: 1.6179 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2500 - val_loss: 1.6173 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2412 - val_loss: 1.6167 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2763 - val_loss: 1.6166 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6229 - accuracy: 0.2456 - val_loss: 1.6161 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6134 - accuracy: 0.2281 - val_loss: 1.6157 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.2544 - val_loss: 1.6147 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2719 - val_loss: 1.6140 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6126 - accuracy: 0.2675 - val_loss: 1.6130 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2719 - val_loss: 1.6126 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6099 - accuracy: 0.2982 - val_loss: 1.6120 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2851 - val_loss: 1.6112 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2544 - val_loss: 1.6107 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2544 - val_loss: 1.6098 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6114 - accuracy: 0.2412 - val_loss: 1.6090 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6092 - accuracy: 0.2719 - val_loss: 1.6084 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.2763 - val_loss: 1.6076 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6037 - accuracy: 0.2675 - val_loss: 1.6069 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6112 - accuracy: 0.2281 - val_loss: 1.6063 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6135 - accuracy: 0.2632 - val_loss: 1.6058 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6083 - accuracy: 0.2632 - val_loss: 1.6053 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6023 - accuracy: 0.2675 - val_loss: 1.6045 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6012 - accuracy: 0.2851 - val_loss: 1.6036 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6029 - accuracy: 0.3070 - val_loss: 1.6031 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6076 - accuracy: 0.2807 - val_loss: 1.6025 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6049 - accuracy: 0.2851 - val_loss: 1.6017 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6016 - accuracy: 0.2719 - val_loss: 1.6010 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2982 - val_loss: 1.6002 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.5984 - accuracy: 0.3026 - val_loss: 1.5988 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.5917 - accuracy: 0.3377 - val_loss: 1.5975 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6063 - accuracy: 0.2632 - val_loss: 1.5967 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 94ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2500 - val_loss: 1.5957 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6086 - accuracy: 0.2544 - val_loss: 1.5955 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 71ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5972 - accuracy: 0.2456 - val_loss: 1.5950 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Node 40 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6600 - accuracy: 0.1842 - val_loss: 1.6590 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 3s/epoch - 408ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6580 - accuracy: 0.2193 - val_loss: 1.6583 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6596 - accuracy: 0.2018 - val_loss: 1.6576 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6590 - accuracy: 0.2588 - val_loss: 1.6571 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2105 - val_loss: 1.6566 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6573 - accuracy: 0.2149 - val_loss: 1.6562 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.2237 - val_loss: 1.6556 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6565 - accuracy: 0.2193 - val_loss: 1.6552 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2281 - val_loss: 1.6546 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2237 - val_loss: 1.6541 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2237 - val_loss: 1.6536 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2237 - val_loss: 1.6531 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2412 - val_loss: 1.6527 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6537 - accuracy: 0.2412 - val_loss: 1.6523 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6520 - accuracy: 0.2193 - val_loss: 1.6518 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2325 - val_loss: 1.6513 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6530 - accuracy: 0.2412 - val_loss: 1.6508 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6529 - accuracy: 0.1798 - val_loss: 1.6505 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6493 - accuracy: 0.2544 - val_loss: 1.6500 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6523 - accuracy: 0.2061 - val_loss: 1.6497 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.1930 - val_loss: 1.6493 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2588 - val_loss: 1.6490 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6484 - accuracy: 0.2500 - val_loss: 1.6487 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2456 - val_loss: 1.6483 - val_accuracy: 0.3276 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2149 - val_loss: 1.6479 - val_accuracy: 0.3276 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6478 - accuracy: 0.2544 - val_loss: 1.6475 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2544 - val_loss: 1.6470 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2105 - val_loss: 1.6465 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6464 - accuracy: 0.2149 - val_loss: 1.6461 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6474 - accuracy: 0.2588 - val_loss: 1.6457 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 54ms/epoch - 7ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2281 - val_loss: 1.6453 - val_accuracy: 0.3276 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6467 - accuracy: 0.2105 - val_loss: 1.6451 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2544 - val_loss: 1.6447 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6454 - accuracy: 0.2368 - val_loss: 1.6442 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2544 - val_loss: 1.6439 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6443 - accuracy: 0.2544 - val_loss: 1.6435 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2719 - val_loss: 1.6432 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2368 - val_loss: 1.6429 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2632 - val_loss: 1.6425 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2719 - val_loss: 1.6419 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2456 - val_loss: 1.6414 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2412 - val_loss: 1.6409 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.2281 - val_loss: 1.6405 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2456 - val_loss: 1.6400 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2632 - val_loss: 1.6396 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2149 - val_loss: 1.6392 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2237 - val_loss: 1.6389 - val_accuracy: 0.3276 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2456 - val_loss: 1.6386 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2807 - val_loss: 1.6383 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6391 - accuracy: 0.2719 - val_loss: 1.6379 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 76ms/epoch - 10ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2237 - val_loss: 1.6376 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6375 - accuracy: 0.2018 - val_loss: 1.6374 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6398 - accuracy: 0.2368 - val_loss: 1.6371 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6384 - accuracy: 0.2368 - val_loss: 1.6368 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2588 - val_loss: 1.6365 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2456 - val_loss: 1.6362 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2281 - val_loss: 1.6359 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6377 - accuracy: 0.2281 - val_loss: 1.6356 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.1886 - val_loss: 1.6353 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2325 - val_loss: 1.6350 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2237 - val_loss: 1.6347 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2632 - val_loss: 1.6343 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2807 - val_loss: 1.6339 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2500 - val_loss: 1.6336 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6356 - accuracy: 0.2149 - val_loss: 1.6333 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2675 - val_loss: 1.6330 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2500 - val_loss: 1.6327 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2588 - val_loss: 1.6323 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2719 - val_loss: 1.6319 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2719 - val_loss: 1.6316 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2851 - val_loss: 1.6312 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2500 - val_loss: 1.6308 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2368 - val_loss: 1.6305 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2018 - val_loss: 1.6302 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2237 - val_loss: 1.6298 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2412 - val_loss: 1.6296 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2544 - val_loss: 1.6292 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2325 - val_loss: 1.6289 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2149 - val_loss: 1.6287 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2456 - val_loss: 1.6284 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2632 - val_loss: 1.6281 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2237 - val_loss: 1.6277 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2675 - val_loss: 1.6274 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2500 - val_loss: 1.6272 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2675 - val_loss: 1.6270 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2412 - val_loss: 1.6264 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2719 - val_loss: 1.6260 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2149 - val_loss: 1.6256 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2325 - val_loss: 1.6253 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2325 - val_loss: 1.6249 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2456 - val_loss: 1.6246 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2588 - val_loss: 1.6243 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.3026 - val_loss: 1.6239 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2456 - val_loss: 1.6235 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2325 - val_loss: 1.6231 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2412 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 70ms/epoch - 9ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2632 - val_loss: 1.6225 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2412 - val_loss: 1.6223 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2500 - val_loss: 1.6220 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Node 40 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 40 - Best Validation Accuracy: 0.3276\n",
      "Best model saved for Node 40 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_40.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_41_dataset.csv\n",
      "Node 41 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6344 - accuracy: 0.2055 - val_loss: 1.6356 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 3s/epoch - 192ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6351 - accuracy: 0.2134 - val_loss: 1.6352 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2451 - val_loss: 1.6348 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2688 - val_loss: 1.6345 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6338 - accuracy: 0.2213 - val_loss: 1.6342 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2451 - val_loss: 1.6338 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2490 - val_loss: 1.6335 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2016 - val_loss: 1.6332 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2451 - val_loss: 1.6330 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.2372 - val_loss: 1.6327 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2372 - val_loss: 1.6325 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6315 - accuracy: 0.2292 - val_loss: 1.6322 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2292 - val_loss: 1.6319 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6305 - accuracy: 0.2253 - val_loss: 1.6317 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.2372 - val_loss: 1.6314 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.1976 - val_loss: 1.6312 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6300 - accuracy: 0.2451 - val_loss: 1.6311 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2095 - val_loss: 1.6308 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2055 - val_loss: 1.6306 - val_accuracy: 0.1406 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6299 - accuracy: 0.2292 - val_loss: 1.6304 - val_accuracy: 0.1250 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2490 - val_loss: 1.6302 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2095 - val_loss: 1.6300 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6269 - accuracy: 0.2095 - val_loss: 1.6297 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2530 - val_loss: 1.6295 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2213 - val_loss: 1.6293 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6266 - accuracy: 0.2332 - val_loss: 1.6291 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2451 - val_loss: 1.6290 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2016 - val_loss: 1.6288 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2569 - val_loss: 1.6286 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2490 - val_loss: 1.6283 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6259 - accuracy: 0.2648 - val_loss: 1.6281 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2095 - val_loss: 1.6279 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2134 - val_loss: 1.6277 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2688 - val_loss: 1.6275 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6247 - accuracy: 0.2332 - val_loss: 1.6274 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2569 - val_loss: 1.6272 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2411 - val_loss: 1.6271 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2648 - val_loss: 1.6269 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 54ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2530 - val_loss: 1.6268 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6228 - accuracy: 0.2688 - val_loss: 1.6267 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2530 - val_loss: 1.6267 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2411 - val_loss: 1.6267 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2451 - val_loss: 1.6266 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2055 - val_loss: 1.6265 - val_accuracy: 0.2188 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2016 - val_loss: 1.6264 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6235 - accuracy: 0.2451 - val_loss: 1.6264 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2806 - val_loss: 1.6263 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2213 - val_loss: 1.6262 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2372 - val_loss: 1.6262 - val_accuracy: 0.1875 - lr: 5.0000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2490 - val_loss: 1.6262 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2727 - val_loss: 1.6262 - val_accuracy: 0.1875 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2372 - val_loss: 1.6262 - val_accuracy: 0.1875 - lr: 2.5000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2411 - val_loss: 1.6261 - val_accuracy: 0.2031 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2332 - val_loss: 1.6261 - val_accuracy: 0.1875 - lr: 2.5000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2451 - val_loss: 1.6260 - val_accuracy: 0.1875 - lr: 2.5000e-05 - 51ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2490 - val_loss: 1.6260 - val_accuracy: 0.1875 - lr: 2.5000e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2648 - val_loss: 1.6260 - val_accuracy: 0.1719 - lr: 2.5000e-05 - 53ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2292 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 2.5000e-05 - 53ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 2.5000e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2846 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2500e-05 - 53ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2688 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2500e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2372 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2500e-05 - 54ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2609 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.2500e-06 - 52ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2648 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.2500e-06 - 55ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2727 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.2500e-06 - 53ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.2500e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2530 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.2500e-06 - 53ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2530 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.1250e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2253 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.1250e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2332 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.1250e-06 - 54ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2569 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.5625e-06 - 52ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2530 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.5625e-06 - 51ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2490 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.5625e-06 - 54ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2490 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 7.8125e-07 - 55ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2727 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 7.8125e-07 - 53ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.1976 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 7.8125e-07 - 54ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2609 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.9062e-07 - 56ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2490 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.9062e-07 - 56ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "16/16 - 0s - loss: 1.6233 - accuracy: 0.2490 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.9062e-07 - 53ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2609 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.9531e-07 - 53ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2569 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.9531e-07 - 51ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2569 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.9531e-07 - 52ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6189 - accuracy: 0.2727 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 9.7656e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2332 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "16/16 - 0s - loss: 1.6201 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 9.7656e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 4.8828e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2569 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 4.8828e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2451 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 4.8828e-08 - 52ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 2.4414e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2688 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 2.4414e-08 - 50ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2332 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 2.4414e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2490 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2207e-08 - 76ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2609 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2207e-08 - 55ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "16/16 - 0s - loss: 1.6203 - accuracy: 0.2411 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 1.2207e-08 - 51ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6246 - accuracy: 0.2213 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.1035e-09 - 50ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2451 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.1035e-09 - 51ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2648 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 6.1035e-09 - 51ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2727 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.0518e-09 - 52ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2451 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.0518e-09 - 50ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2372 - val_loss: 1.6259 - val_accuracy: 0.1719 - lr: 3.0518e-09 - 53ms/epoch - 3ms/step\n",
      "Node 41 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6360 - accuracy: 0.1660 - val_loss: 1.6352 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 3s/epoch - 344ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.1976 - val_loss: 1.6350 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.2332 - val_loss: 1.6347 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2134 - val_loss: 1.6344 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.1660 - val_loss: 1.6342 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.1739 - val_loss: 1.6340 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2174 - val_loss: 1.6338 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2213 - val_loss: 1.6336 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2095 - val_loss: 1.6335 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2016 - val_loss: 1.6333 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2134 - val_loss: 1.6331 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2213 - val_loss: 1.6329 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2134 - val_loss: 1.6327 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2016 - val_loss: 1.6325 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2213 - val_loss: 1.6323 - val_accuracy: 0.1562 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2016 - val_loss: 1.6321 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2411 - val_loss: 1.6319 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2569 - val_loss: 1.6317 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2174 - val_loss: 1.6315 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2016 - val_loss: 1.6313 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2648 - val_loss: 1.6310 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2569 - val_loss: 1.6308 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2253 - val_loss: 1.6306 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2332 - val_loss: 1.6304 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2451 - val_loss: 1.6302 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2411 - val_loss: 1.6300 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2055 - val_loss: 1.6298 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2213 - val_loss: 1.6296 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2174 - val_loss: 1.6294 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2490 - val_loss: 1.6293 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2372 - val_loss: 1.6291 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2253 - val_loss: 1.6290 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2411 - val_loss: 1.6288 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2253 - val_loss: 1.6286 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2411 - val_loss: 1.6284 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.1897 - val_loss: 1.6283 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2332 - val_loss: 1.6281 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2648 - val_loss: 1.6280 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2292 - val_loss: 1.6278 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2332 - val_loss: 1.6277 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2372 - val_loss: 1.6276 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2372 - val_loss: 1.6274 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2372 - val_loss: 1.6273 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2292 - val_loss: 1.6271 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2530 - val_loss: 1.6270 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2292 - val_loss: 1.6268 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2292 - val_loss: 1.6266 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2372 - val_loss: 1.6264 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2490 - val_loss: 1.6263 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2055 - val_loss: 1.6261 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2174 - val_loss: 1.6260 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 55ms/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2372 - val_loss: 1.6258 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2213 - val_loss: 1.6257 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2332 - val_loss: 1.6256 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2411 - val_loss: 1.6255 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2372 - val_loss: 1.6254 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2213 - val_loss: 1.6252 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2372 - val_loss: 1.6251 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2292 - val_loss: 1.6251 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2174 - val_loss: 1.6250 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2372 - val_loss: 1.6248 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2609 - val_loss: 1.6247 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2569 - val_loss: 1.6245 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2292 - val_loss: 1.6243 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2134 - val_loss: 1.6242 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2253 - val_loss: 1.6241 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2292 - val_loss: 1.6239 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2411 - val_loss: 1.6238 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2095 - val_loss: 1.6237 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2332 - val_loss: 1.6236 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2134 - val_loss: 1.6236 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2292 - val_loss: 1.6235 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2372 - val_loss: 1.6234 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2372 - val_loss: 1.6233 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2055 - val_loss: 1.6232 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2253 - val_loss: 1.6230 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2332 - val_loss: 1.6229 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2292 - val_loss: 1.6228 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2451 - val_loss: 1.6227 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2372 - val_loss: 1.6226 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2372 - val_loss: 1.6225 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2174 - val_loss: 1.6224 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2411 - val_loss: 1.6223 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2490 - val_loss: 1.6222 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2490 - val_loss: 1.6221 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 36ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2095 - val_loss: 1.6220 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2451 - val_loss: 1.6220 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6195 - accuracy: 0.2292 - val_loss: 1.6219 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2095 - val_loss: 1.6219 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2213 - val_loss: 1.6218 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2253 - val_loss: 1.6218 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2372 - val_loss: 1.6217 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2490 - val_loss: 1.6216 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2372 - val_loss: 1.6215 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2253 - val_loss: 1.6214 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6155 - accuracy: 0.2411 - val_loss: 1.6213 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2332 - val_loss: 1.6212 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2095 - val_loss: 1.6211 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2411 - val_loss: 1.6210 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2213 - val_loss: 1.6209 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 41 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6621 - accuracy: 0.1976 - val_loss: 1.6608 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 3s/epoch - 192ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6605 - accuracy: 0.2213 - val_loss: 1.6600 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6599 - accuracy: 0.1976 - val_loss: 1.6592 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6574 - accuracy: 0.2372 - val_loss: 1.6583 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6577 - accuracy: 0.2174 - val_loss: 1.6573 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6571 - accuracy: 0.2134 - val_loss: 1.6564 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6556 - accuracy: 0.2372 - val_loss: 1.6556 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6539 - accuracy: 0.2213 - val_loss: 1.6547 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6529 - accuracy: 0.2253 - val_loss: 1.6540 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6537 - accuracy: 0.2253 - val_loss: 1.6535 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6528 - accuracy: 0.2174 - val_loss: 1.6528 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6523 - accuracy: 0.2213 - val_loss: 1.6522 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6498 - accuracy: 0.2372 - val_loss: 1.6516 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6498 - accuracy: 0.2292 - val_loss: 1.6509 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6506 - accuracy: 0.2292 - val_loss: 1.6503 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6477 - accuracy: 0.2569 - val_loss: 1.6497 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6493 - accuracy: 0.2174 - val_loss: 1.6491 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6475 - accuracy: 0.2332 - val_loss: 1.6486 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6453 - accuracy: 0.2292 - val_loss: 1.6479 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6415 - accuracy: 0.2451 - val_loss: 1.6473 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6451 - accuracy: 0.2530 - val_loss: 1.6467 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6463 - accuracy: 0.2372 - val_loss: 1.6461 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6456 - accuracy: 0.2292 - val_loss: 1.6455 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6441 - accuracy: 0.2372 - val_loss: 1.6450 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6424 - accuracy: 0.2411 - val_loss: 1.6446 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6402 - accuracy: 0.2411 - val_loss: 1.6442 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6422 - accuracy: 0.2530 - val_loss: 1.6437 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6430 - accuracy: 0.2174 - val_loss: 1.6432 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6402 - accuracy: 0.2372 - val_loss: 1.6427 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6362 - accuracy: 0.2411 - val_loss: 1.6422 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6362 - accuracy: 0.2174 - val_loss: 1.6417 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6377 - accuracy: 0.2174 - val_loss: 1.6412 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6379 - accuracy: 0.2213 - val_loss: 1.6407 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6364 - accuracy: 0.2292 - val_loss: 1.6402 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6388 - accuracy: 0.2372 - val_loss: 1.6397 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6326 - accuracy: 0.2569 - val_loss: 1.6394 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6340 - accuracy: 0.2609 - val_loss: 1.6391 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 82ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2530 - val_loss: 1.6387 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6345 - accuracy: 0.2292 - val_loss: 1.6384 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6309 - accuracy: 0.2530 - val_loss: 1.6381 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2530 - val_loss: 1.6379 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2490 - val_loss: 1.6377 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 81ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2530 - val_loss: 1.6373 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 79ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2332 - val_loss: 1.6370 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6287 - accuracy: 0.2451 - val_loss: 1.6366 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2213 - val_loss: 1.6362 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6304 - accuracy: 0.2688 - val_loss: 1.6359 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.2213 - val_loss: 1.6356 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 80ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6294 - accuracy: 0.2372 - val_loss: 1.6353 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6289 - accuracy: 0.2648 - val_loss: 1.6351 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2451 - val_loss: 1.6349 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 93ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2569 - val_loss: 1.6346 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2569 - val_loss: 1.6342 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6279 - accuracy: 0.2253 - val_loss: 1.6339 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2530 - val_loss: 1.6337 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6212 - accuracy: 0.2688 - val_loss: 1.6336 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6243 - accuracy: 0.2727 - val_loss: 1.6335 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6257 - accuracy: 0.2530 - val_loss: 1.6332 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6220 - accuracy: 0.2292 - val_loss: 1.6329 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2569 - val_loss: 1.6328 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2530 - val_loss: 1.6327 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2292 - val_loss: 1.6325 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2569 - val_loss: 1.6323 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2648 - val_loss: 1.6321 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6212 - accuracy: 0.2688 - val_loss: 1.6320 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6186 - accuracy: 0.2490 - val_loss: 1.6319 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2530 - val_loss: 1.6318 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2411 - val_loss: 1.6316 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6202 - accuracy: 0.2648 - val_loss: 1.6315 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2648 - val_loss: 1.6313 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6181 - accuracy: 0.2411 - val_loss: 1.6312 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2530 - val_loss: 1.6312 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2648 - val_loss: 1.6311 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2530 - val_loss: 1.6310 - val_accuracy: 0.1875 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2609 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2767 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6120 - accuracy: 0.2648 - val_loss: 1.6307 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2372 - val_loss: 1.6307 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2846 - val_loss: 1.6308 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6111 - accuracy: 0.2727 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6140 - accuracy: 0.2530 - val_loss: 1.6308 - val_accuracy: 0.1719 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2569 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6160 - accuracy: 0.2451 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6089 - accuracy: 0.2648 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2411 - val_loss: 1.6309 - val_accuracy: 0.1719 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Node 41 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6595 - accuracy: 0.2569 - val_loss: 1.6603 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 3s/epoch - 347ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6596 - accuracy: 0.1818 - val_loss: 1.6597 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6586 - accuracy: 0.2213 - val_loss: 1.6592 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6585 - accuracy: 0.2016 - val_loss: 1.6586 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.2372 - val_loss: 1.6580 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2292 - val_loss: 1.6574 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2490 - val_loss: 1.6568 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6567 - accuracy: 0.2095 - val_loss: 1.6563 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2569 - val_loss: 1.6558 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2174 - val_loss: 1.6554 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2490 - val_loss: 1.6549 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2055 - val_loss: 1.6545 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2174 - val_loss: 1.6541 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2253 - val_loss: 1.6536 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6527 - accuracy: 0.2174 - val_loss: 1.6531 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2292 - val_loss: 1.6526 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6513 - accuracy: 0.2648 - val_loss: 1.6523 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2134 - val_loss: 1.6519 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6521 - accuracy: 0.2253 - val_loss: 1.6516 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6488 - accuracy: 0.2411 - val_loss: 1.6512 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6476 - accuracy: 0.2490 - val_loss: 1.6508 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2490 - val_loss: 1.6504 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6469 - accuracy: 0.2569 - val_loss: 1.6500 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6489 - accuracy: 0.2213 - val_loss: 1.6496 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2806 - val_loss: 1.6492 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6449 - accuracy: 0.2253 - val_loss: 1.6488 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6448 - accuracy: 0.2095 - val_loss: 1.6484 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6439 - accuracy: 0.2134 - val_loss: 1.6481 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2253 - val_loss: 1.6477 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2530 - val_loss: 1.6474 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6467 - accuracy: 0.2411 - val_loss: 1.6471 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6465 - accuracy: 0.2372 - val_loss: 1.6467 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2332 - val_loss: 1.6464 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2372 - val_loss: 1.6461 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2411 - val_loss: 1.6457 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2372 - val_loss: 1.6454 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2490 - val_loss: 1.6450 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2767 - val_loss: 1.6448 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2648 - val_loss: 1.6445 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2292 - val_loss: 1.6443 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2569 - val_loss: 1.6440 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6423 - accuracy: 0.2451 - val_loss: 1.6438 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6393 - accuracy: 0.2569 - val_loss: 1.6436 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2332 - val_loss: 1.6433 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6436 - accuracy: 0.2055 - val_loss: 1.6430 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.2530 - val_loss: 1.6427 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2372 - val_loss: 1.6425 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6407 - accuracy: 0.2411 - val_loss: 1.6422 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2688 - val_loss: 1.6419 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2569 - val_loss: 1.6416 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2648 - val_loss: 1.6413 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2846 - val_loss: 1.6411 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2332 - val_loss: 1.6409 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2451 - val_loss: 1.6406 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2569 - val_loss: 1.6404 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2253 - val_loss: 1.6402 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6341 - accuracy: 0.2451 - val_loss: 1.6400 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2372 - val_loss: 1.6398 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2332 - val_loss: 1.6396 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2727 - val_loss: 1.6394 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2609 - val_loss: 1.6392 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6320 - accuracy: 0.2451 - val_loss: 1.6389 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.2372 - val_loss: 1.6387 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2530 - val_loss: 1.6384 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2451 - val_loss: 1.6382 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2727 - val_loss: 1.6380 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2530 - val_loss: 1.6378 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2530 - val_loss: 1.6375 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2806 - val_loss: 1.6373 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2569 - val_loss: 1.6372 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2648 - val_loss: 1.6370 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2411 - val_loss: 1.6369 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2332 - val_loss: 1.6367 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.2688 - val_loss: 1.6366 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2490 - val_loss: 1.6365 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2490 - val_loss: 1.6363 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2767 - val_loss: 1.6361 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2530 - val_loss: 1.6359 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2451 - val_loss: 1.6358 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2332 - val_loss: 1.6356 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2411 - val_loss: 1.6355 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2530 - val_loss: 1.6354 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2253 - val_loss: 1.6352 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2569 - val_loss: 1.6351 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2530 - val_loss: 1.6349 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2609 - val_loss: 1.6348 - val_accuracy: 0.2344 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2688 - val_loss: 1.6347 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2806 - val_loss: 1.6346 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2530 - val_loss: 1.6344 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2727 - val_loss: 1.6343 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2292 - val_loss: 1.6341 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2451 - val_loss: 1.6340 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2806 - val_loss: 1.6340 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2767 - val_loss: 1.6339 - val_accuracy: 0.2188 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2648 - val_loss: 1.6339 - val_accuracy: 0.2031 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2846 - val_loss: 1.6339 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2411 - val_loss: 1.6339 - val_accuracy: 0.2031 - lr: 5.0000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2490 - val_loss: 1.6339 - val_accuracy: 0.1875 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2727 - val_loss: 1.6338 - val_accuracy: 0.1875 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2411 - val_loss: 1.6337 - val_accuracy: 0.1875 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Node 41 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 41 - Best Validation Accuracy: 0.2500\n",
      "Best model saved for Node 41 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_41.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_42_dataset.csv\n",
      "Node 42 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6351 - accuracy: 0.1345 - val_loss: 1.6339 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 2s/epoch - 165ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.1807 - val_loss: 1.6336 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.1681 - val_loss: 1.6333 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.1975 - val_loss: 1.6330 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6324 - accuracy: 0.2101 - val_loss: 1.6327 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2437 - val_loss: 1.6324 - val_accuracy: 0.3000 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6327 - accuracy: 0.1975 - val_loss: 1.6321 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2059 - val_loss: 1.6318 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6312 - accuracy: 0.2395 - val_loss: 1.6315 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.1681 - val_loss: 1.6312 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2017 - val_loss: 1.6309 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2605 - val_loss: 1.6307 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2269 - val_loss: 1.6303 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6285 - accuracy: 0.2773 - val_loss: 1.6299 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.1807 - val_loss: 1.6297 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2689 - val_loss: 1.6295 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2605 - val_loss: 1.6292 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2647 - val_loss: 1.6289 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2647 - val_loss: 1.6286 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6276 - accuracy: 0.2731 - val_loss: 1.6283 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2521 - val_loss: 1.6280 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2227 - val_loss: 1.6277 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2227 - val_loss: 1.6275 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2101 - val_loss: 1.6272 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2815 - val_loss: 1.6270 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6278 - accuracy: 0.1975 - val_loss: 1.6267 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2227 - val_loss: 1.6264 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2185 - val_loss: 1.6261 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2185 - val_loss: 1.6259 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2185 - val_loss: 1.6256 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2227 - val_loss: 1.6253 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2227 - val_loss: 1.6251 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.1723 - val_loss: 1.6249 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2185 - val_loss: 1.6247 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.1891 - val_loss: 1.6246 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2647 - val_loss: 1.6244 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2521 - val_loss: 1.6241 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.2521 - val_loss: 1.6239 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2185 - val_loss: 1.6236 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2353 - val_loss: 1.6235 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2311 - val_loss: 1.6232 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2185 - val_loss: 1.6230 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2563 - val_loss: 1.6227 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2563 - val_loss: 1.6225 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2521 - val_loss: 1.6222 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2353 - val_loss: 1.6220 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2101 - val_loss: 1.6217 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2101 - val_loss: 1.6215 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2311 - val_loss: 1.6214 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2101 - val_loss: 1.6211 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2647 - val_loss: 1.6209 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2059 - val_loss: 1.6208 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2395 - val_loss: 1.6206 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2143 - val_loss: 1.6204 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2143 - val_loss: 1.6203 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2395 - val_loss: 1.6202 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2479 - val_loss: 1.6201 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2227 - val_loss: 1.6199 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6156 - accuracy: 0.2269 - val_loss: 1.6196 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2563 - val_loss: 1.6195 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6164 - accuracy: 0.2101 - val_loss: 1.6193 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6132 - accuracy: 0.2353 - val_loss: 1.6193 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6139 - accuracy: 0.2563 - val_loss: 1.6192 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2689 - val_loss: 1.6190 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6141 - accuracy: 0.2521 - val_loss: 1.6188 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6122 - accuracy: 0.2479 - val_loss: 1.6186 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6110 - accuracy: 0.2521 - val_loss: 1.6184 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2311 - val_loss: 1.6183 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6142 - accuracy: 0.2227 - val_loss: 1.6182 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6118 - accuracy: 0.2227 - val_loss: 1.6181 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6134 - accuracy: 0.2353 - val_loss: 1.6181 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2353 - val_loss: 1.6181 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2479 - val_loss: 1.6180 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2353 - val_loss: 1.6179 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6152 - accuracy: 0.2227 - val_loss: 1.6178 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2059 - val_loss: 1.6177 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6140 - accuracy: 0.2353 - val_loss: 1.6176 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6120 - accuracy: 0.2185 - val_loss: 1.6174 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6078 - accuracy: 0.2479 - val_loss: 1.6174 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2269 - val_loss: 1.6174 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6088 - accuracy: 0.2311 - val_loss: 1.6173 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6096 - accuracy: 0.2185 - val_loss: 1.6173 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6053 - accuracy: 0.2311 - val_loss: 1.6172 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6080 - accuracy: 0.2521 - val_loss: 1.6171 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6089 - accuracy: 0.2311 - val_loss: 1.6171 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6053 - accuracy: 0.2647 - val_loss: 1.6170 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2395 - val_loss: 1.6170 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2479 - val_loss: 1.6170 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6068 - accuracy: 0.2437 - val_loss: 1.6169 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6035 - accuracy: 0.2773 - val_loss: 1.6168 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6043 - accuracy: 0.2479 - val_loss: 1.6168 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6108 - accuracy: 0.2311 - val_loss: 1.6168 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2101 - val_loss: 1.6168 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6111 - accuracy: 0.2353 - val_loss: 1.6168 - val_accuracy: 0.2667 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6060 - accuracy: 0.2479 - val_loss: 1.6168 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6125 - accuracy: 0.2395 - val_loss: 1.6167 - val_accuracy: 0.2667 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6055 - accuracy: 0.2563 - val_loss: 1.6167 - val_accuracy: 0.2500 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6054 - accuracy: 0.2857 - val_loss: 1.6167 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6094 - accuracy: 0.2227 - val_loss: 1.6167 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6030 - accuracy: 0.2689 - val_loss: 1.6167 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Node 42 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6341 - accuracy: 0.2143 - val_loss: 1.6348 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 3s/epoch - 362ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2395 - val_loss: 1.6347 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2227 - val_loss: 1.6346 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.1765 - val_loss: 1.6344 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6346 - accuracy: 0.1975 - val_loss: 1.6343 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2479 - val_loss: 1.6342 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2059 - val_loss: 1.6341 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2395 - val_loss: 1.6339 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2521 - val_loss: 1.6337 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2395 - val_loss: 1.6336 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.1975 - val_loss: 1.6334 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2353 - val_loss: 1.6333 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2941 - val_loss: 1.6331 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2143 - val_loss: 1.6329 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2311 - val_loss: 1.6328 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2269 - val_loss: 1.6327 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2101 - val_loss: 1.6325 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2563 - val_loss: 1.6323 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2773 - val_loss: 1.6320 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2185 - val_loss: 1.6319 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2647 - val_loss: 1.6317 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2227 - val_loss: 1.6315 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2521 - val_loss: 1.6313 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6288 - accuracy: 0.2521 - val_loss: 1.6311 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2101 - val_loss: 1.6309 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6268 - accuracy: 0.2689 - val_loss: 1.6307 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2815 - val_loss: 1.6305 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2479 - val_loss: 1.6302 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2311 - val_loss: 1.6300 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2353 - val_loss: 1.6298 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2185 - val_loss: 1.6296 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2059 - val_loss: 1.6294 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2353 - val_loss: 1.6291 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2353 - val_loss: 1.6289 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2941 - val_loss: 1.6287 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2185 - val_loss: 1.6284 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2395 - val_loss: 1.6282 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2311 - val_loss: 1.6281 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2773 - val_loss: 1.6279 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2773 - val_loss: 1.6277 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 37ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2479 - val_loss: 1.6275 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2563 - val_loss: 1.6273 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2899 - val_loss: 1.6271 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2479 - val_loss: 1.6270 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.1975 - val_loss: 1.6269 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2899 - val_loss: 1.6267 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2521 - val_loss: 1.6266 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2815 - val_loss: 1.6265 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.1975 - val_loss: 1.6263 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2647 - val_loss: 1.6262 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2563 - val_loss: 1.6261 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2731 - val_loss: 1.6259 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2521 - val_loss: 1.6258 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2437 - val_loss: 1.6256 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2479 - val_loss: 1.6254 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2815 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2521 - val_loss: 1.6251 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6176 - accuracy: 0.2941 - val_loss: 1.6249 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2269 - val_loss: 1.6247 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2521 - val_loss: 1.6246 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.1933 - val_loss: 1.6244 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6141 - accuracy: 0.2731 - val_loss: 1.6243 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6138 - accuracy: 0.2731 - val_loss: 1.6241 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.1975 - val_loss: 1.6240 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6134 - accuracy: 0.3025 - val_loss: 1.6239 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6135 - accuracy: 0.3025 - val_loss: 1.6238 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6142 - accuracy: 0.2857 - val_loss: 1.6237 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2059 - val_loss: 1.6236 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2563 - val_loss: 1.6235 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6094 - accuracy: 0.3151 - val_loss: 1.6234 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2395 - val_loss: 1.6233 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6175 - accuracy: 0.2311 - val_loss: 1.6232 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2269 - val_loss: 1.6232 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2437 - val_loss: 1.6231 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6134 - accuracy: 0.3067 - val_loss: 1.6231 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6084 - accuracy: 0.3151 - val_loss: 1.6230 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6112 - accuracy: 0.2563 - val_loss: 1.6229 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6153 - accuracy: 0.2815 - val_loss: 1.6229 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2059 - val_loss: 1.6228 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6148 - accuracy: 0.3067 - val_loss: 1.6227 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6101 - accuracy: 0.2731 - val_loss: 1.6226 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6074 - accuracy: 0.2941 - val_loss: 1.6226 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6100 - accuracy: 0.3025 - val_loss: 1.6225 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2311 - val_loss: 1.6224 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6114 - accuracy: 0.2689 - val_loss: 1.6224 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2353 - val_loss: 1.6223 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2269 - val_loss: 1.6223 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6139 - accuracy: 0.2605 - val_loss: 1.6222 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6140 - accuracy: 0.3025 - val_loss: 1.6221 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6158 - accuracy: 0.2227 - val_loss: 1.6222 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6095 - accuracy: 0.2647 - val_loss: 1.6221 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6097 - accuracy: 0.2479 - val_loss: 1.6220 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6099 - accuracy: 0.3109 - val_loss: 1.6219 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6097 - accuracy: 0.2899 - val_loss: 1.6219 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2563 - val_loss: 1.6219 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6068 - accuracy: 0.2731 - val_loss: 1.6219 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6072 - accuracy: 0.2815 - val_loss: 1.6219 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6039 - accuracy: 0.2857 - val_loss: 1.6218 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6100 - accuracy: 0.2857 - val_loss: 1.6218 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6088 - accuracy: 0.3151 - val_loss: 1.6217 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Node 42 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6609 - accuracy: 0.2185 - val_loss: 1.6609 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 3s/epoch - 169ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6597 - accuracy: 0.2017 - val_loss: 1.6598 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6581 - accuracy: 0.2017 - val_loss: 1.6586 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6579 - accuracy: 0.2353 - val_loss: 1.6575 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6538 - accuracy: 0.2605 - val_loss: 1.6564 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6543 - accuracy: 0.2101 - val_loss: 1.6552 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6560 - accuracy: 0.1891 - val_loss: 1.6543 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6523 - accuracy: 0.2353 - val_loss: 1.6533 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6499 - accuracy: 0.2395 - val_loss: 1.6523 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6500 - accuracy: 0.2311 - val_loss: 1.6515 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6485 - accuracy: 0.2395 - val_loss: 1.6507 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6475 - accuracy: 0.2479 - val_loss: 1.6499 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6449 - accuracy: 0.2437 - val_loss: 1.6491 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2395 - val_loss: 1.6484 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2059 - val_loss: 1.6477 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2059 - val_loss: 1.6469 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6399 - accuracy: 0.2101 - val_loss: 1.6462 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6457 - accuracy: 0.2143 - val_loss: 1.6455 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.1933 - val_loss: 1.6449 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6390 - accuracy: 0.2647 - val_loss: 1.6443 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6370 - accuracy: 0.2521 - val_loss: 1.6436 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.2605 - val_loss: 1.6431 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6349 - accuracy: 0.2479 - val_loss: 1.6427 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6365 - accuracy: 0.2731 - val_loss: 1.6421 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2731 - val_loss: 1.6416 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6371 - accuracy: 0.2143 - val_loss: 1.6412 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.2395 - val_loss: 1.6407 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6370 - accuracy: 0.2059 - val_loss: 1.6402 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2647 - val_loss: 1.6398 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6253 - accuracy: 0.2563 - val_loss: 1.6394 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2437 - val_loss: 1.6390 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6302 - accuracy: 0.2731 - val_loss: 1.6387 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2395 - val_loss: 1.6384 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2563 - val_loss: 1.6381 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2101 - val_loss: 1.6377 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6307 - accuracy: 0.2101 - val_loss: 1.6375 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2479 - val_loss: 1.6372 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2311 - val_loss: 1.6369 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2605 - val_loss: 1.6366 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6329 - accuracy: 0.2311 - val_loss: 1.6363 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2689 - val_loss: 1.6362 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6265 - accuracy: 0.2857 - val_loss: 1.6362 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2227 - val_loss: 1.6361 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2185 - val_loss: 1.6359 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2521 - val_loss: 1.6358 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2647 - val_loss: 1.6356 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2647 - val_loss: 1.6356 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6134 - accuracy: 0.2689 - val_loss: 1.6355 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2437 - val_loss: 1.6354 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6146 - accuracy: 0.2773 - val_loss: 1.6354 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6166 - accuracy: 0.2941 - val_loss: 1.6353 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6147 - accuracy: 0.2521 - val_loss: 1.6354 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 84ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6076 - accuracy: 0.2857 - val_loss: 1.6355 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6116 - accuracy: 0.2773 - val_loss: 1.6356 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6104 - accuracy: 0.2773 - val_loss: 1.6356 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6143 - accuracy: 0.2689 - val_loss: 1.6356 - val_accuracy: 0.2000 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2773 - val_loss: 1.6355 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6119 - accuracy: 0.2731 - val_loss: 1.6356 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Node 42 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6600 - accuracy: 0.2143 - val_loss: 1.6601 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 3s/epoch - 360ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.2437 - val_loss: 1.6592 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6583 - accuracy: 0.2143 - val_loss: 1.6586 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.2311 - val_loss: 1.6581 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6576 - accuracy: 0.1807 - val_loss: 1.6575 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.2227 - val_loss: 1.6570 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2311 - val_loss: 1.6566 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2311 - val_loss: 1.6561 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2017 - val_loss: 1.6554 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2563 - val_loss: 1.6548 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6514 - accuracy: 0.2185 - val_loss: 1.6541 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2353 - val_loss: 1.6534 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6524 - accuracy: 0.2353 - val_loss: 1.6528 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6486 - accuracy: 0.2689 - val_loss: 1.6522 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6493 - accuracy: 0.2311 - val_loss: 1.6517 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6489 - accuracy: 0.2521 - val_loss: 1.6512 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2311 - val_loss: 1.6507 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6490 - accuracy: 0.2185 - val_loss: 1.6502 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6459 - accuracy: 0.2353 - val_loss: 1.6496 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2143 - val_loss: 1.6490 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2311 - val_loss: 1.6484 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2227 - val_loss: 1.6479 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2353 - val_loss: 1.6474 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6441 - accuracy: 0.2521 - val_loss: 1.6468 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2269 - val_loss: 1.6463 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2563 - val_loss: 1.6457 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2605 - val_loss: 1.6453 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6411 - accuracy: 0.2269 - val_loss: 1.6448 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6396 - accuracy: 0.2395 - val_loss: 1.6444 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2479 - val_loss: 1.6440 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2101 - val_loss: 1.6435 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6364 - accuracy: 0.2143 - val_loss: 1.6432 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2185 - val_loss: 1.6427 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2269 - val_loss: 1.6423 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6332 - accuracy: 0.2689 - val_loss: 1.6419 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.2143 - val_loss: 1.6415 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2647 - val_loss: 1.6411 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2605 - val_loss: 1.6407 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2353 - val_loss: 1.6404 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2563 - val_loss: 1.6401 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2689 - val_loss: 1.6398 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2395 - val_loss: 1.6395 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2269 - val_loss: 1.6392 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2521 - val_loss: 1.6390 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2479 - val_loss: 1.6387 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2227 - val_loss: 1.6384 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2353 - val_loss: 1.6382 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2983 - val_loss: 1.6379 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2479 - val_loss: 1.6378 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2437 - val_loss: 1.6376 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2815 - val_loss: 1.6375 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2605 - val_loss: 1.6373 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2983 - val_loss: 1.6372 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2269 - val_loss: 1.6370 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2353 - val_loss: 1.6367 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2437 - val_loss: 1.6366 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2689 - val_loss: 1.6365 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2521 - val_loss: 1.6365 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2731 - val_loss: 1.6365 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2059 - val_loss: 1.6365 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2605 - val_loss: 1.6365 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2815 - val_loss: 1.6366 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2437 - val_loss: 1.6365 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2479 - val_loss: 1.6364 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2311 - val_loss: 1.6364 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2731 - val_loss: 1.6363 - val_accuracy: 0.2000 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2521 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2773 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2773 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 43ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2731 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 1.2500e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2521 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 1.2500e-05 - 41ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6163 - accuracy: 0.2479 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 1.2500e-05 - 42ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2269 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 6.2500e-06 - 41ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2479 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 6.2500e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2563 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 6.2500e-06 - 42ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2689 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 41ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2143 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 41ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2227 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 42ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 41ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2395 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 41ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6122 - accuracy: 0.2437 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.1250e-06 - 42ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2059 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.5625e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2059 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.5625e-06 - 42ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.5625e-06 - 43ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 7.8125e-07 - 48ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2605 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 7.8125e-07 - 45ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2563 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 7.8125e-07 - 46ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2857 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.9062e-07 - 45ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2479 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.9062e-07 - 47ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2479 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 3.9062e-07 - 46ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.9531e-07 - 44ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2353 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.9531e-07 - 49ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2311 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 1.9531e-07 - 45ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2353 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 9.7656e-08 - 62ms/epoch - 8ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6108 - accuracy: 0.2773 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 9.7656e-08 - 45ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2437 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 9.7656e-08 - 45ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 4.8828e-08 - 44ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2479 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 4.8828e-08 - 44ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2521 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 4.8828e-08 - 43ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2647 - val_loss: 1.6362 - val_accuracy: 0.2333 - lr: 2.4414e-08 - 43ms/epoch - 5ms/step\n",
      "Node 42 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 42 - Best Validation Accuracy: 0.3000\n",
      "Best model saved for Node 42 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_42.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_43_dataset.csv\n",
      "Node 43 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6383 - accuracy: 0.2061 - val_loss: 1.6365 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 3s/epoch - 190ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6366 - accuracy: 0.2105 - val_loss: 1.6363 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6382 - accuracy: 0.1754 - val_loss: 1.6359 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2456 - val_loss: 1.6356 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6363 - accuracy: 0.1798 - val_loss: 1.6352 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.2237 - val_loss: 1.6349 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2193 - val_loss: 1.6347 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2544 - val_loss: 1.6344 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.3158 - val_loss: 1.6341 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2281 - val_loss: 1.6338 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6336 - accuracy: 0.2149 - val_loss: 1.6336 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6328 - accuracy: 0.2061 - val_loss: 1.6334 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6323 - accuracy: 0.2237 - val_loss: 1.6331 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6324 - accuracy: 0.2018 - val_loss: 1.6328 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6316 - accuracy: 0.2456 - val_loss: 1.6326 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2500 - val_loss: 1.6323 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2500 - val_loss: 1.6320 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2807 - val_loss: 1.6317 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2193 - val_loss: 1.6315 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6312 - accuracy: 0.2149 - val_loss: 1.6315 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2368 - val_loss: 1.6313 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6309 - accuracy: 0.2412 - val_loss: 1.6311 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6308 - accuracy: 0.2325 - val_loss: 1.6309 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2237 - val_loss: 1.6307 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2544 - val_loss: 1.6305 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2675 - val_loss: 1.6304 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2412 - val_loss: 1.6301 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2105 - val_loss: 1.6297 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2237 - val_loss: 1.6294 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2368 - val_loss: 1.6293 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2588 - val_loss: 1.6291 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.1798 - val_loss: 1.6289 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2325 - val_loss: 1.6288 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2588 - val_loss: 1.6288 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.2456 - val_loss: 1.6288 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2632 - val_loss: 1.6286 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2675 - val_loss: 1.6284 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6289 - accuracy: 0.2105 - val_loss: 1.6282 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2149 - val_loss: 1.6278 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2237 - val_loss: 1.6278 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2281 - val_loss: 1.6276 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2149 - val_loss: 1.6274 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2719 - val_loss: 1.6272 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2412 - val_loss: 1.6270 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2325 - val_loss: 1.6268 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2412 - val_loss: 1.6266 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2281 - val_loss: 1.6265 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6275 - accuracy: 0.2368 - val_loss: 1.6263 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2544 - val_loss: 1.6262 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2719 - val_loss: 1.6259 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2412 - val_loss: 1.6258 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6254 - accuracy: 0.2237 - val_loss: 1.6256 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6215 - accuracy: 0.2675 - val_loss: 1.6256 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2456 - val_loss: 1.6254 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2456 - val_loss: 1.6253 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2149 - val_loss: 1.6253 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2500 - val_loss: 1.6252 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2719 - val_loss: 1.6250 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2149 - val_loss: 1.6249 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.1930 - val_loss: 1.6248 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2632 - val_loss: 1.6246 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2632 - val_loss: 1.6245 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2281 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2237 - val_loss: 1.6242 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6223 - accuracy: 0.2412 - val_loss: 1.6241 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2018 - val_loss: 1.6238 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2281 - val_loss: 1.6237 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2412 - val_loss: 1.6237 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6245 - accuracy: 0.2149 - val_loss: 1.6237 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2500 - val_loss: 1.6236 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.1842 - val_loss: 1.6235 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2368 - val_loss: 1.6235 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2412 - val_loss: 1.6235 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2456 - val_loss: 1.6234 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.2193 - val_loss: 1.6233 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6213 - accuracy: 0.2281 - val_loss: 1.6233 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2588 - val_loss: 1.6232 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6225 - accuracy: 0.2061 - val_loss: 1.6231 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2544 - val_loss: 1.6230 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2061 - val_loss: 1.6230 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2018 - val_loss: 1.6230 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6151 - accuracy: 0.2675 - val_loss: 1.6229 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2632 - val_loss: 1.6229 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2500 - val_loss: 1.6229 - val_accuracy: 0.2586 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2456 - val_loss: 1.6229 - val_accuracy: 0.2586 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6149 - accuracy: 0.2500 - val_loss: 1.6229 - val_accuracy: 0.2586 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2149 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6154 - accuracy: 0.2763 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 2.5000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6199 - accuracy: 0.2325 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 1.2500e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2368 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 1.2500e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2456 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 1.2500e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2061 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2632 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2149 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.1930 - val_loss: 1.6228 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2325 - val_loss: 1.6227 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6200 - accuracy: 0.2675 - val_loss: 1.6227 - val_accuracy: 0.2586 - lr: 6.2500e-06 - 42ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6124 - accuracy: 0.2895 - val_loss: 1.6227 - val_accuracy: 0.2586 - lr: 3.1250e-06 - 41ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6161 - accuracy: 0.2588 - val_loss: 1.6227 - val_accuracy: 0.2586 - lr: 3.1250e-06 - 61ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2237 - val_loss: 1.6227 - val_accuracy: 0.2586 - lr: 3.1250e-06 - 47ms/epoch - 3ms/step\n",
      "Node 43 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6348 - accuracy: 0.1930 - val_loss: 1.6336 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 3s/epoch - 313ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2193 - val_loss: 1.6332 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.1798 - val_loss: 1.6329 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.1886 - val_loss: 1.6327 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.1930 - val_loss: 1.6325 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2018 - val_loss: 1.6324 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1974 - val_loss: 1.6322 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2061 - val_loss: 1.6321 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.1930 - val_loss: 1.6320 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2281 - val_loss: 1.6318 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2281 - val_loss: 1.6316 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2412 - val_loss: 1.6315 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2105 - val_loss: 1.6313 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2500 - val_loss: 1.6310 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2105 - val_loss: 1.6309 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.1842 - val_loss: 1.6308 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2193 - val_loss: 1.6307 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2193 - val_loss: 1.6305 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2149 - val_loss: 1.6303 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2193 - val_loss: 1.6302 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.1930 - val_loss: 1.6300 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2149 - val_loss: 1.6297 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2632 - val_loss: 1.6296 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.1974 - val_loss: 1.6294 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2237 - val_loss: 1.6293 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2193 - val_loss: 1.6292 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2193 - val_loss: 1.6291 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 36ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2149 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2061 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2325 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2193 - val_loss: 1.6289 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2193 - val_loss: 1.6288 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2281 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2544 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2061 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2149 - val_loss: 1.6284 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2281 - val_loss: 1.6283 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2281 - val_loss: 1.6282 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2588 - val_loss: 1.6280 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2193 - val_loss: 1.6278 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2412 - val_loss: 1.6277 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2325 - val_loss: 1.6275 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2193 - val_loss: 1.6274 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6280 - accuracy: 0.1842 - val_loss: 1.6272 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2456 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2237 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2412 - val_loss: 1.6270 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2325 - val_loss: 1.6269 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2061 - val_loss: 1.6268 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2193 - val_loss: 1.6267 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2237 - val_loss: 1.6266 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2456 - val_loss: 1.6265 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2500 - val_loss: 1.6263 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2281 - val_loss: 1.6262 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2325 - val_loss: 1.6260 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2149 - val_loss: 1.6259 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2675 - val_loss: 1.6258 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2412 - val_loss: 1.6257 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2281 - val_loss: 1.6255 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2325 - val_loss: 1.6254 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2193 - val_loss: 1.6253 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2281 - val_loss: 1.6251 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2456 - val_loss: 1.6250 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2105 - val_loss: 1.6250 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.1974 - val_loss: 1.6250 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2412 - val_loss: 1.6249 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2368 - val_loss: 1.6248 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2368 - val_loss: 1.6246 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2500 - val_loss: 1.6245 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2149 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2149 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2325 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2368 - val_loss: 1.6242 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2105 - val_loss: 1.6242 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2368 - val_loss: 1.6242 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2368 - val_loss: 1.6241 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2281 - val_loss: 1.6240 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2281 - val_loss: 1.6239 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2018 - val_loss: 1.6239 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2149 - val_loss: 1.6238 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2544 - val_loss: 1.6238 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2237 - val_loss: 1.6237 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2325 - val_loss: 1.6236 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2368 - val_loss: 1.6234 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2588 - val_loss: 1.6233 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2412 - val_loss: 1.6232 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2325 - val_loss: 1.6231 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2281 - val_loss: 1.6231 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2193 - val_loss: 1.6229 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2544 - val_loss: 1.6228 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.1974 - val_loss: 1.6227 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2412 - val_loss: 1.6227 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6188 - accuracy: 0.2325 - val_loss: 1.6226 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2281 - val_loss: 1.6225 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2061 - val_loss: 1.6224 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2105 - val_loss: 1.6223 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2237 - val_loss: 1.6223 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2061 - val_loss: 1.6222 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2325 - val_loss: 1.6221 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6166 - accuracy: 0.2456 - val_loss: 1.6220 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 43 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6605 - accuracy: 0.2149 - val_loss: 1.6585 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 3s/epoch - 191ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6586 - accuracy: 0.2456 - val_loss: 1.6578 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6572 - accuracy: 0.2281 - val_loss: 1.6572 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6588 - accuracy: 0.2018 - val_loss: 1.6564 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6567 - accuracy: 0.2149 - val_loss: 1.6556 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6558 - accuracy: 0.2281 - val_loss: 1.6549 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6546 - accuracy: 0.2281 - val_loss: 1.6542 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6540 - accuracy: 0.2193 - val_loss: 1.6534 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6538 - accuracy: 0.2018 - val_loss: 1.6527 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6531 - accuracy: 0.2456 - val_loss: 1.6520 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6532 - accuracy: 0.2149 - val_loss: 1.6514 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6507 - accuracy: 0.2412 - val_loss: 1.6507 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6502 - accuracy: 0.2281 - val_loss: 1.6500 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2105 - val_loss: 1.6492 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2368 - val_loss: 1.6485 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6484 - accuracy: 0.2325 - val_loss: 1.6478 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6474 - accuracy: 0.2456 - val_loss: 1.6471 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6451 - accuracy: 0.2675 - val_loss: 1.6464 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6459 - accuracy: 0.2368 - val_loss: 1.6456 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6457 - accuracy: 0.2325 - val_loss: 1.6449 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6456 - accuracy: 0.2368 - val_loss: 1.6443 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6431 - accuracy: 0.2456 - val_loss: 1.6436 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6454 - accuracy: 0.2325 - val_loss: 1.6431 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6417 - accuracy: 0.2412 - val_loss: 1.6427 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6423 - accuracy: 0.2368 - val_loss: 1.6421 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6418 - accuracy: 0.2412 - val_loss: 1.6417 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6396 - accuracy: 0.2412 - val_loss: 1.6412 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6410 - accuracy: 0.2237 - val_loss: 1.6409 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6389 - accuracy: 0.2193 - val_loss: 1.6404 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6402 - accuracy: 0.2500 - val_loss: 1.6398 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6395 - accuracy: 0.2325 - val_loss: 1.6395 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6360 - accuracy: 0.2281 - val_loss: 1.6391 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6391 - accuracy: 0.2325 - val_loss: 1.6386 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6380 - accuracy: 0.2368 - val_loss: 1.6381 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2193 - val_loss: 1.6376 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2237 - val_loss: 1.6372 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6354 - accuracy: 0.2018 - val_loss: 1.6367 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2061 - val_loss: 1.6363 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6347 - accuracy: 0.2368 - val_loss: 1.6360 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6350 - accuracy: 0.2325 - val_loss: 1.6357 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6314 - accuracy: 0.2544 - val_loss: 1.6353 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2237 - val_loss: 1.6347 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2675 - val_loss: 1.6343 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6305 - accuracy: 0.2368 - val_loss: 1.6339 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2061 - val_loss: 1.6335 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6320 - accuracy: 0.2368 - val_loss: 1.6332 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2237 - val_loss: 1.6327 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2719 - val_loss: 1.6322 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2588 - val_loss: 1.6317 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2675 - val_loss: 1.6313 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6267 - accuracy: 0.2281 - val_loss: 1.6310 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6252 - accuracy: 0.2412 - val_loss: 1.6307 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6282 - accuracy: 0.2632 - val_loss: 1.6305 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2763 - val_loss: 1.6300 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6251 - accuracy: 0.2368 - val_loss: 1.6296 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2675 - val_loss: 1.6294 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2281 - val_loss: 1.6290 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2281 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2368 - val_loss: 1.6282 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6257 - accuracy: 0.2412 - val_loss: 1.6278 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6231 - accuracy: 0.2632 - val_loss: 1.6275 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6210 - accuracy: 0.2412 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2675 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6220 - accuracy: 0.2368 - val_loss: 1.6270 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2193 - val_loss: 1.6265 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2719 - val_loss: 1.6261 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2237 - val_loss: 1.6258 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2456 - val_loss: 1.6255 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2412 - val_loss: 1.6252 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6175 - accuracy: 0.2763 - val_loss: 1.6248 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6155 - accuracy: 0.2412 - val_loss: 1.6244 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2851 - val_loss: 1.6242 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6163 - accuracy: 0.2500 - val_loss: 1.6239 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2325 - val_loss: 1.6236 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6173 - accuracy: 0.2456 - val_loss: 1.6233 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6156 - accuracy: 0.2368 - val_loss: 1.6230 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6101 - accuracy: 0.2544 - val_loss: 1.6227 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6084 - accuracy: 0.2763 - val_loss: 1.6222 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6097 - accuracy: 0.2456 - val_loss: 1.6219 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6128 - accuracy: 0.2544 - val_loss: 1.6218 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6144 - accuracy: 0.2061 - val_loss: 1.6214 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6165 - accuracy: 0.2368 - val_loss: 1.6212 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6166 - accuracy: 0.2325 - val_loss: 1.6211 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6129 - accuracy: 0.2588 - val_loss: 1.6208 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6031 - accuracy: 0.2456 - val_loss: 1.6204 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6035 - accuracy: 0.2675 - val_loss: 1.6200 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "15/15 - 0s - loss: 1.6079 - accuracy: 0.2632 - val_loss: 1.6196 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6148 - accuracy: 0.2325 - val_loss: 1.6191 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6109 - accuracy: 0.2368 - val_loss: 1.6190 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "15/15 - 0s - loss: 1.6085 - accuracy: 0.2939 - val_loss: 1.6189 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6103 - accuracy: 0.2632 - val_loss: 1.6190 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6127 - accuracy: 0.2500 - val_loss: 1.6188 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "15/15 - 0s - loss: 1.6090 - accuracy: 0.2939 - val_loss: 1.6187 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6011 - accuracy: 0.2851 - val_loss: 1.6184 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.2895 - val_loss: 1.6182 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "15/15 - 0s - loss: 1.6064 - accuracy: 0.3158 - val_loss: 1.6182 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6058 - accuracy: 0.2632 - val_loss: 1.6181 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6100 - accuracy: 0.2632 - val_loss: 1.6178 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "15/15 - 0s - loss: 1.6059 - accuracy: 0.2588 - val_loss: 1.6173 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.5943 - accuracy: 0.2807 - val_loss: 1.6169 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Node 43 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6614 - accuracy: 0.1930 - val_loss: 1.6594 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 3s/epoch - 315ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6603 - accuracy: 0.1930 - val_loss: 1.6589 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.2149 - val_loss: 1.6584 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6581 - accuracy: 0.2193 - val_loss: 1.6579 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6587 - accuracy: 0.2105 - val_loss: 1.6575 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6564 - accuracy: 0.2368 - val_loss: 1.6571 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.2105 - val_loss: 1.6568 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2149 - val_loss: 1.6564 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.1930 - val_loss: 1.6560 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2500 - val_loss: 1.6557 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2412 - val_loss: 1.6554 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6546 - accuracy: 0.2412 - val_loss: 1.6550 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2325 - val_loss: 1.6546 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6547 - accuracy: 0.2061 - val_loss: 1.6543 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6528 - accuracy: 0.2105 - val_loss: 1.6540 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6526 - accuracy: 0.2588 - val_loss: 1.6536 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2500 - val_loss: 1.6532 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6503 - accuracy: 0.2675 - val_loss: 1.6529 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6530 - accuracy: 0.2412 - val_loss: 1.6525 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2456 - val_loss: 1.6522 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6493 - accuracy: 0.2719 - val_loss: 1.6519 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2719 - val_loss: 1.6516 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2412 - val_loss: 1.6514 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2632 - val_loss: 1.6513 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2018 - val_loss: 1.6512 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2982 - val_loss: 1.6508 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.1798 - val_loss: 1.6505 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2500 - val_loss: 1.6502 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2544 - val_loss: 1.6498 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6484 - accuracy: 0.2763 - val_loss: 1.6495 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6481 - accuracy: 0.2763 - val_loss: 1.6492 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2061 - val_loss: 1.6489 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2500 - val_loss: 1.6486 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2237 - val_loss: 1.6485 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6433 - accuracy: 0.2719 - val_loss: 1.6482 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.3026 - val_loss: 1.6478 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2237 - val_loss: 1.6474 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2719 - val_loss: 1.6470 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2588 - val_loss: 1.6467 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6440 - accuracy: 0.2675 - val_loss: 1.6463 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.3202 - val_loss: 1.6458 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6472 - accuracy: 0.2368 - val_loss: 1.6455 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2456 - val_loss: 1.6453 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2632 - val_loss: 1.6451 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6423 - accuracy: 0.2851 - val_loss: 1.6448 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2456 - val_loss: 1.6446 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2149 - val_loss: 1.6445 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2412 - val_loss: 1.6442 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6366 - accuracy: 0.2939 - val_loss: 1.6439 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2456 - val_loss: 1.6435 - val_accuracy: 0.3103 - lr: 1.0000e-04 - 62ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6413 - accuracy: 0.2193 - val_loss: 1.6432 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.2368 - val_loss: 1.6429 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6390 - accuracy: 0.2500 - val_loss: 1.6427 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6386 - accuracy: 0.2544 - val_loss: 1.6424 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2149 - val_loss: 1.6423 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6357 - accuracy: 0.2851 - val_loss: 1.6420 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6360 - accuracy: 0.2632 - val_loss: 1.6417 - val_accuracy: 0.2931 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.2456 - val_loss: 1.6415 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6366 - accuracy: 0.2412 - val_loss: 1.6412 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6368 - accuracy: 0.2412 - val_loss: 1.6409 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2456 - val_loss: 1.6406 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2544 - val_loss: 1.6404 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2632 - val_loss: 1.6400 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2675 - val_loss: 1.6397 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2544 - val_loss: 1.6395 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2500 - val_loss: 1.6392 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2412 - val_loss: 1.6391 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2763 - val_loss: 1.6389 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6378 - accuracy: 0.2763 - val_loss: 1.6386 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2632 - val_loss: 1.6384 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2412 - val_loss: 1.6381 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2500 - val_loss: 1.6378 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2807 - val_loss: 1.6377 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2544 - val_loss: 1.6375 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2807 - val_loss: 1.6373 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2632 - val_loss: 1.6371 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2939 - val_loss: 1.6369 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2719 - val_loss: 1.6366 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2763 - val_loss: 1.6364 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.3158 - val_loss: 1.6362 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2412 - val_loss: 1.6360 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2500 - val_loss: 1.6357 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2763 - val_loss: 1.6356 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2588 - val_loss: 1.6353 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2763 - val_loss: 1.6352 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6351 - accuracy: 0.2368 - val_loss: 1.6350 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.3114 - val_loss: 1.6347 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2500 - val_loss: 1.6343 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2500 - val_loss: 1.6341 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6267 - accuracy: 0.2456 - val_loss: 1.6337 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2544 - val_loss: 1.6335 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2281 - val_loss: 1.6333 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2500 - val_loss: 1.6332 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2939 - val_loss: 1.6331 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 42ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6198 - accuracy: 0.2807 - val_loss: 1.6330 - val_accuracy: 0.2759 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2544 - val_loss: 1.6329 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2412 - val_loss: 1.6328 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2675 - val_loss: 1.6328 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6271 - accuracy: 0.2500 - val_loss: 1.6328 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2632 - val_loss: 1.6329 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Node 43 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 43 - Best Validation Accuracy: 0.3103\n",
      "Best model saved for Node 43 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_43.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_44_dataset.csv\n",
      "Node 44 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6370 - accuracy: 0.1730 - val_loss: 1.6345 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 3s/epoch - 197ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6346 - accuracy: 0.2110 - val_loss: 1.6343 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2194 - val_loss: 1.6341 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.1688 - val_loss: 1.6339 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2194 - val_loss: 1.6337 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2321 - val_loss: 1.6335 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.1899 - val_loss: 1.6333 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.1772 - val_loss: 1.6331 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2447 - val_loss: 1.6328 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6325 - accuracy: 0.2194 - val_loss: 1.6325 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6319 - accuracy: 0.2194 - val_loss: 1.6323 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6322 - accuracy: 0.2068 - val_loss: 1.6320 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6303 - accuracy: 0.2574 - val_loss: 1.6318 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2363 - val_loss: 1.6316 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2447 - val_loss: 1.6315 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2236 - val_loss: 1.6313 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6304 - accuracy: 0.2194 - val_loss: 1.6311 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6311 - accuracy: 0.2152 - val_loss: 1.6309 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6291 - accuracy: 0.2405 - val_loss: 1.6307 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2321 - val_loss: 1.6305 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2110 - val_loss: 1.6303 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2321 - val_loss: 1.6301 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2025 - val_loss: 1.6299 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2068 - val_loss: 1.6298 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6261 - accuracy: 0.2489 - val_loss: 1.6297 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6277 - accuracy: 0.1983 - val_loss: 1.6295 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2363 - val_loss: 1.6294 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2194 - val_loss: 1.6293 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2236 - val_loss: 1.6291 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.1814 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6274 - accuracy: 0.2363 - val_loss: 1.6288 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6259 - accuracy: 0.2405 - val_loss: 1.6286 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6263 - accuracy: 0.2405 - val_loss: 1.6284 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2110 - val_loss: 1.6283 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6281 - accuracy: 0.2194 - val_loss: 1.6282 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2152 - val_loss: 1.6280 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2363 - val_loss: 1.6280 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2532 - val_loss: 1.6279 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.2405 - val_loss: 1.6278 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6212 - accuracy: 0.2278 - val_loss: 1.6276 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6266 - accuracy: 0.2236 - val_loss: 1.6276 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2194 - val_loss: 1.6273 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2110 - val_loss: 1.6273 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2152 - val_loss: 1.6272 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6244 - accuracy: 0.2236 - val_loss: 1.6270 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2321 - val_loss: 1.6269 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2321 - val_loss: 1.6269 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6230 - accuracy: 0.2068 - val_loss: 1.6268 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2236 - val_loss: 1.6267 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6228 - accuracy: 0.2278 - val_loss: 1.6265 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2068 - val_loss: 1.6266 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6224 - accuracy: 0.2363 - val_loss: 1.6263 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6217 - accuracy: 0.2278 - val_loss: 1.6261 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2405 - val_loss: 1.6261 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.1941 - val_loss: 1.6260 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2532 - val_loss: 1.6258 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2194 - val_loss: 1.6257 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2532 - val_loss: 1.6256 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2321 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6222 - accuracy: 0.1899 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2447 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.2152 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2152 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6211 - accuracy: 0.2363 - val_loss: 1.6255 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2236 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2278 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2194 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2236 - val_loss: 1.6252 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2489 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2363 - val_loss: 1.6253 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2194 - val_loss: 1.6252 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2447 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2363 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2489 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6183 - accuracy: 0.2278 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2236 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "15/15 - 0s - loss: 1.6167 - accuracy: 0.2152 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6168 - accuracy: 0.2194 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 1.2500e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2025 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2405 - val_loss: 1.6251 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6172 - accuracy: 0.2574 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 6.2500e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6193 - accuracy: 0.2278 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2363 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "15/15 - 0s - loss: 1.6202 - accuracy: 0.1983 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2152 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2489 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.1983 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.1250e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2152 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2025 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2110 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.5625e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2236 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "15/15 - 0s - loss: 1.6198 - accuracy: 0.2489 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.2321 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 7.8125e-07 - 47ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "15/15 - 0s - loss: 1.6158 - accuracy: 0.2658 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2152 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 67ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "15/15 - 0s - loss: 1.6192 - accuracy: 0.2236 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 3.9062e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.1899 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.9531e-07 - 45ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2278 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.9531e-07 - 43ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2025 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 1.9531e-07 - 44ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "15/15 - 0s - loss: 1.6184 - accuracy: 0.2574 - val_loss: 1.6250 - val_accuracy: 0.2167 - lr: 9.7656e-08 - 43ms/epoch - 3ms/step\n",
      "Node 44 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6349 - accuracy: 0.1983 - val_loss: 1.6348 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 3s/epoch - 315ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2152 - val_loss: 1.6346 - val_accuracy: 0.2833 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.1983 - val_loss: 1.6344 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6338 - accuracy: 0.1561 - val_loss: 1.6342 - val_accuracy: 0.2667 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.1772 - val_loss: 1.6341 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2447 - val_loss: 1.6340 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2405 - val_loss: 1.6338 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2532 - val_loss: 1.6337 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2068 - val_loss: 1.6335 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2363 - val_loss: 1.6334 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.1899 - val_loss: 1.6332 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2532 - val_loss: 1.6331 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2110 - val_loss: 1.6330 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2278 - val_loss: 1.6329 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2405 - val_loss: 1.6327 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.1688 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2658 - val_loss: 1.6326 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2532 - val_loss: 1.6325 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2489 - val_loss: 1.6324 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1857 - val_loss: 1.6322 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2363 - val_loss: 1.6322 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2236 - val_loss: 1.6321 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2489 - val_loss: 1.6319 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2152 - val_loss: 1.6318 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2700 - val_loss: 1.6318 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2194 - val_loss: 1.6317 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2489 - val_loss: 1.6316 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2025 - val_loss: 1.6315 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2152 - val_loss: 1.6315 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2447 - val_loss: 1.6314 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.1603 - val_loss: 1.6314 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2278 - val_loss: 1.6313 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2363 - val_loss: 1.6313 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2152 - val_loss: 1.6312 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2321 - val_loss: 1.6311 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6277 - accuracy: 0.2194 - val_loss: 1.6310 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2489 - val_loss: 1.6309 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2405 - val_loss: 1.6309 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6262 - accuracy: 0.2278 - val_loss: 1.6308 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2532 - val_loss: 1.6307 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2363 - val_loss: 1.6307 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2616 - val_loss: 1.6306 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2278 - val_loss: 1.6305 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2363 - val_loss: 1.6304 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2616 - val_loss: 1.6303 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2110 - val_loss: 1.6302 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2236 - val_loss: 1.6302 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2278 - val_loss: 1.6301 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2236 - val_loss: 1.6300 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2363 - val_loss: 1.6299 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2321 - val_loss: 1.6298 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2616 - val_loss: 1.6298 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2616 - val_loss: 1.6298 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2025 - val_loss: 1.6297 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2447 - val_loss: 1.6296 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2363 - val_loss: 1.6295 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2574 - val_loss: 1.6294 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2532 - val_loss: 1.6293 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.1857 - val_loss: 1.6293 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2363 - val_loss: 1.6292 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2532 - val_loss: 1.6292 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2194 - val_loss: 1.6291 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6191 - accuracy: 0.2700 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2321 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2700 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2405 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2405 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2110 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2489 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 32ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2532 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2321 - val_loss: 1.6290 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 32ms/epoch - 4ms/step\n",
      "Node 44 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6611 - accuracy: 0.2152 - val_loss: 1.6605 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 3s/epoch - 200ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6604 - accuracy: 0.2152 - val_loss: 1.6599 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6600 - accuracy: 0.1983 - val_loss: 1.6593 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6577 - accuracy: 0.2363 - val_loss: 1.6586 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6570 - accuracy: 0.2068 - val_loss: 1.6579 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6561 - accuracy: 0.2574 - val_loss: 1.6572 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6565 - accuracy: 0.1899 - val_loss: 1.6566 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6543 - accuracy: 0.2321 - val_loss: 1.6560 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6537 - accuracy: 0.2110 - val_loss: 1.6553 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6524 - accuracy: 0.2447 - val_loss: 1.6546 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6510 - accuracy: 0.2363 - val_loss: 1.6541 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6536 - accuracy: 0.2278 - val_loss: 1.6535 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6519 - accuracy: 0.2068 - val_loss: 1.6529 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6484 - accuracy: 0.2447 - val_loss: 1.6523 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6499 - accuracy: 0.2321 - val_loss: 1.6517 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2152 - val_loss: 1.6511 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6470 - accuracy: 0.2489 - val_loss: 1.6507 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2110 - val_loss: 1.6503 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6475 - accuracy: 0.2405 - val_loss: 1.6499 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6472 - accuracy: 0.2152 - val_loss: 1.6494 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6468 - accuracy: 0.2489 - val_loss: 1.6489 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6440 - accuracy: 0.2405 - val_loss: 1.6484 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6451 - accuracy: 0.2025 - val_loss: 1.6480 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6429 - accuracy: 0.2321 - val_loss: 1.6476 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6413 - accuracy: 0.1983 - val_loss: 1.6472 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6437 - accuracy: 0.2321 - val_loss: 1.6468 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6403 - accuracy: 0.2405 - val_loss: 1.6464 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6390 - accuracy: 0.2447 - val_loss: 1.6460 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6401 - accuracy: 0.2405 - val_loss: 1.6457 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6398 - accuracy: 0.2321 - val_loss: 1.6452 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6417 - accuracy: 0.2321 - val_loss: 1.6448 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6376 - accuracy: 0.2447 - val_loss: 1.6445 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6368 - accuracy: 0.2321 - val_loss: 1.6440 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2363 - val_loss: 1.6436 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6383 - accuracy: 0.2278 - val_loss: 1.6432 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6348 - accuracy: 0.2236 - val_loss: 1.6429 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6357 - accuracy: 0.2405 - val_loss: 1.6426 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6342 - accuracy: 0.2405 - val_loss: 1.6422 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6343 - accuracy: 0.2532 - val_loss: 1.6420 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2447 - val_loss: 1.6417 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6331 - accuracy: 0.2532 - val_loss: 1.6413 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6317 - accuracy: 0.2405 - val_loss: 1.6410 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6334 - accuracy: 0.2152 - val_loss: 1.6407 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6309 - accuracy: 0.2321 - val_loss: 1.6404 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6363 - accuracy: 0.2194 - val_loss: 1.6400 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6296 - accuracy: 0.2194 - val_loss: 1.6398 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2110 - val_loss: 1.6396 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2447 - val_loss: 1.6394 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6314 - accuracy: 0.2447 - val_loss: 1.6392 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6269 - accuracy: 0.2616 - val_loss: 1.6389 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2827 - val_loss: 1.6387 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6268 - accuracy: 0.2447 - val_loss: 1.6386 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2363 - val_loss: 1.6384 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2574 - val_loss: 1.6383 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2532 - val_loss: 1.6381 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "15/15 - 0s - loss: 1.6272 - accuracy: 0.2363 - val_loss: 1.6380 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2489 - val_loss: 1.6378 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.2532 - val_loss: 1.6374 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6250 - accuracy: 0.2489 - val_loss: 1.6373 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2363 - val_loss: 1.6371 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2447 - val_loss: 1.6371 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6205 - accuracy: 0.2321 - val_loss: 1.6370 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6204 - accuracy: 0.2700 - val_loss: 1.6368 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2447 - val_loss: 1.6367 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6190 - accuracy: 0.2321 - val_loss: 1.6366 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2616 - val_loss: 1.6363 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2489 - val_loss: 1.6365 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2152 - val_loss: 1.6363 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6130 - accuracy: 0.2658 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2489 - val_loss: 1.6363 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6159 - accuracy: 0.2447 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6189 - accuracy: 0.2447 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 5.0000e-05 - 63ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6150 - accuracy: 0.2658 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 61ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "15/15 - 0s - loss: 1.6105 - accuracy: 0.2278 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6145 - accuracy: 0.2532 - val_loss: 1.6364 - val_accuracy: 0.2167 - lr: 2.5000e-05 - 64ms/epoch - 4ms/step\n",
      "Node 44 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6610 - accuracy: 0.1730 - val_loss: 1.6600 - val_accuracy: 0.1333 - lr: 1.0000e-04 - 3s/epoch - 345ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6599 - accuracy: 0.1857 - val_loss: 1.6596 - val_accuracy: 0.1500 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6592 - accuracy: 0.2278 - val_loss: 1.6593 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6599 - accuracy: 0.1899 - val_loss: 1.6590 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6580 - accuracy: 0.1941 - val_loss: 1.6585 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6591 - accuracy: 0.1814 - val_loss: 1.6581 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6577 - accuracy: 0.1983 - val_loss: 1.6577 - val_accuracy: 0.1667 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2700 - val_loss: 1.6573 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6553 - accuracy: 0.2489 - val_loss: 1.6569 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6551 - accuracy: 0.2278 - val_loss: 1.6565 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6553 - accuracy: 0.2363 - val_loss: 1.6561 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6549 - accuracy: 0.2194 - val_loss: 1.6558 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 41ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6531 - accuracy: 0.2447 - val_loss: 1.6555 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2321 - val_loss: 1.6552 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6544 - accuracy: 0.2152 - val_loss: 1.6549 - val_accuracy: 0.2000 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6521 - accuracy: 0.2152 - val_loss: 1.6546 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6511 - accuracy: 0.2321 - val_loss: 1.6543 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2278 - val_loss: 1.6540 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6517 - accuracy: 0.2152 - val_loss: 1.6537 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2447 - val_loss: 1.6534 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2447 - val_loss: 1.6531 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6506 - accuracy: 0.2447 - val_loss: 1.6529 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2489 - val_loss: 1.6525 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2405 - val_loss: 1.6522 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6483 - accuracy: 0.2532 - val_loss: 1.6519 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6476 - accuracy: 0.2447 - val_loss: 1.6515 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6463 - accuracy: 0.2405 - val_loss: 1.6512 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6456 - accuracy: 0.2321 - val_loss: 1.6508 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2278 - val_loss: 1.6505 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6461 - accuracy: 0.2236 - val_loss: 1.6502 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2532 - val_loss: 1.6499 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2574 - val_loss: 1.6497 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2532 - val_loss: 1.6495 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6434 - accuracy: 0.2827 - val_loss: 1.6493 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6430 - accuracy: 0.2363 - val_loss: 1.6490 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6414 - accuracy: 0.2785 - val_loss: 1.6487 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2152 - val_loss: 1.6485 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6410 - accuracy: 0.2321 - val_loss: 1.6482 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6412 - accuracy: 0.2194 - val_loss: 1.6479 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2447 - val_loss: 1.6476 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2405 - val_loss: 1.6473 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6406 - accuracy: 0.2278 - val_loss: 1.6469 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2658 - val_loss: 1.6466 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6374 - accuracy: 0.2616 - val_loss: 1.6464 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2447 - val_loss: 1.6461 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2785 - val_loss: 1.6459 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2405 - val_loss: 1.6456 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2574 - val_loss: 1.6454 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2574 - val_loss: 1.6452 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2616 - val_loss: 1.6450 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 64ms/epoch - 8ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2616 - val_loss: 1.6448 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6352 - accuracy: 0.2489 - val_loss: 1.6447 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2489 - val_loss: 1.6445 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.2869 - val_loss: 1.6443 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2616 - val_loss: 1.6442 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6323 - accuracy: 0.2321 - val_loss: 1.6440 - val_accuracy: 0.1833 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2658 - val_loss: 1.6439 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2447 - val_loss: 1.6438 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2700 - val_loss: 1.6436 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2785 - val_loss: 1.6434 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2278 - val_loss: 1.6432 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2827 - val_loss: 1.6431 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2489 - val_loss: 1.6429 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2405 - val_loss: 1.6428 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2489 - val_loss: 1.6426 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2405 - val_loss: 1.6425 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2447 - val_loss: 1.6424 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2447 - val_loss: 1.6423 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2574 - val_loss: 1.6421 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2827 - val_loss: 1.6420 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2405 - val_loss: 1.6419 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2405 - val_loss: 1.6417 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2489 - val_loss: 1.6415 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2447 - val_loss: 1.6414 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2532 - val_loss: 1.6413 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2489 - val_loss: 1.6412 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2785 - val_loss: 1.6411 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2447 - val_loss: 1.6410 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2532 - val_loss: 1.6409 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2658 - val_loss: 1.6408 - val_accuracy: 0.2167 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2658 - val_loss: 1.6408 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2405 - val_loss: 1.6408 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2405 - val_loss: 1.6408 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6261 - accuracy: 0.2068 - val_loss: 1.6408 - val_accuracy: 0.2333 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2363 - val_loss: 1.6407 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2574 - val_loss: 1.6407 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2447 - val_loss: 1.6407 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2363 - val_loss: 1.6406 - val_accuracy: 0.2500 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2785 - val_loss: 1.6406 - val_accuracy: 0.2333 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2489 - val_loss: 1.6406 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2532 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6179 - accuracy: 0.2405 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2911 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2405 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 1.2500e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2911 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 1.2500e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2405 - val_loss: 1.6405 - val_accuracy: 0.2500 - lr: 1.2500e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2278 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 6.2500e-06 - 46ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2532 - val_loss: 1.6405 - val_accuracy: 0.2333 - lr: 6.2500e-06 - 45ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2785 - val_loss: 1.6405 - val_accuracy: 0.2500 - lr: 6.2500e-06 - 45ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6186 - accuracy: 0.2658 - val_loss: 1.6405 - val_accuracy: 0.2500 - lr: 3.1250e-06 - 64ms/epoch - 8ms/step\n",
      "Node 44 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 44 - Best Validation Accuracy: 0.2833\n",
      "Best model saved for Node 44 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_44.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_45_dataset.csv\n",
      "Node 45 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6333 - accuracy: 0.1762 - val_loss: 1.6332 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 3s/epoch - 157ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6337 - accuracy: 0.1803 - val_loss: 1.6328 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6334 - accuracy: 0.1967 - val_loss: 1.6324 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2623 - val_loss: 1.6322 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2377 - val_loss: 1.6320 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.1844 - val_loss: 1.6317 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6338 - accuracy: 0.1967 - val_loss: 1.6315 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2172 - val_loss: 1.6312 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6310 - accuracy: 0.2295 - val_loss: 1.6309 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2172 - val_loss: 1.6306 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6294 - accuracy: 0.2336 - val_loss: 1.6303 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6296 - accuracy: 0.2213 - val_loss: 1.6301 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6303 - accuracy: 0.2418 - val_loss: 1.6298 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2008 - val_loss: 1.6296 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2500 - val_loss: 1.6294 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6287 - accuracy: 0.2254 - val_loss: 1.6291 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6302 - accuracy: 0.2254 - val_loss: 1.6289 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6312 - accuracy: 0.2008 - val_loss: 1.6286 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2254 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2500 - val_loss: 1.6281 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2131 - val_loss: 1.6278 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2213 - val_loss: 1.6276 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2459 - val_loss: 1.6273 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2295 - val_loss: 1.6271 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2377 - val_loss: 1.6269 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2049 - val_loss: 1.6267 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2295 - val_loss: 1.6265 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2295 - val_loss: 1.6262 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2459 - val_loss: 1.6260 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2459 - val_loss: 1.6257 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2377 - val_loss: 1.6255 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2254 - val_loss: 1.6252 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2336 - val_loss: 1.6249 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2541 - val_loss: 1.6247 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2459 - val_loss: 1.6245 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2377 - val_loss: 1.6243 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6229 - accuracy: 0.2336 - val_loss: 1.6242 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6214 - accuracy: 0.2295 - val_loss: 1.6241 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2377 - val_loss: 1.6239 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6240 - accuracy: 0.2459 - val_loss: 1.6236 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2459 - val_loss: 1.6235 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2541 - val_loss: 1.6233 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2500 - val_loss: 1.6231 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2623 - val_loss: 1.6228 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2377 - val_loss: 1.6227 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2418 - val_loss: 1.6225 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6223 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2377 - val_loss: 1.6220 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2377 - val_loss: 1.6218 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2377 - val_loss: 1.6216 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2336 - val_loss: 1.6215 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6206 - accuracy: 0.2418 - val_loss: 1.6214 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6179 - accuracy: 0.2459 - val_loss: 1.6211 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2377 - val_loss: 1.6209 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2336 - val_loss: 1.6210 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6167 - accuracy: 0.2295 - val_loss: 1.6208 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6215 - accuracy: 0.2377 - val_loss: 1.6207 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2336 - val_loss: 1.6204 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2213 - val_loss: 1.6203 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2418 - val_loss: 1.6203 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6155 - accuracy: 0.2336 - val_loss: 1.6200 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6138 - accuracy: 0.2459 - val_loss: 1.6199 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2377 - val_loss: 1.6197 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2295 - val_loss: 1.6195 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2254 - val_loss: 1.6193 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2459 - val_loss: 1.6191 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6159 - accuracy: 0.2500 - val_loss: 1.6190 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6141 - accuracy: 0.2377 - val_loss: 1.6189 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6195 - accuracy: 0.2418 - val_loss: 1.6189 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2254 - val_loss: 1.6188 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6185 - accuracy: 0.2295 - val_loss: 1.6188 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6147 - accuracy: 0.2336 - val_loss: 1.6188 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2459 - val_loss: 1.6187 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2213 - val_loss: 1.6186 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6165 - accuracy: 0.2500 - val_loss: 1.6186 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6162 - accuracy: 0.2418 - val_loss: 1.6184 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6131 - accuracy: 0.2418 - val_loss: 1.6184 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2377 - val_loss: 1.6182 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2500 - val_loss: 1.6181 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2418 - val_loss: 1.6181 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2500 - val_loss: 1.6180 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2623 - val_loss: 1.6179 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6140 - accuracy: 0.2541 - val_loss: 1.6177 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2377 - val_loss: 1.6175 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6088 - accuracy: 0.2459 - val_loss: 1.6174 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2459 - val_loss: 1.6172 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6106 - accuracy: 0.2500 - val_loss: 1.6171 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6085 - accuracy: 0.2418 - val_loss: 1.6170 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2336 - val_loss: 1.6170 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6130 - accuracy: 0.2500 - val_loss: 1.6169 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6158 - accuracy: 0.2377 - val_loss: 1.6168 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6107 - accuracy: 0.2377 - val_loss: 1.6166 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6138 - accuracy: 0.2213 - val_loss: 1.6165 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2295 - val_loss: 1.6163 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6116 - accuracy: 0.2377 - val_loss: 1.6163 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6118 - accuracy: 0.2377 - val_loss: 1.6162 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6082 - accuracy: 0.2541 - val_loss: 1.6161 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2459 - val_loss: 1.6160 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6086 - accuracy: 0.2582 - val_loss: 1.6159 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2500 - val_loss: 1.6160 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Node 45 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6350 - accuracy: 0.1885 - val_loss: 1.6346 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 3s/epoch - 360ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2336 - val_loss: 1.6344 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.1885 - val_loss: 1.6342 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2008 - val_loss: 1.6340 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2008 - val_loss: 1.6338 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6343 - accuracy: 0.1844 - val_loss: 1.6336 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6337 - accuracy: 0.2131 - val_loss: 1.6333 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2254 - val_loss: 1.6331 - val_accuracy: 0.2742 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.1803 - val_loss: 1.6329 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2213 - val_loss: 1.6326 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6325 - accuracy: 0.2418 - val_loss: 1.6324 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2049 - val_loss: 1.6322 - val_accuracy: 0.2581 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2500 - val_loss: 1.6319 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2377 - val_loss: 1.6317 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.1967 - val_loss: 1.6315 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2254 - val_loss: 1.6313 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2213 - val_loss: 1.6310 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2418 - val_loss: 1.6308 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2131 - val_loss: 1.6305 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2377 - val_loss: 1.6303 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2213 - val_loss: 1.6302 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2582 - val_loss: 1.6300 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2131 - val_loss: 1.6298 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6309 - accuracy: 0.2254 - val_loss: 1.6296 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2254 - val_loss: 1.6294 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2336 - val_loss: 1.6293 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2418 - val_loss: 1.6291 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2623 - val_loss: 1.6289 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6288 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2582 - val_loss: 1.6285 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2500 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2172 - val_loss: 1.6280 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2459 - val_loss: 1.6278 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2459 - val_loss: 1.6276 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2254 - val_loss: 1.6273 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2377 - val_loss: 1.6271 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2213 - val_loss: 1.6269 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2213 - val_loss: 1.6267 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2459 - val_loss: 1.6265 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2623 - val_loss: 1.6263 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2172 - val_loss: 1.6262 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6276 - accuracy: 0.2254 - val_loss: 1.6261 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2172 - val_loss: 1.6259 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2418 - val_loss: 1.6257 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2541 - val_loss: 1.6254 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6254 - accuracy: 0.2459 - val_loss: 1.6252 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2377 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2377 - val_loss: 1.6249 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2336 - val_loss: 1.6247 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2377 - val_loss: 1.6246 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2377 - val_loss: 1.6245 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2336 - val_loss: 1.6244 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2172 - val_loss: 1.6243 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2336 - val_loss: 1.6242 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2295 - val_loss: 1.6241 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2623 - val_loss: 1.6239 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2295 - val_loss: 1.6238 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2295 - val_loss: 1.6236 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2459 - val_loss: 1.6235 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2254 - val_loss: 1.6233 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2295 - val_loss: 1.6231 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2377 - val_loss: 1.6229 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6240 - accuracy: 0.2500 - val_loss: 1.6228 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2459 - val_loss: 1.6227 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6225 - accuracy: 0.2377 - val_loss: 1.6225 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2500 - val_loss: 1.6224 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2295 - val_loss: 1.6223 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2213 - val_loss: 1.6221 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2295 - val_loss: 1.6220 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2541 - val_loss: 1.6219 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2295 - val_loss: 1.6219 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2377 - val_loss: 1.6217 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2418 - val_loss: 1.6216 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2500 - val_loss: 1.6215 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2459 - val_loss: 1.6213 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6196 - accuracy: 0.2172 - val_loss: 1.6212 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2336 - val_loss: 1.6211 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2377 - val_loss: 1.6210 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2295 - val_loss: 1.6209 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.2254 - val_loss: 1.6209 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2295 - val_loss: 1.6208 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2459 - val_loss: 1.6207 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6151 - accuracy: 0.2213 - val_loss: 1.6206 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2295 - val_loss: 1.6204 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2336 - val_loss: 1.6203 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.2459 - val_loss: 1.6202 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2336 - val_loss: 1.6202 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6183 - accuracy: 0.2418 - val_loss: 1.6201 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6178 - accuracy: 0.2418 - val_loss: 1.6200 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2418 - val_loss: 1.6198 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2377 - val_loss: 1.6197 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6167 - accuracy: 0.2295 - val_loss: 1.6196 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6177 - accuracy: 0.2295 - val_loss: 1.6195 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6171 - accuracy: 0.2377 - val_loss: 1.6194 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2336 - val_loss: 1.6193 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2172 - val_loss: 1.6192 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2459 - val_loss: 1.6191 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2418 - val_loss: 1.6190 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6130 - accuracy: 0.2377 - val_loss: 1.6189 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6164 - accuracy: 0.2254 - val_loss: 1.6188 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 45 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6611 - accuracy: 0.1598 - val_loss: 1.6599 - val_accuracy: 0.2097 - lr: 1.0000e-04 - 3s/epoch - 157ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6591 - accuracy: 0.2049 - val_loss: 1.6585 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6577 - accuracy: 0.2254 - val_loss: 1.6573 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6574 - accuracy: 0.2254 - val_loss: 1.6564 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6550 - accuracy: 0.2623 - val_loss: 1.6555 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6565 - accuracy: 0.2131 - val_loss: 1.6547 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6545 - accuracy: 0.2500 - val_loss: 1.6540 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6542 - accuracy: 0.2295 - val_loss: 1.6532 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6527 - accuracy: 0.2459 - val_loss: 1.6525 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6518 - accuracy: 0.2582 - val_loss: 1.6516 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6510 - accuracy: 0.2213 - val_loss: 1.6509 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6503 - accuracy: 0.2295 - val_loss: 1.6500 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6499 - accuracy: 0.2459 - val_loss: 1.6493 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6486 - accuracy: 0.2500 - val_loss: 1.6487 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6498 - accuracy: 0.2213 - val_loss: 1.6481 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6482 - accuracy: 0.2336 - val_loss: 1.6474 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6461 - accuracy: 0.2377 - val_loss: 1.6467 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6467 - accuracy: 0.2295 - val_loss: 1.6463 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6464 - accuracy: 0.2377 - val_loss: 1.6457 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6456 - accuracy: 0.2336 - val_loss: 1.6451 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6418 - accuracy: 0.2418 - val_loss: 1.6445 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6444 - accuracy: 0.2336 - val_loss: 1.6439 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6442 - accuracy: 0.2336 - val_loss: 1.6436 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6448 - accuracy: 0.2336 - val_loss: 1.6429 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6427 - accuracy: 0.2336 - val_loss: 1.6424 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6434 - accuracy: 0.2418 - val_loss: 1.6417 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6406 - accuracy: 0.2377 - val_loss: 1.6411 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6422 - accuracy: 0.2295 - val_loss: 1.6408 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6380 - accuracy: 0.2295 - val_loss: 1.6403 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6393 - accuracy: 0.2418 - val_loss: 1.6398 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6398 - accuracy: 0.2336 - val_loss: 1.6392 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6379 - accuracy: 0.2336 - val_loss: 1.6388 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6372 - accuracy: 0.2377 - val_loss: 1.6385 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6365 - accuracy: 0.2336 - val_loss: 1.6382 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6368 - accuracy: 0.2254 - val_loss: 1.6379 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6372 - accuracy: 0.2377 - val_loss: 1.6375 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6369 - accuracy: 0.2336 - val_loss: 1.6369 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2377 - val_loss: 1.6365 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6367 - accuracy: 0.2336 - val_loss: 1.6359 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.2377 - val_loss: 1.6357 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6343 - accuracy: 0.2377 - val_loss: 1.6353 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6329 - accuracy: 0.2377 - val_loss: 1.6347 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6349 - accuracy: 0.2459 - val_loss: 1.6344 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6323 - accuracy: 0.2418 - val_loss: 1.6342 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2418 - val_loss: 1.6338 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6288 - accuracy: 0.2336 - val_loss: 1.6333 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2336 - val_loss: 1.6328 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6298 - accuracy: 0.2336 - val_loss: 1.6326 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6311 - accuracy: 0.2459 - val_loss: 1.6323 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2418 - val_loss: 1.6321 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 89ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6297 - accuracy: 0.2377 - val_loss: 1.6320 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2418 - val_loss: 1.6315 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2336 - val_loss: 1.6312 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6255 - accuracy: 0.2418 - val_loss: 1.6308 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2377 - val_loss: 1.6305 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6273 - accuracy: 0.2377 - val_loss: 1.6302 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6260 - accuracy: 0.2336 - val_loss: 1.6299 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6271 - accuracy: 0.2254 - val_loss: 1.6298 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6236 - accuracy: 0.2336 - val_loss: 1.6295 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6221 - accuracy: 0.2418 - val_loss: 1.6292 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2336 - val_loss: 1.6288 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2295 - val_loss: 1.6287 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6224 - accuracy: 0.2336 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6275 - accuracy: 0.2377 - val_loss: 1.6283 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2500 - val_loss: 1.6279 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6251 - accuracy: 0.2295 - val_loss: 1.6276 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6195 - accuracy: 0.2418 - val_loss: 1.6276 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2459 - val_loss: 1.6272 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2377 - val_loss: 1.6270 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6258 - accuracy: 0.2295 - val_loss: 1.6268 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2418 - val_loss: 1.6267 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 68ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2459 - val_loss: 1.6263 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2459 - val_loss: 1.6264 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6187 - accuracy: 0.2418 - val_loss: 1.6259 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2459 - val_loss: 1.6258 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2418 - val_loss: 1.6260 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6175 - accuracy: 0.2418 - val_loss: 1.6259 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6207 - accuracy: 0.2336 - val_loss: 1.6258 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6139 - accuracy: 0.2623 - val_loss: 1.6258 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6136 - accuracy: 0.2377 - val_loss: 1.6257 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6181 - accuracy: 0.2418 - val_loss: 1.6257 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2377 - val_loss: 1.6256 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2418 - val_loss: 1.6254 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2254 - val_loss: 1.6253 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2377 - val_loss: 1.6253 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6168 - accuracy: 0.2541 - val_loss: 1.6254 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6213 - accuracy: 0.2500 - val_loss: 1.6252 - val_accuracy: 0.2419 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6138 - accuracy: 0.2541 - val_loss: 1.6251 - val_accuracy: 0.2419 - lr: 2.5000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2541 - val_loss: 1.6251 - val_accuracy: 0.2419 - lr: 2.5000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6155 - accuracy: 0.2336 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 2.5000e-05 - 74ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6174 - accuracy: 0.2418 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.2623 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 1.2500e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2459 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 1.2500e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2336 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 1.2500e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6180 - accuracy: 0.2500 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 1.2500e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6116 - accuracy: 0.2705 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 6.2500e-06 - 72ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2459 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 6.2500e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6192 - accuracy: 0.2459 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 6.2500e-06 - 72ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2418 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 3.1250e-06 - 88ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6132 - accuracy: 0.2418 - val_loss: 1.6250 - val_accuracy: 0.2419 - lr: 3.1250e-06 - 70ms/epoch - 4ms/step\n",
      "Node 45 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6593 - accuracy: 0.2049 - val_loss: 1.6597 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 3s/epoch - 358ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6605 - accuracy: 0.1803 - val_loss: 1.6591 - val_accuracy: 0.1613 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6582 - accuracy: 0.2172 - val_loss: 1.6586 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2459 - val_loss: 1.6582 - val_accuracy: 0.1774 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6585 - accuracy: 0.2254 - val_loss: 1.6577 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6563 - accuracy: 0.1639 - val_loss: 1.6572 - val_accuracy: 0.1935 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2336 - val_loss: 1.6566 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2705 - val_loss: 1.6561 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 28ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6562 - accuracy: 0.2213 - val_loss: 1.6555 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6541 - accuracy: 0.2541 - val_loss: 1.6551 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6553 - accuracy: 0.2172 - val_loss: 1.6548 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2582 - val_loss: 1.6543 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 38ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6525 - accuracy: 0.2541 - val_loss: 1.6538 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6512 - accuracy: 0.2295 - val_loss: 1.6533 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6519 - accuracy: 0.2336 - val_loss: 1.6528 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2418 - val_loss: 1.6523 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2623 - val_loss: 1.6518 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6495 - accuracy: 0.2377 - val_loss: 1.6514 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6510 - accuracy: 0.2459 - val_loss: 1.6509 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6503 - accuracy: 0.2213 - val_loss: 1.6504 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6487 - accuracy: 0.2254 - val_loss: 1.6499 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6479 - accuracy: 0.2500 - val_loss: 1.6495 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6457 - accuracy: 0.2459 - val_loss: 1.6491 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2500 - val_loss: 1.6486 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2336 - val_loss: 1.6482 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2254 - val_loss: 1.6479 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6445 - accuracy: 0.2459 - val_loss: 1.6476 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2418 - val_loss: 1.6472 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6456 - accuracy: 0.2377 - val_loss: 1.6469 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6458 - accuracy: 0.2377 - val_loss: 1.6466 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2459 - val_loss: 1.6463 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2418 - val_loss: 1.6460 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2295 - val_loss: 1.6457 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6424 - accuracy: 0.2541 - val_loss: 1.6455 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2582 - val_loss: 1.6452 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6402 - accuracy: 0.2623 - val_loss: 1.6449 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6422 - accuracy: 0.2418 - val_loss: 1.6446 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2254 - val_loss: 1.6444 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6432 - accuracy: 0.2295 - val_loss: 1.6440 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6396 - accuracy: 0.2418 - val_loss: 1.6438 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2336 - val_loss: 1.6435 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6386 - accuracy: 0.2418 - val_loss: 1.6433 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6388 - accuracy: 0.2418 - val_loss: 1.6431 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6400 - accuracy: 0.2336 - val_loss: 1.6429 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6405 - accuracy: 0.2418 - val_loss: 1.6427 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2500 - val_loss: 1.6424 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6374 - accuracy: 0.2418 - val_loss: 1.6422 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6359 - accuracy: 0.2582 - val_loss: 1.6419 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6392 - accuracy: 0.2418 - val_loss: 1.6418 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6379 - accuracy: 0.2377 - val_loss: 1.6418 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2418 - val_loss: 1.6418 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 65ms/epoch - 8ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2459 - val_loss: 1.6417 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2500 - val_loss: 1.6415 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6361 - accuracy: 0.2295 - val_loss: 1.6412 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2459 - val_loss: 1.6410 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.2377 - val_loss: 1.6408 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2500 - val_loss: 1.6405 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2418 - val_loss: 1.6403 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6298 - accuracy: 0.2459 - val_loss: 1.6400 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2582 - val_loss: 1.6398 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2541 - val_loss: 1.6396 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2336 - val_loss: 1.6395 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2459 - val_loss: 1.6394 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2623 - val_loss: 1.6393 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2623 - val_loss: 1.6390 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2377 - val_loss: 1.6388 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2623 - val_loss: 1.6386 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6349 - accuracy: 0.2295 - val_loss: 1.6384 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2336 - val_loss: 1.6383 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2418 - val_loss: 1.6382 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.2172 - val_loss: 1.6380 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2459 - val_loss: 1.6378 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2500 - val_loss: 1.6376 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2459 - val_loss: 1.6374 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2254 - val_loss: 1.6372 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2418 - val_loss: 1.6370 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2336 - val_loss: 1.6369 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2336 - val_loss: 1.6367 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2500 - val_loss: 1.6366 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2664 - val_loss: 1.6365 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2459 - val_loss: 1.6364 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2623 - val_loss: 1.6362 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6201 - accuracy: 0.2541 - val_loss: 1.6361 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6162 - accuracy: 0.2705 - val_loss: 1.6361 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2377 - val_loss: 1.6360 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6230 - accuracy: 0.2623 - val_loss: 1.6358 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2213 - val_loss: 1.6357 - val_accuracy: 0.2419 - lr: 1.0000e-04 - 44ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2500 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2705 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 43ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2500 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2500 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6224 - accuracy: 0.2582 - val_loss: 1.6357 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2418 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2377 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 5.0000e-05 - 44ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6215 - accuracy: 0.2377 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2541 - val_loss: 1.6356 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 45ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2213 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 2.5000e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2336 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2541 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 46ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6216 - accuracy: 0.2623 - val_loss: 1.6355 - val_accuracy: 0.2258 - lr: 1.2500e-05 - 45ms/epoch - 6ms/step\n",
      "Node 45 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 45 - Best Validation Accuracy: 0.2742\n",
      "Best model saved for Node 45 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_45.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_46_dataset.csv\n",
      "Node 46 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6367 - accuracy: 0.2152 - val_loss: 1.6347 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 3s/epoch - 179ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6357 - accuracy: 0.2197 - val_loss: 1.6345 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6360 - accuracy: 0.2108 - val_loss: 1.6342 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6364 - accuracy: 0.2197 - val_loss: 1.6341 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6346 - accuracy: 0.2511 - val_loss: 1.6339 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6330 - accuracy: 0.2197 - val_loss: 1.6336 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2242 - val_loss: 1.6332 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6354 - accuracy: 0.2332 - val_loss: 1.6332 - val_accuracy: 0.1250 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6336 - accuracy: 0.2377 - val_loss: 1.6330 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6331 - accuracy: 0.2287 - val_loss: 1.6328 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6336 - accuracy: 0.2332 - val_loss: 1.6326 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2197 - val_loss: 1.6322 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6331 - accuracy: 0.2511 - val_loss: 1.6320 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6321 - accuracy: 0.2242 - val_loss: 1.6318 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6311 - accuracy: 0.2332 - val_loss: 1.6315 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6310 - accuracy: 0.2063 - val_loss: 1.6313 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2377 - val_loss: 1.6310 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2332 - val_loss: 1.6307 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.2332 - val_loss: 1.6303 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6295 - accuracy: 0.1973 - val_loss: 1.6301 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2018 - val_loss: 1.6298 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2197 - val_loss: 1.6295 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2377 - val_loss: 1.6290 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6285 - accuracy: 0.2556 - val_loss: 1.6288 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6287 - accuracy: 0.2197 - val_loss: 1.6285 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.1749 - val_loss: 1.6284 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6306 - accuracy: 0.2197 - val_loss: 1.6281 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6281 - accuracy: 0.2287 - val_loss: 1.6280 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6291 - accuracy: 0.2108 - val_loss: 1.6278 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6271 - accuracy: 0.2332 - val_loss: 1.6276 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6270 - accuracy: 0.2556 - val_loss: 1.6274 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6253 - accuracy: 0.2556 - val_loss: 1.6271 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2197 - val_loss: 1.6270 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6254 - accuracy: 0.2466 - val_loss: 1.6268 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2018 - val_loss: 1.6267 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2691 - val_loss: 1.6265 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6270 - accuracy: 0.2063 - val_loss: 1.6264 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6249 - accuracy: 0.2511 - val_loss: 1.6263 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6242 - accuracy: 0.2287 - val_loss: 1.6261 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6274 - accuracy: 0.2018 - val_loss: 1.6259 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6229 - accuracy: 0.2556 - val_loss: 1.6257 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6252 - accuracy: 0.1794 - val_loss: 1.6254 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2377 - val_loss: 1.6252 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6279 - accuracy: 0.2287 - val_loss: 1.6250 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6236 - accuracy: 0.2511 - val_loss: 1.6248 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.1928 - val_loss: 1.6247 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2287 - val_loss: 1.6246 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6247 - accuracy: 0.2466 - val_loss: 1.6243 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2108 - val_loss: 1.6242 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6245 - accuracy: 0.2242 - val_loss: 1.6240 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2422 - val_loss: 1.6239 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2466 - val_loss: 1.6236 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2646 - val_loss: 1.6234 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.2511 - val_loss: 1.6231 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6207 - accuracy: 0.2332 - val_loss: 1.6229 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6246 - accuracy: 0.2242 - val_loss: 1.6228 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2422 - val_loss: 1.6227 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6199 - accuracy: 0.2377 - val_loss: 1.6225 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6187 - accuracy: 0.2063 - val_loss: 1.6223 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2511 - val_loss: 1.6220 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6169 - accuracy: 0.2691 - val_loss: 1.6218 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6170 - accuracy: 0.2287 - val_loss: 1.6217 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2377 - val_loss: 1.6215 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6208 - accuracy: 0.2242 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2287 - val_loss: 1.6215 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2152 - val_loss: 1.6214 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6208 - accuracy: 0.2377 - val_loss: 1.6212 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2466 - val_loss: 1.6212 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6172 - accuracy: 0.2377 - val_loss: 1.6212 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6197 - accuracy: 0.2287 - val_loss: 1.6210 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6143 - accuracy: 0.2646 - val_loss: 1.6210 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6201 - accuracy: 0.2422 - val_loss: 1.6208 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2197 - val_loss: 1.6206 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6180 - accuracy: 0.2422 - val_loss: 1.6205 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2197 - val_loss: 1.6204 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2152 - val_loss: 1.6202 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6171 - accuracy: 0.2152 - val_loss: 1.6200 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6181 - accuracy: 0.2063 - val_loss: 1.6199 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6136 - accuracy: 0.2377 - val_loss: 1.6197 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2018 - val_loss: 1.6196 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2152 - val_loss: 1.6194 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2287 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6134 - accuracy: 0.2511 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6164 - accuracy: 0.2466 - val_loss: 1.6192 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2511 - val_loss: 1.6191 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2018 - val_loss: 1.6189 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6146 - accuracy: 0.2108 - val_loss: 1.6189 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2735 - val_loss: 1.6189 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2063 - val_loss: 1.6188 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6239 - accuracy: 0.2242 - val_loss: 1.6188 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6122 - accuracy: 0.2197 - val_loss: 1.6187 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6134 - accuracy: 0.1928 - val_loss: 1.6187 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2242 - val_loss: 1.6186 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6147 - accuracy: 0.2197 - val_loss: 1.6185 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6108 - accuracy: 0.2466 - val_loss: 1.6184 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6161 - accuracy: 0.2377 - val_loss: 1.6184 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6113 - accuracy: 0.2511 - val_loss: 1.6184 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6141 - accuracy: 0.2691 - val_loss: 1.6183 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2556 - val_loss: 1.6183 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6126 - accuracy: 0.2422 - val_loss: 1.6182 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Node 46 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6348 - accuracy: 0.1704 - val_loss: 1.6335 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 3s/epoch - 419ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.1749 - val_loss: 1.6334 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2018 - val_loss: 1.6333 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2735 - val_loss: 1.6330 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6323 - accuracy: 0.2556 - val_loss: 1.6326 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 23ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2242 - val_loss: 1.6323 - val_accuracy: 0.2679 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.2197 - val_loss: 1.6320 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6322 - accuracy: 0.2511 - val_loss: 1.6318 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2018 - val_loss: 1.6317 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2287 - val_loss: 1.6315 - val_accuracy: 0.2500 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2422 - val_loss: 1.6314 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2556 - val_loss: 1.6311 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2108 - val_loss: 1.6309 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2511 - val_loss: 1.6307 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6307 - accuracy: 0.1973 - val_loss: 1.6304 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6320 - accuracy: 0.2063 - val_loss: 1.6302 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2466 - val_loss: 1.6300 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6306 - accuracy: 0.2197 - val_loss: 1.6297 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2422 - val_loss: 1.6295 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6288 - accuracy: 0.2511 - val_loss: 1.6293 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6299 - accuracy: 0.2063 - val_loss: 1.6290 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2466 - val_loss: 1.6288 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2556 - val_loss: 1.6286 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2108 - val_loss: 1.6284 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2332 - val_loss: 1.6282 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2646 - val_loss: 1.6280 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6306 - accuracy: 0.2152 - val_loss: 1.6278 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2422 - val_loss: 1.6276 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2063 - val_loss: 1.6274 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2197 - val_loss: 1.6272 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2646 - val_loss: 1.6270 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2063 - val_loss: 1.6268 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2152 - val_loss: 1.6266 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.2466 - val_loss: 1.6264 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2287 - val_loss: 1.6262 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2287 - val_loss: 1.6261 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2108 - val_loss: 1.6260 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2152 - val_loss: 1.6258 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6304 - accuracy: 0.1973 - val_loss: 1.6258 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.1928 - val_loss: 1.6257 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6243 - accuracy: 0.2422 - val_loss: 1.6256 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2422 - val_loss: 1.6254 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6256 - accuracy: 0.2242 - val_loss: 1.6253 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2018 - val_loss: 1.6252 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2556 - val_loss: 1.6250 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6260 - accuracy: 0.2287 - val_loss: 1.6248 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2466 - val_loss: 1.6247 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 33ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2377 - val_loss: 1.6246 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6229 - accuracy: 0.2377 - val_loss: 1.6244 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2242 - val_loss: 1.6243 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 49ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2377 - val_loss: 1.6241 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6230 - accuracy: 0.2287 - val_loss: 1.6239 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6228 - accuracy: 0.1973 - val_loss: 1.6238 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2422 - val_loss: 1.6236 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2242 - val_loss: 1.6234 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2377 - val_loss: 1.6233 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2825 - val_loss: 1.6231 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2377 - val_loss: 1.6230 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6253 - accuracy: 0.2332 - val_loss: 1.6229 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2466 - val_loss: 1.6228 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6242 - accuracy: 0.2108 - val_loss: 1.6227 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2287 - val_loss: 1.6226 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6231 - accuracy: 0.2197 - val_loss: 1.6225 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6238 - accuracy: 0.2422 - val_loss: 1.6225 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6218 - accuracy: 0.1973 - val_loss: 1.6223 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2422 - val_loss: 1.6222 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2466 - val_loss: 1.6221 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6195 - accuracy: 0.2422 - val_loss: 1.6219 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2242 - val_loss: 1.6217 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6207 - accuracy: 0.2377 - val_loss: 1.6216 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6215 - accuracy: 0.2242 - val_loss: 1.6215 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6177 - accuracy: 0.2422 - val_loss: 1.6213 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2242 - val_loss: 1.6212 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6202 - accuracy: 0.2152 - val_loss: 1.6211 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2332 - val_loss: 1.6210 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6201 - accuracy: 0.2197 - val_loss: 1.6210 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6210 - accuracy: 0.2287 - val_loss: 1.6209 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6207 - accuracy: 0.2422 - val_loss: 1.6208 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6203 - accuracy: 0.2377 - val_loss: 1.6207 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2018 - val_loss: 1.6207 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2332 - val_loss: 1.6206 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2646 - val_loss: 1.6204 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2287 - val_loss: 1.6203 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2287 - val_loss: 1.6203 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2242 - val_loss: 1.6202 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6194 - accuracy: 0.2197 - val_loss: 1.6201 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6198 - accuracy: 0.2870 - val_loss: 1.6201 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6166 - accuracy: 0.2511 - val_loss: 1.6200 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2466 - val_loss: 1.6199 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6175 - accuracy: 0.2511 - val_loss: 1.6199 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6125 - accuracy: 0.2466 - val_loss: 1.6198 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6117 - accuracy: 0.2646 - val_loss: 1.6197 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2691 - val_loss: 1.6196 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6165 - accuracy: 0.2197 - val_loss: 1.6194 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2152 - val_loss: 1.6194 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2152 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2377 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2377 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2556 - val_loss: 1.6193 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2108 - val_loss: 1.6192 - val_accuracy: 0.2321 - lr: 5.0000e-05 - 49ms/epoch - 7ms/step\n",
      "Node 46 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6621 - accuracy: 0.1928 - val_loss: 1.6610 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 3s/epoch - 201ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6611 - accuracy: 0.2197 - val_loss: 1.6602 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6585 - accuracy: 0.2242 - val_loss: 1.6594 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6588 - accuracy: 0.2377 - val_loss: 1.6587 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6590 - accuracy: 0.2152 - val_loss: 1.6580 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6565 - accuracy: 0.2197 - val_loss: 1.6571 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6555 - accuracy: 0.2466 - val_loss: 1.6560 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6547 - accuracy: 0.2108 - val_loss: 1.6551 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6536 - accuracy: 0.2332 - val_loss: 1.6542 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6542 - accuracy: 0.2287 - val_loss: 1.6534 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6529 - accuracy: 0.1973 - val_loss: 1.6526 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6506 - accuracy: 0.2601 - val_loss: 1.6519 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6515 - accuracy: 0.2108 - val_loss: 1.6511 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6529 - accuracy: 0.1794 - val_loss: 1.6506 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6508 - accuracy: 0.1749 - val_loss: 1.6500 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6502 - accuracy: 0.1973 - val_loss: 1.6494 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6486 - accuracy: 0.2063 - val_loss: 1.6488 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6454 - accuracy: 0.2646 - val_loss: 1.6481 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6462 - accuracy: 0.2422 - val_loss: 1.6475 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6466 - accuracy: 0.2556 - val_loss: 1.6467 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6455 - accuracy: 0.2511 - val_loss: 1.6461 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6468 - accuracy: 0.2108 - val_loss: 1.6457 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6428 - accuracy: 0.2332 - val_loss: 1.6451 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6447 - accuracy: 0.2242 - val_loss: 1.6446 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6427 - accuracy: 0.2466 - val_loss: 1.6442 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6426 - accuracy: 0.1973 - val_loss: 1.6435 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6460 - accuracy: 0.2197 - val_loss: 1.6430 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6420 - accuracy: 0.1883 - val_loss: 1.6424 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6420 - accuracy: 0.2018 - val_loss: 1.6419 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6389 - accuracy: 0.2377 - val_loss: 1.6414 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6384 - accuracy: 0.2466 - val_loss: 1.6410 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6389 - accuracy: 0.2287 - val_loss: 1.6405 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6393 - accuracy: 0.2332 - val_loss: 1.6401 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6353 - accuracy: 0.2556 - val_loss: 1.6395 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6357 - accuracy: 0.2422 - val_loss: 1.6388 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6370 - accuracy: 0.2511 - val_loss: 1.6383 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6361 - accuracy: 0.2780 - val_loss: 1.6380 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6398 - accuracy: 0.2108 - val_loss: 1.6375 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6345 - accuracy: 0.2332 - val_loss: 1.6369 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6364 - accuracy: 0.2152 - val_loss: 1.6364 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6333 - accuracy: 0.2466 - val_loss: 1.6358 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6307 - accuracy: 0.2422 - val_loss: 1.6354 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2511 - val_loss: 1.6350 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6349 - accuracy: 0.2242 - val_loss: 1.6346 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6315 - accuracy: 0.2422 - val_loss: 1.6343 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6337 - accuracy: 0.2332 - val_loss: 1.6341 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6266 - accuracy: 0.2646 - val_loss: 1.6338 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6284 - accuracy: 0.2466 - val_loss: 1.6333 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6325 - accuracy: 0.2377 - val_loss: 1.6330 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6346 - accuracy: 0.2511 - val_loss: 1.6326 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2780 - val_loss: 1.6323 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6266 - accuracy: 0.2691 - val_loss: 1.6321 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6280 - accuracy: 0.2377 - val_loss: 1.6318 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 85ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.2601 - val_loss: 1.6314 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6248 - accuracy: 0.2287 - val_loss: 1.6309 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6281 - accuracy: 0.2915 - val_loss: 1.6304 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6291 - accuracy: 0.2780 - val_loss: 1.6301 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2601 - val_loss: 1.6301 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2466 - val_loss: 1.6296 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6231 - accuracy: 0.2735 - val_loss: 1.6292 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2332 - val_loss: 1.6291 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2466 - val_loss: 1.6287 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6278 - accuracy: 0.2466 - val_loss: 1.6282 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6217 - accuracy: 0.2422 - val_loss: 1.6280 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2780 - val_loss: 1.6278 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6248 - accuracy: 0.2422 - val_loss: 1.6276 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6227 - accuracy: 0.2556 - val_loss: 1.6274 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6256 - accuracy: 0.2377 - val_loss: 1.6272 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.2466 - val_loss: 1.6270 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6186 - accuracy: 0.2915 - val_loss: 1.6266 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2287 - val_loss: 1.6263 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.2601 - val_loss: 1.6262 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6219 - accuracy: 0.2332 - val_loss: 1.6260 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2601 - val_loss: 1.6259 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6202 - accuracy: 0.2332 - val_loss: 1.6257 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6180 - accuracy: 0.2197 - val_loss: 1.6255 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6088 - accuracy: 0.3049 - val_loss: 1.6254 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6149 - accuracy: 0.2825 - val_loss: 1.6253 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2735 - val_loss: 1.6252 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6172 - accuracy: 0.2601 - val_loss: 1.6250 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2466 - val_loss: 1.6248 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6097 - accuracy: 0.2601 - val_loss: 1.6245 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2377 - val_loss: 1.6243 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6141 - accuracy: 0.2825 - val_loss: 1.6241 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6197 - accuracy: 0.2646 - val_loss: 1.6238 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.2601 - val_loss: 1.6236 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6106 - accuracy: 0.2735 - val_loss: 1.6233 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.2601 - val_loss: 1.6231 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6140 - accuracy: 0.2556 - val_loss: 1.6227 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2287 - val_loss: 1.6226 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6109 - accuracy: 0.2825 - val_loss: 1.6224 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6102 - accuracy: 0.2601 - val_loss: 1.6225 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.3004 - val_loss: 1.6221 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6101 - accuracy: 0.2691 - val_loss: 1.6218 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6053 - accuracy: 0.2960 - val_loss: 1.6215 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6176 - accuracy: 0.2332 - val_loss: 1.6216 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6103 - accuracy: 0.3004 - val_loss: 1.6214 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6069 - accuracy: 0.2511 - val_loss: 1.6213 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6027 - accuracy: 0.2825 - val_loss: 1.6211 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6137 - accuracy: 0.2735 - val_loss: 1.6212 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Node 46 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 2s - loss: 1.6599 - accuracy: 0.1883 - val_loss: 1.6594 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 2s/epoch - 354ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6586 - accuracy: 0.2511 - val_loss: 1.6590 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6576 - accuracy: 0.2466 - val_loss: 1.6586 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6589 - accuracy: 0.2018 - val_loss: 1.6583 - val_accuracy: 0.1607 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6570 - accuracy: 0.2197 - val_loss: 1.6578 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6575 - accuracy: 0.1883 - val_loss: 1.6573 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6578 - accuracy: 0.2018 - val_loss: 1.6569 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2377 - val_loss: 1.6565 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6550 - accuracy: 0.2466 - val_loss: 1.6561 - val_accuracy: 0.1786 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6551 - accuracy: 0.2152 - val_loss: 1.6556 - val_accuracy: 0.1964 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6553 - accuracy: 0.2332 - val_loss: 1.6551 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6533 - accuracy: 0.2332 - val_loss: 1.6547 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6535 - accuracy: 0.2466 - val_loss: 1.6542 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6529 - accuracy: 0.2242 - val_loss: 1.6538 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6515 - accuracy: 0.2152 - val_loss: 1.6533 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6531 - accuracy: 0.2287 - val_loss: 1.6527 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6526 - accuracy: 0.2422 - val_loss: 1.6523 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6530 - accuracy: 0.2063 - val_loss: 1.6519 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6515 - accuracy: 0.1883 - val_loss: 1.6514 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6510 - accuracy: 0.2152 - val_loss: 1.6510 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6488 - accuracy: 0.2422 - val_loss: 1.6505 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6473 - accuracy: 0.2960 - val_loss: 1.6499 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6503 - accuracy: 0.2197 - val_loss: 1.6495 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6489 - accuracy: 0.2197 - val_loss: 1.6490 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6471 - accuracy: 0.2780 - val_loss: 1.6485 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6490 - accuracy: 0.2063 - val_loss: 1.6480 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6492 - accuracy: 0.2108 - val_loss: 1.6477 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6479 - accuracy: 0.2197 - val_loss: 1.6472 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6467 - accuracy: 0.2332 - val_loss: 1.6469 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6474 - accuracy: 0.1973 - val_loss: 1.6466 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6445 - accuracy: 0.2152 - val_loss: 1.6462 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6466 - accuracy: 0.2511 - val_loss: 1.6458 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6469 - accuracy: 0.2287 - val_loss: 1.6454 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6439 - accuracy: 0.2422 - val_loss: 1.6451 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6445 - accuracy: 0.2511 - val_loss: 1.6448 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6444 - accuracy: 0.2287 - val_loss: 1.6444 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6413 - accuracy: 0.2422 - val_loss: 1.6441 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6424 - accuracy: 0.2108 - val_loss: 1.6437 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.1928 - val_loss: 1.6434 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6414 - accuracy: 0.2422 - val_loss: 1.6431 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6399 - accuracy: 0.2422 - val_loss: 1.6427 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6428 - accuracy: 0.2108 - val_loss: 1.6424 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 48ms/epoch - 7ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6425 - accuracy: 0.2287 - val_loss: 1.6421 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6420 - accuracy: 0.2422 - val_loss: 1.6418 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6395 - accuracy: 0.2197 - val_loss: 1.6415 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6412 - accuracy: 0.2108 - val_loss: 1.6412 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.2422 - val_loss: 1.6409 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6400 - accuracy: 0.2422 - val_loss: 1.6407 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6402 - accuracy: 0.2242 - val_loss: 1.6404 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6400 - accuracy: 0.2377 - val_loss: 1.6400 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6384 - accuracy: 0.2601 - val_loss: 1.6397 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6382 - accuracy: 0.2332 - val_loss: 1.6394 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 63ms/epoch - 9ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6365 - accuracy: 0.2601 - val_loss: 1.6391 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6343 - accuracy: 0.2287 - val_loss: 1.6388 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6378 - accuracy: 0.2377 - val_loss: 1.6385 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6413 - accuracy: 0.2377 - val_loss: 1.6382 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6366 - accuracy: 0.2242 - val_loss: 1.6379 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6353 - accuracy: 0.2511 - val_loss: 1.6376 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2422 - val_loss: 1.6373 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6330 - accuracy: 0.2601 - val_loss: 1.6370 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2197 - val_loss: 1.6367 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6337 - accuracy: 0.2377 - val_loss: 1.6365 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2242 - val_loss: 1.6363 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6344 - accuracy: 0.2152 - val_loss: 1.6360 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6352 - accuracy: 0.2466 - val_loss: 1.6357 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2466 - val_loss: 1.6355 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6286 - accuracy: 0.2242 - val_loss: 1.6352 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6313 - accuracy: 0.2197 - val_loss: 1.6349 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6301 - accuracy: 0.2242 - val_loss: 1.6346 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6327 - accuracy: 0.2466 - val_loss: 1.6343 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2556 - val_loss: 1.6340 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2197 - val_loss: 1.6337 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2601 - val_loss: 1.6334 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2422 - val_loss: 1.6331 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2332 - val_loss: 1.6329 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2511 - val_loss: 1.6326 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2152 - val_loss: 1.6324 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2332 - val_loss: 1.6322 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6267 - accuracy: 0.2466 - val_loss: 1.6319 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6290 - accuracy: 0.2377 - val_loss: 1.6316 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6269 - accuracy: 0.2287 - val_loss: 1.6314 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2287 - val_loss: 1.6312 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2377 - val_loss: 1.6310 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6242 - accuracy: 0.2377 - val_loss: 1.6308 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6317 - accuracy: 0.2152 - val_loss: 1.6307 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2018 - val_loss: 1.6306 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6265 - accuracy: 0.2466 - val_loss: 1.6305 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6263 - accuracy: 0.2152 - val_loss: 1.6304 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6193 - accuracy: 0.2152 - val_loss: 1.6302 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6236 - accuracy: 0.2511 - val_loss: 1.6300 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6262 - accuracy: 0.2377 - val_loss: 1.6297 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2422 - val_loss: 1.6295 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6183 - accuracy: 0.2422 - val_loss: 1.6292 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2556 - val_loss: 1.6289 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6272 - accuracy: 0.2377 - val_loss: 1.6287 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6289 - accuracy: 0.2152 - val_loss: 1.6285 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6222 - accuracy: 0.2556 - val_loss: 1.6283 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2242 - val_loss: 1.6282 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6268 - accuracy: 0.1928 - val_loss: 1.6280 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2197 - val_loss: 1.6278 - val_accuracy: 0.2321 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Node 46 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 46 - Best Validation Accuracy: 0.2679\n",
      "Best model saved for Node 46 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_46.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_47_dataset.csv\n",
      "Node 47 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6336 - accuracy: 0.2390 - val_loss: 1.6358 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 3s/epoch - 186ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6339 - accuracy: 0.2191 - val_loss: 1.6355 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6354 - accuracy: 0.2430 - val_loss: 1.6352 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 39ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2351 - val_loss: 1.6348 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6318 - accuracy: 0.2629 - val_loss: 1.6345 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6326 - accuracy: 0.2311 - val_loss: 1.6342 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6338 - accuracy: 0.1952 - val_loss: 1.6340 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2311 - val_loss: 1.6336 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6328 - accuracy: 0.2112 - val_loss: 1.6334 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2231 - val_loss: 1.6331 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2430 - val_loss: 1.6328 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6306 - accuracy: 0.2470 - val_loss: 1.6325 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6317 - accuracy: 0.2271 - val_loss: 1.6323 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6299 - accuracy: 0.2351 - val_loss: 1.6320 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 53ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6308 - accuracy: 0.2231 - val_loss: 1.6317 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2191 - val_loss: 1.6315 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2072 - val_loss: 1.6312 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6320 - accuracy: 0.2151 - val_loss: 1.6309 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6292 - accuracy: 0.2191 - val_loss: 1.6306 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6290 - accuracy: 0.2510 - val_loss: 1.6304 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6284 - accuracy: 0.2231 - val_loss: 1.6299 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6260 - accuracy: 0.2590 - val_loss: 1.6297 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6280 - accuracy: 0.2550 - val_loss: 1.6294 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2351 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2072 - val_loss: 1.6288 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2032 - val_loss: 1.6286 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2510 - val_loss: 1.6284 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6272 - accuracy: 0.2510 - val_loss: 1.6279 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2351 - val_loss: 1.6276 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6268 - accuracy: 0.2271 - val_loss: 1.6274 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6218 - accuracy: 0.2470 - val_loss: 1.6271 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6263 - accuracy: 0.2231 - val_loss: 1.6267 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6265 - accuracy: 0.2390 - val_loss: 1.6264 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2629 - val_loss: 1.6261 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2191 - val_loss: 1.6259 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6264 - accuracy: 0.2271 - val_loss: 1.6257 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2510 - val_loss: 1.6255 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2510 - val_loss: 1.6253 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2390 - val_loss: 1.6251 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2590 - val_loss: 1.6249 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6216 - accuracy: 0.2669 - val_loss: 1.6246 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6191 - accuracy: 0.2669 - val_loss: 1.6244 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6248 - accuracy: 0.2550 - val_loss: 1.6242 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6231 - accuracy: 0.2231 - val_loss: 1.6241 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6253 - accuracy: 0.2112 - val_loss: 1.6239 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6245 - accuracy: 0.2271 - val_loss: 1.6238 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2231 - val_loss: 1.6235 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2669 - val_loss: 1.6235 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6219 - accuracy: 0.2390 - val_loss: 1.6233 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6239 - accuracy: 0.2351 - val_loss: 1.6231 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6208 - accuracy: 0.2231 - val_loss: 1.6229 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6223 - accuracy: 0.2390 - val_loss: 1.6227 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6217 - accuracy: 0.2271 - val_loss: 1.6225 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6200 - accuracy: 0.2311 - val_loss: 1.6225 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2390 - val_loss: 1.6223 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2709 - val_loss: 1.6222 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6210 - accuracy: 0.2231 - val_loss: 1.6221 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6133 - accuracy: 0.2510 - val_loss: 1.6219 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6182 - accuracy: 0.2709 - val_loss: 1.6216 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2510 - val_loss: 1.6214 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6205 - accuracy: 0.2351 - val_loss: 1.6213 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6189 - accuracy: 0.2590 - val_loss: 1.6211 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2669 - val_loss: 1.6210 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2390 - val_loss: 1.6210 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6198 - accuracy: 0.2390 - val_loss: 1.6208 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6190 - accuracy: 0.2590 - val_loss: 1.6207 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2351 - val_loss: 1.6206 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6173 - accuracy: 0.2351 - val_loss: 1.6204 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2311 - val_loss: 1.6203 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2430 - val_loss: 1.6203 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2430 - val_loss: 1.6201 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6197 - accuracy: 0.2390 - val_loss: 1.6201 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6169 - accuracy: 0.2390 - val_loss: 1.6200 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6179 - accuracy: 0.2191 - val_loss: 1.6200 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2351 - val_loss: 1.6198 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2749 - val_loss: 1.6197 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6170 - accuracy: 0.2311 - val_loss: 1.6196 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 1.6109 - accuracy: 0.2470 - val_loss: 1.6195 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6156 - accuracy: 0.2510 - val_loss: 1.6194 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6184 - accuracy: 0.2669 - val_loss: 1.6192 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2470 - val_loss: 1.6191 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2629 - val_loss: 1.6190 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 1.6095 - accuracy: 0.2669 - val_loss: 1.6189 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6161 - accuracy: 0.2629 - val_loss: 1.6188 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6134 - accuracy: 0.2749 - val_loss: 1.6186 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2709 - val_loss: 1.6185 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2550 - val_loss: 1.6184 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6146 - accuracy: 0.2470 - val_loss: 1.6182 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6115 - accuracy: 0.2430 - val_loss: 1.6181 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2430 - val_loss: 1.6180 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6151 - accuracy: 0.2590 - val_loss: 1.6179 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 1.6126 - accuracy: 0.2629 - val_loss: 1.6179 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6129 - accuracy: 0.2311 - val_loss: 1.6179 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6114 - accuracy: 0.2510 - val_loss: 1.6178 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2390 - val_loss: 1.6176 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6121 - accuracy: 0.2789 - val_loss: 1.6175 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6079 - accuracy: 0.2669 - val_loss: 1.6175 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 1.6105 - accuracy: 0.2590 - val_loss: 1.6175 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6102 - accuracy: 0.2749 - val_loss: 1.6174 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 1.6073 - accuracy: 0.2709 - val_loss: 1.6174 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 68ms/epoch - 4ms/step\n",
      "Node 47 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6345 - accuracy: 0.1912 - val_loss: 1.6350 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 3s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6355 - accuracy: 0.1833 - val_loss: 1.6348 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6344 - accuracy: 0.2072 - val_loss: 1.6346 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2311 - val_loss: 1.6343 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6333 - accuracy: 0.2430 - val_loss: 1.6341 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2151 - val_loss: 1.6338 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2311 - val_loss: 1.6336 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2390 - val_loss: 1.6333 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2271 - val_loss: 1.6331 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6331 - accuracy: 0.2072 - val_loss: 1.6329 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.1952 - val_loss: 1.6327 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2510 - val_loss: 1.6325 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6327 - accuracy: 0.2550 - val_loss: 1.6324 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2072 - val_loss: 1.6322 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2072 - val_loss: 1.6321 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2271 - val_loss: 1.6319 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2908 - val_loss: 1.6317 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6314 - accuracy: 0.2470 - val_loss: 1.6316 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2191 - val_loss: 1.6314 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6315 - accuracy: 0.2311 - val_loss: 1.6313 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2191 - val_loss: 1.6311 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2470 - val_loss: 1.6309 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6289 - accuracy: 0.2311 - val_loss: 1.6307 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2510 - val_loss: 1.6305 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2510 - val_loss: 1.6302 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6318 - accuracy: 0.2151 - val_loss: 1.6300 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2311 - val_loss: 1.6299 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6296 - accuracy: 0.2311 - val_loss: 1.6297 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2271 - val_loss: 1.6296 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6270 - accuracy: 0.2430 - val_loss: 1.6294 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 33ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2032 - val_loss: 1.6292 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6317 - accuracy: 0.2311 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2470 - val_loss: 1.6289 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2191 - val_loss: 1.6287 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6259 - accuracy: 0.2470 - val_loss: 1.6286 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2550 - val_loss: 1.6284 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2629 - val_loss: 1.6283 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2629 - val_loss: 1.6281 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2271 - val_loss: 1.6280 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2271 - val_loss: 1.6278 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2390 - val_loss: 1.6276 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2550 - val_loss: 1.6274 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2390 - val_loss: 1.6273 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.2590 - val_loss: 1.6271 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2550 - val_loss: 1.6270 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2390 - val_loss: 1.6268 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6275 - accuracy: 0.2112 - val_loss: 1.6267 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2390 - val_loss: 1.6265 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6269 - accuracy: 0.2669 - val_loss: 1.6264 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2550 - val_loss: 1.6262 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2311 - val_loss: 1.6261 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2550 - val_loss: 1.6260 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2470 - val_loss: 1.6259 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6222 - accuracy: 0.2749 - val_loss: 1.6258 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2709 - val_loss: 1.6256 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2231 - val_loss: 1.6255 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6204 - accuracy: 0.2390 - val_loss: 1.6253 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2390 - val_loss: 1.6253 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2629 - val_loss: 1.6252 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2470 - val_loss: 1.6251 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.3068 - val_loss: 1.6250 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2470 - val_loss: 1.6249 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2510 - val_loss: 1.6247 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2510 - val_loss: 1.6246 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6194 - accuracy: 0.2311 - val_loss: 1.6245 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2430 - val_loss: 1.6243 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2709 - val_loss: 1.6241 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2470 - val_loss: 1.6239 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2629 - val_loss: 1.6237 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2390 - val_loss: 1.6235 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6263 - accuracy: 0.2430 - val_loss: 1.6234 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2231 - val_loss: 1.6232 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6170 - accuracy: 0.2709 - val_loss: 1.6231 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6253 - accuracy: 0.2390 - val_loss: 1.6229 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2311 - val_loss: 1.6228 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6202 - accuracy: 0.2430 - val_loss: 1.6227 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2470 - val_loss: 1.6225 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2669 - val_loss: 1.6225 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6193 - accuracy: 0.2470 - val_loss: 1.6224 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2351 - val_loss: 1.6223 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2112 - val_loss: 1.6222 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6197 - accuracy: 0.2550 - val_loss: 1.6221 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6192 - accuracy: 0.2749 - val_loss: 1.6219 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2351 - val_loss: 1.6218 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6212 - accuracy: 0.2550 - val_loss: 1.6217 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2510 - val_loss: 1.6217 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2390 - val_loss: 1.6215 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6203 - accuracy: 0.2789 - val_loss: 1.6214 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6199 - accuracy: 0.2151 - val_loss: 1.6213 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6172 - accuracy: 0.2550 - val_loss: 1.6212 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6189 - accuracy: 0.2390 - val_loss: 1.6212 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2510 - val_loss: 1.6211 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6185 - accuracy: 0.2430 - val_loss: 1.6210 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6169 - accuracy: 0.2908 - val_loss: 1.6210 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6152 - accuracy: 0.2629 - val_loss: 1.6209 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6182 - accuracy: 0.2590 - val_loss: 1.6208 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6157 - accuracy: 0.2749 - val_loss: 1.6207 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6221 - accuracy: 0.2430 - val_loss: 1.6206 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6147 - accuracy: 0.2430 - val_loss: 1.6204 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6165 - accuracy: 0.2829 - val_loss: 1.6203 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Node 47 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 3s - loss: 1.6607 - accuracy: 0.1554 - val_loss: 1.6596 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 3s/epoch - 186ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 1.6594 - accuracy: 0.1713 - val_loss: 1.6588 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 1.6584 - accuracy: 0.2271 - val_loss: 1.6579 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 1.6560 - accuracy: 0.2191 - val_loss: 1.6571 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 1.6561 - accuracy: 0.2151 - val_loss: 1.6564 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 50ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 1.6554 - accuracy: 0.2390 - val_loss: 1.6554 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 1.6541 - accuracy: 0.2390 - val_loss: 1.6549 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 1.6527 - accuracy: 0.2470 - val_loss: 1.6542 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 1.6532 - accuracy: 0.2351 - val_loss: 1.6535 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 1.6525 - accuracy: 0.2151 - val_loss: 1.6528 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 1.6491 - accuracy: 0.2669 - val_loss: 1.6519 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 1.6483 - accuracy: 0.2231 - val_loss: 1.6512 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 1.6496 - accuracy: 0.2510 - val_loss: 1.6506 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 1.6479 - accuracy: 0.2390 - val_loss: 1.6500 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 1.6462 - accuracy: 0.2669 - val_loss: 1.6494 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 1.6484 - accuracy: 0.2112 - val_loss: 1.6489 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 1.6456 - accuracy: 0.2311 - val_loss: 1.6485 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 1.6467 - accuracy: 0.2470 - val_loss: 1.6479 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 1.6442 - accuracy: 0.2390 - val_loss: 1.6473 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 1.6445 - accuracy: 0.2151 - val_loss: 1.6466 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 1.6454 - accuracy: 0.2390 - val_loss: 1.6461 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 1.6433 - accuracy: 0.2151 - val_loss: 1.6455 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 1.6436 - accuracy: 0.2470 - val_loss: 1.6451 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 1.6412 - accuracy: 0.2311 - val_loss: 1.6445 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 1.6413 - accuracy: 0.2510 - val_loss: 1.6439 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 1.6433 - accuracy: 0.2430 - val_loss: 1.6435 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 1.6392 - accuracy: 0.2311 - val_loss: 1.6430 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 1.6361 - accuracy: 0.2749 - val_loss: 1.6423 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 1.6366 - accuracy: 0.2709 - val_loss: 1.6417 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 1.6373 - accuracy: 0.2590 - val_loss: 1.6411 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 1.6352 - accuracy: 0.2470 - val_loss: 1.6406 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 1.6374 - accuracy: 0.2351 - val_loss: 1.6400 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 1.6356 - accuracy: 0.2789 - val_loss: 1.6396 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 1.6353 - accuracy: 0.2351 - val_loss: 1.6392 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 1.6365 - accuracy: 0.2271 - val_loss: 1.6390 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 1.6319 - accuracy: 0.2749 - val_loss: 1.6386 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 92ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.3108 - val_loss: 1.6383 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 1.6332 - accuracy: 0.2550 - val_loss: 1.6379 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 1.6333 - accuracy: 0.2430 - val_loss: 1.6377 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 1.6301 - accuracy: 0.2231 - val_loss: 1.6374 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 1.6299 - accuracy: 0.2669 - val_loss: 1.6371 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 1.6316 - accuracy: 0.2590 - val_loss: 1.6367 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 1.6325 - accuracy: 0.2390 - val_loss: 1.6364 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 1.6330 - accuracy: 0.2789 - val_loss: 1.6361 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 1.6281 - accuracy: 0.2789 - val_loss: 1.6358 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 1.6274 - accuracy: 0.2829 - val_loss: 1.6354 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 1.6282 - accuracy: 0.2709 - val_loss: 1.6352 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2908 - val_loss: 1.6352 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 1.6285 - accuracy: 0.2430 - val_loss: 1.6346 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 1.6314 - accuracy: 0.2590 - val_loss: 1.6343 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 1.6254 - accuracy: 0.2908 - val_loss: 1.6341 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 1.6278 - accuracy: 0.2749 - val_loss: 1.6339 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 1.6227 - accuracy: 0.2590 - val_loss: 1.6338 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 1.6262 - accuracy: 0.2510 - val_loss: 1.6335 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 1.6222 - accuracy: 0.2550 - val_loss: 1.6333 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 1.6211 - accuracy: 0.2709 - val_loss: 1.6331 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 1.6249 - accuracy: 0.2430 - val_loss: 1.6328 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 1.6234 - accuracy: 0.2629 - val_loss: 1.6325 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 1.6238 - accuracy: 0.2510 - val_loss: 1.6322 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 1.6277 - accuracy: 0.2470 - val_loss: 1.6319 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 1.6244 - accuracy: 0.2629 - val_loss: 1.6316 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 1.6256 - accuracy: 0.2390 - val_loss: 1.6314 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 1.6188 - accuracy: 0.2749 - val_loss: 1.6311 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.3028 - val_loss: 1.6310 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 1.6209 - accuracy: 0.2669 - val_loss: 1.6309 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 1.6204 - accuracy: 0.2590 - val_loss: 1.6309 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 1.6232 - accuracy: 0.2829 - val_loss: 1.6309 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 69ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 1.6177 - accuracy: 0.2749 - val_loss: 1.6304 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 1.6230 - accuracy: 0.2470 - val_loss: 1.6305 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 1.6260 - accuracy: 0.2271 - val_loss: 1.6302 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 1.6176 - accuracy: 0.2709 - val_loss: 1.6298 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2789 - val_loss: 1.6296 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 1.6237 - accuracy: 0.2669 - val_loss: 1.6296 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 1.6149 - accuracy: 0.2430 - val_loss: 1.6296 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 1.6164 - accuracy: 0.2829 - val_loss: 1.6293 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2550 - val_loss: 1.6296 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 70ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2789 - val_loss: 1.6294 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 71ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "16/16 - 0s - loss: 1.6196 - accuracy: 0.2709 - val_loss: 1.6292 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 1.6135 - accuracy: 0.2590 - val_loss: 1.6292 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 1.6148 - accuracy: 0.2789 - val_loss: 1.6292 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 1.6154 - accuracy: 0.2869 - val_loss: 1.6292 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 1.6157 - accuracy: 0.2709 - val_loss: 1.6291 - val_accuracy: 0.2063 - lr: 5.0000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "16/16 - 0s - loss: 1.6166 - accuracy: 0.2590 - val_loss: 1.6292 - val_accuracy: 0.2222 - lr: 5.0000e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 1.6184 - accuracy: 0.2789 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 68ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 1.6183 - accuracy: 0.2470 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 70ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "16/16 - 0s - loss: 1.6193 - accuracy: 0.2629 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 2.5000e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2629 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 91ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 1.6099 - accuracy: 0.2869 - val_loss: 1.6291 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 69ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 1.6127 - accuracy: 0.2829 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 1.6137 - accuracy: 0.2869 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 73ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 1.6172 - accuracy: 0.2470 - val_loss: 1.6290 - val_accuracy: 0.2222 - lr: 1.2500e-05 - 71ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "16/16 - 0s - loss: 1.6153 - accuracy: 0.2669 - val_loss: 1.6291 - val_accuracy: 0.2381 - lr: 1.2500e-05 - 72ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 1.6199 - accuracy: 0.2510 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 70ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 1.6125 - accuracy: 0.2550 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 71ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "16/16 - 0s - loss: 1.6143 - accuracy: 0.2948 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 6.2500e-06 - 71ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2789 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 3.1250e-06 - 72ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 1.6142 - accuracy: 0.2590 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 3.1250e-06 - 71ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "16/16 - 0s - loss: 1.6150 - accuracy: 0.2550 - val_loss: 1.6290 - val_accuracy: 0.2381 - lr: 3.1250e-06 - 72ms/epoch - 5ms/step\n",
      "Node 47 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6599 - accuracy: 0.2351 - val_loss: 1.6601 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 3s/epoch - 313ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6598 - accuracy: 0.1833 - val_loss: 1.6596 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6597 - accuracy: 0.1633 - val_loss: 1.6592 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6598 - accuracy: 0.1793 - val_loss: 1.6587 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6585 - accuracy: 0.1633 - val_loss: 1.6581 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6566 - accuracy: 0.2231 - val_loss: 1.6576 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 34ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6572 - accuracy: 0.1992 - val_loss: 1.6571 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2430 - val_loss: 1.6566 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2271 - val_loss: 1.6559 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6570 - accuracy: 0.1833 - val_loss: 1.6554 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6552 - accuracy: 0.1912 - val_loss: 1.6548 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6550 - accuracy: 0.2151 - val_loss: 1.6543 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 39ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6538 - accuracy: 0.2231 - val_loss: 1.6539 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6536 - accuracy: 0.2430 - val_loss: 1.6533 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6530 - accuracy: 0.2390 - val_loss: 1.6527 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6521 - accuracy: 0.2430 - val_loss: 1.6522 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2629 - val_loss: 1.6516 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6507 - accuracy: 0.2629 - val_loss: 1.6511 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.2311 - val_loss: 1.6506 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6494 - accuracy: 0.3187 - val_loss: 1.6502 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6497 - accuracy: 0.2550 - val_loss: 1.6496 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2470 - val_loss: 1.6492 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6482 - accuracy: 0.2311 - val_loss: 1.6486 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6475 - accuracy: 0.2311 - val_loss: 1.6480 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6475 - accuracy: 0.2271 - val_loss: 1.6476 - val_accuracy: 0.1587 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6453 - accuracy: 0.2311 - val_loss: 1.6471 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6477 - accuracy: 0.2231 - val_loss: 1.6467 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6470 - accuracy: 0.2191 - val_loss: 1.6464 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6462 - accuracy: 0.2470 - val_loss: 1.6460 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 52ms/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6452 - accuracy: 0.2151 - val_loss: 1.6455 - val_accuracy: 0.2540 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6451 - accuracy: 0.2311 - val_loss: 1.6451 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6420 - accuracy: 0.2590 - val_loss: 1.6447 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.1992 - val_loss: 1.6442 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2351 - val_loss: 1.6438 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6446 - accuracy: 0.2311 - val_loss: 1.6434 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6442 - accuracy: 0.2430 - val_loss: 1.6431 - val_accuracy: 0.2381 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2988 - val_loss: 1.6427 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6425 - accuracy: 0.2869 - val_loss: 1.6423 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6427 - accuracy: 0.2191 - val_loss: 1.6419 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6399 - accuracy: 0.2669 - val_loss: 1.6416 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6396 - accuracy: 0.2669 - val_loss: 1.6412 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6417 - accuracy: 0.2789 - val_loss: 1.6408 - val_accuracy: 0.2222 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6404 - accuracy: 0.2271 - val_loss: 1.6405 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2271 - val_loss: 1.6402 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2351 - val_loss: 1.6399 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2590 - val_loss: 1.6395 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2669 - val_loss: 1.6392 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6385 - accuracy: 0.2430 - val_loss: 1.6388 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6383 - accuracy: 0.2191 - val_loss: 1.6385 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6373 - accuracy: 0.2390 - val_loss: 1.6381 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6362 - accuracy: 0.2629 - val_loss: 1.6378 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2789 - val_loss: 1.6374 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 66ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6345 - accuracy: 0.2510 - val_loss: 1.6371 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2590 - val_loss: 1.6368 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2869 - val_loss: 1.6366 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6358 - accuracy: 0.2390 - val_loss: 1.6362 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6350 - accuracy: 0.2669 - val_loss: 1.6360 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2749 - val_loss: 1.6357 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6365 - accuracy: 0.2311 - val_loss: 1.6354 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6363 - accuracy: 0.2590 - val_loss: 1.6351 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2351 - val_loss: 1.6349 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2908 - val_loss: 1.6346 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6353 - accuracy: 0.2390 - val_loss: 1.6344 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2390 - val_loss: 1.6342 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2908 - val_loss: 1.6340 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2311 - val_loss: 1.6338 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2709 - val_loss: 1.6335 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6305 - accuracy: 0.2669 - val_loss: 1.6333 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6294 - accuracy: 0.2510 - val_loss: 1.6330 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2988 - val_loss: 1.6328 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6304 - accuracy: 0.2948 - val_loss: 1.6326 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6307 - accuracy: 0.2590 - val_loss: 1.6324 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2470 - val_loss: 1.6322 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6334 - accuracy: 0.2510 - val_loss: 1.6320 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6308 - accuracy: 0.2430 - val_loss: 1.6317 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2112 - val_loss: 1.6315 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6302 - accuracy: 0.2550 - val_loss: 1.6313 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6312 - accuracy: 0.2390 - val_loss: 1.6310 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.2829 - val_loss: 1.6308 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6272 - accuracy: 0.2351 - val_loss: 1.6305 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6291 - accuracy: 0.2112 - val_loss: 1.6304 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2550 - val_loss: 1.6302 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6237 - accuracy: 0.2669 - val_loss: 1.6301 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6264 - accuracy: 0.2390 - val_loss: 1.6298 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6252 - accuracy: 0.2749 - val_loss: 1.6296 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2550 - val_loss: 1.6294 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2749 - val_loss: 1.6291 - val_accuracy: 0.1746 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2430 - val_loss: 1.6290 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2470 - val_loss: 1.6288 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2629 - val_loss: 1.6287 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2869 - val_loss: 1.6285 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6214 - accuracy: 0.2470 - val_loss: 1.6282 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2191 - val_loss: 1.6281 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2231 - val_loss: 1.6279 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2789 - val_loss: 1.6277 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2829 - val_loss: 1.6276 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2510 - val_loss: 1.6275 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6233 - accuracy: 0.2669 - val_loss: 1.6273 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2669 - val_loss: 1.6271 - val_accuracy: 0.2063 - lr: 1.0000e-04 - 52ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2550 - val_loss: 1.6269 - val_accuracy: 0.1905 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Node 47 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 47 - Best Validation Accuracy: 0.2540\n",
      "Best model saved for Node 47 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_47.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_48_dataset.csv\n",
      "Node 48 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 3s - loss: 1.6348 - accuracy: 0.2155 - val_loss: 1.6344 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 3s/epoch - 168ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6353 - accuracy: 0.2241 - val_loss: 1.6342 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6348 - accuracy: 0.1810 - val_loss: 1.6339 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6345 - accuracy: 0.2155 - val_loss: 1.6337 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6344 - accuracy: 0.2026 - val_loss: 1.6335 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.1983 - val_loss: 1.6333 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6338 - accuracy: 0.2155 - val_loss: 1.6330 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6330 - accuracy: 0.2155 - val_loss: 1.6328 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6326 - accuracy: 0.2284 - val_loss: 1.6325 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6328 - accuracy: 0.2457 - val_loss: 1.6323 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6328 - accuracy: 0.2457 - val_loss: 1.6322 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6313 - accuracy: 0.2284 - val_loss: 1.6321 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6321 - accuracy: 0.2112 - val_loss: 1.6318 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6300 - accuracy: 0.2931 - val_loss: 1.6316 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6310 - accuracy: 0.2543 - val_loss: 1.6314 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6295 - accuracy: 0.2328 - val_loss: 1.6312 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2500 - val_loss: 1.6310 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.2629 - val_loss: 1.6308 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6297 - accuracy: 0.2414 - val_loss: 1.6306 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6299 - accuracy: 0.2155 - val_loss: 1.6304 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6286 - accuracy: 0.2716 - val_loss: 1.6302 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6290 - accuracy: 0.2155 - val_loss: 1.6301 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6287 - accuracy: 0.2371 - val_loss: 1.6299 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6294 - accuracy: 0.2371 - val_loss: 1.6299 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2845 - val_loss: 1.6297 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6284 - accuracy: 0.2500 - val_loss: 1.6294 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6293 - accuracy: 0.2457 - val_loss: 1.6291 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6271 - accuracy: 0.2716 - val_loss: 1.6287 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6280 - accuracy: 0.2672 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6255 - accuracy: 0.2629 - val_loss: 1.6285 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2284 - val_loss: 1.6283 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2371 - val_loss: 1.6282 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6240 - accuracy: 0.3060 - val_loss: 1.6280 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6262 - accuracy: 0.2414 - val_loss: 1.6277 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6258 - accuracy: 0.2284 - val_loss: 1.6276 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6242 - accuracy: 0.2629 - val_loss: 1.6275 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6273 - accuracy: 0.2069 - val_loss: 1.6273 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2888 - val_loss: 1.6271 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.2371 - val_loss: 1.6268 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6226 - accuracy: 0.2500 - val_loss: 1.6267 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2543 - val_loss: 1.6265 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6221 - accuracy: 0.2543 - val_loss: 1.6263 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.2414 - val_loss: 1.6261 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6237 - accuracy: 0.2414 - val_loss: 1.6260 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6234 - accuracy: 0.3147 - val_loss: 1.6260 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2457 - val_loss: 1.6259 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2586 - val_loss: 1.6257 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6227 - accuracy: 0.2457 - val_loss: 1.6256 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2543 - val_loss: 1.6255 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6235 - accuracy: 0.2198 - val_loss: 1.6253 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2586 - val_loss: 1.6253 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "15/15 - 0s - loss: 1.6214 - accuracy: 0.2371 - val_loss: 1.6252 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2069 - val_loss: 1.6251 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6216 - accuracy: 0.2802 - val_loss: 1.6250 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "15/15 - 0s - loss: 1.6219 - accuracy: 0.2802 - val_loss: 1.6250 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2543 - val_loss: 1.6250 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "15/15 - 0s - loss: 1.6197 - accuracy: 0.2371 - val_loss: 1.6250 - val_accuracy: 0.1724 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "15/15 - 0s - loss: 1.6191 - accuracy: 0.3017 - val_loss: 1.6250 - val_accuracy: 0.1724 - lr: 5.0000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "15/15 - 0s - loss: 1.6208 - accuracy: 0.2629 - val_loss: 1.6249 - val_accuracy: 0.1724 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "15/15 - 0s - loss: 1.6177 - accuracy: 0.2845 - val_loss: 1.6249 - val_accuracy: 0.1724 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "15/15 - 0s - loss: 1.6180 - accuracy: 0.2672 - val_loss: 1.6249 - val_accuracy: 0.1897 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "15/15 - 0s - loss: 1.6218 - accuracy: 0.2457 - val_loss: 1.6248 - val_accuracy: 0.1552 - lr: 5.0000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "15/15 - 0s - loss: 1.6182 - accuracy: 0.2586 - val_loss: 1.6247 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "15/15 - 0s - loss: 1.6201 - accuracy: 0.2759 - val_loss: 1.6247 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "15/15 - 0s - loss: 1.6207 - accuracy: 0.2414 - val_loss: 1.6246 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "15/15 - 0s - loss: 1.6169 - accuracy: 0.2716 - val_loss: 1.6246 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "15/15 - 0s - loss: 1.6138 - accuracy: 0.3017 - val_loss: 1.6246 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6209 - accuracy: 0.2629 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "15/15 - 0s - loss: 1.6187 - accuracy: 0.3017 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "15/15 - 0s - loss: 1.6170 - accuracy: 0.2716 - val_loss: 1.6245 - val_accuracy: 0.1897 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "15/15 - 0s - loss: 1.6185 - accuracy: 0.2759 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "15/15 - 0s - loss: 1.6206 - accuracy: 0.2371 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2629 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6203 - accuracy: 0.2716 - val_loss: 1.6245 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "15/15 - 0s - loss: 1.6162 - accuracy: 0.2974 - val_loss: 1.6244 - val_accuracy: 0.2069 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "15/15 - 0s - loss: 1.6194 - accuracy: 0.2888 - val_loss: 1.6244 - val_accuracy: 0.2069 - lr: 1.2500e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "15/15 - 0s - loss: 1.6178 - accuracy: 0.2500 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 1.2500e-05 - 45ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "15/15 - 0s - loss: 1.6196 - accuracy: 0.2284 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 6.2500e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "15/15 - 0s - loss: 1.6181 - accuracy: 0.2931 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 6.2500e-06 - 45ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "15/15 - 0s - loss: 1.6152 - accuracy: 0.3276 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 6.2500e-06 - 44ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "15/15 - 0s - loss: 1.6186 - accuracy: 0.2845 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 3.1250e-06 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "15/15 - 0s - loss: 1.6195 - accuracy: 0.2974 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 3.1250e-06 - 46ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "15/15 - 0s - loss: 1.6179 - accuracy: 0.2543 - val_loss: 1.6244 - val_accuracy: 0.1897 - lr: 3.1250e-06 - 46ms/epoch - 3ms/step\n",
      "Node 48 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6333 - accuracy: 0.2241 - val_loss: 1.6344 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 3s/epoch - 349ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6336 - accuracy: 0.1767 - val_loss: 1.6343 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6330 - accuracy: 0.2241 - val_loss: 1.6342 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6328 - accuracy: 0.2112 - val_loss: 1.6340 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2371 - val_loss: 1.6338 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6324 - accuracy: 0.2198 - val_loss: 1.6337 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6326 - accuracy: 0.2500 - val_loss: 1.6336 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.1983 - val_loss: 1.6334 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6322 - accuracy: 0.2112 - val_loss: 1.6333 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 27ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6321 - accuracy: 0.2155 - val_loss: 1.6332 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 26ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2414 - val_loss: 1.6331 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 25ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2500 - val_loss: 1.6330 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.2500 - val_loss: 1.6329 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2543 - val_loss: 1.6328 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6311 - accuracy: 0.2371 - val_loss: 1.6327 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2026 - val_loss: 1.6326 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6306 - accuracy: 0.2543 - val_loss: 1.6325 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6310 - accuracy: 0.2155 - val_loss: 1.6324 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2241 - val_loss: 1.6322 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2586 - val_loss: 1.6322 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6297 - accuracy: 0.1983 - val_loss: 1.6320 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6295 - accuracy: 0.2457 - val_loss: 1.6319 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2328 - val_loss: 1.6318 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 35ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.2241 - val_loss: 1.6317 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2500 - val_loss: 1.6315 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6292 - accuracy: 0.2026 - val_loss: 1.6314 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6278 - accuracy: 0.2069 - val_loss: 1.6313 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2284 - val_loss: 1.6312 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6284 - accuracy: 0.2284 - val_loss: 1.6311 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6286 - accuracy: 0.2112 - val_loss: 1.6310 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6303 - accuracy: 0.1897 - val_loss: 1.6308 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2371 - val_loss: 1.6307 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6290 - accuracy: 0.2026 - val_loss: 1.6305 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6283 - accuracy: 0.2284 - val_loss: 1.6304 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2672 - val_loss: 1.6303 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2069 - val_loss: 1.6302 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6287 - accuracy: 0.1767 - val_loss: 1.6301 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6281 - accuracy: 0.1810 - val_loss: 1.6299 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6248 - accuracy: 0.2629 - val_loss: 1.6297 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6247 - accuracy: 0.2241 - val_loss: 1.6296 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.2026 - val_loss: 1.6296 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6299 - accuracy: 0.1810 - val_loss: 1.6295 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6258 - accuracy: 0.2500 - val_loss: 1.6295 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2284 - val_loss: 1.6294 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 32ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2112 - val_loss: 1.6293 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2672 - val_loss: 1.6292 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2284 - val_loss: 1.6291 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2629 - val_loss: 1.6290 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2112 - val_loss: 1.6289 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2716 - val_loss: 1.6289 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2543 - val_loss: 1.6289 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6238 - accuracy: 0.2284 - val_loss: 1.6288 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6250 - accuracy: 0.2284 - val_loss: 1.6288 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2586 - val_loss: 1.6288 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2155 - val_loss: 1.6288 - val_accuracy: 0.2069 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6257 - accuracy: 0.2241 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2155 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 5.0000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2198 - val_loss: 1.6287 - val_accuracy: 0.2241 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2931 - val_loss: 1.6287 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2543 - val_loss: 1.6287 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2543 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2241 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 29ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "8/8 - 0s - loss: 1.6220 - accuracy: 0.2543 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 2.5000e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2026 - val_loss: 1.6286 - val_accuracy: 0.2069 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.3017 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.2500e-05 - 30ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "8/8 - 0s - loss: 1.6235 - accuracy: 0.2284 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.2500e-05 - 31ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2328 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 6.2500e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6226 - accuracy: 0.2586 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2586 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 6.2500e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2328 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.1250e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2457 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.1250e-06 - 30ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2414 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.1250e-06 - 32ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2802 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2543 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.1767 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.5625e-06 - 31ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6205 - accuracy: 0.2888 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 7.8125e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6229 - accuracy: 0.2543 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "8/8 - 0s - loss: 1.6234 - accuracy: 0.2112 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 7.8125e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2284 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.9062e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6227 - accuracy: 0.2414 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.9062e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "8/8 - 0s - loss: 1.6245 - accuracy: 0.2198 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 3.9062e-07 - 29ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6208 - accuracy: 0.2759 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6218 - accuracy: 0.2328 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.9531e-07 - 30ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2500 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.9531e-07 - 31ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6249 - accuracy: 0.2284 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 9.7656e-08 - 31ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6210 - accuracy: 0.2672 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 9.7656e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "8/8 - 0s - loss: 1.6228 - accuracy: 0.2500 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 9.7656e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2457 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6231 - accuracy: 0.2198 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2759 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 4.8828e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6265 - accuracy: 0.1853 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 2.4414e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6206 - accuracy: 0.2500 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 2.4414e-08 - 29ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "8/8 - 0s - loss: 1.6244 - accuracy: 0.2414 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 2.4414e-08 - 35ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6213 - accuracy: 0.2629 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6223 - accuracy: 0.2328 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.2207e-08 - 30ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "8/8 - 0s - loss: 1.6260 - accuracy: 0.1810 - val_loss: 1.6286 - val_accuracy: 0.2241 - lr: 1.2207e-08 - 29ms/epoch - 4ms/step\n",
      "Node 48 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 - 2s - loss: 1.6608 - accuracy: 0.2026 - val_loss: 1.6614 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 2s/epoch - 166ms/step\n",
      "Epoch 2/100\n",
      "15/15 - 0s - loss: 1.6595 - accuracy: 0.2414 - val_loss: 1.6607 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "15/15 - 0s - loss: 1.6592 - accuracy: 0.1853 - val_loss: 1.6599 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "15/15 - 0s - loss: 1.6591 - accuracy: 0.1681 - val_loss: 1.6592 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "15/15 - 0s - loss: 1.6569 - accuracy: 0.2155 - val_loss: 1.6584 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "15/15 - 0s - loss: 1.6569 - accuracy: 0.2112 - val_loss: 1.6577 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "15/15 - 0s - loss: 1.6560 - accuracy: 0.1940 - val_loss: 1.6569 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "15/15 - 0s - loss: 1.6554 - accuracy: 0.2069 - val_loss: 1.6562 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "15/15 - 0s - loss: 1.6539 - accuracy: 0.2069 - val_loss: 1.6556 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "15/15 - 0s - loss: 1.6521 - accuracy: 0.2414 - val_loss: 1.6548 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "15/15 - 0s - loss: 1.6512 - accuracy: 0.1983 - val_loss: 1.6542 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "15/15 - 0s - loss: 1.6510 - accuracy: 0.2672 - val_loss: 1.6536 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "15/15 - 0s - loss: 1.6512 - accuracy: 0.2069 - val_loss: 1.6530 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "15/15 - 0s - loss: 1.6517 - accuracy: 0.2112 - val_loss: 1.6524 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "15/15 - 0s - loss: 1.6486 - accuracy: 0.2069 - val_loss: 1.6520 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "15/15 - 0s - loss: 1.6490 - accuracy: 0.2198 - val_loss: 1.6515 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "15/15 - 0s - loss: 1.6492 - accuracy: 0.2155 - val_loss: 1.6510 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "15/15 - 0s - loss: 1.6481 - accuracy: 0.2241 - val_loss: 1.6504 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "15/15 - 0s - loss: 1.6473 - accuracy: 0.2672 - val_loss: 1.6499 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "15/15 - 0s - loss: 1.6455 - accuracy: 0.2543 - val_loss: 1.6495 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "15/15 - 0s - loss: 1.6449 - accuracy: 0.2543 - val_loss: 1.6492 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "15/15 - 0s - loss: 1.6394 - accuracy: 0.3190 - val_loss: 1.6489 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "15/15 - 0s - loss: 1.6458 - accuracy: 0.1983 - val_loss: 1.6485 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "15/15 - 0s - loss: 1.6405 - accuracy: 0.3147 - val_loss: 1.6481 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "15/15 - 0s - loss: 1.6415 - accuracy: 0.2974 - val_loss: 1.6479 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "15/15 - 0s - loss: 1.6439 - accuracy: 0.2543 - val_loss: 1.6477 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "15/15 - 0s - loss: 1.6390 - accuracy: 0.2586 - val_loss: 1.6476 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "15/15 - 0s - loss: 1.6383 - accuracy: 0.2845 - val_loss: 1.6473 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "15/15 - 0s - loss: 1.6389 - accuracy: 0.2802 - val_loss: 1.6470 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "15/15 - 0s - loss: 1.6380 - accuracy: 0.2802 - val_loss: 1.6467 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "15/15 - 0s - loss: 1.6379 - accuracy: 0.2457 - val_loss: 1.6463 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "15/15 - 0s - loss: 1.6371 - accuracy: 0.2802 - val_loss: 1.6459 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "15/15 - 0s - loss: 1.6367 - accuracy: 0.2586 - val_loss: 1.6455 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "15/15 - 0s - loss: 1.6332 - accuracy: 0.2888 - val_loss: 1.6452 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "15/15 - 0s - loss: 1.6349 - accuracy: 0.2974 - val_loss: 1.6450 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 68ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "15/15 - 0s - loss: 1.6340 - accuracy: 0.3060 - val_loss: 1.6449 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "15/15 - 0s - loss: 1.6348 - accuracy: 0.2716 - val_loss: 1.6447 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 38/100\n",
      "15/15 - 0s - loss: 1.6337 - accuracy: 0.2500 - val_loss: 1.6445 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 39/100\n",
      "15/15 - 0s - loss: 1.6312 - accuracy: 0.3190 - val_loss: 1.6444 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "15/15 - 0s - loss: 1.6301 - accuracy: 0.3017 - val_loss: 1.6442 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 41/100\n",
      "15/15 - 0s - loss: 1.6315 - accuracy: 0.2931 - val_loss: 1.6440 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "15/15 - 0s - loss: 1.6279 - accuracy: 0.2888 - val_loss: 1.6438 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "15/15 - 0s - loss: 1.6292 - accuracy: 0.3060 - val_loss: 1.6437 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "15/15 - 0s - loss: 1.6306 - accuracy: 0.2414 - val_loss: 1.6437 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 65ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "15/15 - 0s - loss: 1.6324 - accuracy: 0.2716 - val_loss: 1.6436 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 64ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "15/15 - 0s - loss: 1.6251 - accuracy: 0.3060 - val_loss: 1.6436 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "15/15 - 0s - loss: 1.6246 - accuracy: 0.2716 - val_loss: 1.6436 - val_accuracy: 0.1552 - lr: 5.0000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "15/15 - 0s - loss: 1.6243 - accuracy: 0.3276 - val_loss: 1.6437 - val_accuracy: 0.1552 - lr: 5.0000e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "15/15 - 0s - loss: 1.6270 - accuracy: 0.2845 - val_loss: 1.6437 - val_accuracy: 0.1552 - lr: 5.0000e-05 - 71ms/epoch - 5ms/step\n",
      "Epoch 50/100\n",
      "15/15 - 0s - loss: 1.6248 - accuracy: 0.2931 - val_loss: 1.6437 - val_accuracy: 0.1552 - lr: 2.5000e-05 - 88ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "15/15 - 0s - loss: 1.6249 - accuracy: 0.2888 - val_loss: 1.6437 - val_accuracy: 0.1379 - lr: 2.5000e-05 - 65ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "15/15 - 0s - loss: 1.6247 - accuracy: 0.3017 - val_loss: 1.6437 - val_accuracy: 0.1379 - lr: 2.5000e-05 - 66ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "15/15 - 0s - loss: 1.6232 - accuracy: 0.2672 - val_loss: 1.6437 - val_accuracy: 0.1379 - lr: 1.2500e-05 - 67ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "15/15 - 0s - loss: 1.6241 - accuracy: 0.2931 - val_loss: 1.6436 - val_accuracy: 0.1379 - lr: 1.2500e-05 - 66ms/epoch - 4ms/step\n",
      "Node 48 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 3s - loss: 1.6615 - accuracy: 0.1983 - val_loss: 1.6604 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 3s/epoch - 345ms/step\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6599 - accuracy: 0.1853 - val_loss: 1.6600 - val_accuracy: 0.2069 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.6603 - accuracy: 0.1422 - val_loss: 1.6597 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.6587 - accuracy: 0.2241 - val_loss: 1.6593 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.6584 - accuracy: 0.2284 - val_loss: 1.6589 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.6579 - accuracy: 0.2069 - val_loss: 1.6585 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.6574 - accuracy: 0.2112 - val_loss: 1.6581 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.6574 - accuracy: 0.2198 - val_loss: 1.6577 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.6561 - accuracy: 0.2026 - val_loss: 1.6573 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.6555 - accuracy: 0.2457 - val_loss: 1.6569 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.6558 - accuracy: 0.2371 - val_loss: 1.6566 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.6559 - accuracy: 0.1767 - val_loss: 1.6563 - val_accuracy: 0.2586 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.2371 - val_loss: 1.6559 - val_accuracy: 0.2414 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.6540 - accuracy: 0.1940 - val_loss: 1.6555 - val_accuracy: 0.2241 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.6535 - accuracy: 0.2672 - val_loss: 1.6551 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.6522 - accuracy: 0.2457 - val_loss: 1.6547 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.6532 - accuracy: 0.2328 - val_loss: 1.6543 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.6518 - accuracy: 0.2198 - val_loss: 1.6541 - val_accuracy: 0.1897 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6508 - accuracy: 0.2371 - val_loss: 1.6538 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6515 - accuracy: 0.1724 - val_loss: 1.6535 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.6498 - accuracy: 0.2931 - val_loss: 1.6532 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 1.6500 - accuracy: 0.2241 - val_loss: 1.6529 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 1.6491 - accuracy: 0.2198 - val_loss: 1.6525 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 1.6502 - accuracy: 0.2241 - val_loss: 1.6522 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 1.6484 - accuracy: 0.2716 - val_loss: 1.6518 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 1.6482 - accuracy: 0.2112 - val_loss: 1.6515 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2284 - val_loss: 1.6511 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 1.6460 - accuracy: 0.2500 - val_loss: 1.6507 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 1.6455 - accuracy: 0.2328 - val_loss: 1.6503 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 1.6466 - accuracy: 0.2198 - val_loss: 1.6500 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2974 - val_loss: 1.6496 - val_accuracy: 0.1724 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 1.6450 - accuracy: 0.2457 - val_loss: 1.6493 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 1.6429 - accuracy: 0.2845 - val_loss: 1.6489 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 1.6443 - accuracy: 0.2543 - val_loss: 1.6486 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 1.6447 - accuracy: 0.2371 - val_loss: 1.6484 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 1.6431 - accuracy: 0.2716 - val_loss: 1.6482 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 51ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 1.6438 - accuracy: 0.2371 - val_loss: 1.6479 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 1.6426 - accuracy: 0.2629 - val_loss: 1.6477 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 1.6415 - accuracy: 0.2500 - val_loss: 1.6474 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 1.6437 - accuracy: 0.2414 - val_loss: 1.6472 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 1.6409 - accuracy: 0.2414 - val_loss: 1.6469 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 1.6408 - accuracy: 0.2543 - val_loss: 1.6466 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2716 - val_loss: 1.6462 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 1.6401 - accuracy: 0.2586 - val_loss: 1.6459 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 1.6418 - accuracy: 0.2371 - val_loss: 1.6457 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 1.6403 - accuracy: 0.2500 - val_loss: 1.6455 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2845 - val_loss: 1.6452 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 1.6395 - accuracy: 0.2500 - val_loss: 1.6450 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 1.6382 - accuracy: 0.2672 - val_loss: 1.6448 - val_accuracy: 0.0862 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2931 - val_loss: 1.6447 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 1.6376 - accuracy: 0.2845 - val_loss: 1.6444 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 1.6372 - accuracy: 0.2845 - val_loss: 1.6442 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 67ms/epoch - 8ms/step\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 1.6354 - accuracy: 0.2672 - val_loss: 1.6439 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 1.6348 - accuracy: 0.2759 - val_loss: 1.6436 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 1.6347 - accuracy: 0.3276 - val_loss: 1.6433 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 53ms/epoch - 7ms/step\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 1.6342 - accuracy: 0.2672 - val_loss: 1.6431 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 1.6335 - accuracy: 0.2888 - val_loss: 1.6429 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 1.6369 - accuracy: 0.2543 - val_loss: 1.6427 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 1.6340 - accuracy: 0.2629 - val_loss: 1.6425 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 1.6339 - accuracy: 0.2414 - val_loss: 1.6424 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 1.6329 - accuracy: 0.2716 - val_loss: 1.6422 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 1.6313 - accuracy: 0.2629 - val_loss: 1.6420 - val_accuracy: 0.0862 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2759 - val_loss: 1.6418 - val_accuracy: 0.0862 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2500 - val_loss: 1.6416 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2716 - val_loss: 1.6414 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 1.6319 - accuracy: 0.2629 - val_loss: 1.6413 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 1.6279 - accuracy: 0.2802 - val_loss: 1.6411 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 1.6316 - accuracy: 0.2500 - val_loss: 1.6410 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 1.6282 - accuracy: 0.2672 - val_loss: 1.6408 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 1.6300 - accuracy: 0.2328 - val_loss: 1.6407 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 1.6274 - accuracy: 0.2672 - val_loss: 1.6405 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 1.6301 - accuracy: 0.2629 - val_loss: 1.6404 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 1.6255 - accuracy: 0.2759 - val_loss: 1.6402 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 1.6293 - accuracy: 0.2716 - val_loss: 1.6401 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 1.6285 - accuracy: 0.2112 - val_loss: 1.6400 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 1.6251 - accuracy: 0.2586 - val_loss: 1.6398 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 1.6256 - accuracy: 0.2716 - val_loss: 1.6396 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 1.6243 - accuracy: 0.3103 - val_loss: 1.6395 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 1.6273 - accuracy: 0.2543 - val_loss: 1.6394 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 1.6241 - accuracy: 0.2414 - val_loss: 1.6393 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2672 - val_loss: 1.6392 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 1.6239 - accuracy: 0.2543 - val_loss: 1.6391 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 1.6246 - accuracy: 0.2845 - val_loss: 1.6390 - val_accuracy: 0.1552 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2845 - val_loss: 1.6388 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 1.6266 - accuracy: 0.2974 - val_loss: 1.6387 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 1.6211 - accuracy: 0.2629 - val_loss: 1.6387 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 46ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 1.6184 - accuracy: 0.3103 - val_loss: 1.6387 - val_accuracy: 0.1379 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 1.6242 - accuracy: 0.2500 - val_loss: 1.6386 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 1.6219 - accuracy: 0.2629 - val_loss: 1.6384 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 1.6207 - accuracy: 0.2974 - val_loss: 1.6383 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 1.6200 - accuracy: 0.2716 - val_loss: 1.6383 - val_accuracy: 0.1207 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 1.6217 - accuracy: 0.2931 - val_loss: 1.6382 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 1.6174 - accuracy: 0.2759 - val_loss: 1.6381 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 1.6161 - accuracy: 0.2629 - val_loss: 1.6380 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 50ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 1.6209 - accuracy: 0.2759 - val_loss: 1.6380 - val_accuracy: 0.1034 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 1.6232 - accuracy: 0.2672 - val_loss: 1.6379 - val_accuracy: 0.0862 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 1.6149 - accuracy: 0.2845 - val_loss: 1.6379 - val_accuracy: 0.0690 - lr: 1.0000e-04 - 47ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 1.6150 - accuracy: 0.2931 - val_loss: 1.6380 - val_accuracy: 0.0690 - lr: 1.0000e-04 - 48ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "8/8 - 0s - loss: 1.6187 - accuracy: 0.2716 - val_loss: 1.6382 - val_accuracy: 0.0862 - lr: 1.0000e-04 - 49ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 1.6236 - accuracy: 0.2888 - val_loss: 1.6382 - val_accuracy: 0.0862 - lr: 5.0000e-05 - 49ms/epoch - 6ms/step\n",
      "Node 48 - Best Configuration: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 48 - Best Validation Accuracy: 0.2586\n",
      "Best model saved for Node 48 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_48.h5\n",
      "Processing file: /Users/zxgan/FYP_Kubernetes/Dataset/node_node_49_dataset.csv\n",
      "Node 49 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6344 - accuracy: 0.1943 - val_loss: 1.6342 - val_accuracy: 0.2075 - lr: 1.0000e-04 - 3s/epoch - 204ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6355 - accuracy: 0.1469 - val_loss: 1.6339 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6336 - accuracy: 0.1943 - val_loss: 1.6337 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6338 - accuracy: 0.1991 - val_loss: 1.6334 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6327 - accuracy: 0.2322 - val_loss: 1.6332 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6323 - accuracy: 0.2275 - val_loss: 1.6329 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6323 - accuracy: 0.2038 - val_loss: 1.6326 - val_accuracy: 0.3396 - lr: 1.0000e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6346 - accuracy: 0.1706 - val_loss: 1.6324 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6307 - accuracy: 0.2180 - val_loss: 1.6321 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2464 - val_loss: 1.6318 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6320 - accuracy: 0.1943 - val_loss: 1.6315 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2085 - val_loss: 1.6313 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6301 - accuracy: 0.2512 - val_loss: 1.6311 - val_accuracy: 0.2075 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6305 - accuracy: 0.2227 - val_loss: 1.6309 - val_accuracy: 0.2075 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6306 - accuracy: 0.2180 - val_loss: 1.6307 - val_accuracy: 0.2075 - lr: 1.0000e-04 - 49ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6292 - accuracy: 0.1801 - val_loss: 1.6305 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6296 - accuracy: 0.1991 - val_loss: 1.6304 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6290 - accuracy: 0.1991 - val_loss: 1.6302 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6287 - accuracy: 0.2275 - val_loss: 1.6300 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6298 - accuracy: 0.2133 - val_loss: 1.6298 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6289 - accuracy: 0.2133 - val_loss: 1.6296 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6272 - accuracy: 0.2417 - val_loss: 1.6294 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6267 - accuracy: 0.2417 - val_loss: 1.6292 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6277 - accuracy: 0.2085 - val_loss: 1.6290 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6286 - accuracy: 0.2133 - val_loss: 1.6288 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2227 - val_loss: 1.6286 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6267 - accuracy: 0.2417 - val_loss: 1.6284 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6279 - accuracy: 0.2275 - val_loss: 1.6282 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6257 - accuracy: 0.2133 - val_loss: 1.6281 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6271 - accuracy: 0.1943 - val_loss: 1.6279 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6261 - accuracy: 0.2180 - val_loss: 1.6277 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6266 - accuracy: 0.2322 - val_loss: 1.6275 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2370 - val_loss: 1.6273 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6260 - accuracy: 0.2512 - val_loss: 1.6271 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6249 - accuracy: 0.2370 - val_loss: 1.6269 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6228 - accuracy: 0.2133 - val_loss: 1.6268 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2464 - val_loss: 1.6267 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6241 - accuracy: 0.2417 - val_loss: 1.6264 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6235 - accuracy: 0.2322 - val_loss: 1.6261 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6220 - accuracy: 0.2180 - val_loss: 1.6258 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6229 - accuracy: 0.2370 - val_loss: 1.6256 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6205 - accuracy: 0.2512 - val_loss: 1.6254 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2227 - val_loss: 1.6253 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6196 - accuracy: 0.2370 - val_loss: 1.6251 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6225 - accuracy: 0.2085 - val_loss: 1.6250 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2607 - val_loss: 1.6248 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2322 - val_loss: 1.6246 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6212 - accuracy: 0.2370 - val_loss: 1.6244 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6215 - accuracy: 0.2038 - val_loss: 1.6242 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6224 - accuracy: 0.2085 - val_loss: 1.6241 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6184 - accuracy: 0.2370 - val_loss: 1.6240 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6163 - accuracy: 0.2322 - val_loss: 1.6238 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6208 - accuracy: 0.2227 - val_loss: 1.6237 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6210 - accuracy: 0.2322 - val_loss: 1.6235 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2796 - val_loss: 1.6234 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6184 - accuracy: 0.2275 - val_loss: 1.6233 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6203 - accuracy: 0.2133 - val_loss: 1.6231 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2559 - val_loss: 1.6229 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.2275 - val_loss: 1.6228 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.6159 - accuracy: 0.2322 - val_loss: 1.6228 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2322 - val_loss: 1.6226 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2559 - val_loss: 1.6225 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6178 - accuracy: 0.2275 - val_loss: 1.6223 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6167 - accuracy: 0.2227 - val_loss: 1.6221 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6174 - accuracy: 0.2370 - val_loss: 1.6219 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6160 - accuracy: 0.2417 - val_loss: 1.6218 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.2464 - val_loss: 1.6218 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6117 - accuracy: 0.2370 - val_loss: 1.6217 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6151 - accuracy: 0.2654 - val_loss: 1.6215 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6183 - accuracy: 0.2559 - val_loss: 1.6214 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6130 - accuracy: 0.2464 - val_loss: 1.6213 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6153 - accuracy: 0.2512 - val_loss: 1.6212 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6165 - accuracy: 0.2417 - val_loss: 1.6211 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6060 - accuracy: 0.3081 - val_loss: 1.6210 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6102 - accuracy: 0.2512 - val_loss: 1.6209 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6090 - accuracy: 0.2654 - val_loss: 1.6207 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6156 - accuracy: 0.2370 - val_loss: 1.6206 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 50ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6134 - accuracy: 0.2464 - val_loss: 1.6205 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6111 - accuracy: 0.2607 - val_loss: 1.6203 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6133 - accuracy: 0.2370 - val_loss: 1.6201 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6130 - accuracy: 0.2275 - val_loss: 1.6201 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6096 - accuracy: 0.2701 - val_loss: 1.6200 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6073 - accuracy: 0.2654 - val_loss: 1.6198 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6086 - accuracy: 0.2417 - val_loss: 1.6198 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6073 - accuracy: 0.2607 - val_loss: 1.6197 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6105 - accuracy: 0.2275 - val_loss: 1.6196 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6106 - accuracy: 0.2180 - val_loss: 1.6194 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6081 - accuracy: 0.2654 - val_loss: 1.6193 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6108 - accuracy: 0.2607 - val_loss: 1.6191 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6157 - accuracy: 0.2370 - val_loss: 1.6191 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6103 - accuracy: 0.2275 - val_loss: 1.6189 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6154 - accuracy: 0.2133 - val_loss: 1.6188 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6168 - accuracy: 0.2322 - val_loss: 1.6187 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6074 - accuracy: 0.2322 - val_loss: 1.6186 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6029 - accuracy: 0.2559 - val_loss: 1.6185 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6077 - accuracy: 0.2559 - val_loss: 1.6184 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6080 - accuracy: 0.2133 - val_loss: 1.6182 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 48ms/epoch - 3ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6052 - accuracy: 0.2986 - val_loss: 1.6181 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6031 - accuracy: 0.2796 - val_loss: 1.6180 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6036 - accuracy: 0.2749 - val_loss: 1.6179 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 46ms/epoch - 3ms/step\n",
      "Node 49 - Training with config: {'units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6359 - accuracy: 0.1706 - val_loss: 1.6351 - val_accuracy: 0.1698 - lr: 1.0000e-04 - 3s/epoch - 358ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6348 - accuracy: 0.2180 - val_loss: 1.6349 - val_accuracy: 0.1887 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6350 - accuracy: 0.1991 - val_loss: 1.6347 - val_accuracy: 0.1887 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6325 - accuracy: 0.2180 - val_loss: 1.6345 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6359 - accuracy: 0.2038 - val_loss: 1.6344 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6335 - accuracy: 0.1991 - val_loss: 1.6342 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6359 - accuracy: 0.2133 - val_loss: 1.6340 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6342 - accuracy: 0.2180 - val_loss: 1.6339 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6326 - accuracy: 0.2227 - val_loss: 1.6337 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6315 - accuracy: 0.2464 - val_loss: 1.6335 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.1896 - val_loss: 1.6334 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6312 - accuracy: 0.2512 - val_loss: 1.6332 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.1991 - val_loss: 1.6331 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6311 - accuracy: 0.2133 - val_loss: 1.6328 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2133 - val_loss: 1.6327 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6303 - accuracy: 0.2654 - val_loss: 1.6325 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6283 - accuracy: 0.2654 - val_loss: 1.6323 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6290 - accuracy: 0.2417 - val_loss: 1.6322 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6300 - accuracy: 0.2370 - val_loss: 1.6321 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6294 - accuracy: 0.2559 - val_loss: 1.6318 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6285 - accuracy: 0.2180 - val_loss: 1.6317 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6314 - accuracy: 0.2322 - val_loss: 1.6315 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6310 - accuracy: 0.2322 - val_loss: 1.6314 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2275 - val_loss: 1.6312 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6281 - accuracy: 0.2275 - val_loss: 1.6310 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6277 - accuracy: 0.2370 - val_loss: 1.6308 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6257 - accuracy: 0.2322 - val_loss: 1.6306 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6297 - accuracy: 0.2417 - val_loss: 1.6304 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2464 - val_loss: 1.6302 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6266 - accuracy: 0.2227 - val_loss: 1.6300 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6273 - accuracy: 0.2275 - val_loss: 1.6298 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2322 - val_loss: 1.6296 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6271 - accuracy: 0.2417 - val_loss: 1.6294 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2322 - val_loss: 1.6293 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2322 - val_loss: 1.6291 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6264 - accuracy: 0.2417 - val_loss: 1.6289 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6270 - accuracy: 0.2370 - val_loss: 1.6287 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 33ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2275 - val_loss: 1.6286 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2085 - val_loss: 1.6285 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2370 - val_loss: 1.6283 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 34ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2417 - val_loss: 1.6282 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2417 - val_loss: 1.6281 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6254 - accuracy: 0.2275 - val_loss: 1.6280 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6258 - accuracy: 0.2275 - val_loss: 1.6278 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2275 - val_loss: 1.6276 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2417 - val_loss: 1.6275 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2227 - val_loss: 1.6274 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6239 - accuracy: 0.2275 - val_loss: 1.6272 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6229 - accuracy: 0.2464 - val_loss: 1.6271 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6220 - accuracy: 0.2227 - val_loss: 1.6269 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 48ms/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2417 - val_loss: 1.6268 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2370 - val_loss: 1.6266 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2464 - val_loss: 1.6265 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6191 - accuracy: 0.2417 - val_loss: 1.6263 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2227 - val_loss: 1.6261 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6190 - accuracy: 0.2559 - val_loss: 1.6259 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2180 - val_loss: 1.6257 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6241 - accuracy: 0.2417 - val_loss: 1.6256 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6232 - accuracy: 0.2701 - val_loss: 1.6255 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6216 - accuracy: 0.2370 - val_loss: 1.6253 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6222 - accuracy: 0.2464 - val_loss: 1.6252 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6211 - accuracy: 0.2275 - val_loss: 1.6251 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6234 - accuracy: 0.2227 - val_loss: 1.6249 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6207 - accuracy: 0.2133 - val_loss: 1.6248 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6200 - accuracy: 0.2227 - val_loss: 1.6247 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2322 - val_loss: 1.6245 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6182 - accuracy: 0.2417 - val_loss: 1.6244 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6131 - accuracy: 0.2559 - val_loss: 1.6243 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6164 - accuracy: 0.2464 - val_loss: 1.6242 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6150 - accuracy: 0.2322 - val_loss: 1.6240 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6205 - accuracy: 0.2464 - val_loss: 1.6239 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6180 - accuracy: 0.2512 - val_loss: 1.6239 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6179 - accuracy: 0.2417 - val_loss: 1.6238 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 32ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6160 - accuracy: 0.2370 - val_loss: 1.6237 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6168 - accuracy: 0.2370 - val_loss: 1.6236 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6167 - accuracy: 0.2370 - val_loss: 1.6235 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6168 - accuracy: 0.2559 - val_loss: 1.6234 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6169 - accuracy: 0.2417 - val_loss: 1.6233 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6169 - accuracy: 0.2512 - val_loss: 1.6232 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6154 - accuracy: 0.2417 - val_loss: 1.6231 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6172 - accuracy: 0.2370 - val_loss: 1.6230 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6114 - accuracy: 0.2512 - val_loss: 1.6229 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6154 - accuracy: 0.2417 - val_loss: 1.6228 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6188 - accuracy: 0.2227 - val_loss: 1.6228 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6098 - accuracy: 0.2464 - val_loss: 1.6227 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6209 - accuracy: 0.2370 - val_loss: 1.6226 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6189 - accuracy: 0.2370 - val_loss: 1.6226 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6143 - accuracy: 0.2607 - val_loss: 1.6225 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6145 - accuracy: 0.2607 - val_loss: 1.6224 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6155 - accuracy: 0.2607 - val_loss: 1.6223 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6123 - accuracy: 0.2370 - val_loss: 1.6222 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6153 - accuracy: 0.2275 - val_loss: 1.6221 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6184 - accuracy: 0.2370 - val_loss: 1.6220 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6107 - accuracy: 0.2322 - val_loss: 1.6219 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6113 - accuracy: 0.2559 - val_loss: 1.6217 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 29ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6142 - accuracy: 0.2464 - val_loss: 1.6217 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6134 - accuracy: 0.2417 - val_loss: 1.6216 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6142 - accuracy: 0.2370 - val_loss: 1.6215 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 30ms/epoch - 4ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6118 - accuracy: 0.2512 - val_loss: 1.6214 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 31ms/epoch - 4ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6136 - accuracy: 0.2275 - val_loss: 1.6213 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 49ms/epoch - 7ms/step\n",
      "Node 49 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 1.6614 - accuracy: 0.1611 - val_loss: 1.6594 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 3s/epoch - 201ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 1.6592 - accuracy: 0.2085 - val_loss: 1.6586 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 1.6591 - accuracy: 0.1706 - val_loss: 1.6580 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 1.6571 - accuracy: 0.2417 - val_loss: 1.6574 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 1.6570 - accuracy: 0.2180 - val_loss: 1.6569 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 1.6555 - accuracy: 0.2512 - val_loss: 1.6563 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 1.6559 - accuracy: 0.2464 - val_loss: 1.6558 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 1.6534 - accuracy: 0.2796 - val_loss: 1.6552 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 1.6544 - accuracy: 0.2322 - val_loss: 1.6546 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 1.6530 - accuracy: 0.2180 - val_loss: 1.6541 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 1.6521 - accuracy: 0.2701 - val_loss: 1.6535 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 1.6503 - accuracy: 0.2559 - val_loss: 1.6531 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 1.6507 - accuracy: 0.2227 - val_loss: 1.6526 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 70ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 1.6485 - accuracy: 0.2796 - val_loss: 1.6520 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 1.6488 - accuracy: 0.2417 - val_loss: 1.6513 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 1.6496 - accuracy: 0.2180 - val_loss: 1.6508 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 1.6480 - accuracy: 0.2275 - val_loss: 1.6502 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 1.6460 - accuracy: 0.2749 - val_loss: 1.6496 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 1.6499 - accuracy: 0.2417 - val_loss: 1.6492 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 1.6470 - accuracy: 0.2701 - val_loss: 1.6485 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 1.6449 - accuracy: 0.2559 - val_loss: 1.6479 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 1.6445 - accuracy: 0.2322 - val_loss: 1.6473 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 1.6433 - accuracy: 0.2464 - val_loss: 1.6467 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 1.6424 - accuracy: 0.2464 - val_loss: 1.6460 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 1.6441 - accuracy: 0.2464 - val_loss: 1.6455 - val_accuracy: 0.2642 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 1.6431 - accuracy: 0.2464 - val_loss: 1.6448 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 1.6429 - accuracy: 0.2417 - val_loss: 1.6443 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 1.6420 - accuracy: 0.2796 - val_loss: 1.6437 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 1.6419 - accuracy: 0.2701 - val_loss: 1.6434 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.6390 - accuracy: 0.2559 - val_loss: 1.6430 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.6372 - accuracy: 0.2701 - val_loss: 1.6427 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.6369 - accuracy: 0.2796 - val_loss: 1.6424 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.6368 - accuracy: 0.2796 - val_loss: 1.6419 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.6368 - accuracy: 0.2749 - val_loss: 1.6412 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.6397 - accuracy: 0.2464 - val_loss: 1.6408 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.6370 - accuracy: 0.2607 - val_loss: 1.6406 - val_accuracy: 0.2830 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.6326 - accuracy: 0.2796 - val_loss: 1.6399 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6359 - accuracy: 0.2749 - val_loss: 1.6393 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6364 - accuracy: 0.2607 - val_loss: 1.6386 - val_accuracy: 0.3396 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6332 - accuracy: 0.2891 - val_loss: 1.6383 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6361 - accuracy: 0.2607 - val_loss: 1.6379 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.6334 - accuracy: 0.2796 - val_loss: 1.6375 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.6312 - accuracy: 0.2938 - val_loss: 1.6370 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.6318 - accuracy: 0.2512 - val_loss: 1.6366 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 63ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.6303 - accuracy: 0.2559 - val_loss: 1.6363 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.6299 - accuracy: 0.2654 - val_loss: 1.6359 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.6279 - accuracy: 0.2749 - val_loss: 1.6353 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.6317 - accuracy: 0.2844 - val_loss: 1.6349 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.6294 - accuracy: 0.2654 - val_loss: 1.6345 - val_accuracy: 0.3019 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.6273 - accuracy: 0.2749 - val_loss: 1.6339 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.6243 - accuracy: 0.2938 - val_loss: 1.6333 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 83ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.6299 - accuracy: 0.2654 - val_loss: 1.6329 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.6255 - accuracy: 0.2701 - val_loss: 1.6322 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.6263 - accuracy: 0.2749 - val_loss: 1.6319 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.6232 - accuracy: 0.2464 - val_loss: 1.6316 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.6206 - accuracy: 0.2891 - val_loss: 1.6310 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 67ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.6269 - accuracy: 0.2512 - val_loss: 1.6307 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 65ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.6240 - accuracy: 0.2844 - val_loss: 1.6309 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.6268 - accuracy: 0.2749 - val_loss: 1.6310 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 64ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "14/14 - 0s - loss: 1.6194 - accuracy: 0.2796 - val_loss: 1.6308 - val_accuracy: 0.3208 - lr: 1.0000e-04 - 66ms/epoch - 5ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.3223 - val_loss: 1.6303 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 1.6230 - accuracy: 0.2701 - val_loss: 1.6298 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 1.6182 - accuracy: 0.2938 - val_loss: 1.6296 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 1.6198 - accuracy: 0.2796 - val_loss: 1.6292 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2512 - val_loss: 1.6289 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 1.6204 - accuracy: 0.2796 - val_loss: 1.6286 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 1.6219 - accuracy: 0.2417 - val_loss: 1.6285 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 72ms/epoch - 5ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 1.6193 - accuracy: 0.3175 - val_loss: 1.6283 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 1.6188 - accuracy: 0.2844 - val_loss: 1.6282 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 1.6238 - accuracy: 0.2701 - val_loss: 1.6280 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 1.6199 - accuracy: 0.3033 - val_loss: 1.6278 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 62ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 1.6189 - accuracy: 0.2654 - val_loss: 1.6274 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 1.6173 - accuracy: 0.2701 - val_loss: 1.6274 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 1.6175 - accuracy: 0.3128 - val_loss: 1.6272 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 1.6138 - accuracy: 0.3081 - val_loss: 1.6269 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 1.6222 - accuracy: 0.2844 - val_loss: 1.6267 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 1.6135 - accuracy: 0.3081 - val_loss: 1.6267 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 1.6122 - accuracy: 0.2844 - val_loss: 1.6265 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 1.6130 - accuracy: 0.3081 - val_loss: 1.6265 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 1.6140 - accuracy: 0.2938 - val_loss: 1.6263 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 1.6145 - accuracy: 0.3175 - val_loss: 1.6261 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 1.6120 - accuracy: 0.2844 - val_loss: 1.6259 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 1.6191 - accuracy: 0.2607 - val_loss: 1.6255 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 1.6108 - accuracy: 0.3081 - val_loss: 1.6255 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 1.6158 - accuracy: 0.2749 - val_loss: 1.6254 - val_accuracy: 0.3208 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 1.6151 - accuracy: 0.3033 - val_loss: 1.6251 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 1.6072 - accuracy: 0.2986 - val_loss: 1.6248 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 1.6104 - accuracy: 0.2749 - val_loss: 1.6247 - val_accuracy: 0.3396 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 1.6105 - accuracy: 0.2938 - val_loss: 1.6244 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.2891 - val_loss: 1.6243 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 1.6099 - accuracy: 0.2654 - val_loss: 1.6242 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 1.6110 - accuracy: 0.2986 - val_loss: 1.6238 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 1.6119 - accuracy: 0.3081 - val_loss: 1.6236 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 1.6091 - accuracy: 0.3033 - val_loss: 1.6234 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 1.6092 - accuracy: 0.3033 - val_loss: 1.6232 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 66ms/epoch - 5ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 1.6106 - accuracy: 0.2844 - val_loss: 1.6231 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 1.6062 - accuracy: 0.2938 - val_loss: 1.6230 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 64ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 1.6162 - accuracy: 0.2701 - val_loss: 1.6227 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 67ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 1.6127 - accuracy: 0.3270 - val_loss: 1.6226 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 65ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 1.6078 - accuracy: 0.2654 - val_loss: 1.6225 - val_accuracy: 0.3585 - lr: 5.0000e-05 - 68ms/epoch - 5ms/step\n",
      "Node 49 - Training with config: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 32, 'l2_reg': 0.001, 'epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 1.6599 - accuracy: 0.2559 - val_loss: 1.6589 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 3s/epoch - 365ms/step\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 1.6596 - accuracy: 0.2227 - val_loss: 1.6586 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 1.6599 - accuracy: 0.1896 - val_loss: 1.6581 - val_accuracy: 0.2075 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 1.6567 - accuracy: 0.2559 - val_loss: 1.6576 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 24ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 1.6570 - accuracy: 0.2227 - val_loss: 1.6571 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 25ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 1.6567 - accuracy: 0.2180 - val_loss: 1.6566 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 1.6567 - accuracy: 0.2417 - val_loss: 1.6561 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 1.6568 - accuracy: 0.2038 - val_loss: 1.6556 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 1.6565 - accuracy: 0.2322 - val_loss: 1.6551 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 1.6563 - accuracy: 0.2038 - val_loss: 1.6547 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 1.6549 - accuracy: 0.2180 - val_loss: 1.6543 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 27ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 1.6534 - accuracy: 0.2322 - val_loss: 1.6539 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 26ms/epoch - 4ms/step\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 1.6526 - accuracy: 0.2607 - val_loss: 1.6534 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 28ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 1.6526 - accuracy: 0.2227 - val_loss: 1.6529 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 1.6529 - accuracy: 0.2370 - val_loss: 1.6524 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 1.6509 - accuracy: 0.2464 - val_loss: 1.6520 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 1.6495 - accuracy: 0.2464 - val_loss: 1.6515 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 1.6505 - accuracy: 0.2227 - val_loss: 1.6512 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 1.6509 - accuracy: 0.2417 - val_loss: 1.6508 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 1.6498 - accuracy: 0.2275 - val_loss: 1.6503 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 1.6480 - accuracy: 0.2322 - val_loss: 1.6498 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 47ms/epoch - 7ms/step\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 1.6468 - accuracy: 0.2370 - val_loss: 1.6493 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 1.6465 - accuracy: 0.2512 - val_loss: 1.6488 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 1.6499 - accuracy: 0.2322 - val_loss: 1.6483 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 1.6485 - accuracy: 0.2227 - val_loss: 1.6478 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 1.6456 - accuracy: 0.2227 - val_loss: 1.6474 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 1.6439 - accuracy: 0.2417 - val_loss: 1.6469 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 1.6452 - accuracy: 0.2227 - val_loss: 1.6464 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 1.6475 - accuracy: 0.2085 - val_loss: 1.6460 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2133 - val_loss: 1.6457 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 1.6435 - accuracy: 0.2275 - val_loss: 1.6453 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2559 - val_loss: 1.6449 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 1.6409 - accuracy: 0.2417 - val_loss: 1.6446 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 1.6434 - accuracy: 0.2275 - val_loss: 1.6442 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 1.6424 - accuracy: 0.2322 - val_loss: 1.6438 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 1.6390 - accuracy: 0.2275 - val_loss: 1.6434 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 1.6410 - accuracy: 0.2370 - val_loss: 1.6430 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 1.6396 - accuracy: 0.2417 - val_loss: 1.6427 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 1.6407 - accuracy: 0.2275 - val_loss: 1.6424 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 1.6383 - accuracy: 0.2322 - val_loss: 1.6422 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 1.6374 - accuracy: 0.2322 - val_loss: 1.6419 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 1.6377 - accuracy: 0.2227 - val_loss: 1.6416 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 1.6413 - accuracy: 0.2322 - val_loss: 1.6412 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 1.6346 - accuracy: 0.2370 - val_loss: 1.6409 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 1.6354 - accuracy: 0.2417 - val_loss: 1.6405 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 1.6407 - accuracy: 0.2464 - val_loss: 1.6402 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 1.6344 - accuracy: 0.2275 - val_loss: 1.6399 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 1.6352 - accuracy: 0.2512 - val_loss: 1.6396 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 1.6345 - accuracy: 0.2322 - val_loss: 1.6393 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 1.6338 - accuracy: 0.2322 - val_loss: 1.6390 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 1.6371 - accuracy: 0.2417 - val_loss: 1.6387 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 1.6325 - accuracy: 0.2322 - val_loss: 1.6384 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 1.6340 - accuracy: 0.2417 - val_loss: 1.6380 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 1.6339 - accuracy: 0.2322 - val_loss: 1.6377 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 62ms/epoch - 9ms/step\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 1.6295 - accuracy: 0.2417 - val_loss: 1.6374 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 1.6344 - accuracy: 0.2275 - val_loss: 1.6371 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2417 - val_loss: 1.6368 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 1.6366 - accuracy: 0.2275 - val_loss: 1.6366 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 1.6318 - accuracy: 0.2417 - val_loss: 1.6364 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 1.6339 - accuracy: 0.2322 - val_loss: 1.6362 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 1.6274 - accuracy: 0.2370 - val_loss: 1.6359 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 1.6316 - accuracy: 0.2227 - val_loss: 1.6356 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 1.6296 - accuracy: 0.2512 - val_loss: 1.6353 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 1.6331 - accuracy: 0.2370 - val_loss: 1.6350 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 1.6302 - accuracy: 0.2275 - val_loss: 1.6347 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2417 - val_loss: 1.6344 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 1.6278 - accuracy: 0.2417 - val_loss: 1.6341 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 1.6246 - accuracy: 0.2512 - val_loss: 1.6339 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 1.6225 - accuracy: 0.2607 - val_loss: 1.6337 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 1.6235 - accuracy: 0.2370 - val_loss: 1.6334 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 40ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 1.6259 - accuracy: 0.2417 - val_loss: 1.6331 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 1.6237 - accuracy: 0.2417 - val_loss: 1.6328 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 1.6234 - accuracy: 0.2512 - val_loss: 1.6324 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 1.6224 - accuracy: 0.2559 - val_loss: 1.6321 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 1.6255 - accuracy: 0.2275 - val_loss: 1.6318 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 1.6276 - accuracy: 0.2370 - val_loss: 1.6314 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2559 - val_loss: 1.6312 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 1.6250 - accuracy: 0.2654 - val_loss: 1.6310 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 1.6208 - accuracy: 0.2417 - val_loss: 1.6308 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 1.6291 - accuracy: 0.2464 - val_loss: 1.6305 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 1.6131 - accuracy: 0.2891 - val_loss: 1.6302 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 45ms/epoch - 6ms/step\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 1.6197 - accuracy: 0.2559 - val_loss: 1.6299 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 1.6185 - accuracy: 0.2749 - val_loss: 1.6296 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 41ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2654 - val_loss: 1.6293 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 1.6196 - accuracy: 0.2559 - val_loss: 1.6292 - val_accuracy: 0.2264 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 1.6213 - accuracy: 0.2512 - val_loss: 1.6289 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 1.6155 - accuracy: 0.2417 - val_loss: 1.6288 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 1.6092 - accuracy: 0.2749 - val_loss: 1.6287 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 46ms/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 1.6206 - accuracy: 0.2512 - val_loss: 1.6285 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 1.6154 - accuracy: 0.2559 - val_loss: 1.6284 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 1.6144 - accuracy: 0.2464 - val_loss: 1.6281 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 1.6132 - accuracy: 0.2654 - val_loss: 1.6278 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 1.6122 - accuracy: 0.2749 - val_loss: 1.6276 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 1.6091 - accuracy: 0.2607 - val_loss: 1.6273 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 1.6107 - accuracy: 0.2654 - val_loss: 1.6270 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 1.6116 - accuracy: 0.2607 - val_loss: 1.6266 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 1.6120 - accuracy: 0.2607 - val_loss: 1.6264 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 43ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 1.6145 - accuracy: 0.2749 - val_loss: 1.6263 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 1.6094 - accuracy: 0.2607 - val_loss: 1.6261 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 44ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 1.6138 - accuracy: 0.2701 - val_loss: 1.6260 - val_accuracy: 0.2453 - lr: 1.0000e-04 - 42ms/epoch - 6ms/step\n",
      "Node 49 - Best Configuration: {'units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'batch_size': 16, 'l2_reg': 0.001, 'epochs': 100}\n",
      "Node 49 - Best Validation Accuracy: 0.3585\n",
      "Best model saved for Node 49 at: /Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_49.h5\n",
      "Summary saved to: /Users/zxgan/FYP_Kubernetes/Dataset/lstm_accuracy_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# File path and naming convention\n",
    "directory = '/Users/zxgan/FYP_Kubernetes/Dataset/'\n",
    "file_prefix = 'node_node_'\n",
    "file_suffix = '_dataset.csv'\n",
    "num_files = 50\n",
    "\n",
    "# Hyperparameter configurations\n",
    "param_grid_ae = {\n",
    "    'units': [32, 64, 128],\n",
    "    'dropout_rate': [0.3,0.4, 0.5],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'l2_reg': [0.001, 0.01, 0.1],\n",
    "    'epochs': [100]\n",
    "}\n",
    "config_combinations = list(itertools.product(*param_grid_ae.values()))\n",
    "param_grid_keys = list(param_grid_ae.keys())\n",
    "\n",
    "# Initialize summary\n",
    "results_summary = []\n",
    "\n",
    "# Function to build Bidirectional LSTM model\n",
    "def build_bidirectional_lstm(input_shape, num_classes, units, dropout_rate, l2_reg=None):\n",
    "    reg = l2(l2_reg) if l2_reg else None\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), input_shape=input_shape),\n",
    "        Bidirectional(LSTM(units // 2, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)),\n",
    "        Dense(units // 4, activation='relu', kernel_regularizer=reg),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Loop through all datasets\n",
    "for i in range(num_files):\n",
    "    file_path = f\"{directory}{file_prefix}{i}{file_suffix}\"\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Load and preprocess dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "    features = data.drop(columns=['timestamp', 'node_name', 'pod_status_Running', 'pod_status_Pending', \n",
    "                                   'pod_status_Succeeded', 'pod_status_Failed', 'pod_status_Unknown'])\n",
    "    targets = data[['pod_status_Running', 'pod_status_Pending', 'pod_status_Succeeded', \n",
    "                    'pod_status_Failed', 'pod_status_Unknown']].idxmax(axis=1).astype('category').cat.codes\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42, stratify=targets)\n",
    "    \n",
    "    # Normalize the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Reshape inputs for LSTM\n",
    "    X_train_lstm = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "    X_test_lstm = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "    \n",
    "    input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    best_model = None\n",
    "    best_config = None\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    for config in config_combinations:\n",
    "        config_dict = dict(zip(param_grid_keys, config))\n",
    "        print(f\"Node {i} - Training with config: {config_dict}\")\n",
    "        \n",
    "        # Build and compile model\n",
    "        model = build_bidirectional_lstm(input_shape, num_classes, units=config_dict['units'], \n",
    "                                         dropout_rate=config_dict['dropout_rate'], l2_reg=config_dict['l2_reg'])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config_dict['learning_rate']),\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        # Early stopping and learning rate scheduler\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train_lstm, y_train,\n",
    "            epochs=config_dict['epochs'],\n",
    "            batch_size=config_dict['batch_size'],\n",
    "            validation_data=(X_test_lstm, y_test),\n",
    "            callbacks=[early_stopping, lr_scheduler],\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        val_accuracy = max(history.history['val_accuracy'])\n",
    "        \n",
    "        # If better, save the model and configuration\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = model\n",
    "            best_config = config_dict\n",
    "    \n",
    "    print(f\"Node {i} - Best Configuration: {best_config}\")\n",
    "    print(f\"Node {i} - Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save the best model for this dataset\n",
    "    model_path = f\"/Users/zxgan/FYP_Kubernetes/LSTM_Model/LSTM_Model_Node_{i}.h5\"\n",
    "    best_model.save(model_path)\n",
    "    print(f\"Best model saved for Node {i} at: {model_path}\")\n",
    "    \n",
    "    # Add results to the summary\n",
    "    results_summary.append({\n",
    "        \"Node\": f\"Node_{i}\",\n",
    "        \"Best Config\": str(best_config),\n",
    "        \"Best Validation Accuracy\": best_val_accuracy\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "\n",
    "# Save results to a CSV\n",
    "summary_path = f\"{directory}lstm_accuracy_summary.csv\"\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "print(f\"Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
